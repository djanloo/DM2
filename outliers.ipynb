{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T14:21:52.078474Z",
     "start_time": "2023-05-24T14:21:51.967182Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import os\n",
    "from pandas.core.dtypes.common import is_numeric_dtype\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'dataset'\n",
    "DATASET = os.path.join(DATA_FOLDER, 'preprocessed_df.csv')\n",
    "LABELLED_OUTLIERS = os.path.join(DATA_FOLDER, 'outliers_labelled.csv')\n",
    "OUTLIERS_REMOVED = os.path.join(DATA_FOLDER, 'outliers_removed.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET)\n",
    "\n",
    "numerical_attr_list = [col for col in df.columns if is_numeric_dtype(df[col])]\n",
    "categorical_attr_list = [col for col in df.columns if not is_numeric_dtype(df[col])]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preliminary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Redefine some stuff of used OD classes\n",
    "# to obtain code continuity\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from pyod.models.abod import ABOD\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "class MyLOF(LocalOutlierFactor):\n",
    "    name = 'LOF'\n",
    "\n",
    "    @property\n",
    "    def scores(self): return self.negative_outlier_factor_\n",
    "\n",
    "class MyABOD(ABOD):\n",
    "    name = 'ABOD'\n",
    "\n",
    "    @property\n",
    "    def scores(self): return self.decision_scores_\n",
    "\n",
    "class MyISFO(IsolationForest):\n",
    "    name = 'ISFO'\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        self._train_samp = X\n",
    "        return super().fit(X)\n",
    "    \n",
    "    @property\n",
    "    def scores(self): return self.score_samples(self._train_samp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each method finds the top `p%` outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = 0.02\n",
    "\n",
    "methods = [MyLOF, MyABOD, MyISFO]\n",
    "params = [dict(n_jobs=-1), dict(), dict(n_jobs=-1, n_estimators=100)] # Parameters of the estimators\n",
    "params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The sub-samples in which the dataset is divided\n",
    "# Currently the OD is performed on each element of (vocal_channel, sex) product category\n",
    "locality_areas = []\n",
    "for vc in ['song', 'speech']:\n",
    "    for s in ['M','F']:\n",
    "        locality_areas.append(dict(vocal_channel=vc, sex=s))\n",
    "\n",
    "locality_areas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for loop on each combination of outliers classifier and parameters\n",
    "for meth, pars in zip(methods, params):\n",
    "\n",
    "    # Initializes each record not to be an outlier\n",
    "    df[f'is_{meth.name}_outlier'] = False\n",
    "\n",
    "    for locality in locality_areas:\n",
    "\n",
    "        # locality_mask: row i == True iff the corresponding row in the dataset matches\n",
    "        # the dictionary values under consideration (i.e., the values of sex and vc)\n",
    "        locality_mask = np.array([(df[key] == val) for key, val in locality.items()]).all(axis=0)\n",
    "\n",
    "        # np.sum(locality_mask) -> number of rows that belong to the same category\n",
    "        #                          (again, 4 categories grouped by sex and vc)\n",
    "        #\n",
    "        # N_p -> number of outliers to be detected for the category (p = 0.02 -> always 2%)\n",
    "        N_p = int(p * np.sum(locality_mask))\n",
    "        print(f'{meth.name}: Taking {N_p} outliers for locality {list(locality.keys())} = {list(locality.values())}',\n",
    "              end='')\n",
    "\n",
    "        # subsamp -> numeric columns of the dataset objects that belong to the category under consideration\n",
    "        subsamp = df[numerical_attr_list][locality_mask].values\n",
    "        subsamp = MinMaxScaler().fit_transform(subsamp)\n",
    "\n",
    "        # get an instance of the estimator (meth) passing the parameters (pars) as arguments\n",
    "        outlier_detector = meth(**pars)\n",
    "        outlier_detector.fit(subsamp)\n",
    "\n",
    "        # save scores into the dataframe\n",
    "        df.loc[locality_mask, f'{meth.name}_score'] = outlier_detector.scores\n",
    "\n",
    "        # takes the indexes of the worsts\n",
    "        bad_kids = df.loc[locality_mask, f'{meth.name}_score'].nsmallest(N_p).index\n",
    "        print(f' --> {bad_kids.values}')\n",
    "\n",
    "        # set them to be outliers\n",
    "        df.loc[bad_kids, f'is_{meth.name}_outlier'] = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# assigns a different color based on whether it is an outlier or not, and the method by which it was detected\n",
    "df['outlier_color'] = 'k'\n",
    "code_map = dict(not_outlier='k', ABOD='g', LOF='r', ISFO='b')\n",
    "for meth in methods:\n",
    "    df.loc[df[f'is_{meth.name}_outlier'], 'outlier_color'] = code_map[meth.name]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now check whether the outliers have a predominant category"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_polar_closed(items, r, ax, **kwargs):\n",
    "    items = list(items)\n",
    "    asort = np.argsort(items)\n",
    "\n",
    "    items = np.array(items)[asort]\n",
    "    r = np.array(list(r))[asort]\n",
    "\n",
    "    theta = np.linspace(0, 6.28, len(items), endpoint=False)\n",
    "\n",
    "    theta = np.append(theta, theta[0])\n",
    "    r = np.append(r, r[0])\n",
    "    fill_kwargs = kwargs.copy()\n",
    "    fill_kwargs['alpha'] = 0.6,\n",
    "    fill_kwargs['label'] = ''\n",
    "\n",
    "    ax.fill_between(theta,0*r, r, **fill_kwargs)\n",
    "    ax.plot(theta, r, **kwargs)\n",
    "\n",
    "    ax.set_xticks(theta[:-1], items)\n",
    "    ax.set_rticks([])\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,8), subplot_kw={'projection': 'polar'})\n",
    "for i, cat in enumerate(['emotion', 'actor']):\n",
    "    cat_vals, cat_counts = np.unique(df[cat], return_counts=True)\n",
    "    if cat =='actor':\n",
    "        cat_vals = [int(act_name.split('_')[1]) for act_name in cat_vals]\n",
    "    cat_counts = cat_counts/np.sum(cat_counts)\n",
    "\n",
    "    for meth in methods:\n",
    "        outlying_items, counts_num = np.unique(df.loc[df[f'is_{ meth.name}_outlier'], cat], return_counts=True)\n",
    "        counts_num = counts_num/np.sum(counts_num)\n",
    "        if cat == 'actor':\n",
    "            outlying_items = [int(act_name.split('_')[1]) for act_name in outlying_items]\n",
    "\n",
    "        counts = {c:0 for c in np.unique(cat_vals)}\n",
    "        for outlying_item, out_count, cc in zip(outlying_items, counts_num, cat_counts):\n",
    "            # Normalize on category count\n",
    "            # e.g.: More values of fear --> more outliers of fear\n",
    "            counts[outlying_item] = out_count/cc\n",
    "\n",
    "        plot_polar_closed(counts.keys(), counts.values(), axes[i], label=meth.name, color=code_map[meth.name])\n",
    "\n",
    "axes[i].legend()\n",
    "axes[0].set_title('emotion')\n",
    "axes[1].set_title('actor');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "binary_categories = ['emotional_intensity',  'statement', 'repetition', 'sex', 'vocal_channel',]\n",
    "fig, axes = plt.subplots(1, len(binary_categories), figsize=(10, 4), sharey=True)\n",
    "for cat, ax in zip(binary_categories, axes):\n",
    "    small_df = pd.DataFrame()\n",
    "    for meth in methods:\n",
    "        o_values, o_counts = np.unique(df.loc[df[f'is_{meth.name}_outlier'], cat], return_counts = True)\n",
    "        a_values, a_counts = np.unique(df[cat], return_counts = True)\n",
    "        small_df = pd.concat([small_df, pd.DataFrame(dict(  method=[meth.name]*len(a_values), \n",
    "                                                            cat=cat,\n",
    "                                                            rel_counts=o_counts/a_counts,\n",
    "                                                            attr=a_values))])\n",
    "        \n",
    "    obj = sns.barplot(data=small_df,  x='method', y='rel_counts', ax=ax, hue='attr', alpha=0.8)\n",
    "    ax.legend([], [], frameon=False)\n",
    "    ax.set_title(cat)\n",
    "    ax.set_ylabel('')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check into an embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "from umap import UMAP\n",
    "reducer = UMAP(n_components=2, n_neighbors=100)\n",
    "embedding = reducer.fit_transform(MinMaxScaler().fit_transform(df[numerical_attr_list]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(*embedding.T, color=\"k\", s=5)\n",
    "plt.scatter(*(embedding[df.outlier_color != \"k\"]).T, c=df.outlier_color[df.outlier_color != \"k\"], alpha=0.6, s=50)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "leg_handles, leg_lab = [], []\n",
    "for k,v in code_map.items():\n",
    "    leg_handles.append(Patch(color=v))\n",
    "    leg_lab.append(k)\n",
    "plt.legend(leg_handles, leg_lab);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TEST: Outliers on embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "n_comp = 2\n",
    "reduced_columns = [f'fake_attr{i}' for i in range(n_comp)]\n",
    "\n",
    "reducer = PCA(n_components=n_comp)\n",
    "X = reducer.fit_transform(MinMaxScaler().fit_transform(df[numerical_attr_list]))\n",
    "\n",
    "df_reduced = pd.DataFrame(list(X), columns=reduced_columns)\n",
    "df_reduced = df_reduced.join(df[categorical_attr_list])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = 0.01\n",
    "\n",
    "methods = [MyLOF, MyABOD, MyISFO]\n",
    "params = [dict(n_jobs=-1),# LOF\n",
    "          dict(method='fast', n_neighbors=15, contamination=p),# ABOD\n",
    "          dict(n_jobs=-1, n_estimators=200)# ISFO\n",
    "          ] # Parameters of the estimators\n",
    "\n",
    "for meth, pars in zip(methods, params):\n",
    "    # Initializes each record not to be an outlier\n",
    "    df_reduced[f'{meth.name}_score'] = 70\n",
    "    df_reduced[f'is_{meth.name}_outlier'] = False\n",
    "    for locality in locality_areas:\n",
    "        locality_mask = np.array([(df_reduced[key] == val).values for key, val in locality.items()]).all(axis=0)\n",
    "        N_p = int(p*np.sum(locality_mask))\n",
    "        print(f'{meth.name}: Taking {N_p} outliers for locality {list(locality.keys())} = {list(locality.values())}', end='')\n",
    "\n",
    "        subsamp = MinMaxScaler().fit_transform( df_reduced.loc[locality_mask][reduced_columns].values )\n",
    "        outlier_detector = meth(**pars)\n",
    "        outlier_detector.fit(subsamp)\n",
    "        df_reduced.loc[locality_mask, f'{meth.name}_score'] = outlier_detector.scores\n",
    "\n",
    "        # Takes the worsts\n",
    "        bad_kids = df_reduced.loc[locality_mask, f'{meth.name}_score'].nsmallest(N_p).index\n",
    "        print(f' --> {bad_kids.values}')\n",
    "        # Set them to be outliers\n",
    "        df_reduced.loc[bad_kids,f'is_{meth.name}_outlier'] = True\n",
    "        \n",
    "df_reduced['outlier_color'] = 'k'\n",
    "code_map = dict(not_outlier='k', ABOD='g', LOF='r', ISFO='b')\n",
    "for meth in methods:\n",
    "    df_reduced.loc[df_reduced[f'is_{meth.name}_outlier'], 'outlier_color'] = code_map[meth.name]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(10,8), subplot_kw={'projection': 'polar'})\n",
    "for i, cat in enumerate(['emotion', 'actor']):\n",
    "    cat_vals, cat_counts = np.unique(df[cat], return_counts=True)\n",
    "    if cat =='actor':\n",
    "        cat_vals = [int(act_name.split('_')[1]) for act_name in cat_vals]\n",
    "    cat_counts = cat_counts/np.sum(cat_counts)\n",
    "\n",
    "    for meth in methods:\n",
    "        outlying_items, counts_num = np.unique(df.loc[df[f'is_{ meth.name}_outlier'], cat], return_counts=True)\n",
    "        counts_num = counts_num/np.sum(counts_num)\n",
    "        if cat == 'actor':\n",
    "            outlying_items = [int(act_name.split('_')[1]) for act_name in outlying_items]\n",
    "\n",
    "        counts = {c:0 for c in np.unique(cat_vals)}\n",
    "        for outlying_item, out_count, cc in zip(outlying_items, counts_num, cat_counts):\n",
    "            # Normalize on category count\n",
    "            # e.g.: More values of fear --> more outliers of fear\n",
    "            counts[outlying_item] = out_count/cc\n",
    "\n",
    "        plot_polar_closed(counts.keys(), counts.values(), axes[i], label=meth.name, color=code_map[meth.name])\n",
    "\n",
    "axes[i].legend()\n",
    "axes[0].set_title('emotion');\n",
    "axes[1].set_title('actor');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], color='k', s=5)\n",
    "plt.scatter(X[df_reduced.outlier_color != 'k',0], X[df_reduced.outlier_color != 'k',1], c=df_reduced.outlier_color[df_reduced.outlier_color != 'k'], alpha=0.6, s=50)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "leg_handles, leg_lab = [], []\n",
    "for k,v in code_map.items():\n",
    "    leg_handles.append(Patch(color=v))\n",
    "    leg_lab.append(k)\n",
    "plt.legend(leg_handles, leg_lab);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TEST 2: OD Aggregation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bag = df.copy()\n",
    "print(len(df_bag))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Redefine some stuff of used OD classes\n",
    "# to obtain code continuity\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from pyod.models.abod import ABOD\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class AggregatedOD(object):\n",
    "    name = 'aggregatedOD'\n",
    "    def __init__(self, coefficient_vector=None, **pars):\n",
    "        self.methods = []\n",
    "        if coefficient_vector is None:\n",
    "            coefficient_vector = np.ones(3)/3\n",
    "        else:\n",
    "            self.coefficient_vector = np.array(coefficient_vector)/np.sum(coefficient_vector)\n",
    "\n",
    "        for od_meth in [MyISFO, MyABOD, MyLOF]:\n",
    "            self.methods.append(od_meth(** (pars.get(od_meth.name, dict() ))))\n",
    "\n",
    "    def fit(self, X):\n",
    "        for od_meth in self.methods:\n",
    "            od_meth.fit(X)\n",
    "\n",
    "    @property\n",
    "    def scores(self):\n",
    "        self.single_scores = [MinMaxScaler().fit_transform(od_meth.scores.reshape(-1,1)).reshape(-1) for od_meth in self.methods]\n",
    "        self.single_scores = np.array(self.single_scores)\n",
    "        return self.coefficient_vector[None, :].dot(self.single_scores).reshape(-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = 0.01\n",
    "\n",
    "params = dict(ISFO=dict(n_jobs=-1, n_estimators=100),\n",
    "              ABOD=dict(),\n",
    "              LOF=dict(n_jobs=-1), ) # Parameters of the estimators\n",
    "\n",
    "meth = AggregatedOD\n",
    "outlier_detector = meth(coefficient_vector=[0.3, 1,1], \n",
    "                        **params)\n",
    "\n",
    "# Initializes each record not to be an outlier\n",
    "df_bag[f'is_{meth.name}_outlier'] = False\n",
    "df_bag[f'{meth.name}_score'] = 70\n",
    "\n",
    "for locality in locality_areas:\n",
    "    locality_mask = np.array([(df_bag[key] == val).values for key, val in locality.items()]).all(axis=0)\n",
    "    N_p = int(p*np.sum(locality_mask))\n",
    "    print(f'{meth.name}: Taking {N_p} outliers for locality {list(locality.keys())} = {list(locality.values())}', end='')\n",
    "\n",
    "    subsamp = MinMaxScaler().fit_transform( df_bag.loc[locality_mask][numerical_attr_list].values )\n",
    "    outlier_detector.fit(subsamp)\n",
    "    df_bag.loc[locality_mask, f'{meth.name}_score'] = outlier_detector.scores\n",
    "    for m,s in zip(outlier_detector.methods, outlier_detector.single_scores):\n",
    "        df_bag.loc[locality_mask, f'{m.name}_score'] = s\n",
    "\n",
    "\n",
    "    # Takes the worsts\n",
    "    bad_kids = df_bag.loc[locality_mask, f'{meth.name}_score'].nsmallest(N_p).index\n",
    "    print(f' --> {bad_kids.values}')\n",
    "    # Set them to be outliers\n",
    "    df_bag.loc[bad_kids,f'is_{meth.name}_outlier'] = True\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in [u for u in df_bag.columns if u.endswith(\"score\")]:\n",
    "    plt.hist(df_bag[col], bins=50, alpha=0.5, label=col);\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(df_bag[\"ABOD_score\"], df_bag[\"LOF_score\"],label=\"ABOD vs LOF\", s=3, alpha=0.6)\n",
    "plt.scatter(df_bag[\"ABOD_score\"], df_bag[\"ISFO_score\"],label=\"ABOD vs ISFO\", s=3, alpha=0.6)\n",
    "plt.scatter(df_bag[\"LOF_score\"], df_bag[\"ISFO_score\"],label=\"LOF vs ISFO\", s=3, alpha=0.6)\n",
    "\n",
    "plt.plot(np.linspace(0,1), np.linspace(0,1), ls=\":\", color=\"k\", label=\"perfect accordance\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reducer = Isomap(n_components=2, n_neighbors=15)\n",
    "X = reducer.fit_transform(df_bag[numerical_attr_list])\n",
    "plt.scatter(X[:,0], X[:,1], c=df_bag.aggregatedOD_score, cmap=\"viridis\", s=10)\n",
    "mask = df_bag[\"is_aggregatedOD_outlier\"]\n",
    "plt.scatter(X[mask, 0], X[mask, 1], color=\"r\", marker=\"x\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "code_map = dict(not_outlier=\"k\", ABOD=\"g\", LOF=\"r\", ISFO=\"b\", aggregatedOD=\"k\")\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,8), subplot_kw={'projection': 'polar'})\n",
    "for i, cat in enumerate([\"emotion\", \"actor\"]):\n",
    "    cat_vals, cat_counts = np.unique(df_bag[cat], return_counts=True)\n",
    "    if cat ==\"actor\":\n",
    "        cat_vals = [int(act_name.split(\"_\")[1]) for act_name in cat_vals]\n",
    "    cat_counts = cat_counts/np.sum(cat_counts)\n",
    "\n",
    "    for meth in outlier_detector.methods+[outlier_detector]:\n",
    "        outlying_items, counts_num = np.unique(df_bag.loc[df_bag[f\"is_{ meth.name}_outlier\"], cat], return_counts=True)\n",
    "        counts_num = counts_num/np.sum(counts_num)\n",
    "        if cat == \"actor\":\n",
    "            outlying_items = [int(act_name.split(\"_\")[1]) for act_name in outlying_items]\n",
    "\n",
    "        counts = {c:0 for c in np.unique(cat_vals)}\n",
    "        for outlying_item, out_count, cc in zip(outlying_items, counts_num, cat_counts):\n",
    "            # Normalize on category count\n",
    "            # e.g.: More values of fear --> more outliers of fear\n",
    "            counts[outlying_item] = out_count/cc\n",
    "\n",
    "        plot_polar_closed(counts.keys(), counts.values(), axes[i], label=meth.name, color=code_map[meth.name])\n",
    "\n",
    "axes[i].legend()\n",
    "axes[0].set_title(\"emotion\");\n",
    "axes[1].set_title(\"actor\");"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bag = df_bag.reset_index(drop=True)\n",
    "df_bag.to_csv(LABELLED_OUTLIERS, index=False)\n",
    "\n",
    "# Reove outliers\n",
    "df_outliers_removed = df_bag.loc[np.logical_not(df_bag.is_aggregatedOD_outlier)]\n",
    "df_outliers_removed.to_csv(OUTLIERS_REMOVED, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T14:22:07.997909Z",
     "start_time": "2023-05-24T14:22:07.995177Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2-PeqFRmfa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:59:22.972829Z",
     "start_time": "2023-06-29T13:59:22.970452Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "import default_style\n",
    "\n",
    "TS_DATASET_FOLDER = os.path.join('..', 'dataset')\n",
    "TS_PREPROC_FOLDER = os.path.join(TS_DATASET_FOLDER, 'preprocessed_traces')\n",
    "DF_PREPROC_FILE = os.path.join(TS_PREPROC_FOLDER, 'preproc_ts.df')\n",
    "\n",
    "TARGET = 'statement'\n",
    "TRACES = 'syllables_02_STFT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "  vocal_channel  emotion emotional_intensity statement repetition     actor   \n0        speech  neutral              normal      kids        1st  actor_01  \\\n1        speech  neutral              normal      kids        2nd  actor_01   \n2        speech  neutral              normal      dogs        1st  actor_01   \n3        speech  neutral              normal      dogs        2nd  actor_01   \n4        speech     calm              normal      kids        1st  actor_01   \n\n                                                path sex   begin_s     end_s   \n0  ../dataset/Audio_Speech_Actors_01-24/Actor_01/...   M  1.009833  2.252000  \\\n1  ../dataset/Audio_Speech_Actors_01-24/Actor_01/...   M  1.068500  2.294667   \n2  ../dataset/Audio_Speech_Actors_01-24/Actor_01/...   M  1.012000  2.238500   \n3  ../dataset/Audio_Speech_Actors_01-24/Actor_01/...   M  1.008833  2.187167   \n4  ../dataset/Audio_Speech_Actors_01-24/Actor_01/...   M  1.023667  2.534167   \n\n                                      fourier_coeffs   \n0  [1.9371510e-07 1.2311488e-02 1.1168750e-02 ......  \\\n1  [3.5017729e-07 2.6199006e-02 2.5683409e-02 ......   \n2  [2.4959445e-07 1.2348385e-02 1.0678725e-02 ......   \n3  [1.1920929e-07 1.2154797e-02 1.6620804e-02 ......   \n4  [1.1920929e-07 2.0026919e-03 7.9689088e-04 ......   \n\n                             filtered_fourier_coeffs  syll_0_start_index   \n0  [1.9371510e-07 1.2311473e-02 1.1168692e-02 ......                   0  \\\n1  [3.5017729e-07 2.6198970e-02 2.5683273e-02 ......                   0   \n2  [2.49594450e-07 1.23483688e-02 1.06786685e-02 ...                   0   \n3  [1.1920929e-07 1.2154780e-02 1.6620707e-02 ......                   0   \n4  [1.1920929e-07 2.0026902e-03 7.9688808e-04 ......                   0   \n\n   syll_1_start_index  syll_2_start_index  syll_3_start_index   \n0                1128                2240                3200  \\\n1                2008                3208                3880   \n2                2816                3352                3912   \n3                1664                2664                3208   \n4                2088                3584                4832   \n\n   syll_4_start_index  syll_5_start_index  syll_6_start_index   \n0                4304                5208                5808  \\\n1                4224                5112                5800   \n2                4296                5232                5880   \n3                3672                4840                5448   \n4                5800                6944                7560   \n\n   syll_7_start_index  \n0                7448  \n1                7352  \n2                7352  \n3                7064  \n4                9056  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>vocal_channel</th>\n      <th>emotion</th>\n      <th>emotional_intensity</th>\n      <th>statement</th>\n      <th>repetition</th>\n      <th>actor</th>\n      <th>path</th>\n      <th>sex</th>\n      <th>begin_s</th>\n      <th>end_s</th>\n      <th>fourier_coeffs</th>\n      <th>filtered_fourier_coeffs</th>\n      <th>syll_0_start_index</th>\n      <th>syll_1_start_index</th>\n      <th>syll_2_start_index</th>\n      <th>syll_3_start_index</th>\n      <th>syll_4_start_index</th>\n      <th>syll_5_start_index</th>\n      <th>syll_6_start_index</th>\n      <th>syll_7_start_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>speech</td>\n      <td>neutral</td>\n      <td>normal</td>\n      <td>kids</td>\n      <td>1st</td>\n      <td>actor_01</td>\n      <td>../dataset/Audio_Speech_Actors_01-24/Actor_01/...</td>\n      <td>M</td>\n      <td>1.009833</td>\n      <td>2.252000</td>\n      <td>[1.9371510e-07 1.2311488e-02 1.1168750e-02 ......</td>\n      <td>[1.9371510e-07 1.2311473e-02 1.1168692e-02 ......</td>\n      <td>0</td>\n      <td>1128</td>\n      <td>2240</td>\n      <td>3200</td>\n      <td>4304</td>\n      <td>5208</td>\n      <td>5808</td>\n      <td>7448</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>speech</td>\n      <td>neutral</td>\n      <td>normal</td>\n      <td>kids</td>\n      <td>2nd</td>\n      <td>actor_01</td>\n      <td>../dataset/Audio_Speech_Actors_01-24/Actor_01/...</td>\n      <td>M</td>\n      <td>1.068500</td>\n      <td>2.294667</td>\n      <td>[3.5017729e-07 2.6199006e-02 2.5683409e-02 ......</td>\n      <td>[3.5017729e-07 2.6198970e-02 2.5683273e-02 ......</td>\n      <td>0</td>\n      <td>2008</td>\n      <td>3208</td>\n      <td>3880</td>\n      <td>4224</td>\n      <td>5112</td>\n      <td>5800</td>\n      <td>7352</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>speech</td>\n      <td>neutral</td>\n      <td>normal</td>\n      <td>dogs</td>\n      <td>1st</td>\n      <td>actor_01</td>\n      <td>../dataset/Audio_Speech_Actors_01-24/Actor_01/...</td>\n      <td>M</td>\n      <td>1.012000</td>\n      <td>2.238500</td>\n      <td>[2.4959445e-07 1.2348385e-02 1.0678725e-02 ......</td>\n      <td>[2.49594450e-07 1.23483688e-02 1.06786685e-02 ...</td>\n      <td>0</td>\n      <td>2816</td>\n      <td>3352</td>\n      <td>3912</td>\n      <td>4296</td>\n      <td>5232</td>\n      <td>5880</td>\n      <td>7352</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>speech</td>\n      <td>neutral</td>\n      <td>normal</td>\n      <td>dogs</td>\n      <td>2nd</td>\n      <td>actor_01</td>\n      <td>../dataset/Audio_Speech_Actors_01-24/Actor_01/...</td>\n      <td>M</td>\n      <td>1.008833</td>\n      <td>2.187167</td>\n      <td>[1.1920929e-07 1.2154797e-02 1.6620804e-02 ......</td>\n      <td>[1.1920929e-07 1.2154780e-02 1.6620707e-02 ......</td>\n      <td>0</td>\n      <td>1664</td>\n      <td>2664</td>\n      <td>3208</td>\n      <td>3672</td>\n      <td>4840</td>\n      <td>5448</td>\n      <td>7064</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>speech</td>\n      <td>calm</td>\n      <td>normal</td>\n      <td>kids</td>\n      <td>1st</td>\n      <td>actor_01</td>\n      <td>../dataset/Audio_Speech_Actors_01-24/Actor_01/...</td>\n      <td>M</td>\n      <td>1.023667</td>\n      <td>2.534167</td>\n      <td>[1.1920929e-07 2.0026919e-03 7.9689088e-04 ......</td>\n      <td>[1.1920929e-07 2.0026902e-03 7.9688808e-04 ......</td>\n      <td>0</td>\n      <td>2088</td>\n      <td>3584</td>\n      <td>4832</td>\n      <td>5800</td>\n      <td>6944</td>\n      <td>7560</td>\n      <td>9056</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DF_PREPROC_FILE).drop(columns=['Unnamed: 0'])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:59:22.994859Z",
     "start_time": "2023-06-29T13:59:22.975462Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(2452, 27, 27)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(TS_PREPROC_FOLDER, f'{TRACES}.npy')\n",
    "traces = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "traces.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:59:23.039865Z",
     "start_time": "2023-06-29T13:59:22.995952Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RGB format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# array of empty RGB matrixes\n",
    "rgb_traces = np.zeros((len(traces), traces.shape[1], traces.shape[2], 3), dtype=np.float32)\n",
    "\n",
    "for i in range(len(traces)):\n",
    "    trace = traces[i]\n",
    "\n",
    "    min_value = np.min(trace)\n",
    "    max_value = np.max(trace)\n",
    "    normalized_trace = (trace - min_value) / (max_value - min_value)\n",
    "\n",
    "    red_channel = normalized_trace\n",
    "    green_channel = np.zeros_like(normalized_trace)\n",
    "    blue_channel = np.zeros_like(normalized_trace)\n",
    "\n",
    "    rgb_trace = np.dstack((red_channel, green_channel, blue_channel))\n",
    "    rgb_traces[i] = rgb_trace\n",
    "\n",
    "\n",
    "display(rgb_traces.shape)\n",
    "\n",
    "\"\"\"\n",
    "from PIL import Image\n",
    "\n",
    "rgb_traces = []\n",
    "\n",
    "for i in range(len(traces)):\n",
    "    trace = traces[i]\n",
    "\n",
    "    min_value = np.min(trace)\n",
    "    max_value = np.max(trace)\n",
    "    normalized_trace = (trace - min_value) / (max_value - min_value)\n",
    "\n",
    "    normalized_trace = (normalized_trace * 255).astype(np.uint8)\n",
    "\n",
    "    rgb_trace = Image.fromarray(normalized_trace, mode='L').convert('RGB')\n",
    "\n",
    "    rgb_traces.append(rgb_trace)\n",
    "\n",
    "\n",
    "rgb_traces = np.array([np.array(trace) for trace in rgb_traces])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:59:23.101650Z",
     "start_time": "2023-06-29T13:59:23.005976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 354.331x236.22 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(rgb_traces[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:59:23.150839Z",
     "start_time": "2023-06-29T13:59:23.101080Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training, Validation and Test Sets Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[[132, 132, 132],\n         [134, 134, 134],\n         [139, 139, 139],\n         ...,\n         [107, 107, 107],\n         [ 92,  92,  92],\n         [ 84,  84,  84]],\n\n        [[124, 124, 124],\n         [151, 151, 151],\n         [154, 154, 154],\n         ...,\n         [ 84,  84,  84],\n         [ 69,  69,  69],\n         [ 74,  74,  74]],\n\n        [[ 99,  99,  99],\n         [137, 137, 137],\n         [130, 130, 130],\n         ...,\n         [ 86,  86,  86],\n         [107, 107, 107],\n         [ 87,  87,  87]],\n\n        ...,\n\n        [[ 77,  77,  77],\n         [194, 194, 194],\n         [192, 192, 192],\n         ...,\n         [ 47,  47,  47],\n         [ 54,  54,  54],\n         [ 56,  56,  56]],\n\n        [[127, 127, 127],\n         [162, 162, 162],\n         [173, 173, 173],\n         ...,\n         [ 63,  63,  63],\n         [ 67,  67,  67],\n         [ 66,  66,  66]],\n\n        [[158, 158, 158],\n         [180, 180, 180],\n         [169, 169, 169],\n         ...,\n         [ 88,  88,  88],\n         [ 82,  82,  82],\n         [ 76,  76,  76]]],\n\n\n       [[[105, 105, 105],\n         [192, 192, 192],\n         [240, 240, 240],\n         ...,\n         [ 98,  98,  98],\n         [ 71,  71,  71],\n         [115, 115, 115]],\n\n        [[110, 110, 110],\n         [194, 194, 194],\n         [243, 243, 243],\n         ...,\n         [129, 129, 129],\n         [123, 123, 123],\n         [124, 124, 124]],\n\n        [[111, 111, 111],\n         [192, 192, 192],\n         [243, 243, 243],\n         ...,\n         [133, 133, 133],\n         [100, 100, 100],\n         [138, 138, 138]],\n\n        ...,\n\n        [[ 78,  78,  78],\n         [193, 193, 193],\n         [222, 222, 222],\n         ...,\n         [101, 101, 101],\n         [ 58,  58,  58],\n         [109, 109, 109]],\n\n        [[ 99,  99,  99],\n         [191, 191, 191],\n         [213, 213, 213],\n         ...,\n         [ 99,  99,  99],\n         [ 95,  95,  95],\n         [ 90,  90,  90]],\n\n        [[ 99,  99,  99],\n         [192, 192, 192],\n         [213, 213, 213],\n         ...,\n         [ 76,  76,  76],\n         [ 91,  91,  91],\n         [ 91,  91,  91]]],\n\n\n       [[[146, 146, 146],\n         [213, 213, 213],\n         [198, 198, 198],\n         ...,\n         [ 72,  72,  72],\n         [ 83,  83,  83],\n         [ 46,  46,  46]],\n\n        [[140, 140, 140],\n         [227, 227, 227],\n         [217, 217, 217],\n         ...,\n         [122, 122, 122],\n         [101, 101, 101],\n         [ 86,  86,  86]],\n\n        [[146, 146, 146],\n         [226, 226, 226],\n         [217, 217, 217],\n         ...,\n         [125, 125, 125],\n         [156, 156, 156],\n         [127, 127, 127]],\n\n        ...,\n\n        [[154, 154, 154],\n         [243, 243, 243],\n         [251, 251, 251],\n         ...,\n         [145, 145, 145],\n         [124, 124, 124],\n         [123, 123, 123]],\n\n        [[165, 165, 165],\n         [237, 237, 237],\n         [242, 242, 242],\n         ...,\n         [ 69,  69,  69],\n         [ 87,  87,  87],\n         [ 39,  39,  39]],\n\n        [[175, 175, 175],\n         [225, 225, 225],\n         [244, 244, 244],\n         ...,\n         [ 99,  99,  99],\n         [113, 113, 113],\n         [ 78,  78,  78]]],\n\n\n       ...,\n\n\n       [[[153, 153, 153],\n         [118, 118, 118],\n         [126, 126, 126],\n         ...,\n         [ 82,  82,  82],\n         [101, 101, 101],\n         [ 64,  64,  64]],\n\n        [[145, 145, 145],\n         [130, 130, 130],\n         [132, 132, 132],\n         ...,\n         [114, 114, 114],\n         [114, 114, 114],\n         [113, 113, 113]],\n\n        [[127, 127, 127],\n         [102, 102, 102],\n         [116, 116, 116],\n         ...,\n         [113, 113, 113],\n         [116, 116, 116],\n         [122, 122, 122]],\n\n        ...,\n\n        [[121, 121, 121],\n         [116, 116, 116],\n         [125, 125, 125],\n         ...,\n         [ 87,  87,  87],\n         [ 99,  99,  99],\n         [ 90,  90,  90]],\n\n        [[114, 114, 114],\n         [114, 114, 114],\n         [125, 125, 125],\n         ...,\n         [ 73,  73,  73],\n         [ 97,  97,  97],\n         [ 72,  72,  72]],\n\n        [[119, 119, 119],\n         [ 90,  90,  90],\n         [105, 105, 105],\n         ...,\n         [ 61,  61,  61],\n         [ 69,  69,  69],\n         [ 53,  53,  53]]],\n\n\n       [[[120, 120, 120],\n         [145, 145, 145],\n         [142, 142, 142],\n         ...,\n         [122, 122, 122],\n         [101, 101, 101],\n         [131, 131, 131]],\n\n        [[134, 134, 134],\n         [131, 131, 131],\n         [110, 110, 110],\n         ...,\n         [105, 105, 105],\n         [116, 116, 116],\n         [109, 109, 109]],\n\n        [[134, 134, 134],\n         [126, 126, 126],\n         [148, 148, 148],\n         ...,\n         [133, 133, 133],\n         [106, 106, 106],\n         [ 79,  79,  79]],\n\n        ...,\n\n        [[ 91,  91,  91],\n         [ 77,  77,  77],\n         [ 47,  47,  47],\n         ...,\n         [ 26,  26,  26],\n         [ 31,  31,  31],\n         [  4,   4,   4]],\n\n        [[106, 106, 106],\n         [ 82,  82,  82],\n         [ 74,  74,  74],\n         ...,\n         [ 49,  49,  49],\n         [ 32,  32,  32],\n         [ 19,  19,  19]],\n\n        [[105, 105, 105],\n         [ 92,  92,  92],\n         [ 96,  96,  96],\n         ...,\n         [ 83,  83,  83],\n         [ 33,  33,  33],\n         [ 25,  25,  25]]],\n\n\n       [[[ 55,  55,  55],\n         [127, 127, 127],\n         [100, 100, 100],\n         ...,\n         [116, 116, 116],\n         [110, 110, 110],\n         [102, 102, 102]],\n\n        [[102, 102, 102],\n         [118, 118, 118],\n         [106, 106, 106],\n         ...,\n         [124, 124, 124],\n         [ 93,  93,  93],\n         [137, 137, 137]],\n\n        [[104, 104, 104],\n         [ 51,  51,  51],\n         [ 97,  97,  97],\n         ...,\n         [131, 131, 131],\n         [146, 146, 146],\n         [159, 159, 159]],\n\n        ...,\n\n        [[ 95,  95,  95],\n         [ 84,  84,  84],\n         [103, 103, 103],\n         ...,\n         [ 76,  76,  76],\n         [ 66,  66,  66],\n         [ 74,  74,  74]],\n\n        [[108, 108, 108],\n         [119, 119, 119],\n         [ 95,  95,  95],\n         ...,\n         [ 31,  31,  31],\n         [ 45,  45,  45],\n         [ 75,  75,  75]],\n\n        [[  0,   0,   0],\n         [108, 108, 108],\n         [102, 102, 102],\n         ...,\n         [ 47,  47,  47],\n         [ 64,  64,  64],\n         [ 52,  52,  52]]]], dtype=uint8)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by actors\n",
    "sorted_indices = df['actor'].argsort()\n",
    "df = df.iloc[sorted_indices].reset_index(drop=True)\n",
    "\n",
    "traces = traces[sorted_indices]\n",
    "\n",
    "rgb_traces"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:59:23.160262Z",
     "start_time": "2023-06-29T13:59:23.153406Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "((1462, 27, 27, 3),\n (366, 27, 27, 3),\n (624, 27, 27, 3),\n (1462,),\n (366,),\n (624,))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_index = df[df['actor'] == 'actor_19'].index[0]\n",
    "\n",
    "X_train = rgb_traces[:split_index]\n",
    "X_test = rgb_traces[split_index:]\n",
    "\n",
    "y_train = df[TARGET][:split_index].to_numpy()\n",
    "y_test = df[TARGET][split_index:].to_numpy()\n",
    "\n",
    "X_train_v, X_valid, y_train_v, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=100)\n",
    "\n",
    "X_train_v.shape, X_valid.shape, X_test.shape, y_train_v.shape, y_valid.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:59:23.302048Z",
     "start_time": "2023-06-29T13:59:23.162829Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_train_v = label_encoder.fit_transform(y_train_v)\n",
    "y_valid = label_encoder.transform(y_valid)\n",
    "y_test = label_encoder.transform(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:59:23.306168Z",
     "start_time": "2023-06-29T13:59:23.304598Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from keras.src.layers import Conv2D, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Dense\n",
    "from keras import Sequential\n",
    "\n",
    "\n",
    "def build_model(input_shape, n_categories,\n",
    "                n_conv=0, n_hidden=0, hidden_nodes=32,\n",
    "                dropout=0.01, filters=8, kernel_size=5, **kwargs):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=filters,\n",
    "                     kernel_size=(kernel_size, kernel_size),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape,\n",
    "                     padding='same'\n",
    "                     ))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for _ in range(n_conv):\n",
    "        model.add(Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(Dense(hidden_nodes, activation='relu'))\n",
    "\n",
    "    model.add(Dense(n_categories, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:59:26.435378Z",
     "start_time": "2023-06-29T13:59:23.309204Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-29 15:59:26,594] A new study created in memory with name: no-name-f8e361d7-97fb-40a5-958c-0c0685ee9541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running little bitch having n_conv=1, dropout=0.13348666325984723, hidden_nodes=98\n",
      "12/12 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-29 16:01:54,141] Trial 0 finished with value: 0.5136612021857924 and parameters: {'n_conv': 1, 'n_hidden': 0, 'hidden_nodes': 98, 'dropout': 0.13348666325984723, 'filters': 16, 'kernel_size': 11, 'batch_size': 57, 'epochs': 67}. Best is trial 0 with value: 0.5136612021857924.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    n_conv = trial.suggest_int('n_conv', 0, 3)\n",
    "    n_hidden = trial.suggest_int('n_hidden', 0, 3)\n",
    "    hidden_nodes = trial.suggest_int('hidden_nodes', 8, 256)\n",
    "    dropout = trial.suggest_float('dropout', 0, 0.2)\n",
    "    filters = trial.suggest_int('filters', 2, 16)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 2, 16)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)\n",
    "    epochs = trial.suggest_int('epochs', 5, 90)\n",
    "\n",
    "    print(f\"Running little bitch having n_conv={n_conv}, dropout={dropout}, hidden_nodes={hidden_nodes}\")\n",
    "\n",
    "    cnn = build_model(X_train_v.shape[1:], len(np.unique(y_train_v)),\n",
    "                      n_hidden=n_hidden,\n",
    "                      hidden_nodes=hidden_nodes,\n",
    "                      n_conv=n_conv,\n",
    "                      dropout=dropout,\n",
    "                      filters=filters,\n",
    "                      kernel_size=kernel_size,\n",
    "                      )\n",
    "\n",
    "    cnn.fit(X_train_v, y_train_v, batch_size=batch_size, epochs=epochs, verbose=False)\n",
    "\n",
    "    y_pred = np.argmax(cnn.predict(X_valid), axis=1)\n",
    "\n",
    "    error = accuracy_score(y_valid, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_fun, n_trials=1, n_jobs=-1, catch=ValueError)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T14:01:54.145452Z",
     "start_time": "2023-06-29T13:59:26.438365Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_conv': 1,\n 'n_hidden': 0,\n 'hidden_nodes': 98,\n 'dropout': 0.13348666325984723,\n 'filters': 16,\n 'kernel_size': 11,\n 'batch_size': 57,\n 'epochs': 67}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T14:01:54.150284Z",
     "start_time": "2023-06-29T14:01:54.147537Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 27, 27, 16)        5824      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 27, 27, 16)        64        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 27, 27, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 27, 16)        30992     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 27, 27, 16)        64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 27, 27, 16)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 27, 27, 16)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 16)                0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36978 (144.45 KB)\n",
      "Trainable params: 36914 (144.20 KB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = build_model(X_train.shape[1:], 2, **best_params)\n",
    "cnn.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T14:01:54.308042Z",
     "start_time": "2023-06-29T14:01:54.150559Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/67\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.7000 - accuracy: 0.5295\n",
      "Epoch 2/67\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.6907 - accuracy: 0.5284\n",
      "Epoch 3/67\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 0.6893 - accuracy: 0.5427\n",
      "Epoch 4/67\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.6878 - accuracy: 0.5509\n",
      "Epoch 5/67\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.6865 - accuracy: 0.5525\n",
      "Epoch 6/67\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.6856 - accuracy: 0.5509\n",
      "Epoch 7/67\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.6886 - accuracy: 0.5487\n",
      "Epoch 8/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6859 - accuracy: 0.5372\n",
      "Epoch 9/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6857 - accuracy: 0.5509\n",
      "Epoch 10/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6850 - accuracy: 0.5503\n",
      "Epoch 11/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6853 - accuracy: 0.5585\n",
      "Epoch 12/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6830 - accuracy: 0.5509\n",
      "Epoch 13/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6844 - accuracy: 0.5509\n",
      "Epoch 14/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6868 - accuracy: 0.5454\n",
      "Epoch 15/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6830 - accuracy: 0.5618\n",
      "Epoch 16/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6817 - accuracy: 0.5624\n",
      "Epoch 17/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6823 - accuracy: 0.5695\n",
      "Epoch 18/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6818 - accuracy: 0.5695\n",
      "Epoch 19/67\n",
      "33/33 [==============================] - 3s 95ms/step - loss: 0.6806 - accuracy: 0.5678\n",
      "Epoch 20/67\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.6807 - accuracy: 0.5771\n",
      "Epoch 21/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6788 - accuracy: 0.5728\n",
      "Epoch 22/67\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 0.6804 - accuracy: 0.5695\n",
      "Epoch 23/67\n",
      "33/33 [==============================] - 3s 93ms/step - loss: 0.6791 - accuracy: 0.5706\n",
      "Epoch 24/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6799 - accuracy: 0.5760\n",
      "Epoch 25/67\n",
      "33/33 [==============================] - 3s 93ms/step - loss: 0.6759 - accuracy: 0.5711\n",
      "Epoch 26/67\n",
      "33/33 [==============================] - 3s 93ms/step - loss: 0.6778 - accuracy: 0.5826\n",
      "Epoch 27/67\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.6746 - accuracy: 0.5782\n",
      "Epoch 28/67\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.6733 - accuracy: 0.5832\n",
      "Epoch 29/67\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.6745 - accuracy: 0.5832\n",
      "Epoch 30/67\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.6760 - accuracy: 0.5596\n",
      "Epoch 31/67\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.6712 - accuracy: 0.5881\n",
      "Epoch 32/67\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.6733 - accuracy: 0.5897\n",
      "Epoch 33/67\n",
      "33/33 [==============================] - 3s 95ms/step - loss: 0.6734 - accuracy: 0.5760\n",
      "Epoch 34/67\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.6680 - accuracy: 0.5886\n",
      "Epoch 35/67\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.6688 - accuracy: 0.5908\n",
      "Epoch 36/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6693 - accuracy: 0.5941\n",
      "Epoch 37/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6682 - accuracy: 0.5979\n",
      "Epoch 38/67\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.6619 - accuracy: 0.6105\n",
      "Epoch 39/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6601 - accuracy: 0.6039\n",
      "Epoch 40/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6577 - accuracy: 0.6089\n",
      "Epoch 41/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6591 - accuracy: 0.6034\n",
      "Epoch 42/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6562 - accuracy: 0.6176\n",
      "Epoch 43/67\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.6519 - accuracy: 0.6214\n",
      "Epoch 44/67\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.6522 - accuracy: 0.6143\n",
      "Epoch 45/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6499 - accuracy: 0.6171\n",
      "Epoch 46/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6450 - accuracy: 0.6187\n",
      "Epoch 47/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6416 - accuracy: 0.6214\n",
      "Epoch 48/67\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 0.6463 - accuracy: 0.6214\n",
      "Epoch 49/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6385 - accuracy: 0.6236\n",
      "Epoch 50/67\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.6337 - accuracy: 0.6395\n",
      "Epoch 51/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6303 - accuracy: 0.6488\n",
      "Epoch 52/67\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.6292 - accuracy: 0.6389\n",
      "Epoch 53/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6216 - accuracy: 0.6515\n",
      "Epoch 54/67\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.6249 - accuracy: 0.6444\n",
      "Epoch 55/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6128 - accuracy: 0.6674\n",
      "Epoch 56/67\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.6107 - accuracy: 0.6652\n",
      "Epoch 57/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.6059 - accuracy: 0.6668\n",
      "Epoch 58/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.5975 - accuracy: 0.6854\n",
      "Epoch 59/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.5968 - accuracy: 0.6734\n",
      "Epoch 60/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.5887 - accuracy: 0.7057\n",
      "Epoch 61/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.5896 - accuracy: 0.6876\n",
      "Epoch 62/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.5853 - accuracy: 0.6964\n",
      "Epoch 63/67\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 0.5802 - accuracy: 0.7040\n",
      "Epoch 64/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.5762 - accuracy: 0.7030\n",
      "Epoch 65/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.5605 - accuracy: 0.7221\n",
      "Epoch 66/67\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.5710 - accuracy: 0.7019\n",
      "Epoch 67/67\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.5535 - accuracy: 0.7248\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x28ea64730>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T14:05:15.316187Z",
     "start_time": "2023-06-29T14:01:54.306904Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 14ms/step\n",
      "Cohen k 0.0064102564102563875\n",
      "Accuracy 0.5032051282051282\n",
      "F1-score [0.38      0.5855615]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.30      0.38       312\n",
      "           1       0.50      0.70      0.59       312\n",
      "\n",
      "    accuracy                           0.50       624\n",
      "   macro avg       0.50      0.50      0.48       624\n",
      "weighted avg       0.50      0.50      0.48       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, cohen_kappa_score\n",
    "\n",
    "predictions = cnn.predict(X_test)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(f'Cohen k {cohen_kappa_score(y_test, y_pred)}')\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T14:05:15.665893Z",
     "start_time": "2023-06-29T14:05:15.312047Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LIME"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d267219e4fa0431fb2d2ace8f7b6ecaa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(X_test[0], cnn.predict, top_labels=2)\n",
    "\n",
    "image, mask = explanation.get_image_and_mask(0, hide_rest=True)\n",
    "marked_image = mark_boundaries(image, mask)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T14:05:18.607235Z",
     "start_time": "2023-06-29T14:05:15.664670Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 354.331x236.22 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_test[0], cmap='gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(marked_image / 255)\n",
    "plt.title('LIME Explanation')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T14:05:18.912540Z",
     "start_time": "2023-06-29T14:05:18.612861Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

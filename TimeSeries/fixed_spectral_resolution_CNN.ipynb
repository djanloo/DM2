{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e834b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import default_style\n",
    "\n",
    "TS_DATASET_FOLDER = os.path.join(\"..\", \"dataset\")\n",
    "TS_PREPROC_FOLDER = os.path.join(TS_DATASET_FOLDER, \"preprocessed_traces\")\n",
    "DF_PREPROC_FILE = os.path.join(TS_PREPROC_FOLDER, \"preproc_ts.df\")\n",
    "\n",
    "INTERESTING_TRACES = [\"clean_trace\"]\n",
    "\n",
    "\n",
    "df = pd.read_csv(DF_PREPROC_FILE)\n",
    "traces = dict()\n",
    "for t in INTERESTING_TRACES:\n",
    "    traces[t] = np.load(os.path.join(TS_PREPROC_FOLDER, f\"{t}.npy\"), allow_pickle=True)\n",
    "\n",
    "# traces[\"syll_labels\"] = np.repeat(np.arange(7), len(traces[\"syllables_fourier\"])//7)\n",
    "# print(traces[\"syll_labels\"].shape)\n",
    "\n",
    "SAMPLING_RATE = 48_000/8\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6d6916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2452/2452 [00:08<00:00, 277.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from djanloo_fourier import FixedResolutionSTFTransformer\n",
    "\n",
    "fixedtr = FixedResolutionSTFTransformer(n_spectral_points=289, pad_spectra=False)\n",
    "STFTs = fixedtr.transform(traces[\"clean_trace\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2fe3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 17:01:26.104690: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-29 17:01:26.170726: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-29 17:01:26.171769: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 17:01:27.498502: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, Dense, Flatten, AveragePooling1D\n",
    "from keras.models import Sequential\n",
    "\n",
    "def build_model(input_shape, n_categories,\n",
    "                n_conv_blocks=2, n_dense_blocks=2, \n",
    "                filters=16, kernel_size=5, pool_size=2, \n",
    "                dense_nodes=256):\n",
    "\n",
    "    model = Sequential()\n",
    "    # Conv1d + temporal average pooling\n",
    "    for block_id in range(n_conv_blocks):\n",
    "        conv = Conv1D(filters, kernel_size, \n",
    "                      input_shape=input_shape,\n",
    "                      activation=\"relu\", name=f\"conv_{block_id}\")\n",
    "        \n",
    "        pool = AveragePooling1D(name=f\"avg_pooling_{block_id}\")\n",
    "        \n",
    "        model.add(conv)\n",
    "        model.add(pool)\n",
    "        \n",
    "    # Flattens stuff :3\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # A good dose of Dense layers never hurted anybody\n",
    "    for block_id in range(n_dense_blocks):\n",
    "        model.add(Dense(dense_nodes, activation=\"relu\", name=f\"dense_{block_id}\"))\n",
    "    \n",
    "    # Let the garbage out\n",
    "    model.add(Dense(n_categories, activation=\"softmax\", name=\"output\"))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", \n",
    "                  loss=\"sparse_categorical_crossentropy\", \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab0ba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27] tot 28 samples are 2452\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27] tot 28 samples are 1961\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27] tot 28 samples are 491\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_0 (Conv1D)             (None, 102, 5)            7230      \n",
      "                                                                 \n",
      " avg_pooling_0 (AveragePooli  (None, 51, 5)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv_1 (Conv1D)             (None, 47, 5)             130       \n",
      "                                                                 \n",
      " avg_pooling_1 (AveragePooli  (None, 23, 5)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv_2 (Conv1D)             (None, 19, 5)             130       \n",
      "                                                                 \n",
      " avg_pooling_2 (AveragePooli  (None, 9, 5)             0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 45)                0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 41)                1886      \n",
      "                                                                 \n",
      " output (Dense)              (None, 28)                1176      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,552\n",
      "Trainable params: 10,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "49/49 [==============================] - 4s 39ms/step - loss: 3.5289 - accuracy: 0.0261 - val_loss: 3.3309 - val_accuracy: 0.0509\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 3.3280 - accuracy: 0.0300 - val_loss: 3.3282 - val_accuracy: 0.0280\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 3.3245 - accuracy: 0.0306 - val_loss: 3.3254 - val_accuracy: 0.0433\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 3.3204 - accuracy: 0.0376 - val_loss: 3.3227 - val_accuracy: 0.0433\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 3.3162 - accuracy: 0.0332 - val_loss: 3.3204 - val_accuracy: 0.0433\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 3.3125 - accuracy: 0.0364 - val_loss: 3.3203 - val_accuracy: 0.0458\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 3.3105 - accuracy: 0.0332 - val_loss: 3.3203 - val_accuracy: 0.0356\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 3.3097 - accuracy: 0.0357 - val_loss: 3.3221 - val_accuracy: 0.0356\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 3.3085 - accuracy: 0.0357 - val_loss: 3.3230 - val_accuracy: 0.0331\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 3.3072 - accuracy: 0.0466 - val_loss: 3.3247 - val_accuracy: 0.0331\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 3.3051 - accuracy: 0.0466 - val_loss: 3.3228 - val_accuracy: 0.0382\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 3.2805 - accuracy: 0.0523 - val_loss: 3.2373 - val_accuracy: 0.0738\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 3.0629 - accuracy: 0.0976 - val_loss: 2.9654 - val_accuracy: 0.1043\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 2.8422 - accuracy: 0.1199 - val_loss: 2.8372 - val_accuracy: 0.1221\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 2.7569 - accuracy: 0.1358 - val_loss: 2.8040 - val_accuracy: 0.1196\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 2.7221 - accuracy: 0.1301 - val_loss: 2.7835 - val_accuracy: 0.1323\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 2.6965 - accuracy: 0.1352 - val_loss: 2.7821 - val_accuracy: 0.1094\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 1s 28ms/step - loss: 2.6799 - accuracy: 0.1378 - val_loss: 2.7582 - val_accuracy: 0.1272\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 2.6630 - accuracy: 0.1543 - val_loss: 2.7648 - val_accuracy: 0.1399\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 2.6526 - accuracy: 0.1492 - val_loss: 2.7597 - val_accuracy: 0.1145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc = LabelEncoder()\n",
    "subset = np.ones(len(df)).astype(bool)#(df.vocal_channel == \"song\")\n",
    "labels = np.array([f\"{s}{e}{vc}\" for s,e,vc in zip(df.sex, df.emotion, df.vocal_channel)])\n",
    "\n",
    "y = enc.fit_transform(labels[subset])\n",
    "X = pad_sequences(STFTs)[subset]\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(np.unique(y),\"tot\", len(np.unique(y)), \"samples are\", len(y))\n",
    "print(np.unique(ytrain),\"tot\", len(np.unique(ytrain)), \"samples are\", len(ytrain))\n",
    "print(np.unique(ytest),\"tot\", len(np.unique(ytest)), \"samples are\", len(ytest))\n",
    "\n",
    "\n",
    "test_params = {'n_conv_blocks': 3, 'filters': 5, 'kernel_size': 5, 'pool_size': 5, 'n_dense_blocks': 1, 'dense_nodes': 41}\n",
    "test_model = build_model(Xtrain.shape[1:], len(np.unique(y)), **test_params)\n",
    "test_model.summary()\n",
    "hist = test_model.fit(Xtrain, ytrain, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d6c60",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425eba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the tuning the spectral resolution is optimized too\n",
    "from djanloo_fourier import FixedResolutionSTFTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Gets labels\n",
    "enc = LabelEncoder()\n",
    "labels = np.array([f\"{s}{e}{vc}\" for s,e,vc in zip(df.sex, df.emotion, df.vocal_channel)])\n",
    "y = enc.fit_transform(labels)\n",
    "\n",
    "\n",
    "def objective(trial, train_idxs, val_idxs):\n",
    "    global traces, df, y\n",
    "    \n",
    "    epochs=trial.suggest_int('epochs',15,40)\n",
    "    \n",
    "    ## Really gets the dataset of STFTs\n",
    "    fixedtr = FixedResolutionSTFTransformer(n_spectral_points=trial.suggest_int('n_spectral_points', 50, 300),\n",
    "                                            pad_spectra=False,\n",
    "                                           verbose=False)\n",
    "    \n",
    "    # Gets STFTs\n",
    "    STFTs = fixedtr.transform(traces[\"clean_trace\"])\n",
    "    X = pad_sequences(STFTs)\n",
    "    \n",
    "    ## Concerning the model ...\n",
    "    \n",
    "    pars = dict(## Conv stuff\n",
    "                n_conv_blocks=trial.suggest_int('n_conv_blocks', 1, 4), \n",
    "                filters=trial.suggest_int('filters', 2, 16), \n",
    "                kernel_size=trial.suggest_int('kernel_size', 3, 9), \n",
    "                pool_size=trial.suggest_int('pool_size', 2, 8),\n",
    "                \n",
    "                ## Dense stuff\n",
    "                n_dense_blocks=trial.suggest_int('n_dense_blocks', 1, 4), \n",
    "                dense_nodes=trial.suggest_int('dense_nodes', 16, 256)\n",
    "               )\n",
    "    print(f\"running model having {pars} with SpRes = {fixedtr.n_spectral_points} for epochs = {epochs}\")\n",
    "    \n",
    "    model = build_model(X.shape[1:], len(np.unique(y)), **pars)\n",
    "    model.fit(\n",
    "                    X[train_idxs], y[train_idxs], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=trial.suggest_int('batch_size', 16, 32),\n",
    "                    verbose=False\n",
    "                    )\n",
    "    \n",
    "    ## Estimate accuracy\n",
    "    y_pred = np.argmax(model.predict(X[val_idxs], verbose=False), axis=1)\n",
    "    acc = accuracy_score(y[val_idxs], y_pred)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46e9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splits the dataset\n",
    "idxs = np.arange(len(df))\n",
    "np.random.shuffle(idxs)\n",
    "train_idxs, val_idxs, test_idxs = np.split(idxs, (len(df)*np.array([0.7, 0.8])).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2094f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-29 17:28:59,589] A new study created in memory with name: no-name-207e32f6-26c8-4492-810e-deb43c833a30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model having {'n_conv_blocks': 3, 'filters': 15, 'kernel_size': 9, 'pool_size': 2, 'n_dense_blocks': 2, 'dense_nodes': 155} with SpRes = 85 for epochs = 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 17:29:11.751476: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 207704640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model having {'n_conv_blocks': 2, 'filters': 16, 'kernel_size': 4, 'pool_size': 2, 'n_dense_blocks': 4, 'dense_nodes': 44} with SpRes = 194 for epochs = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 17:29:16.518437: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 209063712 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model having {'n_conv_blocks': 4, 'filters': 5, 'kernel_size': 3, 'pool_size': 5, 'n_dense_blocks': 1, 'dense_nodes': 230} with SpRes = 192 for epochs = 31\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "trial_function = lambda trial: objective(trial, train_idxs, val_idxs)\n",
    "study.optimize(trial_function, n_trials=150, n_jobs=-1, catch=ValueError)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d3d5f8",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84721277",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(best_params)\n",
    "# cnn = build_model((54,54), 2, **best_params)\n",
    "# cnn.summary()\n",
    "# cnn.fit( np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)), \n",
    "#             epochs=best_params[\"epochs\"], \n",
    "#             batch_size=best_params[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d77031ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ypred = np.argmax(test_model.predict(Xtest), axis=1)\n",
    "\n",
    "# print(accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a722123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# plt.matshow(confusion_matrix(ytest, ypred))\n",
    "# plt.xticks(np.unique(ytest), labels = enc.inverse_transform(np.unique(ytest)), rotation=90);\n",
    "# plt.yticks(np.unique(ytest), labels = enc.inverse_transform(np.unique(ytest)), rotation=0);\n",
    "\n",
    "# plt.title(f\"accuracy = {accuracy_score(ytest, ypred)*100:.2f}\")\n",
    "# plt.grid(ls=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30e3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2",
   "language": "python",
   "name": "dm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

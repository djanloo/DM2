{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:51.437524Z",
     "start_time": "2023-06-06T16:34:51.223699Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tf as tf\n",
    "\n",
    "from pandas.core.dtypes.common import is_numeric_dtype\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression, SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'dataset'\n",
    "DATASET = os.path.join(DATA_FOLDER, 'outliers_removed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:51.440207Z",
     "start_time": "2023-06-06T16:34:51.438779Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   frame_count       sum          mean       std       min       max   \n0       158558  0.145081  9.150000e-07  0.004001 -0.038422  0.040588  \\\n1       160160  0.114319  7.137790e-07  0.004283 -0.042603  0.048157   \n2       156956  0.149963  9.554485e-07  0.005084 -0.037018  0.058472   \n3       152152  0.139618  9.176213e-07  0.004886 -0.036652  0.062683   \n4       169769  0.137665  8.108948e-07  0.002956 -0.026245  0.026215   \n\n        q01       q05       q25  q75  ...  actor_actor_24  actor_actor_3   \n0 -0.012586 -0.005890 -0.000031  0.0  ...               0              0  \\\n1 -0.013550 -0.006104 -0.000031  0.0  ...               0              0   \n2 -0.015822 -0.007294  0.000000  0.0  ...               0              0   \n3 -0.014923 -0.006714 -0.000031  0.0  ...               0              0   \n4 -0.009399 -0.004364 -0.000031  0.0  ...               0              0   \n\n   actor_actor_4  actor_actor_5  actor_actor_6  actor_actor_7  actor_actor_8   \n0              0              0              0              0              0  \\\n1              0              0              0              0              0   \n2              0              0              0              0              0   \n3              0              0              0              0              0   \n4              0              0              0              0              0   \n\n   actor_actor_9  sex_F  sex_M  \n0              0      0      1  \n1              0      0      1  \n2              0      0      1  \n3              0      0      1  \n4              0      0      1  \n\n[5 rows x 285 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame_count</th>\n      <th>sum</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>q01</th>\n      <th>q05</th>\n      <th>q25</th>\n      <th>q75</th>\n      <th>...</th>\n      <th>actor_actor_24</th>\n      <th>actor_actor_3</th>\n      <th>actor_actor_4</th>\n      <th>actor_actor_5</th>\n      <th>actor_actor_6</th>\n      <th>actor_actor_7</th>\n      <th>actor_actor_8</th>\n      <th>actor_actor_9</th>\n      <th>sex_F</th>\n      <th>sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>158558</td>\n      <td>0.145081</td>\n      <td>9.150000e-07</td>\n      <td>0.004001</td>\n      <td>-0.038422</td>\n      <td>0.040588</td>\n      <td>-0.012586</td>\n      <td>-0.005890</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>160160</td>\n      <td>0.114319</td>\n      <td>7.137790e-07</td>\n      <td>0.004283</td>\n      <td>-0.042603</td>\n      <td>0.048157</td>\n      <td>-0.013550</td>\n      <td>-0.006104</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>156956</td>\n      <td>0.149963</td>\n      <td>9.554485e-07</td>\n      <td>0.005084</td>\n      <td>-0.037018</td>\n      <td>0.058472</td>\n      <td>-0.015822</td>\n      <td>-0.007294</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>152152</td>\n      <td>0.139618</td>\n      <td>9.176213e-07</td>\n      <td>0.004886</td>\n      <td>-0.036652</td>\n      <td>0.062683</td>\n      <td>-0.014923</td>\n      <td>-0.006714</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>169769</td>\n      <td>0.137665</td>\n      <td>8.108948e-07</td>\n      <td>0.002956</td>\n      <td>-0.026245</td>\n      <td>0.026215</td>\n      <td>-0.009399</td>\n      <td>-0.004364</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 285 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET)\n",
    "\n",
    "categorical_attr_list = [col for col in df.columns if not is_numeric_dtype(df[col])]\n",
    "\n",
    "# one hot encoding\n",
    "df_reg = df.drop(columns=categorical_attr_list)\n",
    "df_reg = df_reg.join(pd.get_dummies(df[categorical_attr_list], columns=categorical_attr_list).astype(int))\n",
    "\n",
    "df_reg.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:51.515367Z",
     "start_time": "2023-06-06T16:34:51.441449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "stft_min    False\nsc_min      False\ndtype: bool"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_correct = ['stft_min', 'sc_min']\n",
    "(df[features_to_correct] < 0).any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:51.519528Z",
     "start_time": "2023-06-06T16:34:51.517543Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# stft_min"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['mfcc_q50',\n 'sc_q01',\n 'sc_q05',\n 'stft_q01',\n 'stft_q05',\n 'mfcc_q25_w1',\n 'mfcc_q50_w1',\n 'sc_q05_w1',\n 'sc_q25_w1',\n 'stft_q05_w1',\n 'q50_w2',\n 'q50_w3',\n 'lag1_q50_w3',\n 'q75_w4']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET = 'stft_min'\n",
    "\n",
    "# drop quantile columns with high percentage of zeros (20%)\n",
    "zero_percentage = (df_reg == 0).mean()\n",
    "to_drop = [col for col in df_reg.columns if zero_percentage[col] > 0.2 and re.search(r'q\\d{2}', col)]\n",
    "df_reg = df_reg.drop(columns=to_drop)\n",
    "to_drop"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:51.526615Z",
     "start_time": "2023-06-06T16:34:51.521770Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAHFCAYAAAD1zS3+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+IUlEQVR4nO3dd3RUZf7H8c8kIYUOCUXKooL0MARCQAGBiK40wQAqKriyS0CC5bjSRFEpRgHLCkFAkCKudFCxwNpXBaLBBBHQoKtGakKHhNT7+yNmfpk0JmGGmcx9v87hnMx97n2e5zt3Yj7eNhbDMAwBAACYjI+7JwAAAOAOhCAAAGBKhCAAAGBKhCAAAGBKhCAAAGBKhCAAAGBKhCAAAGBKhCAAAGBKhCAAxXjCM1Q9YQ5XgiN1muW9AK40QhBQyYwcOVKtWrWy/WvdurXCwsIUFRWlVatWKScnx279yMhITZkyxeH+P/74Y02ePPmS602ZMkWRkZEVHqc0Z8+e1aRJk/Ttt9/alo0cOVIjR4687L6dJScnR1OmTFFYWJg6deqknTt3VqifhQsXatmyZXbL5s6dq4iICHXs2FFbtmxxeH84S6tWrTR//vwrNh7gTn7ungCA8mvbtq2eeuopSVJubq7OnDmjL774QrGxsfr222/18ssvy8cn//9xFixYoOrVqzvc94oVKxxab/z48Ro1alS5534p+/fv19tvv62hQ4falhXU6in++9//avPmzRo/frxuuOEGtW3btkL9/Otf/9KECRNsr3/66SctXbpUd9xxhwYPHqxrr71WDz/8sLOm7ZC1a9eqYcOGV3RMwF0IQUAlVL16dXXs2NFuWWRkpK699lrNnj1bW7du1W233SZJFf4DfSl/+ctfXNJvSVq0aHHFxnLE6dOnJUlRUVFq2rSp0/sdMGCAwsPDndZveRT9XAHejNNhgBe599571aBBA61Zs8a2rOhpqoKA1KFDB3Xr1k2PPfaYjh07Jin/tFN8fLzi4+PVqlUr7dq1S7t27VKrVq20Zs0a9enTR506ddJXX31V7HSYJGVnZ2vWrFnq0qWLwsPDNXnyZJ08edLWXtJprYL+C8YqOLo0atQo27pFt8vMzFRcXJxuvfVWhYaG6pZbbtGSJUuUl5dnN9a0adO0ZMkS9e7dW6Ghobrrrru0Z8+eMt/D3Nxcvfnmmxo0aJA6dOig3r17a968ecrMzJSUfxqw4P3s27dvqafp8vLy9NJLLykyMlLt27dXZGSkXnjhBWVnZ0vKP+0k5R+pKzgFVdDXfffdp8jIyBL3h6NatWqlt956S1OmTFHnzp0VERGhWbNm6eLFi3r++efVrVs3de3aVdOmTbPVVrBdwemwgn2zY8cOjR49WlarVd27d9fcuXOVm5vr8FwAT8WRIMCL+Pj46Prrr9d7772nnJwc+fnZ/4onJCRo0qRJGj9+vLp06aKjR49q7ty5+uc//6nVq1frqaee0sSJEyXln4Jq0aKFfvjhB0n5f6yfeOIJXbx4UWFhYXr33XeLjf/BBx/IarXqueee08mTJzVv3jwdPHhQ69atk6+v7yXn365dO02fPl0zZszQ9OnT1bVr12LrGIahcePGKTExURMmTFDr1q21a9cuvfzyy0pJSdHMmTNt627btk3NmzfXE088IcMw9Pzzz+vBBx/UJ598Uup8pk+frrfffltjxoxReHi49u3bp7i4OO3fv19Lly7V+PHj1bBhQ7366qtasGCBrrnmmhL7ee211/TWW29p8uTJatq0qZKSkvTSSy+pSpUqeuihh7R27VrdeeedGjZsmIYPH66GDRuqbt26ttrDwsLk7+9fbH+Ux9y5czVw4EAtWLBAn376qVauXKkvv/xSrVu31rx585SYmKj58+frmmuu0T/+8Y9S+3nsscd09913a8yYMfrss8+0dOlSNW3aVHfddVe55gN4GkIQ4GVCQkKUnZ2t06dPKyQkxK4tISFBgYGBio6Olr+/vySpdu3a+v7772UYhlq0aGG7fqjoaZG7775bt956a5lj16lTR8uWLVPVqlVtr2NiYvTFF1+oT58+l5x79erVbX/oW7RoUeIf/S+++EJff/21XnzxRQ0YMECS1L17dwUGBupf//qXRo0apeuuu05S/gXMy5Yts9V04cIFTZ48Wfv371f79u2L9X3w4EFt2LBB//znPxUdHW3ru379+po0aZK++OIL9erVy3YqsE2bNmrSpEmJtcTHx6t9+/a2a5siIiIUFBSkGjVqSPr/97dhw4a2nwvXXnAas7T94YgWLVpoxowZtvHXr1+v7OxszZs3T35+furRo4e2bdum3bt3l9nP8OHDFRMTI0m6/vrr9dFHH+mzzz4jBKHS43QY4GUKbqe2WCzF2rp06aKMjAwNHDhQL7zwgr799lv16NFDEyZMKHH9wtq0aXPJsXv16mULQFL+qTg/Pz9988035ayidPHx8fLz8ysWyAqugYqPj7ctKxzqJKlBgwaSpIyMjFL7lmQLVwUGDBggX1/fcp2O6tq1q7766ivdfffdWrp0qQ4ePKh7771XgwcPdriPyxUWFmb72dfXV3Xq1FG7du3sjhDWrl1b586dc7gfKT+4paenO3eygBsQggAvc+zYMQUGBqp27drF2sLCwrRkyRI1bdpUy5cv1z333KMbb7xRb7zxxiX7LRxuSlOvXj271z4+PqpTp47Onj3r8Pwv5cyZM6pTp06x01kFYxf+gx4UFFRsPpLsrh0q2nfhvgr4+fmpTp06lwwLhf3jH//Q9OnTdfHiRc2bN08DBgzQwIEDK3w7fUWUdFegI/uxqMDAQLvXPj4+PLsIXoEQBHiRnJwc7dq1S506dSr1mpeePXtq2bJl+uabb7Ro0SK1bNlSs2bNuuQFw44ouLupQG5urk6dOqXg4GC7ZYWV94hCrVq1dOrUqWL9HD9+XFL+KbiKqlWrliQpNTXVbnl2drZOnTpVrr59fHx0zz33aNOmTfrqq68UGxurrKwsPfjgg8rKyqrwHAE4DyEI8CJr165VamqqRowYUWL7888/r6FDh8owDAUFBalPnz62B/EdPnxY0v8fLamIr776yu5hjdu2bVNOTo7tAufq1avr6NGjdtskJCTYvb7UBdQRERHKycnRhx9+aLf8nXfekSR17ty5wvOPiIiQJL333nt2y9977z3l5uaWq++77rpLs2bNkiQFBwcrKipK99xzj86ePavz589Lcuy9vpz9AaBsXBgNVELnz59XYmKipPxTO6dOndKXX36ptWvX6rbbbtMtt9xS4nbdunXT8uXLNWXKFN12223Kzs7W0qVLVbt2bXXr1k2SVLNmTX333XfasWNHuZ8xlJqaqgcffFAjR47Ur7/+qhdffFHdu3fX9ddfL0nq06ePPvnkE8XGxioyMlLffvuttmzZYtdHwYXDn332mWrVqqXWrVvbtd94443q2rWrnnjiCR07dkytW7dWfHy8XnvtNd1+++2X9UyhFi1a6Pbbb9crr7yijIwMdenSRfv379eCBQvUtWtX9ezZ0+G+unTpotdff10hISEKCwvTsWPHtHz5ckVERKhu3bqS8t/r3bt365tvvin1uUBF90fB0SoAl48QBFRC+/bt05133ikp/wLoatWqqWXLlnr66ac1fPjwUrfr1auX5s2bp9dff912MXTnzp21atUq2zVE99xzj/bu3asxY8YoNjZW9evXd3hed999t86dO6eYmBj5+/tr0KBBmjhxou2i66FDh+r333/X5s2btWbNGnXp0kWvvPKK3ZGr6667TgMHDtSbb76p//73v9q6davdGBaLRYsXL9Yrr7yiFStW6OTJk2rSpIkeffRR3X///Q7PtTSzZ89Ws2bNtHHjRr322muqX7++Ro0apfHjx5frqMzDDz8sf39/bdy4UXFxcapRo4YiIyP1z3/+07bOuHHjtHDhQo0ZM0bvv/9+if0U3R+DBg267BoB5LMYXN0GAABMiCNBAFBJ5OXllXpnW2FFH5IJoGQcCQKASmLKlCnavHnzJdf78ccfr8BsgMqPEAQAlcQff/yhU6dOXXK90NDQKzAboPIjBAEAAFPiARQAAMCUCEEAAMCUCEEAAMCUCEEAAMCUeJhEGU6cOCdnXzZusUjBwTVc0renoEbvQI3ewQw1Suaokxod395RhKAyGIZc9kFzZd+eghq9AzV6BzPUKJmjTmp0Hk6HAQAAUyIEAQAAUyIEAQAAUyIEAQAAUyIEAQAAUyIEAQAAUyIEAQAAUyIEAQAAUyIEAQAAUyIEAQAAUyIEAQAAUyIEAQAAUyIEAQAAUyIEAQAAUyIEuYmvr498fXn7AQBwFz93T8BsfH19NHfbAR06ma6GtQIV3a2ZcnPz3D0tAABMhxDkBsfOXlTKyXR3TwMAAFPjfAwAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAljwhBWVlZGjhwoHbt2mVblpiYqLvuukthYWH661//qvXr19tt8/XXX2vgwIGyWq0aNWqUUlJS7NpXrFihnj17KiwsTI8//rgyMjKuSC0AAKBycHsIyszM1KOPPqrk5GTbstTUVI0ZM0YRERHavHmzHnroIc2cOVOfffaZJOnw4cOKiYlRVFSUNmzYoLp162r8+PEyDEOStG3bNi1YsEAzZszQypUrlZSUpLlz57qjPAAA4KHcGoIOHjyoO+64Q7///rvd8o8++kghISF69NFHdfXVV2vAgAEaMmSI3n33XUnS+vXr1b59e40ePVrXXXedYmNjdejQIcXHx0uSVq1apfvuu099+vRRhw4d9Mwzz2jjxo0cDQIAADZuDUHx8fHq2rWr1q5da7e8Z8+eio2NLbb++fPnJUlJSUkKDw+3LQ8KClK7du2UmJio3Nxcff/993btHTt2VHZ2tg4cOOCiSgAAQGXj587B77777hKXN2nSRE2aNLG9PnHihN577z09+OCDkvJPl9WvX99um+DgYB09elRnz55VZmamXbufn59q166to0ePlmt+Fku5Vq9QnxaLa8Zxp4J6vK2uwqjRO1Cj9zBDndTo+PaOcmsIcsTFixf14IMPKiQkRHfeeackKSMjQ/7+/nbr+fv7KysrSxcvXrS9Lqm9PIKDa1zGzMtWpYqv/Px8VKdONZeN4W6ufP88BTV6B2r0Hmaokxqdx6ND0IULFzR+/Hj9+uuv+ve//62goCBJUkBAQLFAk5WVpZo1ayogIMD2umh7wfaOOnHinP681tpp/Pzyz0BmZ+cqJydPp05dUG5unnMHcTOLJf8D7Ir3z1NQo3egRu9hhjqp0fHtHeWxIej8+fP6xz/+od9//10rV67U1VdfbWtr0KCB0tLS7NZPS0tTmzZtVLt2bQUEBCgtLU3NmzeXJOXk5Oj06dOqV69eueZgGHL6B61of64Yw1N4c20FqNE7UKP3MEOd1Og8br9FviR5eXmaMGGC/vjjD73xxhu67rrr7NqtVqsSEhJsrzMyMrRv3z5ZrVb5+PgoNDTUrj0xMVF+fn5q3br1FasBAAB4No8MQRs2bNCuXbs0a9Ys1axZU6mpqUpNTdXp06clSUOHDtXu3bu1ZMkSJScna+rUqWrSpIm6du0qKf+C62XLlumjjz7Snj179PTTT+uOO+4o9+kwAADgvTzydNi2bduUl5ensWPH2i2PiIjQG2+8oSZNmmj+/Pl69tlnFRcXp7CwMMXFxcny52XhAwYM0KFDhzR9+nRlZWXplltu0cSJE91RCgAA8FAeE4J+/PFH28/Lli275Pq9evVSr169Sm2Pjo5WdHS0U+YGAAC8j0eeDgMAAHA1QhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAlQhAAADAljwhBWVlZGjhwoHbt2mVblpKSor/97W/q2LGj+vfvry+//NJum6+//loDBw6U1WrVqFGjlJKSYte+YsUK9ezZU2FhYXr88ceVkZFxRWoBAACVg9tDUGZmph599FElJyfblhmGoZiYGIWEhGjjxo0aPHiwJkyYoMOHD0uSDh8+rJiYGEVFRWnDhg2qW7euxo8fL8MwJEnbtm3TggULNGPGDK1cuVJJSUmaO3euW+oDAACeya0h6ODBg7rjjjv0+++/2y3fuXOnUlJSNGPGDDVv3lxjx45Vx44dtXHjRknS+vXr1b59e40ePVrXXXedYmNjdejQIcXHx0uSVq1apfvuu099+vRRhw4d9Mwzz2jjxo0cDQIAADZuDUHx8fHq2rWr1q5da7c8KSlJbdu2VdWqVW3LOnfurMTERFt7eHi4rS0oKEjt2rVTYmKicnNz9f3339u1d+zYUdnZ2Tpw4IBrCwIAAJWGnzsHv/vuu0tcnpqaqvr169stCw4O1tGjRy/ZfvbsWWVmZtq1+/n5qXbt2rbtHWWxlGv1CvVpsbhmHHcqqMfb6iqMGr0DNXoPM9RJjY5v7yi3hqDSZGRkyN/f326Zv7+/srKyLtl+8eJF2+vStndUcHCN8k7dYVWq+MrPz0d16lRz2Rju5sr3z1NQo3egRu9hhjqp0Xk8MgQFBATo9OnTdsuysrIUGBhoay8aaLKyslSzZk0FBATYXhdtDwoKKtc8Tpw4pz+vtXYaP7/8M5DZ2bnKycnTqVMXlJub59xB3Mxiyf8Au+L98xTU6B2o0XuYoU5qdHx7R3lkCGrQoIEOHjxotywtLc12iqtBgwZKS0sr1t6mTRvVrl1bAQEBSktLU/PmzSVJOTk5On36tOrVq1eueRiGnP5BK9qfK8bwFN5cWwFq9A7U6D3MUCc1Oo/bb5EvidVq1Q8//GA7tSVJCQkJslqttvaEhARbW0ZGhvbt2yer1SofHx+FhobatScmJsrPz0+tW7e+ckUAAACP5pEhKCIiQldddZWmTp2q5ORkLVmyRHv27NGwYcMkSUOHDtXu3bu1ZMkSJScna+rUqWrSpIm6du0qKf+C62XLlumjjz7Snj179PTTT+uOO+4o9+kwAADgvTwyBPn6+mrhwoVKTU1VVFSU3nnnHcXFxalRo0aSpCZNmmj+/PnauHGjhg0bptOnTysuLk6WPy8LHzBggMaOHavp06dr9OjR6tChgyZOnOjOkgAAgIfxmGuCfvzxR7vXzZo10+rVq0tdv1evXurVq1ep7dHR0YqOjnba/AAAgHfxyCNBAAAArkYIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApuTRIejIkSMaO3asOnXqpMjISK1YscLWtm/fPg0fPlxWq1VDhw7V3r177bbdunWr+vbtK6vVqpiYGJ08efIKzx4AAHgyjw5BjzzyiKpWrapNmzbp8ccf18svv6z//Oc/Sk9PV3R0tMLDw7Vp0yaFhYVp7NixSk9PlyTt2bNH06ZN04QJE7R27VqdPXtWU6dOdXM1AADAk3hsCDpz5owSExP1wAMP6Oqrr1bfvn3Vs2dP7dixQ++//74CAgI0adIkNW/eXNOmTVO1atX04YcfSpJWr16tfv36aciQIWrdurXmzJmjzz//XCkpKW6uCgAAeAqPDUGBgYEKCgrSpk2blJ2drV9++UW7d+9WmzZtlJSUpM6dO8tisUiSLBaLOnXqpMTERElSUlKSwsPDbX1dddVVatSokZKSktxRCgAA8EB+7p5AaQICAjR9+nTNnDlTq1atUm5urqKiojR8+HB9/PHHatGihd36wcHBSk5OliQdP35c9evXL9Z+9OjRcs3hz4zlVEX7tFhcM447FdTjbXUVRo3egRq9hxnqpEbHt3eUx4YgSfr555/Vp08f3X///UpOTtbMmTN1/fXXKyMjQ/7+/nbr+vv7KysrS5J08eLFMtsdFRxc4/IKKEOVKr7y8/NRnTrVXDaGu7ny/fMU1OgdqNF7mKFOanQejw1BO3bs0IYNG/T5558rMDBQoaGhOnbsmF599VU1bdq0WKDJyspSYGCgpPyjSCW1BwUFlWsOJ06ck2FcXh1F+fnln4HMzs5VTk6eTp26oNzcPOcO4mYWS/4H2BXvn6egRu9Ajd7DDHVSo+PbO8pjQ9DevXvVrFkzW7CRpLZt22rRokUKDw9XWlqa3fppaWm2U2ANGjQosb1evXrlmoNhyOkftKL9uWIMT+HNtRWgRu9Ajd7DDHVSo/N47IXR9evX12+//WZ3ROeXX35RkyZNZLVa9d1338n48x0yDEO7d++W1WqVJFmtViUkJNi2O3LkiI4cOWJrBwAA8NgQFBkZqSpVquiJJ57Q//73P33yySdatGiRRo4cqVtvvVVnz57V7NmzdfDgQc2ePVsZGRnq16+fJGnEiBF6++23tX79eh04cECTJk1S79691bRpUzdXBQAAPIXHhqAaNWpoxYoVSk1N1bBhwxQbG6sHHnhAd955p6pXr67FixcrISFBUVFRSkpK0pIlS1S1alVJUlhYmGbMmKG4uDiNGDFCtWrVUmxsrJsrAgAAnsRjrwmSpBYtWmj58uUltnXo0EGbN28udduoqChFRUW5amoAAKCS89gjQQAAAK5ECAIAAKZECAIAAKZECAIAAKZECAIAAKZECAIAAKZECAIAAKZECAIAAKZECAIAAKZECAIAAKZECAIAAKbk9BB08uRJZ3cJAADgdBUKQW3atCkx7Bw6dEg33XTTZU8KAADA1Rz+FvktW7Zo06ZNkiTDMBQTE6MqVarYrXP8+HHVq1fPuTMEAABwAYdD0M0336w//vhDkhQfH6+OHTuqWrVqdutUrVpVN998s3NnCAAA4AIOh6Bq1appwoQJkqTGjRurf//+CggIcNnEAAAAXMnhEFTY7bffrt9++0179+5VdnZ2sfYhQ4Zc7rwAAABcqkIhaOnSpZo3b55q1apV7JSYxWIhBAEAAI9XoRD0+uuva+LEifr73//u7PkAAABcERW6RT4zM1O33HKLs+cCAABwxVQoBA0aNEj//ve/ZRiGs+cDAABwRVTodNj58+e1YcMGbd26VU2aNCn2vKBVq1Y5ZXIAAACuUqEQdPXVV2vcuHHOngsAAMAVU6EQVPC8IAAAgMqqQiFo6tSpZbbHxsZWaDIAAABXilO+RT4nJ0f/+9//9P7776tu3brO6BIAAMClKnQkqLQjPUuXLtVPP/10WRMCAAC4EpxyJKjArbfeqv/85z/O7BIAAMAlnBaC0tPTtW7dOtWpU8dZXQIAALhMhU6HtW7dWhaLpdjygIAAzZo167InBQAA4GoVCkFFH4ZosVhUpUoVtWjRQtWrV3fKxAAAAFypQiEoIiJCkvTrr7/q559/Vl5enq655hoCEAAAqDQqFILOnj2rqVOn6uOPP1atWrWUm5urCxcuqEuXLoqLi1ONGjWcPU8AAACnqtCF0bNmzdLRo0f1/vvva9euXfr222/17rvvKj09nQclAgCASqFCIeiTTz7R008/rWuvvda2rEWLFpo+fbo+/vhjp00OAADAVSoUggICAuTjU3xTi8Wi3Nzcy54UAACAq1UoBEVGRuqZZ57R77//blv266+/atasWerVq5fTJgcAAOAqFboweuLEiYqJidFf//pX1axZU5J05swZ3XjjjXryySedOkEAAABXKHcI+u2339SoUSO98cYb+vHHH/Xzzz8rICBAV199tZo3b+6KOQIAADidw6fDDMPQrFmz1K9fP3333XeSpFatWql///7auHGjBg4cqOeee06GYbhssgAAAM7icAhatWqV3n//fcXFxdkellhg4cKFiouL0+bNm/XWW285fZIAAADO5nAIWrdunZ588kn16dOnxPbIyEg99thjhCAAAFApOByCDh06pA4dOpS5Trdu3ZSSknLZkwIAAHA1h0NQcHCwDh06VOY6R48eVe3atS93TjZZWVl65pln1KVLF91www168cUXbdcc7du3T8OHD5fVatXQoUO1d+9eu223bt2qvn37ymq1KiYmRidPnnTavAAAQOXncAi6+eabNX/+fGVnZ5fYnpOTowULFqhHjx5Om9ysWbP09ddfa9myZXrhhRe0bt06rV27Vunp6YqOjlZ4eLg2bdqksLAwjR07Vunp6ZKkPXv2aNq0aZowYYLWrl1r+64zAACAAg7fIj9+/HgNGzZMUVFRGjlypNq3b68aNWrozJkz+uGHH7R69WpduHBBc+bMccrETp8+rY0bN2r58uW203CjR49WUlKS/Pz8FBAQoEmTJslisWjatGn64osv9OGHHyoqKkqrV69Wv379NGTIEEnSnDlz1KdPH6WkpKhp06ZOmR8AAKjcHA5BNWvW1Lp16zRv3jw999xzysjIkJR/63yNGjXUv39/PfjggwoJCXHKxBISElS9enW7O9Gio6MlSU8++aQ6d+4si8UiKf/rOjp16qTExERFRUUpKSlJY8aMsW131VVXqVGjRkpKSiIEAQAASeV8WGLt2rU1a9YsTZ8+XSkpKTp79qxq166tv/zlL/L19XXqxFJSUtS4cWNt2bJFixYtUnZ2tqKiovTAAw8oNTVVLVq0sFs/ODhYycnJkqTjx4+rfv36xdqPHj1arjn8mbGcqmifFotrxnGngnq8ra7CqNE7UKP3MEOd1Oj49o6q0Ndm+Pv7u/zp0Onp6frtt9+0Zs0axcbGKjU1VdOnT1dQUJAyMjLk7+9fbE5ZWVmSpIsXL5bZ7qjg4BqXV0QZqlTxlZ+fj+rUqeayMdzNle+fp6BG70CN3sMMdVKj81QoBF0Jfn5+On/+vF544QU1btxYknT48GG99dZbatasWbFAk5WVpcDAQEn533JfUntQUFC55nDixDk5+wHYfn7516JnZ+cqJydPp05dUG5unnMHcTOLJf8D7Ir3z1NQo3egRu9hhjqp0fHtHeWxIahevXoKCAiwBSBJuuaaa3TkyBFFREQoLS3Nbv20tDTbKbAGDRqU2F6vXr1yzcEw5PQPWtH+XDGGp/Dm2gpQo3egRu9hhjqp0XkcvkX+SrNarcrMzNT//vc/27JffvlFjRs3ltVq1XfffWd7ZpBhGNq9e7esVqtt24SEBNt2R44c0ZEjR2ztAAAAHhuCrr32WvXu3VtTp07VgQMH9N///ldLlizRiBEjdOutt+rs2bOaPXu2Dh48qNmzZysjI0P9+vWTJI0YMUJvv/221q9frwMHDmjSpEnq3bs3d4YBAAAbjw1BkjRv3jz95S9/0YgRIzR58mTdc889GjlypKpXr67FixcrISHBdkv8kiVLVLVqVUlSWFiYZsyYobi4OI0YMUK1atVSbGysm6sBAACexGOvCZKkGjVqlPrwxQ4dOmjz5s2lbhsVFaWoqChXTQ0AAFRyHn0kCAAAwFUIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQIQQAAwJQqTQiKjo7WlClTbK/37dun4cOHy2q1aujQodq7d6/d+lu3blXfvn1ltVoVExOjkydPXukpAwAAD1YpQtB7772nzz//3PY6PT1d0dHRCg8P16ZNmxQWFqaxY8cqPT1dkrRnzx5NmzZNEyZM0Nq1a3X27FlNnTrVXdMHAAAeyOND0OnTpzVnzhyFhobalr3//vsKCAjQpEmT1Lx5c02bNk3VqlXThx9+KElavXq1+vXrpyFDhqh169aaM2eOPv/8c6WkpLirDAAA4GE8PgQ9//zzGjx4sFq0aGFblpSUpM6dO8tisUiSLBaLOnXqpMTERFt7eHi4bf2rrrpKjRo1UlJS0hWdOwAA8Fx+7p5AWXbs2KFvv/1W7777rp5++mnb8tTUVLtQJEnBwcFKTk6WJB0/flz169cv1n706NFyjf9nxnKqon1aLK4Zx50K6vG2ugqjRu9Ajd7DDHVSo+PbO8pjQ1BmZqaeeuopTZ8+XYGBgXZtGRkZ8vf3t1vm7++vrKwsSdLFixfLbHdUcHCNCszcMVWq+MrPz0d16lRz2Rju5sr3z1NQo3egRu9hhjqp0Xk8NgQtWLBA7du3V8+ePYu1BQQEFAs0WVlZtrBUWntQUFC55nDixDkZRjknfgl+fvlnILOzc5WTk6dTpy4oNzfPuYO4mcWS/wF2xfvnKajRO1Cj9zBDndTo+PaO8tgQ9N577yktLU1hYWGSZAs127Zt08CBA5WWlma3flpamu0UWIMGDUpsr1evXrnmYBhy+getaH+uGMNTeHNtBajRO1Cj9zBDndToPB4bgt544w3l5OTYXs+bN0+S9Nhjj+mbb77Ra6+9JsMwZLFYZBiGdu/erXHjxkmSrFarEhISFBUVJUk6cuSIjhw5IqvVeuULAQAAHsljQ1Djxo3tXlerln/tTLNmzRQcHKwXXnhBs2fP1l133aU1a9YoIyND/fr1kySNGDFCI0eOVMeOHRUaGqrZs2erd+/eatq06RWvAwAAeCaPv0W+JNWrV9fixYttR3uSkpK0ZMkSVa1aVZIUFhamGTNmKC4uTiNGjFCtWrUUGxvr5lkDAABP4rFHgop67rnn7F536NBBmzdvLnX9qKgo2+kwAACAoirlkSAAAIDLRQgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACm5NEh6NixY3rooYcUERGhnj17KjY2VpmZmZKklJQU/e1vf1PHjh3Vv39/ffnll3bbfv311xo4cKCsVqtGjRqllJQUd5QAAAA8lMeGIMMw9NBDDykjI0NvvvmmXnrpJX366ad6+eWXZRiGYmJiFBISoo0bN2rw4MGaMGGCDh8+LEk6fPiwYmJiFBUVpQ0bNqhu3boaP368DMNwc1UAAMBT+Ll7AqX55ZdflJiYqK+++kohISGSpIceekjPP/+8brzxRqWkpGjNmjWqWrWqmjdvrh07dmjjxo168MEHtX79erVv316jR4+WJMXGxqp79+6Kj49X165d3VkWAADwEB57JKhevXpaunSpLQAVOH/+vJKSktS2bVtVrVrVtrxz585KTEyUJCUlJSk8PNzWFhQUpHbt2tnaAQAAPPZIUM2aNdWzZ0/b67y8PK1evVrdunVTamqq6tevb7d+cHCwjh49KkmXbHeUxVLByZejT4vFNeO4U0E93lZXYdToHajRe5ihTmp0fHtHeWwIKmru3Lnat2+fNmzYoBUrVsjf39+u3d/fX1lZWZKkjIyMMtsdFRxc4/ImXYYqVXzl5+ejOnWquWwMd3Pl++cpqNE7UKP3MEOd1Og8lSIEzZ07VytXrtRLL72kli1bKiAgQKdPn7ZbJysrS4GBgZKkgICAYoEnKytLNWvWLNe4J06ck7Ovpfbzyz8DmZ2dq5ycPJ06dUG5uXnOHcTNLJb8D7Ar3j9PQY3egRq9hxnqpEbHt3eUx4egmTNn6q233tLcuXP117/+VZLUoEEDHTx40G69tLQ02ymwBg0aKC0trVh7mzZtyjW2YcjpH7Si/bliDE/hzbUVoEbvQI3ewwx1UqPzeOyF0ZK0YMECrVmzRi+++KIGDBhgW261WvXDDz/o4sWLtmUJCQmyWq229oSEBFtbRkaG9u3bZ2sHAADw2BD0888/a+HChRozZow6d+6s1NRU27+IiAhdddVVmjp1qpKTk7VkyRLt2bNHw4YNkyQNHTpUu3fv1pIlS5ScnKypU6eqSZMm3B4PAABsPDYEffzxx8rNzdWrr76qHj162P3z9fXVwoULlZqaqqioKL3zzjuKi4tTo0aNJElNmjTR/PnztXHjRg0bNkynT59WXFycLN58ST0AACgXj70mKDo6WtHR0aW2N2vWTKtXry61vVevXurVq5crpgYAALyAxx4JAgAAcCVCEAAAMCWPPR1mBj4WydfXosJZ1NueGQQAgKciBLlR/RqBWvTVbzpyJkOS1LBWoKK7NSMIAQBwBRCC3OzImQylnEx39zQAADAdrgkCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmxNdmeJCiX6jKd4gBAOA6hCAPUvgLVfkyVQAAXIsQ5GH4QlUAAK4MrgkCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmxC3yHooHJwIA4FqEIA/FgxMBAHAtQpAH48GJAAC4DtcEAQAAU+JIUCVQ9PogiWuEAAC4XISgSqDw9UGSdFXtQI274Wrl5hqSCEQAAFQEIaiSKHx9UMOa/x+KCEQAAFQMIaiSKghFhQMRd5EBAOA4QpAX4C4yAADKj7vDAACAKRGCAACAKRGCAACAKXFNkIn4+vKcIQAAChCCTMLX10dLdv6mo2culngXGQEJAGA2hCAvUtKTpQv4+lp09MzFEu8iu1RAAgDAGxGCvEjRJ0u3b1xLJ85n6ciZDLVvXKvMbUsLSAAAeCtCkJcp+mTpo2cv2h6qWKDoEaP8n0tuk8RpMwCAVyIEmVBJR4xKayt8eqzwabOiX9chEYoAAJULIcikih4xKq2tqILTZoW/rkOy/1JXy58Hlnx9fWQYxfsgLAEAPIHXhqDMzEw988wz2r59uwIDAzV69GiNHj3a3dOqdAqfHit82kwq/Utd2zeupVMZ2Tp0Mt3uuiRJ5brw2tmn3pzRX0EfFotj613OWAAA1/LaEDRnzhzt3btXK1eu1OHDhzV58mQ1atRIt956q7unVqkUPj12qYurC3+pa1p6lu3nguuSpLLvYCvM19eiV7/6tdRTb6UpLXA441Re0bvopvRv69B6rrjbjpAFAJfPK0NQenq61q9fr9dee03t2rVTu3btlJycrDfffJMQVAGFw83lKhqqCt+9VviIUfvGtUo99VbadmWFpcKPCCjrVF5ZynrMQH67T7H1HA19JXEk0BUNWYXDUdE+irY5MlbBdgWnNZ3VnyPrOYpAiMIKPq98FuAIrwxBBw4cUE5OjsLCwmzLOnfurEWLFikvL08+PnxbiDsVDlWF714rfMSorOuUStvuUmGprP5KCmZl9eFT5LqnwkeuyrrQvLQAV3RcRwNd0dOVBXMo2kfR+Tkylq+vRXO3HdChP9+n0vorWtel5l6w3aUCnCMudcTwUqGtPKc13cnR8FnaNkWVFZbLUtrY5RmrIuM60l/hz6urbty43MBd0ffdW3hi/V4ZglJTU1WnTh35+/vbloWEhCgzM1OnT59W3bp1HerHx0clXth7OSwWqWmdqvJV/h+VgCq+CvDL/2AUfl3az1dyvcvpIyjAzyU1XqqPkxeybetV8bXI389HAX4+quJrUbPgaqX2V7Bd4W3K6qNto5paE/+bUs9mSpKuCammAD/fEscqa04l/SzlB7P39h/XifNZuiakms5ezNaJ81m2sQrPo/B6BXMoqY/C83NkrGtCqsnft/T1Co9VuM9Lzb1gO3+//OBmsfjIx8eirfuP62Sh9QrPo6Sfi/ZXeFxJqlvdXwPb1FdenmHXf9E+6tUMUP/W9YqFtsuZU3nbylqvtDrK6q/wNgVBz88vP7AX7aPwumUp7T0sa/uy3ndHxy3PPin4vJb1WaiowmM7Y+4V6aPovqxMSqq/f6t6ysuzD0IFNVb07++l/sem2PqGUdneykvbsmWL/vWvf+nTTz+1LUtJSVHfvn31+eefq2HDhm6cHQAA8ASecazXyQICApSVlWW3rOB1YODlX9cCAAAqP68MQQ0aNNCpU6eUk5NjW5aamqrAwEDVrFnTjTMDAACewitDUJs2beTn56fExETbsoSEBIWGhnJRNAAAkOSlISgoKEhDhgzR008/rT179uijjz7S66+/rlGjRrl7agAAwEN45YXRkpSRkaGnn35a27dvV/Xq1fX3v/9df/vb39w9LQAA4CG8NgQBAACUxStPhwEAAFwKIQgAAJgSIQgAAJgSIagCMjMz9fjjjys8PFw9evTQ66+/Xuq6+/bt0/Dhw2W1WjV06FDt3bvXrn3r1q3q27evrFarYmJidPLkSVubYRiaN2+eunXrpoiICM2ZM6fYI8Zd5UrVuG/fPrVq1cruX1RUlMvqKsyZNRZ49dVXNWXKFLtl3rIfC5RUozv3o+S8Og3D0JIlSxQZGalOnTrpvvvu08GDB+3aK/u+vFSN3vA7mZubq3nz5ql79+4KCwvTww8/rLS0NFu7N+zHS9XoDfuxsA8++ECtWrWq8DilMlBuM2bMMAYNGmTs3bvX2L59uxEWFmZ88MEHxda7cOGC0b17d+O5554zDh48aMycOdO44YYbjAsXLhiGYRhJSUlGhw4djM2bNxv79+837r33XiM6Otq2/bJly4xevXoZ33zzjbFjxw6jR48extKlS72qxrffftsYPHiwcfz4cdu/kydPVqoaC7z77rtGmzZtjMmTJ9st94b9WKC0Gt25Hw3DeXX++9//Nrp27Wp88sknxi+//GI8/vjjRu/evY309HTDMLxjX16qRm/4nVy4cKHRp08fIz4+3khOTjbuu+8+4/7777dt7w378VI1esN+LHDmzBmje/fuRsuWLSs0TlkIQeV04cIFIzQ01Ni5c6dtWVxcnHHvvfcWW3f9+vVGZGSkkZeXZxiGYeTl5Rk333yzsXHjRsMwDGPixIl2f0wOHz5stGrVyvj9998NwzCMXr162dY1DMPYsmWL0adPH5fUVdiVrPHFF180Hn30UVeWUyJn1pidnW1Mnz7dCA0NNW655ZZiAcEb9uOlanTXfjQM59Y5fPhwY/Hixbb1s7KyjI4dOxpffvmlYRjesS8vVaM3/E7Onz/f2L59u239jz76yOjQoYPttTfsx0vV6A37scC0adOMu+66yy4ElWecsnA6rJwOHDignJwchYWF2ZZ17txZSUlJxQ6nJiUlqXPnzrL8+bW2FotFnTp1sj3JOikpSeHh4bb1r7rqKjVq1EhJSUk6duyYjhw5oi5dutiNc+jQIR0/ftyFFV65GiXp559/1tVXX+3SekrizBrT09P1448/at26dXb9SfKa/VhWjZL79qPk3DonTZqk2267zba+xWKRYRg6d+6c1+zLsmqUvON3csKECbr55pslSSdOnND69esVEREhyXt+J8uqUfKO/ShJ8fHxio+P17hx4yo8TlkIQeWUmpqqOnXqyN/f37YsJCREmZmZOn36dLF169evb7csODhYR48elSQdP3681PbU1FRJsmsPCQmRJNv2rnKlapTyf1H379+vQYMGqXfv3po+fbrOnz/vgqrsObPGmjVras2aNWrdunWJ40iVfz+WVaPkvv0oObfO8PBwNWzY0Na2fv165eTkqHPnzl6zL8uqUfKO38kCr7zyim644Qbt3r3bdh2bt+zHAiXVKHnHfszKytKTTz6p6dOnF/vy8/KMUxZCUDllZGTYvemSbK+LfnN9aesWrHfx4sVS2y9evGjXd1njONuVqjE7O1spKSnKzs7Ws88+q9mzZ2v37t2aOHGis0sqxpk1lsVb9mNZ3LkfJdfVmZSUpOeff15///vfVa9ePa/cl0Vr9LbfycGDB2vDhg26/vrrNXr0aJ0/f97r9mNJNXrLfoyLi1O7du3Uo0ePyxqnLH4OrwlJUkBAQLE3uOB10aRa2roF65XWHhQUZLczAwIC7MYJCgpyUjUlu1I1VqlSRTt37lRAQICqVKkiSXruuec0dOhQHTt2TA0aNHBqXY7MWyp/jWXxlv1YFnfuR8k1dX733XcaM2aMbrzxRj388MOSvG9fllSjt/1ONmvWTJI0Z84c3Xjjjdq+fbtatGhhW98b9mNJNUZFRVX6/fjTTz9p3bp1evfddy97nLJwJKicGjRooFOnTiknJ8e2LDU1VYGBgapZs2axdQvfsihJaWlptsN/pbXXq1fP9iEtOHRb+Od69eo5r6ASXKkaJal69eq2X1JJat68uaT88/au5MwaLzVOQd+Fx5Eq1368FHftR8n5de7atUujR49Wt27d9MILL8jHx8e2bUHfhceRKt++LK1GyTt+Jz/99FO7+QYEBKhp06Y6deqU1+zHsmqUKv9+3L59u86cOaObb75ZYWFhGjNmjCQpLCxM77zzTrnGKQshqJzatGkjPz8/uwu3EhISFBoaavcfEkmyWq367rvvZPz59WyGYWj37t2yWq229oSEBNv6R44c0ZEjR2S1WtWgQQM1atTIrj0hIUGNGjVy+A9TRV2pGg8ePKiwsDClpKTY2vfv3y8/Pz/b/924ijNrLIu37MeyuHM/Ss6t86efftIDDzygnj176uWXX7b7I+It+7KsGr3ld/L555/Xli1bbOufP39ev/76q5o3b+41+7GsGr1hP95777364IMPtGXLFm3ZskWzZs2SJG3ZskWRkZHlGqdM5bqXDIZhGMaTTz5pDBgwwEhKSjL+85//GJ06dTK2bdtmGIZhHD9+3MjIyDAMwzDOnTtndOvWzZg5c6aRnJxszJw50+jevbvtGQi7d+822rVrZ6xbt872DJ2xY8faxlm8eLHRo0cPY+fOncbOnTuNHj16GK+//rrX1Jibm2sMHjzYuO+++4wff/zR+Oabb4z+/fsbTz31VKWqsbDJkycXu33cG/ZjYUVrdPd+NAzn1XnnnXca/fv3Nw4fPmz3fJWC7b1hX5ZVo7v3pbNqXLVqldGlSxfjs88+M3766Sdj3Lhxxu23327k5uYahuEd+7GsGr1lPxa2c+fOYs8JKmscRxGCKiA9Pd2YNGmS0bFjR6NHjx7G8uXLbW0tW7a0e8ZBUlKSMWTIECM0NNQYNmyY8cMPP9j1tXHjRqNXr15Gx44djZiYGLuHWeXk5BjPPvusER4ebnTt2tWYO3eu7XkKrnalajx8+LARExNjhIeHGxEREcbMmTONzMxMl9dnGM6tsUBJIchb9mOBkmp05340DOfUefz4caNly5Yl/ivYvrLvS0dq9IbfydzcXGPx4sVG7969jQ4dOhgPPPCAcfToUVt7Zd+PjtToDfuxsJJCUFnjOMpiGH8ehwIAADARrgkCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCAACmRAgCUKns2LFDP//8s+31/Pnz1blzZ4WHh+v8+fP64IMPdOLECaePu2vXLrVq1crp/QJwHx6WCKBSadWqlVatWqWuXbvqzJkzioiI0MyZM9W9e3dJUmRkpD7++GM1adLEqeNmZWXpzJkzLv+STQBXDkeCAFRa58+flyRdf/31aty4sVz5/3T+/v4EIMDLEIIAeKRVq1apT58+Cg0NVVRUlL799ltFRkZKkkaNGqUpU6bYXvft21dTpkzRTTfdJEm66aabtGnTpkuOMXLkSC1btkz333+/OnTooGHDhum3337Tk08+qbCwMN1yyy2Kj4+XZH867I8//lCrVq20fft29e3bV6GhoRo7dqxOnz7tgncCgKsQggB4nH379mnOnDl66qmn9MEHHyg8PFyPPPKI1q1bJyn/OqBp06Zp/fr1kqT169cXe92/f3+HxoqLi9Mdd9yhTZs26dy5cxo2bJhCQkK0YcMGXXfddZo1a1ap2y5atEgvvviiVq9ere+//17Lly+/zMoBXEl+7p4AABR16NAhWSwWNWrUSE2aNNEjjzyiPn36qHbt2pKkWrVqqUaNGqpbt64kqW7dusVeBwYGOjRWnz591K9fP0n5R5Tef/99PfTQQ7JYLLrjjjsUExNT6rYPPfSQOnToIEkaNGiQvv/++4qWDMANCEEAPE6PHj3UsmVLDRo0SG3bttVNN92k4cOHy8/P+f/JKnwBdWBgoBo1aiSLxWJ7nZ2dXeq2zZo1s/1cvXr1MtcF4Hk4HQbA4wQFBWn9+vVauXKlIiIitGnTJkVFRenYsWNOH6tosPLxcfw/i1WqVHH2dABcQYQgAB7nu+++0+LFi9WtWzdNnTpVH374oTIzM5WQkFDmdgVHcADAEZwOA+BxAgMDFRcXp5CQEF1//fX65ptvlJ6erlatWqlq1apKTk5W27Zti20XFBQkSTpw4IDq1KmjatWqXempA6hEOBIEwOO0adNGs2fP1tKlS9WvXz8tWrRIc+fOVfPmzTVy5EjNmTNH8+fPL7Zd3bp1ddttt+mRRx6x3SkGAKXhidEAAMCUOBIEAABMiWuCAHil2bNna8OGDaW2jx07VuPGjbuCMwLgaTgdBsArnTx5UufOnSu1vVatWraHLwIwJ0IQAAAwJa4JAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApkQIAgAApvR/cNZXnmJAiPQAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x=df[TARGET])\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:51.747261Z",
     "start_time": "2023-06-06T16:34:51.529219Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847, 270) (212, 270) (361, 270) (1009, 270)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# rows to be fixed, do not reset indexes!\n",
    "df_zero = df_reg[df_reg[TARGET] == 0]\n",
    "df_nz = df_reg[df_reg[TARGET] != 0].reset_index(drop=True)\n",
    "\n",
    "# dataframe has been one hot encoded\n",
    "split_index = df_nz.index[df_nz['actor_actor_19'] == 1][0]\n",
    "\n",
    "df_train = df_nz[:split_index]\n",
    "df_test = df_nz[split_index:]\n",
    "\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.2, random_state=100)\n",
    "\n",
    "y_train = np.log10(df_train[TARGET].to_numpy())\n",
    "y_valid = np.log10(df_valid[TARGET].to_numpy())\n",
    "y_test = np.log10(df_test[TARGET].to_numpy())\n",
    "\n",
    "df_zero = df_zero.drop([TARGET], axis=1)\n",
    "df_train = df_train.drop([TARGET], axis=1)\n",
    "df_valid = df_valid.drop([TARGET], axis=1)\n",
    "df_test = df_test.drop([TARGET], axis=1)\n",
    "\n",
    "X_to_pred = df_zero.to_numpy()\n",
    "X_train = df_train.to_numpy()\n",
    "X_valid = df_valid.to_numpy()\n",
    "X_test = df_test.to_numpy()\n",
    "\n",
    "print(X_train.shape, X_valid.shape, X_test.shape, X_to_pred.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:51.762706Z",
     "start_time": "2023-06-06T16:34:51.750889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_selector = SelectKBest(score_func=f_regression, k='all')\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar([i for i in range(len(f_selector.scores_))], f_selector.scores_)\n",
    "plt.xlabel('Feature index')\n",
    "plt.ylabel('Estimated value')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:52.367832Z",
     "start_time": "2023-06-06T16:34:51.776380Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "      mfcc_q25    mfcc_q99  stft_mean  stft_std  stft_q25  mfcc_q25_w2   \n259 -18.582673  133.537021   0.391166  0.350493  0.037039   -25.548968  \\\n157  -2.432008  140.389436   0.618064  0.281252  0.400627   -11.883626   \n667 -10.434671  169.611666   0.499650  0.347630  0.142961   -18.150980   \n707 -11.989990  140.775630   0.500564  0.321720  0.203172   -19.689170   \n125  -6.579166   90.324497   0.475922  0.349201  0.106374   -15.118881   \n..         ...         ...        ...       ...       ...          ...   \n802 -10.531611  188.840487   0.448354  0.342674  0.105303   -16.788827   \n53  -10.841864  159.482310   0.512951  0.316919  0.221845   -20.016054   \n350  -7.651122  151.113206   0.543641  0.328328  0.233966   -13.594585   \n79  -10.683922  143.316089   0.513574  0.286984  0.275286   -11.417866   \n792  -2.116944  152.105091   0.636902  0.295871  0.413712   -10.847955   \n\n     mfcc_q50_w2  mfcc_q99_w2  stft_sum_w2  stft_q05_w2  stft_q25_w2   \n259   -14.335812   131.763970   316.827272     0.002076     0.019907  \\\n157     0.331137   157.141432   487.714941     0.047736     0.247174   \n667    -7.070016   177.324767   409.154710     0.007334     0.053486   \n707    -6.076445   132.367535   424.497157     0.012076     0.085660   \n125     0.000000    92.440168   351.456816     0.002707     0.027473   \n..           ...          ...          ...          ...          ...   \n802    -4.730709   181.582949   469.988087     0.016418     0.071749   \n53     -4.384253   176.553050   452.237700     0.045298     0.156050   \n350    -2.200245   156.181359   492.584031     0.025636     0.164514   \n79     -2.853683   147.437486   577.809521     0.057310     0.276032   \n792     0.000000   148.006489   482.397157     0.036796     0.246890   \n\n     stft_skew_w2   mfcc_sum_w3  mfcc_q25_w3  mfcc_q50_w3  mfcc_q75_w3   \n259      1.368237 -70611.711781   -25.377122   -12.167407    -1.477520  \\\n157     -0.016021 -37384.776127    -9.452207     0.308263     9.277478   \n667      0.865939 -39253.197492   -17.626914    -5.782738     6.776643   \n707      0.328339 -46073.398204   -21.128508   -10.204088     2.029520   \n125      0.804747 -39812.423944   -25.070787    -7.274005     9.855553   \n..            ...           ...          ...          ...          ...   \n802      0.886020 -54877.142055   -18.882193    -4.978764     7.866954   \n53       0.706239 -30872.660059   -18.504748    -4.311820    10.084295   \n350      0.347103 -38947.164248   -17.357152    -6.596020     6.551662   \n79       0.175891 -37772.767541   -16.525048    -5.833418     5.294950   \n792      0.027626 -28996.039009   -10.309630    -1.024038    10.095972   \n\n     mfcc_q99_w3  stft_q25_w3  sex_F  sex_M  \n259   141.949765     0.006469      1      0  \n157   208.015807     0.228734      0      1  \n667   182.314767     0.089444      0      1  \n707   174.004688     0.052809      1      0  \n125   124.347880     0.013650      1      0  \n..           ...          ...    ...    ...  \n802   207.137736     0.043049      0      1  \n53    166.648179     0.122665      0      1  \n350   192.158127     0.081348      1      0  \n79    171.602208     0.172040      0      1  \n792   213.165450     0.153596      0      1  \n\n[847 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mfcc_q25</th>\n      <th>mfcc_q99</th>\n      <th>stft_mean</th>\n      <th>stft_std</th>\n      <th>stft_q25</th>\n      <th>mfcc_q25_w2</th>\n      <th>mfcc_q50_w2</th>\n      <th>mfcc_q99_w2</th>\n      <th>stft_sum_w2</th>\n      <th>stft_q05_w2</th>\n      <th>stft_q25_w2</th>\n      <th>stft_skew_w2</th>\n      <th>mfcc_sum_w3</th>\n      <th>mfcc_q25_w3</th>\n      <th>mfcc_q50_w3</th>\n      <th>mfcc_q75_w3</th>\n      <th>mfcc_q99_w3</th>\n      <th>stft_q25_w3</th>\n      <th>sex_F</th>\n      <th>sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>259</th>\n      <td>-18.582673</td>\n      <td>133.537021</td>\n      <td>0.391166</td>\n      <td>0.350493</td>\n      <td>0.037039</td>\n      <td>-25.548968</td>\n      <td>-14.335812</td>\n      <td>131.763970</td>\n      <td>316.827272</td>\n      <td>0.002076</td>\n      <td>0.019907</td>\n      <td>1.368237</td>\n      <td>-70611.711781</td>\n      <td>-25.377122</td>\n      <td>-12.167407</td>\n      <td>-1.477520</td>\n      <td>141.949765</td>\n      <td>0.006469</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>-2.432008</td>\n      <td>140.389436</td>\n      <td>0.618064</td>\n      <td>0.281252</td>\n      <td>0.400627</td>\n      <td>-11.883626</td>\n      <td>0.331137</td>\n      <td>157.141432</td>\n      <td>487.714941</td>\n      <td>0.047736</td>\n      <td>0.247174</td>\n      <td>-0.016021</td>\n      <td>-37384.776127</td>\n      <td>-9.452207</td>\n      <td>0.308263</td>\n      <td>9.277478</td>\n      <td>208.015807</td>\n      <td>0.228734</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>-10.434671</td>\n      <td>169.611666</td>\n      <td>0.499650</td>\n      <td>0.347630</td>\n      <td>0.142961</td>\n      <td>-18.150980</td>\n      <td>-7.070016</td>\n      <td>177.324767</td>\n      <td>409.154710</td>\n      <td>0.007334</td>\n      <td>0.053486</td>\n      <td>0.865939</td>\n      <td>-39253.197492</td>\n      <td>-17.626914</td>\n      <td>-5.782738</td>\n      <td>6.776643</td>\n      <td>182.314767</td>\n      <td>0.089444</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>707</th>\n      <td>-11.989990</td>\n      <td>140.775630</td>\n      <td>0.500564</td>\n      <td>0.321720</td>\n      <td>0.203172</td>\n      <td>-19.689170</td>\n      <td>-6.076445</td>\n      <td>132.367535</td>\n      <td>424.497157</td>\n      <td>0.012076</td>\n      <td>0.085660</td>\n      <td>0.328339</td>\n      <td>-46073.398204</td>\n      <td>-21.128508</td>\n      <td>-10.204088</td>\n      <td>2.029520</td>\n      <td>174.004688</td>\n      <td>0.052809</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>-6.579166</td>\n      <td>90.324497</td>\n      <td>0.475922</td>\n      <td>0.349201</td>\n      <td>0.106374</td>\n      <td>-15.118881</td>\n      <td>0.000000</td>\n      <td>92.440168</td>\n      <td>351.456816</td>\n      <td>0.002707</td>\n      <td>0.027473</td>\n      <td>0.804747</td>\n      <td>-39812.423944</td>\n      <td>-25.070787</td>\n      <td>-7.274005</td>\n      <td>9.855553</td>\n      <td>124.347880</td>\n      <td>0.013650</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>802</th>\n      <td>-10.531611</td>\n      <td>188.840487</td>\n      <td>0.448354</td>\n      <td>0.342674</td>\n      <td>0.105303</td>\n      <td>-16.788827</td>\n      <td>-4.730709</td>\n      <td>181.582949</td>\n      <td>469.988087</td>\n      <td>0.016418</td>\n      <td>0.071749</td>\n      <td>0.886020</td>\n      <td>-54877.142055</td>\n      <td>-18.882193</td>\n      <td>-4.978764</td>\n      <td>7.866954</td>\n      <td>207.137736</td>\n      <td>0.043049</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>-10.841864</td>\n      <td>159.482310</td>\n      <td>0.512951</td>\n      <td>0.316919</td>\n      <td>0.221845</td>\n      <td>-20.016054</td>\n      <td>-4.384253</td>\n      <td>176.553050</td>\n      <td>452.237700</td>\n      <td>0.045298</td>\n      <td>0.156050</td>\n      <td>0.706239</td>\n      <td>-30872.660059</td>\n      <td>-18.504748</td>\n      <td>-4.311820</td>\n      <td>10.084295</td>\n      <td>166.648179</td>\n      <td>0.122665</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>-7.651122</td>\n      <td>151.113206</td>\n      <td>0.543641</td>\n      <td>0.328328</td>\n      <td>0.233966</td>\n      <td>-13.594585</td>\n      <td>-2.200245</td>\n      <td>156.181359</td>\n      <td>492.584031</td>\n      <td>0.025636</td>\n      <td>0.164514</td>\n      <td>0.347103</td>\n      <td>-38947.164248</td>\n      <td>-17.357152</td>\n      <td>-6.596020</td>\n      <td>6.551662</td>\n      <td>192.158127</td>\n      <td>0.081348</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>-10.683922</td>\n      <td>143.316089</td>\n      <td>0.513574</td>\n      <td>0.286984</td>\n      <td>0.275286</td>\n      <td>-11.417866</td>\n      <td>-2.853683</td>\n      <td>147.437486</td>\n      <td>577.809521</td>\n      <td>0.057310</td>\n      <td>0.276032</td>\n      <td>0.175891</td>\n      <td>-37772.767541</td>\n      <td>-16.525048</td>\n      <td>-5.833418</td>\n      <td>5.294950</td>\n      <td>171.602208</td>\n      <td>0.172040</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>792</th>\n      <td>-2.116944</td>\n      <td>152.105091</td>\n      <td>0.636902</td>\n      <td>0.295871</td>\n      <td>0.413712</td>\n      <td>-10.847955</td>\n      <td>0.000000</td>\n      <td>148.006489</td>\n      <td>482.397157</td>\n      <td>0.036796</td>\n      <td>0.246890</td>\n      <td>0.027626</td>\n      <td>-28996.039009</td>\n      <td>-10.309630</td>\n      <td>-1.024038</td>\n      <td>10.095972</td>\n      <td>213.165450</td>\n      <td>0.153596</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>847 rows Ã— 20 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_selector = SelectKBest(score_func=f_regression, k=20)\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "X_train = f_selector.transform(X_train)\n",
    "X_valid = f_selector.transform(X_valid)\n",
    "X_test = f_selector.transform(X_test)\n",
    "X_to_pred = f_selector.transform(X_to_pred)\n",
    "\n",
    "# selected columns\n",
    "selected_indices = f_selector.get_support(indices=True)\n",
    "df_train.iloc[:, selected_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:52.391067Z",
     "start_time": "2023-06-06T16:34:52.355780Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_to_pred = scaler.fit_transform(X_to_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:52.478283Z",
     "start_time": "2023-06-06T16:34:52.401180Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:34:52,703] A new study created in memory with name: no-name-7d9a19ad-9e9c-4ad8-92de-8335eb5b9b51\n",
      "[I 2023-06-06 18:34:53,010] Trial 0 finished with value: 0.11062560721036152 and parameters: {'booster': 'dart', 'gamma': 3.703844713417619, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.49664111945153055}. Best is trial 0 with value: 0.11062560721036152.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "\n",
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    booster = trial.suggest_categorical('booster', ['gbtree', 'dart'])\n",
    "    gamma = trial.suggest_float('gamma', 0, 5)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 3)\n",
    "    subsample = trial.suggest_float('subsample', 0.4, 1)\n",
    "\n",
    "    xgb = XGBRegressor(booster=booster, gamma=gamma, max_depth=max_depth, min_child_weight=min_child_weight, subsample=subsample)\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_valid)\n",
    "\n",
    "    error = mean_squared_error(y_valid, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective_fun, n_trials=1, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:53.024253Z",
     "start_time": "2023-06-06T16:34:52.411297Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'dart', 'gamma': 3.703844713417619, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.49664111945153055}\n",
      "Root mean squared error = 0.3840\n",
      "R-squared = 0.6778\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "xgb = XGBRegressor(**best_params)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "print(best_params)\n",
    "print('Root mean squared error = %.4f' % np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('R-squared = %.4f' % r2_score(y_test, y_pred_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:53.541174Z",
     "start_time": "2023-06-06T16:34:53.025803Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.01006559, 0.01006559, 0.00795419, ..., 0.00016802, 0.00013427,\n       0.00013427], dtype=float32)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_to_pred)\n",
    "y_pred = np.power(10, y_pred)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:53.558645Z",
     "start_time": "2023-06-06T16:34:53.542157Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative values predicted\n",
    "np.count_nonzero(y_pred < 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:53.585802Z",
     "start_time": "2023-06-06T16:34:53.562155Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df_zero[TARGET] = y_pred\n",
    "df.update(df_zero)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:53.586563Z",
     "start_time": "2023-06-06T16:34:53.566428Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x=TARGET)\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:53.757763Z",
     "start_time": "2023-06-06T16:34:53.591318Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x=TARGET, log_scale=True)\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:34:54.187972Z",
     "start_time": "2023-06-06T16:34:53.758325Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:34:56,743] A new study created in memory with name: no-name-082e73ba-ce31-465f-8687-7a4f869cf1be\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x2994edee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x2994edee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:34:59,288] Trial 7 finished with value: 0.16050885109453394 and parameters: {'n_hidden': 1, 'n_units': 49, 'learning_rate': 0.06784879239092631}. Best is trial 7 with value: 0.16050885109453394.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:34:59,318] Trial 6 finished with value: 0.15821098462041855 and parameters: {'n_hidden': 1, 'n_units': 122, 'learning_rate': 0.0153557452296386}. Best is trial 6 with value: 0.15821098462041855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:34:59,362] Trial 3 finished with value: 0.1609158237630155 and parameters: {'n_hidden': 2, 'n_units': 40, 'learning_rate': 0.0901492527326611}. Best is trial 6 with value: 0.15821098462041855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:34:59,435] Trial 4 finished with value: 0.1895827836327629 and parameters: {'n_hidden': 3, 'n_units': 128, 'learning_rate': 0.08492206916603057}. Best is trial 6 with value: 0.15821098462041855.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:34:59,452] Trial 2 finished with value: 0.14703826107099102 and parameters: {'n_hidden': 1, 'n_units': 35, 'learning_rate': 0.011798972860688423}. Best is trial 2 with value: 0.14703826107099102.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step\n",
      "7/7 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:34:59,543] Trial 5 finished with value: 0.19046161376208848 and parameters: {'n_hidden': 3, 'n_units': 95, 'learning_rate': 0.026094479772101567}. Best is trial 2 with value: 0.14703826107099102.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:34:59,557] Trial 0 finished with value: 0.14986720621274952 and parameters: {'n_hidden': 3, 'n_units': 126, 'learning_rate': 0.01761650459366454}. Best is trial 2 with value: 0.14703826107099102.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:34:59,583] Trial 1 finished with value: 0.17047726668769464 and parameters: {'n_hidden': 1, 'n_units': 53, 'learning_rate': 0.06227228418484587}. Best is trial 2 with value: 0.14703826107099102.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:01,906] Trial 8 finished with value: 0.1977125477859595 and parameters: {'n_hidden': 2, 'n_units': 85, 'learning_rate': 0.05004549846679425}. Best is trial 2 with value: 0.14703826107099102.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:02,012] Trial 12 finished with value: 0.1467013127062448 and parameters: {'n_hidden': 2, 'n_units': 35, 'learning_rate': 0.030908537956130622}. Best is trial 12 with value: 0.1467013127062448.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:02,114] Trial 11 finished with value: 0.18363263602812724 and parameters: {'n_hidden': 2, 'n_units': 127, 'learning_rate': 0.04872141813425359}. Best is trial 12 with value: 0.1467013127062448.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:02,198] Trial 10 finished with value: 0.18666981666578128 and parameters: {'n_hidden': 3, 'n_units': 54, 'learning_rate': 0.016817329432873816}. Best is trial 12 with value: 0.1467013127062448.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:02,296] Trial 15 finished with value: 0.14838061241289044 and parameters: {'n_hidden': 3, 'n_units': 49, 'learning_rate': 0.01788386817312971}. Best is trial 12 with value: 0.1467013127062448.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 15ms/step\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:02,647] Trial 14 finished with value: 0.2276928124448776 and parameters: {'n_hidden': 2, 'n_units': 102, 'learning_rate': 0.09204905895105228}. Best is trial 12 with value: 0.1467013127062448.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:02,721] Trial 13 finished with value: 0.13232557886534113 and parameters: {'n_hidden': 3, 'n_units': 107, 'learning_rate': 0.03086232790788675}. Best is trial 13 with value: 0.13232557886534113.\n",
      "[I 2023-06-06 18:35:02,774] Trial 9 finished with value: 0.21109850030458338 and parameters: {'n_hidden': 2, 'n_units': 127, 'learning_rate': 0.05369001764298745}. Best is trial 13 with value: 0.13232557886534113.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:04,524] Trial 16 finished with value: 0.16766236424111375 and parameters: {'n_hidden': 1, 'n_units': 93, 'learning_rate': 0.08737683374683997}. Best is trial 13 with value: 0.13232557886534113.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:04,699] Trial 19 finished with value: 0.15573087189913304 and parameters: {'n_hidden': 1, 'n_units': 32, 'learning_rate': 0.006949572615045051}. Best is trial 13 with value: 0.13232557886534113.\n",
      "[I 2023-06-06 18:35:04,703] Trial 18 finished with value: 0.1967032752662156 and parameters: {'n_hidden': 1, 'n_units': 34, 'learning_rate': 0.0005229167709979166}. Best is trial 13 with value: 0.13232557886534113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:04,863] Trial 17 finished with value: 0.11211784893340758 and parameters: {'n_hidden': 2, 'n_units': 67, 'learning_rate': 0.032975421691815}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:04,893] Trial 20 finished with value: 0.14668757004558622 and parameters: {'n_hidden': 1, 'n_units': 32, 'learning_rate': 0.006559230108338235}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:05,095] Trial 21 finished with value: 0.18762979108887523 and parameters: {'n_hidden': 1, 'n_units': 32, 'learning_rate': 0.0016740942806373928}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 26ms/step\n",
      "1/7 [===>..........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:05,569] Trial 22 finished with value: 0.11819825767656726 and parameters: {'n_hidden': 2, 'n_units': 65, 'learning_rate': 0.031167573267385236}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:05,699] Trial 23 finished with value: 0.2000754542908009 and parameters: {'n_hidden': 2, 'n_units': 68, 'learning_rate': 0.03537559526150647}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:07,452] Trial 24 finished with value: 0.13888781374350115 and parameters: {'n_hidden': 2, 'n_units': 64, 'learning_rate': 0.033942468221902784}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 13ms/step\n",
      "7/7 [==============================] - 0s 10ms/step\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "7/7 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:07,835] Trial 29 finished with value: 0.1484050514218046 and parameters: {'n_hidden': 2, 'n_units': 69, 'learning_rate': 0.033971987927065295}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:07,867] Trial 26 finished with value: 0.1646878621898033 and parameters: {'n_hidden': 2, 'n_units': 70, 'learning_rate': 0.032901769127046815}. Best is trial 17 with value: 0.11211784893340758.\n",
      "[I 2023-06-06 18:35:07,876] Trial 28 finished with value: 0.12853378934318824 and parameters: {'n_hidden': 2, 'n_units': 68, 'learning_rate': 0.0346033394147815}. Best is trial 17 with value: 0.11211784893340758.\n",
      "[I 2023-06-06 18:35:07,893] Trial 30 finished with value: 0.1383403333068532 and parameters: {'n_hidden': 2, 'n_units': 70, 'learning_rate': 0.03531610007114392}. Best is trial 17 with value: 0.11211784893340758.\n",
      "[I 2023-06-06 18:35:07,936] Trial 27 finished with value: 0.1325102720036865 and parameters: {'n_hidden': 2, 'n_units': 68, 'learning_rate': 0.03594105091861508}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:08,154] Trial 31 finished with value: 0.18272919322253373 and parameters: {'n_hidden': 2, 'n_units': 69, 'learning_rate': 0.03842260084175882}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:08,873] Trial 25 finished with value: 0.12789067339529808 and parameters: {'n_hidden': 2, 'n_units': 68, 'learning_rate': 0.03034445120273249}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:10,197] Trial 32 finished with value: 0.1438449377065016 and parameters: {'n_hidden': 2, 'n_units': 74, 'learning_rate': 0.04156803996327599}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:10,552] Trial 35 finished with value: 0.11708670303651869 and parameters: {'n_hidden': 2, 'n_units': 78, 'learning_rate': 0.04175777156135048}. Best is trial 17 with value: 0.11211784893340758.\n",
      "[I 2023-06-06 18:35:10,556] Trial 34 finished with value: 0.12501528818595156 and parameters: {'n_hidden': 2, 'n_units': 78, 'learning_rate': 0.04156093163558196}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:10,727] Trial 37 finished with value: 0.1419186525159503 and parameters: {'n_hidden': 2, 'n_units': 79, 'learning_rate': 0.023458933769559417}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:10,861] Trial 33 finished with value: 0.15993205813063743 and parameters: {'n_hidden': 3, 'n_units': 114, 'learning_rate': 0.041645176226239894}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 16ms/step\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:11,291] Trial 38 finished with value: 0.13116891789655952 and parameters: {'n_hidden': 3, 'n_units': 79, 'learning_rate': 0.026942762729811418}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:11,436] Trial 36 finished with value: 0.1533448685997027 and parameters: {'n_hidden': 2, 'n_units': 79, 'learning_rate': 0.02313993538813907}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:11,772] Trial 39 finished with value: 0.12939885869017465 and parameters: {'n_hidden': 2, 'n_units': 78, 'learning_rate': 0.024169143276410076}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:13,095] Trial 40 finished with value: 0.17521039628638646 and parameters: {'n_hidden': 2, 'n_units': 58, 'learning_rate': 0.02344144195211369}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step\n",
      "7/7 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:13,364] Trial 42 finished with value: 0.13440806408503936 and parameters: {'n_hidden': 2, 'n_units': 80, 'learning_rate': 0.04452740545835965}. Best is trial 17 with value: 0.11211784893340758.\n",
      "[I 2023-06-06 18:35:13,396] Trial 41 finished with value: 0.16170249476283818 and parameters: {'n_hidden': 2, 'n_units': 81, 'learning_rate': 0.024017354448991873}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:13,518] Trial 43 finished with value: 0.11585547664651602 and parameters: {'n_hidden': 3, 'n_units': 58, 'learning_rate': 0.042281753991978054}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:13,692] Trial 44 finished with value: 0.1835416879307717 and parameters: {'n_hidden': 2, 'n_units': 81, 'learning_rate': 0.02254014136455732}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:13,866] Trial 45 finished with value: 0.15103847639329804 and parameters: {'n_hidden': 2, 'n_units': 58, 'learning_rate': 0.022656485345965642}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:14,036] Trial 46 finished with value: 0.13615880775324316 and parameters: {'n_hidden': 2, 'n_units': 87, 'learning_rate': 0.04561868120218781}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:14,423] Trial 47 finished with value: 0.1283726608878033 and parameters: {'n_hidden': 2, 'n_units': 58, 'learning_rate': 0.043927467392550705}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:16,100] Trial 48 finished with value: 0.12232460636499892 and parameters: {'n_hidden': 2, 'n_units': 88, 'learning_rate': 0.04244748519300145}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:16,287] Trial 50 finished with value: 0.12677442658629245 and parameters: {'n_hidden': 2, 'n_units': 61, 'learning_rate': 0.055706300089418945}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:16,363] Trial 49 finished with value: 0.16194608368814145 and parameters: {'n_hidden': 2, 'n_units': 61, 'learning_rate': 0.04520059902395726}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 9ms/step\n",
      "7/7 [==============================] - 0s 8ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:16,796] Trial 51 finished with value: 0.3968948898934489 and parameters: {'n_hidden': 3, 'n_units': 88, 'learning_rate': 0.053214481343783114}. Best is trial 17 with value: 0.11211784893340758.\n",
      "[I 2023-06-06 18:35:16,804] Trial 52 finished with value: 0.33396269489780583 and parameters: {'n_hidden': 3, 'n_units': 61, 'learning_rate': 0.05718058627426704}. Best is trial 17 with value: 0.11211784893340758.\n",
      "[I 2023-06-06 18:35:16,842] Trial 54 finished with value: 0.14089683747288723 and parameters: {'n_hidden': 3, 'n_units': 47, 'learning_rate': 0.054639404461860136}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:17,046] Trial 53 finished with value: 0.2756050962422651 and parameters: {'n_hidden': 3, 'n_units': 89, 'learning_rate': 0.057166308825632714}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:18,089] Trial 55 finished with value: 0.5972730583156407 and parameters: {'n_hidden': 3, 'n_units': 45, 'learning_rate': 0.05620296860335383}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:19,164] Trial 56 finished with value: 0.2119784874209605 and parameters: {'n_hidden': 3, 'n_units': 91, 'learning_rate': 0.05495407258211489}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:19,380] Trial 58 finished with value: 0.14626837344172797 and parameters: {'n_hidden': 3, 'n_units': 88, 'learning_rate': 0.038846404062036384}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:19,459] Trial 57 finished with value: 0.131684641390005 and parameters: {'n_hidden': 3, 'n_units': 51, 'learning_rate': 0.04863594632277626}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:19,833] Trial 60 finished with value: 0.12936825468947477 and parameters: {'n_hidden': 2, 'n_units': 92, 'learning_rate': 0.039432315489334374}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 11ms/step\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:20,054] Trial 59 finished with value: 0.12762316761931916 and parameters: {'n_hidden': 2, 'n_units': 46, 'learning_rate': 0.03963265763232868}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:20,210] Trial 61 finished with value: 0.1372114191429346 and parameters: {'n_hidden': 2, 'n_units': 96, 'learning_rate': 0.03964281066965965}. Best is trial 17 with value: 0.11211784893340758.\n",
      "[I 2023-06-06 18:35:20,263] Trial 62 finished with value: 0.163262838958142 and parameters: {'n_hidden': 2, 'n_units': 98, 'learning_rate': 0.05080480392343953}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:21,350] Trial 63 finished with value: 0.14977338198739767 and parameters: {'n_hidden': 2, 'n_units': 96, 'learning_rate': 0.040314887451481006}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:22,421] Trial 65 finished with value: 0.11738314984984234 and parameters: {'n_hidden': 2, 'n_units': 97, 'learning_rate': 0.04770814265100533}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:22,449] Trial 64 finished with value: 0.1312682932431147 and parameters: {'n_hidden': 2, 'n_units': 98, 'learning_rate': 0.03983020835306224}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:22,676] Trial 67 finished with value: 0.1419739626990277 and parameters: {'n_hidden': 2, 'n_units': 75, 'learning_rate': 0.02979174036937868}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 19ms/step\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:23,122] Trial 68 finished with value: 0.16014454103333586 and parameters: {'n_hidden': 2, 'n_units': 99, 'learning_rate': 0.048384360777055324}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:23,170] Trial 66 finished with value: 0.13398520537789374 and parameters: {'n_hidden': 2, 'n_units': 98, 'learning_rate': 0.039563678332826556}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step\n",
      "7/7 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:23,360] Trial 69 finished with value: 0.16031878997158025 and parameters: {'n_hidden': 2, 'n_units': 74, 'learning_rate': 0.04983077763086277}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:23,420] Trial 70 finished with value: 0.16011550953200418 and parameters: {'n_hidden': 2, 'n_units': 73, 'learning_rate': 0.028915165654156704}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:24,311] Trial 71 finished with value: 0.13787269900079085 and parameters: {'n_hidden': 2, 'n_units': 84, 'learning_rate': 0.02972191704224797}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:25,288] Trial 72 finished with value: 0.14408442100103247 and parameters: {'n_hidden': 2, 'n_units': 107, 'learning_rate': 0.030075450019583855}. Best is trial 17 with value: 0.11211784893340758.\n",
      "[I 2023-06-06 18:35:25,325] Trial 73 finished with value: 0.16560215056717675 and parameters: {'n_hidden': 2, 'n_units': 73, 'learning_rate': 0.03049603613480969}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:25,550] Trial 74 finished with value: 0.15235007854243485 and parameters: {'n_hidden': 2, 'n_units': 84, 'learning_rate': 0.03635777148136857}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:25,702] Trial 75 finished with value: 0.20763877916744405 and parameters: {'n_hidden': 1, 'n_units': 84, 'learning_rate': 0.04331158101891629}. Best is trial 17 with value: 0.11211784893340758.\n",
      "[I 2023-06-06 18:35:25,741] Trial 76 finished with value: 0.1470336135269963 and parameters: {'n_hidden': 1, 'n_units': 73, 'learning_rate': 0.03663186184698913}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n",
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:26,258] Trial 78 finished with value: 0.14264383217695867 and parameters: {'n_hidden': 2, 'n_units': 64, 'learning_rate': 0.036440812281806366}. Best is trial 17 with value: 0.11211784893340758.\n",
      "[I 2023-06-06 18:35:26,272] Trial 77 finished with value: 0.18274408383881782 and parameters: {'n_hidden': 1, 'n_units': 64, 'learning_rate': 0.036804882898224554}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:27,422] Trial 79 finished with value: 0.14369970858462167 and parameters: {'n_hidden': 2, 'n_units': 64, 'learning_rate': 0.03691071075812469}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:28,196] Trial 80 finished with value: 0.1307943303308966 and parameters: {'n_hidden': 2, 'n_units': 64, 'learning_rate': 0.0368890892005769}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:28,437] Trial 82 finished with value: 0.11321655164284578 and parameters: {'n_hidden': 1, 'n_units': 65, 'learning_rate': 0.04321989605538901}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:28,549] Trial 83 finished with value: 0.17791464817513675 and parameters: {'n_hidden': 2, 'n_units': 65, 'learning_rate': 0.04585567678252972}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:28,771] Trial 84 finished with value: 0.12318262416671144 and parameters: {'n_hidden': 2, 'n_units': 64, 'learning_rate': 0.046208143821886295}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:28,815] Trial 81 finished with value: 0.157855646690729 and parameters: {'n_hidden': 2, 'n_units': 64, 'learning_rate': 0.036519840976495695}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:28,948] Trial 85 finished with value: 0.14846214412777842 and parameters: {'n_hidden': 2, 'n_units': 55, 'learning_rate': 0.0471458715809082}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/7 [========================>.....] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:29,136] Trial 86 finished with value: 0.1812213445958111 and parameters: {'n_hidden': 2, 'n_units': 54, 'learning_rate': 0.046477078268829505}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:30,196] Trial 87 finished with value: 0.13170185896946615 and parameters: {'n_hidden': 2, 'n_units': 54, 'learning_rate': 0.04727911689994697}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:31,087] Trial 88 finished with value: 0.14028187698554623 and parameters: {'n_hidden': 2, 'n_units': 39, 'learning_rate': 0.046571504212182833}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:31,463] Trial 89 finished with value: 0.14609188606839216 and parameters: {'n_hidden': 1, 'n_units': 104, 'learning_rate': 0.042434552817777416}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:31,646] Trial 91 finished with value: 0.11445656339666999 and parameters: {'n_hidden': 1, 'n_units': 54, 'learning_rate': 0.042469646572263216}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:31,772] Trial 93 finished with value: 0.11523140993789258 and parameters: {'n_hidden': 1, 'n_units': 55, 'learning_rate': 0.04206868546468064}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:31,786] Trial 92 finished with value: 0.17433407469291642 and parameters: {'n_hidden': 2, 'n_units': 54, 'learning_rate': 0.042952121926004}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:31,963] Trial 90 finished with value: 0.16860211715723072 and parameters: {'n_hidden': 1, 'n_units': 55, 'learning_rate': 0.04623681352918767}. Best is trial 17 with value: 0.11211784893340758.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:35:32,006] Trial 94 finished with value: 0.157536650419323 and parameters: {'n_hidden': 1, 'n_units': 77, 'learning_rate': 0.04215659447891695}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:32,480] Trial 95 finished with value: 0.1603140683645305 and parameters: {'n_hidden': 1, 'n_units': 76, 'learning_rate': 0.042617914510735835}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:32,731] Trial 96 finished with value: 0.15382483114692633 and parameters: {'n_hidden': 1, 'n_units': 60, 'learning_rate': 0.04251014617434541}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:32,843] Trial 97 finished with value: 0.1439824060165147 and parameters: {'n_hidden': 1, 'n_units': 67, 'learning_rate': 0.032336055892056036}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:32,883] Trial 98 finished with value: 0.1566649174955182 and parameters: {'n_hidden': 1, 'n_units': 76, 'learning_rate': 0.04336708228453849}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 557us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:35:32,909] Trial 99 finished with value: 0.12972665314295692 and parameters: {'n_hidden': 1, 'n_units': 57, 'learning_rate': 0.03389688474809812}. Best is trial 17 with value: 0.11211784893340758.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_model(trial):\n",
    "\n",
    "    n_hidden = trial.suggest_int('n_hidden', 1, 3)\n",
    "    n_units = trial.suggest_int('n_units', 32, 128)\n",
    "    learn_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_units, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "    for i in range(n_hidden):\n",
    "        model.add(Dense(n_units, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "                  metrics=tensorflow.keras.metrics.MeanSquaredError())\n",
    "    return model\n",
    "\n",
    "\n",
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_valid, y_valid), verbose=False)\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    error = mean_squared_error(y_valid, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective_fun, n_trials=100, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:35:32.914632Z",
     "start_time": "2023-06-06T16:34:54.191132Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 581us/step\n",
      "Root mean squared error = 2.7518\n",
      "R-squared = -15.5430\n"
     ]
    }
   ],
   "source": [
    "model = create_model(study.best_trial)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "print('Root mean squared error = %.4f' % np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('R-squared = %.4f' % r2_score(y_test, y_pred_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:35:33.021694Z",
     "start_time": "2023-06-06T16:35:32.915901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 433us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.44786194],\n       [0.45082343],\n       [0.44174415],\n       ...,\n       [0.6130293 ],\n       [0.59593785],\n       [0.6281475 ]], dtype=float32)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_to_pred)\n",
    "y_pred = np.power(10, y_pred)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:35:33.063645Z",
     "start_time": "2023-06-06T16:35:32.994881Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:35:33.063835Z",
     "start_time": "2023-06-06T16:35:33.051799Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

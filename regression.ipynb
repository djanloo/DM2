{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:55:16.425916Z",
     "start_time": "2023-06-06T16:55:16.215068Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.core.dtypes.common import is_numeric_dtype\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression, SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'dataset'\n",
    "DATASET = os.path.join(DATA_FOLDER, 'outliers_removed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:55:16.428770Z",
     "start_time": "2023-06-06T16:55:16.426902Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   frame_count       sum          mean       std       min       max   \n0       158558  0.145081  9.150000e-07  0.004001 -0.038422  0.040588  \\\n1       160160  0.114319  7.137790e-07  0.004283 -0.042603  0.048157   \n2       156956  0.149963  9.554485e-07  0.005084 -0.037018  0.058472   \n3       152152  0.139618  9.176213e-07  0.004886 -0.036652  0.062683   \n4       169769  0.137665  8.108948e-07  0.002956 -0.026245  0.026215   \n\n        q01       q05       q25  q75  ...  actor_actor_24  actor_actor_3   \n0 -0.012586 -0.005890 -0.000031  0.0  ...               0              0  \\\n1 -0.013550 -0.006104 -0.000031  0.0  ...               0              0   \n2 -0.015822 -0.007294  0.000000  0.0  ...               0              0   \n3 -0.014923 -0.006714 -0.000031  0.0  ...               0              0   \n4 -0.009399 -0.004364 -0.000031  0.0  ...               0              0   \n\n   actor_actor_4  actor_actor_5  actor_actor_6  actor_actor_7  actor_actor_8   \n0              0              0              0              0              0  \\\n1              0              0              0              0              0   \n2              0              0              0              0              0   \n3              0              0              0              0              0   \n4              0              0              0              0              0   \n\n   actor_actor_9  sex_F  sex_M  \n0              0      0      1  \n1              0      0      1  \n2              0      0      1  \n3              0      0      1  \n4              0      0      1  \n\n[5 rows x 285 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame_count</th>\n      <th>sum</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>q01</th>\n      <th>q05</th>\n      <th>q25</th>\n      <th>q75</th>\n      <th>...</th>\n      <th>actor_actor_24</th>\n      <th>actor_actor_3</th>\n      <th>actor_actor_4</th>\n      <th>actor_actor_5</th>\n      <th>actor_actor_6</th>\n      <th>actor_actor_7</th>\n      <th>actor_actor_8</th>\n      <th>actor_actor_9</th>\n      <th>sex_F</th>\n      <th>sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>158558</td>\n      <td>0.145081</td>\n      <td>9.150000e-07</td>\n      <td>0.004001</td>\n      <td>-0.038422</td>\n      <td>0.040588</td>\n      <td>-0.012586</td>\n      <td>-0.005890</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>160160</td>\n      <td>0.114319</td>\n      <td>7.137790e-07</td>\n      <td>0.004283</td>\n      <td>-0.042603</td>\n      <td>0.048157</td>\n      <td>-0.013550</td>\n      <td>-0.006104</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>156956</td>\n      <td>0.149963</td>\n      <td>9.554485e-07</td>\n      <td>0.005084</td>\n      <td>-0.037018</td>\n      <td>0.058472</td>\n      <td>-0.015822</td>\n      <td>-0.007294</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>152152</td>\n      <td>0.139618</td>\n      <td>9.176213e-07</td>\n      <td>0.004886</td>\n      <td>-0.036652</td>\n      <td>0.062683</td>\n      <td>-0.014923</td>\n      <td>-0.006714</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>169769</td>\n      <td>0.137665</td>\n      <td>8.108948e-07</td>\n      <td>0.002956</td>\n      <td>-0.026245</td>\n      <td>0.026215</td>\n      <td>-0.009399</td>\n      <td>-0.004364</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 285 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET)\n",
    "\n",
    "categorical_attr_list = [col for col in df.columns if not is_numeric_dtype(df[col])]\n",
    "\n",
    "# one hot encoding\n",
    "df_reg = df.drop(columns=categorical_attr_list)\n",
    "df_reg = df_reg.join(pd.get_dummies(df[categorical_attr_list], columns=categorical_attr_list).astype(int))\n",
    "\n",
    "df_reg.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:55:16.512528Z",
     "start_time": "2023-06-06T16:55:16.430191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "stft_min    False\nsc_min      False\ndtype: bool"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_correct = ['stft_min', 'sc_min']\n",
    "(df[features_to_correct] < 0).any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:55:16.516709Z",
     "start_time": "2023-06-06T16:55:16.514621Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# stft_min"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['mfcc_q50',\n 'sc_q01',\n 'sc_q05',\n 'stft_q01',\n 'stft_q05',\n 'mfcc_q25_w1',\n 'mfcc_q50_w1',\n 'sc_q05_w1',\n 'sc_q25_w1',\n 'stft_q05_w1',\n 'q50_w2',\n 'q50_w3',\n 'lag1_q50_w3',\n 'q75_w4']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET = 'stft_min'\n",
    "\n",
    "# drop quantile columns with high percentage of zeros (20%)\n",
    "zero_percentage = (df_reg == 0).mean()\n",
    "to_drop = [col for col in df_reg.columns if zero_percentage[col] > 0.2 and re.search(r'q\\d{2}', col)]\n",
    "df_reg = df_reg.drop(columns=to_drop)\n",
    "to_drop"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:55:16.524184Z",
     "start_time": "2023-06-06T16:55:16.519093Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x=df[TARGET])\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:55:16.776014Z",
     "start_time": "2023-06-06T16:55:16.525901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847, 270) (212, 270) (361, 270) (1009, 270)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# rows to be fixed, do not reset indexes!\n",
    "df_zero = df_reg[df_reg[TARGET] == 0]\n",
    "df_nz = df_reg[df_reg[TARGET] != 0].reset_index(drop=True)\n",
    "\n",
    "# dataframe has been one hot encoded\n",
    "split_index = df_nz.index[df_nz['actor_actor_19'] == 1][0]\n",
    "\n",
    "df_train = df_nz[:split_index]\n",
    "df_test = df_nz[split_index:]\n",
    "\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.2, random_state=100)\n",
    "\n",
    "y_train = np.log10(df_train[TARGET].to_numpy())\n",
    "y_valid = np.log10(df_valid[TARGET].to_numpy())\n",
    "y_test = np.log10(df_test[TARGET].to_numpy())\n",
    "\n",
    "df_zero = df_zero.drop([TARGET], axis=1)\n",
    "df_train = df_train.drop([TARGET], axis=1)\n",
    "df_valid = df_valid.drop([TARGET], axis=1)\n",
    "df_test = df_test.drop([TARGET], axis=1)\n",
    "\n",
    "X_to_pred = df_zero.to_numpy()\n",
    "X_train = df_train.to_numpy()\n",
    "X_valid = df_valid.to_numpy()\n",
    "X_test = df_test.to_numpy()\n",
    "\n",
    "print(X_train.shape, X_valid.shape, X_test.shape, X_to_pred.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:55:16.780411Z",
     "start_time": "2023-06-06T16:55:16.772266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_selector = SelectKBest(score_func=f_regression, k='all')\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar([i for i in range(len(f_selector.scores_))], f_selector.scores_)\n",
    "plt.xlabel('Feature index')\n",
    "plt.ylabel('Estimated value')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:55:17.331118Z",
     "start_time": "2023-06-06T16:55:16.782490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "      mfcc_q25    mfcc_q99  stft_mean  stft_std  stft_q25  mfcc_q25_w2   \n259 -18.582673  133.537021   0.391166  0.350493  0.037039   -25.548968  \\\n157  -2.432008  140.389436   0.618064  0.281252  0.400627   -11.883626   \n667 -10.434671  169.611666   0.499650  0.347630  0.142961   -18.150980   \n707 -11.989990  140.775630   0.500564  0.321720  0.203172   -19.689170   \n125  -6.579166   90.324497   0.475922  0.349201  0.106374   -15.118881   \n..         ...         ...        ...       ...       ...          ...   \n802 -10.531611  188.840487   0.448354  0.342674  0.105303   -16.788827   \n53  -10.841864  159.482310   0.512951  0.316919  0.221845   -20.016054   \n350  -7.651122  151.113206   0.543641  0.328328  0.233966   -13.594585   \n79  -10.683922  143.316089   0.513574  0.286984  0.275286   -11.417866   \n792  -2.116944  152.105091   0.636902  0.295871  0.413712   -10.847955   \n\n     mfcc_q50_w2  mfcc_q99_w2  stft_sum_w2  stft_q05_w2  stft_q25_w2   \n259   -14.335812   131.763970   316.827272     0.002076     0.019907  \\\n157     0.331137   157.141432   487.714941     0.047736     0.247174   \n667    -7.070016   177.324767   409.154710     0.007334     0.053486   \n707    -6.076445   132.367535   424.497157     0.012076     0.085660   \n125     0.000000    92.440168   351.456816     0.002707     0.027473   \n..           ...          ...          ...          ...          ...   \n802    -4.730709   181.582949   469.988087     0.016418     0.071749   \n53     -4.384253   176.553050   452.237700     0.045298     0.156050   \n350    -2.200245   156.181359   492.584031     0.025636     0.164514   \n79     -2.853683   147.437486   577.809521     0.057310     0.276032   \n792     0.000000   148.006489   482.397157     0.036796     0.246890   \n\n     stft_skew_w2   mfcc_sum_w3  mfcc_q25_w3  mfcc_q50_w3  mfcc_q75_w3   \n259      1.368237 -70611.711781   -25.377122   -12.167407    -1.477520  \\\n157     -0.016021 -37384.776127    -9.452207     0.308263     9.277478   \n667      0.865939 -39253.197492   -17.626914    -5.782738     6.776643   \n707      0.328339 -46073.398204   -21.128508   -10.204088     2.029520   \n125      0.804747 -39812.423944   -25.070787    -7.274005     9.855553   \n..            ...           ...          ...          ...          ...   \n802      0.886020 -54877.142055   -18.882193    -4.978764     7.866954   \n53       0.706239 -30872.660059   -18.504748    -4.311820    10.084295   \n350      0.347103 -38947.164248   -17.357152    -6.596020     6.551662   \n79       0.175891 -37772.767541   -16.525048    -5.833418     5.294950   \n792      0.027626 -28996.039009   -10.309630    -1.024038    10.095972   \n\n     mfcc_q99_w3  stft_q25_w3  sex_F  sex_M  \n259   141.949765     0.006469      1      0  \n157   208.015807     0.228734      0      1  \n667   182.314767     0.089444      0      1  \n707   174.004688     0.052809      1      0  \n125   124.347880     0.013650      1      0  \n..           ...          ...    ...    ...  \n802   207.137736     0.043049      0      1  \n53    166.648179     0.122665      0      1  \n350   192.158127     0.081348      1      0  \n79    171.602208     0.172040      0      1  \n792   213.165450     0.153596      0      1  \n\n[847 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mfcc_q25</th>\n      <th>mfcc_q99</th>\n      <th>stft_mean</th>\n      <th>stft_std</th>\n      <th>stft_q25</th>\n      <th>mfcc_q25_w2</th>\n      <th>mfcc_q50_w2</th>\n      <th>mfcc_q99_w2</th>\n      <th>stft_sum_w2</th>\n      <th>stft_q05_w2</th>\n      <th>stft_q25_w2</th>\n      <th>stft_skew_w2</th>\n      <th>mfcc_sum_w3</th>\n      <th>mfcc_q25_w3</th>\n      <th>mfcc_q50_w3</th>\n      <th>mfcc_q75_w3</th>\n      <th>mfcc_q99_w3</th>\n      <th>stft_q25_w3</th>\n      <th>sex_F</th>\n      <th>sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>259</th>\n      <td>-18.582673</td>\n      <td>133.537021</td>\n      <td>0.391166</td>\n      <td>0.350493</td>\n      <td>0.037039</td>\n      <td>-25.548968</td>\n      <td>-14.335812</td>\n      <td>131.763970</td>\n      <td>316.827272</td>\n      <td>0.002076</td>\n      <td>0.019907</td>\n      <td>1.368237</td>\n      <td>-70611.711781</td>\n      <td>-25.377122</td>\n      <td>-12.167407</td>\n      <td>-1.477520</td>\n      <td>141.949765</td>\n      <td>0.006469</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>-2.432008</td>\n      <td>140.389436</td>\n      <td>0.618064</td>\n      <td>0.281252</td>\n      <td>0.400627</td>\n      <td>-11.883626</td>\n      <td>0.331137</td>\n      <td>157.141432</td>\n      <td>487.714941</td>\n      <td>0.047736</td>\n      <td>0.247174</td>\n      <td>-0.016021</td>\n      <td>-37384.776127</td>\n      <td>-9.452207</td>\n      <td>0.308263</td>\n      <td>9.277478</td>\n      <td>208.015807</td>\n      <td>0.228734</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>-10.434671</td>\n      <td>169.611666</td>\n      <td>0.499650</td>\n      <td>0.347630</td>\n      <td>0.142961</td>\n      <td>-18.150980</td>\n      <td>-7.070016</td>\n      <td>177.324767</td>\n      <td>409.154710</td>\n      <td>0.007334</td>\n      <td>0.053486</td>\n      <td>0.865939</td>\n      <td>-39253.197492</td>\n      <td>-17.626914</td>\n      <td>-5.782738</td>\n      <td>6.776643</td>\n      <td>182.314767</td>\n      <td>0.089444</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>707</th>\n      <td>-11.989990</td>\n      <td>140.775630</td>\n      <td>0.500564</td>\n      <td>0.321720</td>\n      <td>0.203172</td>\n      <td>-19.689170</td>\n      <td>-6.076445</td>\n      <td>132.367535</td>\n      <td>424.497157</td>\n      <td>0.012076</td>\n      <td>0.085660</td>\n      <td>0.328339</td>\n      <td>-46073.398204</td>\n      <td>-21.128508</td>\n      <td>-10.204088</td>\n      <td>2.029520</td>\n      <td>174.004688</td>\n      <td>0.052809</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>-6.579166</td>\n      <td>90.324497</td>\n      <td>0.475922</td>\n      <td>0.349201</td>\n      <td>0.106374</td>\n      <td>-15.118881</td>\n      <td>0.000000</td>\n      <td>92.440168</td>\n      <td>351.456816</td>\n      <td>0.002707</td>\n      <td>0.027473</td>\n      <td>0.804747</td>\n      <td>-39812.423944</td>\n      <td>-25.070787</td>\n      <td>-7.274005</td>\n      <td>9.855553</td>\n      <td>124.347880</td>\n      <td>0.013650</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>802</th>\n      <td>-10.531611</td>\n      <td>188.840487</td>\n      <td>0.448354</td>\n      <td>0.342674</td>\n      <td>0.105303</td>\n      <td>-16.788827</td>\n      <td>-4.730709</td>\n      <td>181.582949</td>\n      <td>469.988087</td>\n      <td>0.016418</td>\n      <td>0.071749</td>\n      <td>0.886020</td>\n      <td>-54877.142055</td>\n      <td>-18.882193</td>\n      <td>-4.978764</td>\n      <td>7.866954</td>\n      <td>207.137736</td>\n      <td>0.043049</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>-10.841864</td>\n      <td>159.482310</td>\n      <td>0.512951</td>\n      <td>0.316919</td>\n      <td>0.221845</td>\n      <td>-20.016054</td>\n      <td>-4.384253</td>\n      <td>176.553050</td>\n      <td>452.237700</td>\n      <td>0.045298</td>\n      <td>0.156050</td>\n      <td>0.706239</td>\n      <td>-30872.660059</td>\n      <td>-18.504748</td>\n      <td>-4.311820</td>\n      <td>10.084295</td>\n      <td>166.648179</td>\n      <td>0.122665</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>-7.651122</td>\n      <td>151.113206</td>\n      <td>0.543641</td>\n      <td>0.328328</td>\n      <td>0.233966</td>\n      <td>-13.594585</td>\n      <td>-2.200245</td>\n      <td>156.181359</td>\n      <td>492.584031</td>\n      <td>0.025636</td>\n      <td>0.164514</td>\n      <td>0.347103</td>\n      <td>-38947.164248</td>\n      <td>-17.357152</td>\n      <td>-6.596020</td>\n      <td>6.551662</td>\n      <td>192.158127</td>\n      <td>0.081348</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>-10.683922</td>\n      <td>143.316089</td>\n      <td>0.513574</td>\n      <td>0.286984</td>\n      <td>0.275286</td>\n      <td>-11.417866</td>\n      <td>-2.853683</td>\n      <td>147.437486</td>\n      <td>577.809521</td>\n      <td>0.057310</td>\n      <td>0.276032</td>\n      <td>0.175891</td>\n      <td>-37772.767541</td>\n      <td>-16.525048</td>\n      <td>-5.833418</td>\n      <td>5.294950</td>\n      <td>171.602208</td>\n      <td>0.172040</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>792</th>\n      <td>-2.116944</td>\n      <td>152.105091</td>\n      <td>0.636902</td>\n      <td>0.295871</td>\n      <td>0.413712</td>\n      <td>-10.847955</td>\n      <td>0.000000</td>\n      <td>148.006489</td>\n      <td>482.397157</td>\n      <td>0.036796</td>\n      <td>0.246890</td>\n      <td>0.027626</td>\n      <td>-28996.039009</td>\n      <td>-10.309630</td>\n      <td>-1.024038</td>\n      <td>10.095972</td>\n      <td>213.165450</td>\n      <td>0.153596</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>847 rows Ã— 20 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_selector = SelectKBest(score_func=f_regression, k=20)\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "X_train = f_selector.transform(X_train)\n",
    "X_valid = f_selector.transform(X_valid)\n",
    "X_test = f_selector.transform(X_test)\n",
    "X_to_pred = f_selector.transform(X_to_pred)\n",
    "\n",
    "# selected columns\n",
    "selected_indices = f_selector.get_support(indices=True)\n",
    "df_train.iloc[:, selected_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:55:17.489763Z",
     "start_time": "2023-06-06T16:55:17.332700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_to_pred = scaler.fit_transform(X_to_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:55:17.490038Z",
     "start_time": "2023-06-06T16:55:17.382087Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:55:17,594] A new study created in memory with name: no-name-cbe8de46-b1b7-4c12-9ff4-e1b2b34b77ce\n",
      "[I 2023-06-06 18:55:19,529] Trial 4 finished with value: 0.11796647465753987 and parameters: {'booster': 'gbtree', 'gamma': 1.7037425866491451, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.4156858596445524}. Best is trial 4 with value: 0.11796647465753987.\n",
      "[I 2023-06-06 18:55:20,859] Trial 0 finished with value: 0.10250763442487572 and parameters: {'booster': 'gbtree', 'gamma': 3.9110924420764532, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.9427092505420954}. Best is trial 0 with value: 0.10250763442487572.\n",
      "[I 2023-06-06 18:55:21,260] Trial 7 finished with value: 0.10851934395318798 and parameters: {'booster': 'dart', 'gamma': 3.960382159131991, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8149627386308748}. Best is trial 0 with value: 0.10250763442487572.\n",
      "[I 2023-06-06 18:55:22,047] Trial 5 finished with value: 0.09984923142932843 and parameters: {'booster': 'gbtree', 'gamma': 4.50385846629295, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.7236126737154256}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:22,138] Trial 2 finished with value: 0.1072137738204432 and parameters: {'booster': 'gbtree', 'gamma': 0.3307880643976835, 'max_depth': 17, 'min_child_weight': 3, 'subsample': 0.952419001038029}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:22,366] Trial 1 finished with value: 0.10586102012360489 and parameters: {'booster': 'gbtree', 'gamma': 3.7085124141894403, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.8429762092139987}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:22,455] Trial 3 finished with value: 0.10344954617566499 and parameters: {'booster': 'gbtree', 'gamma': 0.6878541612943662, 'max_depth': 20, 'min_child_weight': 3, 'subsample': 0.9415796360503599}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:22,673] Trial 6 finished with value: 0.1176804259341192 and parameters: {'booster': 'dart', 'gamma': 2.406533255001926, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.45837527022524766}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:23,030] Trial 8 finished with value: 0.10402808683555036 and parameters: {'booster': 'dart', 'gamma': 4.930147506815783, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.9622256638275279}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:26,237] Trial 10 finished with value: 0.1098379690106523 and parameters: {'booster': 'dart', 'gamma': 2.1192683544656177, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.664195726208759}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:27,317] Trial 15 finished with value: 0.10775657415302206 and parameters: {'booster': 'gbtree', 'gamma': 0.7364696621488709, 'max_depth': 16, 'min_child_weight': 1, 'subsample': 0.9333821041454832}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:27,510] Trial 9 finished with value: 0.11622015852910836 and parameters: {'booster': 'dart', 'gamma': 4.651898218700143, 'max_depth': 17, 'min_child_weight': 2, 'subsample': 0.5597354795038678}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:27,830] Trial 16 finished with value: 0.11376834991689219 and parameters: {'booster': 'dart', 'gamma': 4.035279845741386, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.5360334226129373}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:28,926] Trial 11 finished with value: 0.10138226285970817 and parameters: {'booster': 'dart', 'gamma': 3.6966405335241976, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.633989234095016}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:29,454] Trial 13 finished with value: 0.10079627163432137 and parameters: {'booster': 'dart', 'gamma': 3.1128804122448077, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.7548819953281931}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:29,576] Trial 12 finished with value: 0.10106816446648798 and parameters: {'booster': 'dart', 'gamma': 4.352724143304761, 'max_depth': 17, 'min_child_weight': 2, 'subsample': 0.8079555312702362}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:30,003] Trial 14 finished with value: 0.10178600769950684 and parameters: {'booster': 'dart', 'gamma': 1.5877065556977665, 'max_depth': 20, 'min_child_weight': 3, 'subsample': 0.9134866368032143}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:30,273] Trial 17 finished with value: 0.10448759587050369 and parameters: {'booster': 'gbtree', 'gamma': 4.839463354050019, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.6629464908168178}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:30,935] Trial 18 finished with value: 0.10710125402467419 and parameters: {'booster': 'gbtree', 'gamma': 3.4900545501700955, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.6688976616836941}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:31,100] Trial 19 finished with value: 0.10892907163709248 and parameters: {'booster': 'gbtree', 'gamma': 3.4799134779709755, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.7400237431871213}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:31,328] Trial 20 finished with value: 0.10027965805029505 and parameters: {'booster': 'gbtree', 'gamma': 3.172330680912614, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.7693901807030965}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:33,041] Trial 23 finished with value: 0.10359679860198272 and parameters: {'booster': 'gbtree', 'gamma': 3.011018063923793, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.7582937769473141}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:33,571] Trial 24 finished with value: 0.10117974634469995 and parameters: {'booster': 'gbtree', 'gamma': 3.25784866217391, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.7384201051112353}. Best is trial 5 with value: 0.09984923142932843.\n",
      "[I 2023-06-06 18:55:34,006] Trial 25 finished with value: 0.09626483240458396 and parameters: {'booster': 'gbtree', 'gamma': 3.111589032301432, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.7418582950035281}. Best is trial 25 with value: 0.09626483240458396.\n",
      "[I 2023-06-06 18:55:34,153] Trial 22 finished with value: 0.1014920086878931 and parameters: {'booster': 'gbtree', 'gamma': 3.0576879978310854, 'max_depth': 20, 'min_child_weight': 2, 'subsample': 0.7473439810041079}. Best is trial 25 with value: 0.09626483240458396.\n",
      "[I 2023-06-06 18:55:34,286] Trial 26 finished with value: 0.09603736986533955 and parameters: {'booster': 'gbtree', 'gamma': 3.0805391911211384, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.7507295203539861}. Best is trial 26 with value: 0.09603736986533955.\n",
      "[I 2023-06-06 18:55:34,589] Trial 28 finished with value: 0.10432300624046689 and parameters: {'booster': 'gbtree', 'gamma': 3.026613397117507, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.7329995145702186}. Best is trial 26 with value: 0.09603736986533955.\n",
      "[I 2023-06-06 18:55:35,512] Trial 21 finished with value: 0.10117221753960673 and parameters: {'booster': 'dart', 'gamma': 3.0560705432302506, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.7131971388180584}. Best is trial 26 with value: 0.09603736986533955.\n",
      "[I 2023-06-06 18:55:35,800] Trial 27 finished with value: 0.0951846044231484 and parameters: {'booster': 'gbtree', 'gamma': 3.103170331957249, 'max_depth': 19, 'min_child_weight': 2, 'subsample': 0.7405842529721048}. Best is trial 27 with value: 0.0951846044231484.\n",
      "[I 2023-06-06 18:55:35,991] Trial 33 finished with value: 0.1057393462223226 and parameters: {'booster': 'gbtree', 'gamma': 2.596902057530838, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.8682551873955932}. Best is trial 27 with value: 0.0951846044231484.\n",
      "[I 2023-06-06 18:55:37,044] Trial 31 finished with value: 0.10219733375382851 and parameters: {'booster': 'gbtree', 'gamma': 2.949914647211176, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.8690643131905864}. Best is trial 27 with value: 0.0951846044231484.\n",
      "[I 2023-06-06 18:55:37,088] Trial 32 finished with value: 0.10362272547150925 and parameters: {'booster': 'gbtree', 'gamma': 4.324966418630325, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.8608863422634934}. Best is trial 27 with value: 0.0951846044231484.\n",
      "[I 2023-06-06 18:55:37,146] Trial 29 finished with value: 0.10097710379090921 and parameters: {'booster': 'gbtree', 'gamma': 2.9672023001924814, 'max_depth': 19, 'min_child_weight': 3, 'subsample': 0.7303235430944522}. Best is trial 27 with value: 0.0951846044231484.\n",
      "[I 2023-06-06 18:55:37,487] Trial 34 finished with value: 0.10239118630992922 and parameters: {'booster': 'gbtree', 'gamma': 4.488873896698372, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.7001924727519494}. Best is trial 27 with value: 0.0951846044231484.\n",
      "[I 2023-06-06 18:55:37,647] Trial 30 finished with value: 0.09878718395174481 and parameters: {'booster': 'gbtree', 'gamma': 2.9918356092018525, 'max_depth': 19, 'min_child_weight': 3, 'subsample': 0.7186690744465546}. Best is trial 27 with value: 0.0951846044231484.\n",
      "[I 2023-06-06 18:55:38,654] Trial 36 finished with value: 0.10226290738431199 and parameters: {'booster': 'gbtree', 'gamma': 2.6468476123486484, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.8870393748544716}. Best is trial 27 with value: 0.0951846044231484.\n",
      "[I 2023-06-06 18:55:38,691] Trial 35 finished with value: 0.1032767961259402 and parameters: {'booster': 'gbtree', 'gamma': 4.520237761224426, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.8615924547866044}. Best is trial 27 with value: 0.0951846044231484.\n",
      "[I 2023-06-06 18:55:38,875] Trial 37 finished with value: 0.09366986453766302 and parameters: {'booster': 'gbtree', 'gamma': 2.6097726072333662, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.7908633556878183}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:40,116] Trial 45 finished with value: 0.09813719183439149 and parameters: {'booster': 'gbtree', 'gamma': 3.512141971298198, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.815201814710907}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:41,783] Trial 38 finished with value: 0.10442341304150586 and parameters: {'booster': 'gbtree', 'gamma': 4.129708597082081, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.7856410930912141}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:41,811] Trial 39 finished with value: 0.09938257314463823 and parameters: {'booster': 'gbtree', 'gamma': 3.753537952108314, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.802727339236552}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:41,885] Trial 40 finished with value: 0.09866119317623197 and parameters: {'booster': 'gbtree', 'gamma': 3.7536857261377543, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.7894874057280394}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:41,921] Trial 42 finished with value: 0.10396427796947343 and parameters: {'booster': 'gbtree', 'gamma': 2.7053355852958, 'max_depth': 18, 'min_child_weight': 3, 'subsample': 0.7974676714333033}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:42,240] Trial 41 finished with value: 0.10179647961450913 and parameters: {'booster': 'gbtree', 'gamma': 3.8456735592640086, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.7801982948751391}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:42,725] Trial 51 finished with value: 0.10590420811524633 and parameters: {'booster': 'gbtree', 'gamma': 3.3666110334689083, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8253254204386498}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:42,924] Trial 46 finished with value: 0.0988897967397458 and parameters: {'booster': 'gbtree', 'gamma': 2.2234349067504895, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.7809288948851709}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:43,134] Trial 49 finished with value: 0.10220345230883392 and parameters: {'booster': 'gbtree', 'gamma': 2.729018596037507, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8288591356414878}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:43,151] Trial 48 finished with value: 0.10712171180373517 and parameters: {'booster': 'gbtree', 'gamma': 3.519454664084707, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8322614584684974}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:43,571] Trial 50 finished with value: 0.10106134730369945 and parameters: {'booster': 'gbtree', 'gamma': 3.387703542592508, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8348384492346903}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:43,585] Trial 43 finished with value: 0.104239726350775 and parameters: {'booster': 'gbtree', 'gamma': 3.554730190775378, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.8245529883420177}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:43,705] Trial 44 finished with value: 0.09922317212302975 and parameters: {'booster': 'gbtree', 'gamma': 3.7135438982135636, 'max_depth': 18, 'min_child_weight': 1, 'subsample': 0.790184190289063}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:43,990] Trial 52 finished with value: 0.1032149454181431 and parameters: {'booster': 'gbtree', 'gamma': 3.4502461806518854, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8184482618958634}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:44,094] Trial 54 finished with value: 0.10588899236878317 and parameters: {'booster': 'gbtree', 'gamma': 3.5871523185547516, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8299003444881151}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:44,170] Trial 53 finished with value: 0.09928059917542863 and parameters: {'booster': 'gbtree', 'gamma': 3.5214678926916707, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8144240747007487}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:44,620] Trial 47 finished with value: 0.10288642198431129 and parameters: {'booster': 'gbtree', 'gamma': 3.7479923392218084, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.7965178662787327}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:44,961] Trial 55 finished with value: 0.11119143803000417 and parameters: {'booster': 'gbtree', 'gamma': 3.304101563814305, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.6868658786468469}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:45,518] Trial 57 finished with value: 0.10170494230341766 and parameters: {'booster': 'gbtree', 'gamma': 2.414167334042683, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9905283634981517}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:45,550] Trial 56 finished with value: 0.09494101387412693 and parameters: {'booster': 'gbtree', 'gamma': 2.3303784940688823, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.7626445519695524}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:46,342] Trial 58 finished with value: 0.09985824592271209 and parameters: {'booster': 'gbtree', 'gamma': 3.30854414582307, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.7667675468924896}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:46,617] Trial 59 finished with value: 0.09984145366759842 and parameters: {'booster': 'gbtree', 'gamma': 3.2797515606643515, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.7655154201769668}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:48,075] Trial 61 finished with value: 0.10108708338986346 and parameters: {'booster': 'gbtree', 'gamma': 2.8048778993884826, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.7540796892835078}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:48,198] Trial 60 finished with value: 0.09798185083266736 and parameters: {'booster': 'gbtree', 'gamma': 3.2544636096031234, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.7553328013002534}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:48,788] Trial 62 finished with value: 0.10075340836314971 and parameters: {'booster': 'gbtree', 'gamma': 3.2077062560293457, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.7549345180085107}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:51,570] Trial 63 finished with value: 0.1014342375996961 and parameters: {'booster': 'dart', 'gamma': 4.043736944688926, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.7779169949053062}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:52,060] Trial 64 finished with value: 0.10453631336434883 and parameters: {'booster': 'dart', 'gamma': 3.994839834019284, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.7586154168066022}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:52,301] Trial 65 finished with value: 0.10095768585675857 and parameters: {'booster': 'dart', 'gamma': 2.8295049304651108, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.7502188293715375}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:52,951] Trial 66 finished with value: 0.10110887314362411 and parameters: {'booster': 'dart', 'gamma': 2.802415795236249, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.750037512201715}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:53,348] Trial 67 finished with value: 0.09985126646078461 and parameters: {'booster': 'dart', 'gamma': 2.776058567692125, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.7578915650843252}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:54,130] Trial 68 finished with value: 0.09927680789601508 and parameters: {'booster': 'dart', 'gamma': 2.4910201665497973, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.7204671063499369}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:54,252] Trial 69 finished with value: 0.10140624359071869 and parameters: {'booster': 'dart', 'gamma': 2.796355831533196, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.7119914190846962}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:54,896] Trial 70 finished with value: 0.10223872100655201 and parameters: {'booster': 'dart', 'gamma': 2.4842469194840513, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.713073922128584}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:55,396] Trial 72 finished with value: 0.09862759533902048 and parameters: {'booster': 'gbtree', 'gamma': 2.8449800992949976, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.7083643641165382}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:55,398] Trial 73 finished with value: 0.10035148505763304 and parameters: {'booster': 'gbtree', 'gamma': 2.5334138664884804, 'max_depth': 12, 'min_child_weight': 3, 'subsample': 0.7213473063813315}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:56,359] Trial 75 finished with value: 0.09587388507751433 and parameters: {'booster': 'gbtree', 'gamma': 2.4835176657023816, 'max_depth': 12, 'min_child_weight': 3, 'subsample': 0.7241706494519125}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:56,360] Trial 77 finished with value: 0.10204366129860133 and parameters: {'booster': 'gbtree', 'gamma': 3.178910924524128, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.701719473613049}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:56,605] Trial 74 finished with value: 0.09573233715119678 and parameters: {'booster': 'gbtree', 'gamma': 2.5154054907963754, 'max_depth': 15, 'min_child_weight': 3, 'subsample': 0.71713470311108}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:57,132] Trial 76 finished with value: 0.09407469401894628 and parameters: {'booster': 'gbtree', 'gamma': 3.1358615355069444, 'max_depth': 12, 'min_child_weight': 3, 'subsample': 0.6960191706710891}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:57,497] Trial 71 finished with value: 0.09781725544068605 and parameters: {'booster': 'dart', 'gamma': 2.8377666489983238, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.7248548069319863}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:59,213] Trial 79 finished with value: 0.0939177839837843 and parameters: {'booster': 'gbtree', 'gamma': 3.138321511303348, 'max_depth': 16, 'min_child_weight': 3, 'subsample': 0.7330804462671691}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:59,302] Trial 78 finished with value: 0.10004458596456361 and parameters: {'booster': 'gbtree', 'gamma': 3.155267708823216, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.8040149845041299}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:55:59,666] Trial 80 finished with value: 0.09401677541813391 and parameters: {'booster': 'gbtree', 'gamma': 3.125409577825987, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.734413085368504}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:00,189] Trial 81 finished with value: 0.10218338426158226 and parameters: {'booster': 'gbtree', 'gamma': 2.240232530317128, 'max_depth': 16, 'min_child_weight': 3, 'subsample': 0.7401127179160694}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:00,221] Trial 82 finished with value: 0.10041192990094015 and parameters: {'booster': 'gbtree', 'gamma': 3.1215258234248133, 'max_depth': 16, 'min_child_weight': 3, 'subsample': 0.7362770993799251}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:00,298] Trial 84 finished with value: 0.10472436487181211 and parameters: {'booster': 'gbtree', 'gamma': 2.258921712670311, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.6809785089761613}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:00,416] Trial 83 finished with value: 0.09703190735618814 and parameters: {'booster': 'gbtree', 'gamma': 2.241634877598557, 'max_depth': 16, 'min_child_weight': 3, 'subsample': 0.7334906969509045}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:00,693] Trial 85 finished with value: 0.10084119290300675 and parameters: {'booster': 'gbtree', 'gamma': 2.3804569464948337, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.6790099264904018}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:02,960] Trial 86 finished with value: 0.09970774812994421 and parameters: {'booster': 'gbtree', 'gamma': 2.203098212814844, 'max_depth': 16, 'min_child_weight': 3, 'subsample': 0.6824121748871783}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:03,115] Trial 87 finished with value: 0.10490244039984542 and parameters: {'booster': 'gbtree', 'gamma': 2.2508859048671006, 'max_depth': 17, 'min_child_weight': 3, 'subsample': 0.6773406338494301}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:03,432] Trial 88 finished with value: 0.10074758818261449 and parameters: {'booster': 'gbtree', 'gamma': 2.329732865494737, 'max_depth': 17, 'min_child_weight': 3, 'subsample': 0.6809755273515241}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:03,993] Trial 90 finished with value: 0.10350188527223232 and parameters: {'booster': 'gbtree', 'gamma': 2.6523174225439177, 'max_depth': 17, 'min_child_weight': 3, 'subsample': 0.6677311523533084}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:04,068] Trial 89 finished with value: 0.09800320319412215 and parameters: {'booster': 'gbtree', 'gamma': 2.6442982902176624, 'max_depth': 17, 'min_child_weight': 3, 'subsample': 0.6854788746222392}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:04,195] Trial 91 finished with value: 0.09865199335494969 and parameters: {'booster': 'gbtree', 'gamma': 2.6085949980082432, 'max_depth': 17, 'min_child_weight': 3, 'subsample': 0.6888340165222275}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:04,326] Trial 92 finished with value: 0.10568187297182177 and parameters: {'booster': 'gbtree', 'gamma': 2.6606021563308877, 'max_depth': 17, 'min_child_weight': 3, 'subsample': 0.6927395645365495}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:04,451] Trial 93 finished with value: 0.09731363753667573 and parameters: {'booster': 'gbtree', 'gamma': 2.6322544928931424, 'max_depth': 17, 'min_child_weight': 3, 'subsample': 0.6488754510926013}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:05,750] Trial 95 finished with value: 0.11149797392146037 and parameters: {'booster': 'gbtree', 'gamma': 2.9536236133384683, 'max_depth': 15, 'min_child_weight': 3, 'subsample': 0.6533734587514711}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:05,767] Trial 94 finished with value: 0.10679541245417518 and parameters: {'booster': 'gbtree', 'gamma': 2.6344267855835954, 'max_depth': 15, 'min_child_weight': 3, 'subsample': 0.6985014049137761}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:05,857] Trial 97 finished with value: 0.10374128776218947 and parameters: {'booster': 'gbtree', 'gamma': 2.9884691324933406, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.6985036104764187}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:06,068] Trial 96 finished with value: 0.09943372709851327 and parameters: {'booster': 'gbtree', 'gamma': 2.6220651714873884, 'max_depth': 20, 'min_child_weight': 3, 'subsample': 0.6524395352867732}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:06,175] Trial 98 finished with value: 0.09718673844355964 and parameters: {'booster': 'gbtree', 'gamma': 2.977616812039691, 'max_depth': 15, 'min_child_weight': 3, 'subsample': 0.7722667772179671}. Best is trial 37 with value: 0.09366986453766302.\n",
      "[I 2023-06-06 18:56:06,195] Trial 99 finished with value: 0.1022136001368548 and parameters: {'booster': 'gbtree', 'gamma': 2.962266641272433, 'max_depth': 15, 'min_child_weight': 3, 'subsample': 0.7008629724911981}. Best is trial 37 with value: 0.09366986453766302.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "\n",
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    booster = trial.suggest_categorical('booster', ['gbtree', 'dart'])\n",
    "    gamma = trial.suggest_float('gamma', 0, 5)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 3)\n",
    "    subsample = trial.suggest_float('subsample', 0.4, 1)\n",
    "\n",
    "    xgb = XGBRegressor(booster=booster, gamma=gamma, max_depth=max_depth, min_child_weight=min_child_weight, subsample=subsample)\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_valid)\n",
    "\n",
    "    error = mean_squared_error(y_valid, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective_fun, n_trials=100, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:56:06.206362Z",
     "start_time": "2023-06-06T16:55:17.395929Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'gbtree', 'gamma': 2.6097726072333662, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.7908633556878183}\n",
      "Root mean squared error = 0.3973\n",
      "R-squared = 0.6552\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "xgb = XGBRegressor(**best_params)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "print(best_params)\n",
    "print('Root mean squared error = %.4f' % np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('R-squared = %.4f' % r2_score(y_test, y_pred_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:56:06.493466Z",
     "start_time": "2023-06-06T16:56:06.201192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.01002509, 0.01002509, 0.00939152, ..., 0.00018898, 0.00011112,\n       0.00011112], dtype=float32)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_to_pred)\n",
    "y_pred = np.power(10, y_pred)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:56:06.498191Z",
     "start_time": "2023-06-06T16:56:06.494635Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative values predicted\n",
    "np.count_nonzero(y_pred < 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:56:06.503802Z",
     "start_time": "2023-06-06T16:56:06.501643Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df_zero[TARGET] = y_pred\n",
    "df.update(df_zero)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:56:06.543241Z",
     "start_time": "2023-06-06T16:56:06.503960Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x=TARGET)\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:56:06.762345Z",
     "start_time": "2023-06-06T16:56:06.528497Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x=TARGET, log_scale=True)\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:56:07.164492Z",
     "start_time": "2023-06-06T16:56:06.762947Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:56:10,204] A new study created in memory with name: no-name-cb0c9579-e81e-45d7-8d72-36621dfda84b\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function at 0x2b525d700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function at 0x2b525d700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x2b525dd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x2b525dd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[I 2023-06-06 18:56:13,010] Trial 6 finished with value: 0.14700718224048615 and parameters: {'n_hidden': 1, 'n_units': 57, 'learning_rate': 0.050216681313764604}. Best is trial 6 with value: 0.14700718224048615.\n",
      "[I 2023-06-06 18:56:13,014] Trial 7 finished with value: 0.16439925134181976 and parameters: {'n_hidden': 1, 'n_units': 58, 'learning_rate': 0.04244036258415641}. Best is trial 6 with value: 0.14700718224048615.\n",
      "[I 2023-06-06 18:56:13,061] Trial 3 finished with value: 0.224782332777977 and parameters: {'n_hidden': 1, 'n_units': 110, 'learning_rate': 0.07382860955648406}. Best is trial 6 with value: 0.14700718224048615.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:13,129] Trial 1 finished with value: 0.202677384018898 and parameters: {'n_hidden': 1, 'n_units': 94, 'learning_rate': 0.0004715473813257265}. Best is trial 6 with value: 0.14700718224048615.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:13,193] Trial 2 finished with value: 0.12603917717933655 and parameters: {'n_hidden': 2, 'n_units': 51, 'learning_rate': 0.047070178326929675}. Best is trial 2 with value: 0.12603917717933655.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:13,203] Trial 0 finished with value: 0.12156123667955399 and parameters: {'n_hidden': 1, 'n_units': 124, 'learning_rate': 0.011140925832628285}. Best is trial 0 with value: 0.12156123667955399.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:13,295] Trial 4 finished with value: 0.589845597743988 and parameters: {'n_hidden': 2, 'n_units': 118, 'learning_rate': 0.06846898919469131}. Best is trial 0 with value: 0.12156123667955399.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:13,358] Trial 5 finished with value: 0.181585893034935 and parameters: {'n_hidden': 2, 'n_units': 89, 'learning_rate': 0.01877416081010944}. Best is trial 0 with value: 0.12156123667955399.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:15,899] Trial 8 finished with value: 0.15990586578845978 and parameters: {'n_hidden': 1, 'n_units': 93, 'learning_rate': 0.08197422310454676}. Best is trial 0 with value: 0.12156123667955399.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:16,035] Trial 9 finished with value: 0.10951240360736847 and parameters: {'n_hidden': 3, 'n_units': 76, 'learning_rate': 0.003311356973087233}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:16,094] Trial 10 finished with value: 0.5700446367263794 and parameters: {'n_hidden': 2, 'n_units': 127, 'learning_rate': 0.07373173182013376}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:16,098] Trial 12 finished with value: 0.21795497834682465 and parameters: {'n_hidden': 1, 'n_units': 120, 'learning_rate': 0.05686849865633862}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:16,375] Trial 11 finished with value: 0.6121655702590942 and parameters: {'n_hidden': 3, 'n_units': 89, 'learning_rate': 0.053333331298961895}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:16,414] Trial 13 finished with value: 0.24341356754302979 and parameters: {'n_hidden': 2, 'n_units': 126, 'learning_rate': 0.07372278506637298}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:16,629] Trial 14 finished with value: 0.791620671749115 and parameters: {'n_hidden': 3, 'n_units': 124, 'learning_rate': 0.08703118501512386}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:17,245] Trial 15 finished with value: 0.1536930799484253 and parameters: {'n_hidden': 2, 'n_units': 120, 'learning_rate': 0.03656125719989969}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:18,816] Trial 16 finished with value: 0.5683013796806335 and parameters: {'n_hidden': 2, 'n_units': 33, 'learning_rate': 0.08024916709505292}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:18,962] Trial 19 finished with value: 0.1407693475484848 and parameters: {'n_hidden': 3, 'n_units': 70, 'learning_rate': 0.0008081039821215595}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:19,030] Trial 17 finished with value: 0.5682872533798218 and parameters: {'n_hidden': 3, 'n_units': 34, 'learning_rate': 0.0995404897992634}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:19,233] Trial 18 finished with value: 0.12266341596841812 and parameters: {'n_hidden': 3, 'n_units': 72, 'learning_rate': 0.0010672187687112786}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:19,349] Trial 20 finished with value: 0.20361007750034332 and parameters: {'n_hidden': 3, 'n_units': 73, 'learning_rate': 0.00020933506540234126}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:19,675] Trial 21 finished with value: 0.44574445486068726 and parameters: {'n_hidden': 3, 'n_units': 71, 'learning_rate': 0.00013147494021824822}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:19,857] Trial 22 finished with value: 0.12726546823978424 and parameters: {'n_hidden': 3, 'n_units': 74, 'learning_rate': 0.0023167923665186707}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:20,410] Trial 23 finished with value: 0.1245172768831253 and parameters: {'n_hidden': 3, 'n_units': 72, 'learning_rate': 0.003848123958853577}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:22,001] Trial 24 finished with value: 2.880638360977173 and parameters: {'n_hidden': 3, 'n_units': 73, 'learning_rate': 4.104910190064074e-05}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:22,251] Trial 25 finished with value: 0.12005428224802017 and parameters: {'n_hidden': 3, 'n_units': 74, 'learning_rate': 0.014550942949743368}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:22,266] Trial 26 finished with value: 0.11416256427764893 and parameters: {'n_hidden': 3, 'n_units': 75, 'learning_rate': 0.01724394323416885}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:22,596] Trial 27 finished with value: 0.10999204218387604 and parameters: {'n_hidden': 3, 'n_units': 103, 'learning_rate': 0.01866340958868867}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:22,669] Trial 28 finished with value: 0.1503511220216751 and parameters: {'n_hidden': 3, 'n_units': 105, 'learning_rate': 0.01550289743469243}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:23,042] Trial 29 finished with value: 0.16672679781913757 and parameters: {'n_hidden': 3, 'n_units': 104, 'learning_rate': 0.016069155542508692}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:23,670] Trial 31 finished with value: 0.13390003144741058 and parameters: {'n_hidden': 3, 'n_units': 104, 'learning_rate': 0.015644017272375445}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:23,852] Trial 30 finished with value: 0.11374012380838394 and parameters: {'n_hidden': 3, 'n_units': 104, 'learning_rate': 0.014317883404169243}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:25,203] Trial 32 finished with value: 0.12101736664772034 and parameters: {'n_hidden': 3, 'n_units': 101, 'learning_rate': 0.01423088574007811}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:25,225] Trial 33 finished with value: 0.15327399969100952 and parameters: {'n_hidden': 2, 'n_units': 104, 'learning_rate': 0.014159260922833237}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:25,295] Trial 34 finished with value: 0.17080381512641907 and parameters: {'n_hidden': 3, 'n_units': 81, 'learning_rate': 0.023232910310118243}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:25,832] Trial 35 finished with value: 0.12689173221588135 and parameters: {'n_hidden': 3, 'n_units': 104, 'learning_rate': 0.02388614971710732}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:25,940] Trial 36 finished with value: 0.132968470454216 and parameters: {'n_hidden': 3, 'n_units': 82, 'learning_rate': 0.018514336850542098}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:26,341] Trial 37 finished with value: 0.12474796175956726 and parameters: {'n_hidden': 3, 'n_units': 82, 'learning_rate': 0.028269585378951606}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:27,170] Trial 39 finished with value: 0.13698582351207733 and parameters: {'n_hidden': 3, 'n_units': 84, 'learning_rate': 0.02292876497736802}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:27,291] Trial 38 finished with value: 0.11407051980495453 and parameters: {'n_hidden': 3, 'n_units': 84, 'learning_rate': 0.026018652120331026}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:28,418] Trial 40 finished with value: 0.16407550871372223 and parameters: {'n_hidden': 3, 'n_units': 81, 'learning_rate': 0.02344172081427403}. Best is trial 9 with value: 0.10951240360736847.\n",
      "[I 2023-06-06 18:56:28,484] Trial 41 finished with value: 0.16329973936080933 and parameters: {'n_hidden': 3, 'n_units': 80, 'learning_rate': 0.02281020322311686}. Best is trial 9 with value: 0.10951240360736847.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:28,595] Trial 42 finished with value: 0.10276579111814499 and parameters: {'n_hidden': 3, 'n_units': 82, 'learning_rate': 0.025381844050372027}. Best is trial 42 with value: 0.10276579111814499.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:29,140] Trial 43 finished with value: 0.12627166509628296 and parameters: {'n_hidden': 3, 'n_units': 82, 'learning_rate': 0.009733002075853378}. Best is trial 42 with value: 0.10276579111814499.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:29,547] Trial 44 finished with value: 0.13978272676467896 and parameters: {'n_hidden': 2, 'n_units': 114, 'learning_rate': 0.027085893598753387}. Best is trial 42 with value: 0.10276579111814499.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:29,702] Trial 45 finished with value: 0.09658299386501312 and parameters: {'n_hidden': 2, 'n_units': 112, 'learning_rate': 0.009786518928066281}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:30,136] Trial 46 finished with value: 0.12902462482452393 and parameters: {'n_hidden': 2, 'n_units': 112, 'learning_rate': 0.007440649481511272}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:30,533] Trial 47 finished with value: 0.11594221740961075 and parameters: {'n_hidden': 2, 'n_units': 113, 'learning_rate': 0.008216066433212883}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:31,535] Trial 49 finished with value: 0.12379048764705658 and parameters: {'n_hidden': 2, 'n_units': 64, 'learning_rate': 0.008908273624356457}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:31,549] Trial 50 finished with value: 0.12427123636007309 and parameters: {'n_hidden': 2, 'n_units': 94, 'learning_rate': 0.00963127241459448}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:31,602] Trial 48 finished with value: 0.11489073187112808 and parameters: {'n_hidden': 3, 'n_units': 112, 'learning_rate': 0.008659792395263535}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:32,217] Trial 51 finished with value: 0.09718435257673264 and parameters: {'n_hidden': 2, 'n_units': 112, 'learning_rate': 0.009180628646485351}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:32,459] Trial 52 finished with value: 0.12142381072044373 and parameters: {'n_hidden': 2, 'n_units': 66, 'learning_rate': 0.01100366454777333}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:32,706] Trial 53 finished with value: 0.1345423012971878 and parameters: {'n_hidden': 2, 'n_units': 96, 'learning_rate': 0.008075195878876977}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:33,481] Trial 54 finished with value: 0.11554866284132004 and parameters: {'n_hidden': 2, 'n_units': 64, 'learning_rate': 0.007721660698986256}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:33,780] Trial 55 finished with value: 0.12348078191280365 and parameters: {'n_hidden': 2, 'n_units': 95, 'learning_rate': 0.009596130570481358}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:34,593] Trial 58 finished with value: 0.1262611299753189 and parameters: {'n_hidden': 2, 'n_units': 92, 'learning_rate': 0.031950129125019905}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:34,742] Trial 56 finished with value: 0.11250096559524536 and parameters: {'n_hidden': 2, 'n_units': 95, 'learning_rate': 0.006828493529361653}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:35,398] Trial 61 finished with value: 0.1358622908592224 and parameters: {'n_hidden': 1, 'n_units': 118, 'learning_rate': 0.005542040069006361}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:35,411] Trial 57 finished with value: 0.1550360918045044 and parameters: {'n_hidden': 2, 'n_units': 97, 'learning_rate': 0.03240059753849367}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:35,415] Trial 59 finished with value: 0.13333941996097565 and parameters: {'n_hidden': 2, 'n_units': 98, 'learning_rate': 0.005417943200378576}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:35,444] Trial 60 finished with value: 0.13527938723564148 and parameters: {'n_hidden': 2, 'n_units': 98, 'learning_rate': 0.005671691100992388}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:36,394] Trial 62 finished with value: 0.14790508151054382 and parameters: {'n_hidden': 1, 'n_units': 117, 'learning_rate': 0.0055236924600002985}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:36,818] Trial 63 finished with value: 0.13206346333026886 and parameters: {'n_hidden': 1, 'n_units': 119, 'learning_rate': 0.004822492473217095}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:37,522] Trial 64 finished with value: 0.12811826169490814 and parameters: {'n_hidden': 1, 'n_units': 100, 'learning_rate': 0.0041280627066851115}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:37,715] Trial 65 finished with value: 0.10759183019399643 and parameters: {'n_hidden': 1, 'n_units': 118, 'learning_rate': 0.004509420912262685}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:38,271] Trial 67 finished with value: 0.14166909456253052 and parameters: {'n_hidden': 2, 'n_units': 108, 'learning_rate': 0.004496446253856217}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:38,437] Trial 69 finished with value: 0.12334662675857544 and parameters: {'n_hidden': 2, 'n_units': 89, 'learning_rate': 0.019136030922641184}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:38,441] Trial 66 finished with value: 0.13087284564971924 and parameters: {'n_hidden': 2, 'n_units': 108, 'learning_rate': 0.019579791386433263}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:38,574] Trial 68 finished with value: 0.11291243135929108 and parameters: {'n_hidden': 2, 'n_units': 108, 'learning_rate': 0.0037470694836834123}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:39,387] Trial 70 finished with value: 0.16456381976604462 and parameters: {'n_hidden': 2, 'n_units': 90, 'learning_rate': 0.01255463157595589}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:39,893] Trial 71 finished with value: 0.15228889882564545 and parameters: {'n_hidden': 2, 'n_units': 88, 'learning_rate': 0.019226987249541343}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:40,732] Trial 73 finished with value: 0.12294995039701462 and parameters: {'n_hidden': 1, 'n_units': 123, 'learning_rate': 0.012290976310022725}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:40,995] Trial 74 finished with value: 0.12180500477552414 and parameters: {'n_hidden': 1, 'n_units': 89, 'learning_rate': 0.020217920496206222}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:41,271] Trial 75 finished with value: 0.13689787685871124 and parameters: {'n_hidden': 1, 'n_units': 122, 'learning_rate': 0.002297134036089052}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:41,517] Trial 76 finished with value: 0.12013743072748184 and parameters: {'n_hidden': 1, 'n_units': 108, 'learning_rate': 0.011840983021884365}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:41,972] Trial 78 finished with value: 0.12431023269891739 and parameters: {'n_hidden': 1, 'n_units': 126, 'learning_rate': 0.011580227886901578}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:41,982] Trial 77 finished with value: 0.12253905832767487 and parameters: {'n_hidden': 1, 'n_units': 90, 'learning_rate': 0.012454175979844297}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:42,710] Trial 79 finished with value: 0.1243302971124649 and parameters: {'n_hidden': 1, 'n_units': 125, 'learning_rate': 0.012205386258357407}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:43,264] Trial 72 finished with value: 0.1161467432975769 and parameters: {'n_hidden': 2, 'n_units': 123, 'learning_rate': 0.020036875982970378}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:43,591] Trial 80 finished with value: 0.13121642172336578 and parameters: {'n_hidden': 2, 'n_units': 107, 'learning_rate': 0.0023877170897841546}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:43,765] Trial 81 finished with value: 0.11438938975334167 and parameters: {'n_hidden': 2, 'n_units': 109, 'learning_rate': 0.0030456745489788922}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:44,276] Trial 82 finished with value: 0.11806746572256088 and parameters: {'n_hidden': 2, 'n_units': 127, 'learning_rate': 0.0021367060172415627}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:44,410] Trial 83 finished with value: 0.11652106046676636 and parameters: {'n_hidden': 2, 'n_units': 116, 'learning_rate': 0.0016953145541894164}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:44,714] Trial 85 finished with value: 0.1370001584291458 and parameters: {'n_hidden': 2, 'n_units': 39, 'learning_rate': 0.0021329385702367233}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:44,847] Trial 84 finished with value: 0.14342032372951508 and parameters: {'n_hidden': 2, 'n_units': 116, 'learning_rate': 0.0025799786919819363}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:45,894] Trial 86 finished with value: 0.14008554816246033 and parameters: {'n_hidden': 2, 'n_units': 77, 'learning_rate': 0.0022858390335801794}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:46,575] Trial 87 finished with value: 0.1478799283504486 and parameters: {'n_hidden': 2, 'n_units': 101, 'learning_rate': 0.0022692042509457563}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:46,937] Trial 88 finished with value: 0.10651156306266785 and parameters: {'n_hidden': 3, 'n_units': 102, 'learning_rate': 0.016113632618326473}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:47,108] Trial 89 finished with value: 0.10854808241128922 and parameters: {'n_hidden': 3, 'n_units': 102, 'learning_rate': 0.014529702840639834}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:47,713] Trial 90 finished with value: 0.11983998864889145 and parameters: {'n_hidden': 3, 'n_units': 115, 'learning_rate': 0.016684060536030963}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:47,786] Trial 91 finished with value: 0.12040523439645767 and parameters: {'n_hidden': 3, 'n_units': 101, 'learning_rate': 0.015996038287286077}. Best is trial 45 with value: 0.09658299386501312.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:56:48,193] Trial 92 finished with value: 0.15001997351646423 and parameters: {'n_hidden': 3, 'n_units': 102, 'learning_rate': 0.016334855638479643}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:48,618] Trial 93 finished with value: 0.12507164478302002 and parameters: {'n_hidden': 3, 'n_units': 102, 'learning_rate': 0.015484034218707466}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:48,862] Trial 94 finished with value: 0.144216850399971 and parameters: {'n_hidden': 3, 'n_units': 101, 'learning_rate': 0.016744508207924856}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:49,140] Trial 95 finished with value: 0.15385082364082336 and parameters: {'n_hidden': 3, 'n_units': 111, 'learning_rate': 0.016309482900258975}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:49,288] Trial 96 finished with value: 0.12606747448444366 and parameters: {'n_hidden': 3, 'n_units': 111, 'learning_rate': 0.016242377462250667}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:49,311] Trial 97 finished with value: 0.12706564366817474 and parameters: {'n_hidden': 3, 'n_units': 78, 'learning_rate': 0.01767088577667383}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:49,450] Trial 98 finished with value: 0.11456874758005142 and parameters: {'n_hidden': 3, 'n_units': 111, 'learning_rate': 0.01572243544300172}. Best is trial 45 with value: 0.09658299386501312.\n",
      "[I 2023-06-06 18:56:49,526] Trial 99 finished with value: 0.11670269072055817 and parameters: {'n_hidden': 3, 'n_units': 110, 'learning_rate': 0.00742848916995726}. Best is trial 45 with value: 0.09658299386501312.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_model(trial):\n",
    "\n",
    "    n_hidden = trial.suggest_int('n_hidden', 1, 3)\n",
    "    n_units = trial.suggest_int('n_units', 32, 128)\n",
    "    learn_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_units, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "    for i in range(n_hidden):\n",
    "        model.add(Dense(n_units, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "                  metrics=tensorflow.keras.metrics.MeanSquaredError())\n",
    "    return model\n",
    "\n",
    "\n",
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_valid, y_valid), verbose=False)\n",
    "\n",
    "    error = model.evaluate(X_valid, y_valid, verbose=False)[1]\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective_fun, n_trials=100, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:56:49.529810Z",
     "start_time": "2023-06-06T16:56:07.167168Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 370us/step\n",
      "Root mean squared error = 0.5130\n",
      "R-squared = 0.4250\n"
     ]
    }
   ],
   "source": [
    "model = create_model(study.best_trial)\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_valid, y_valid), verbose=False)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "print('Root mean squared error = %.4f' % np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('R-squared = %.4f' % r2_score(y_test, y_pred_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:56:50.245132Z",
     "start_time": "2023-06-06T16:56:49.531724Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 372us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.0197151 ],\n       [0.02003535],\n       [0.01469635],\n       ...,\n       [0.00014938],\n       [0.00015547],\n       [0.00013633]], dtype=float32)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_to_pred)\n",
    "y_pred = np.power(10, y_pred)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:56:50.288313Z",
     "start_time": "2023-06-06T16:56:50.245990Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:56:50.289481Z",
     "start_time": "2023-06-06T16:56:50.287282Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

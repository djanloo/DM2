{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:20:38.165673Z",
     "start_time": "2023-06-06T19:20:37.947448Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.core.dtypes.common import is_numeric_dtype\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression, SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'dataset'\n",
    "DATASET = os.path.join(DATA_FOLDER, 'outliers_removed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:20:38.167949Z",
     "start_time": "2023-06-06T19:20:38.166466Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   frame_count       sum          mean       std       min       max   \n0       158558  0.145081  9.150000e-07  0.004001 -0.038422  0.040588  \\\n1       160160  0.114319  7.137790e-07  0.004283 -0.042603  0.048157   \n2       156956  0.149963  9.554485e-07  0.005084 -0.037018  0.058472   \n3       152152  0.139618  9.176213e-07  0.004886 -0.036652  0.062683   \n4       169769  0.137665  8.108948e-07  0.002956 -0.026245  0.026215   \n\n        q01       q05       q25  q75  ...  actor_actor_24  actor_actor_3   \n0 -0.012586 -0.005890 -0.000031  0.0  ...               0              0  \\\n1 -0.013550 -0.006104 -0.000031  0.0  ...               0              0   \n2 -0.015822 -0.007294  0.000000  0.0  ...               0              0   \n3 -0.014923 -0.006714 -0.000031  0.0  ...               0              0   \n4 -0.009399 -0.004364 -0.000031  0.0  ...               0              0   \n\n   actor_actor_4  actor_actor_5  actor_actor_6  actor_actor_7  actor_actor_8   \n0              0              0              0              0              0  \\\n1              0              0              0              0              0   \n2              0              0              0              0              0   \n3              0              0              0              0              0   \n4              0              0              0              0              0   \n\n   actor_actor_9  sex_F  sex_M  \n0              0      0      1  \n1              0      0      1  \n2              0      0      1  \n3              0      0      1  \n4              0      0      1  \n\n[5 rows x 285 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame_count</th>\n      <th>sum</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>q01</th>\n      <th>q05</th>\n      <th>q25</th>\n      <th>q75</th>\n      <th>...</th>\n      <th>actor_actor_24</th>\n      <th>actor_actor_3</th>\n      <th>actor_actor_4</th>\n      <th>actor_actor_5</th>\n      <th>actor_actor_6</th>\n      <th>actor_actor_7</th>\n      <th>actor_actor_8</th>\n      <th>actor_actor_9</th>\n      <th>sex_F</th>\n      <th>sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>158558</td>\n      <td>0.145081</td>\n      <td>9.150000e-07</td>\n      <td>0.004001</td>\n      <td>-0.038422</td>\n      <td>0.040588</td>\n      <td>-0.012586</td>\n      <td>-0.005890</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>160160</td>\n      <td>0.114319</td>\n      <td>7.137790e-07</td>\n      <td>0.004283</td>\n      <td>-0.042603</td>\n      <td>0.048157</td>\n      <td>-0.013550</td>\n      <td>-0.006104</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>156956</td>\n      <td>0.149963</td>\n      <td>9.554485e-07</td>\n      <td>0.005084</td>\n      <td>-0.037018</td>\n      <td>0.058472</td>\n      <td>-0.015822</td>\n      <td>-0.007294</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>152152</td>\n      <td>0.139618</td>\n      <td>9.176213e-07</td>\n      <td>0.004886</td>\n      <td>-0.036652</td>\n      <td>0.062683</td>\n      <td>-0.014923</td>\n      <td>-0.006714</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>169769</td>\n      <td>0.137665</td>\n      <td>8.108948e-07</td>\n      <td>0.002956</td>\n      <td>-0.026245</td>\n      <td>0.026215</td>\n      <td>-0.009399</td>\n      <td>-0.004364</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 285 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET)\n",
    "\n",
    "categorical_attr_list = [col for col in df.columns if not is_numeric_dtype(df[col])]\n",
    "\n",
    "# one hot encoding\n",
    "df_reg = df.drop(columns=categorical_attr_list)\n",
    "df_reg = df_reg.join(pd.get_dummies(df[categorical_attr_list], columns=categorical_attr_list).astype(int))\n",
    "\n",
    "df_reg.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:20:38.244727Z",
     "start_time": "2023-06-06T19:20:38.170224Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "stft_min    False\nsc_min      False\ndtype: bool"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_correct = ['stft_min', 'sc_min']\n",
    "(df[features_to_correct] < 0).any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:20:38.250848Z",
     "start_time": "2023-06-06T19:20:38.248399Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# stft_min"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['mfcc_q50',\n 'sc_q01',\n 'sc_q05',\n 'stft_q01',\n 'stft_q05',\n 'mfcc_q25_w1',\n 'mfcc_q50_w1',\n 'sc_q05_w1',\n 'sc_q25_w1',\n 'stft_q05_w1',\n 'q50_w2',\n 'q50_w3',\n 'lag1_q50_w3',\n 'q75_w4']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET = 'stft_min'\n",
    "\n",
    "# drop quantile columns with high percentage of zeros (20%)\n",
    "zero_percentage = (df_reg == 0).mean()\n",
    "to_drop = [col for col in df_reg.columns if zero_percentage[col] > 0.2 and re.search(r'q\\d{2}', col)]\n",
    "df_reg = df_reg.drop(columns=to_drop)\n",
    "to_drop"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:20:38.257012Z",
     "start_time": "2023-06-06T19:20:38.251910Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x=df[TARGET])\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:20:38.443993Z",
     "start_time": "2023-06-06T19:20:38.257842Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847, 270) (212, 270) (361, 270) (1009, 270)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# rows to be fixed, do not reset indexes!\n",
    "df_zero = df_reg[df_reg[TARGET] == 0]\n",
    "df_nz = df_reg[df_reg[TARGET] != 0].reset_index(drop=True)\n",
    "\n",
    "# dataframe has been one hot encoded\n",
    "split_index = df_nz.index[df_nz['actor_actor_19'] == 1][0]\n",
    "\n",
    "df_train = df_nz[:split_index]\n",
    "df_test = df_nz[split_index:]\n",
    "\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.2, random_state=100)\n",
    "\n",
    "y_train = np.log10(df_train[TARGET].to_numpy())\n",
    "y_valid = np.log10(df_valid[TARGET].to_numpy())\n",
    "y_test = np.log10(df_test[TARGET].to_numpy())\n",
    "\n",
    "df_zero = df_zero.drop([TARGET], axis=1)\n",
    "df_train = df_train.drop([TARGET], axis=1)\n",
    "df_valid = df_valid.drop([TARGET], axis=1)\n",
    "df_test = df_test.drop([TARGET], axis=1)\n",
    "\n",
    "X_to_pred = df_zero.to_numpy()\n",
    "X_train = df_train.to_numpy()\n",
    "X_valid = df_valid.to_numpy()\n",
    "X_test = df_test.to_numpy()\n",
    "\n",
    "print(X_train.shape, X_valid.shape, X_test.shape, X_to_pred.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:20:38.455925Z",
     "start_time": "2023-06-06T19:20:38.448956Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_selector = SelectKBest(score_func=f_regression, k='all')\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar([i for i in range(len(f_selector.scores_))], f_selector.scores_)\n",
    "plt.xlabel('Feature index')\n",
    "plt.ylabel('Estimated value')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:20:38.797565Z",
     "start_time": "2023-06-06T19:20:38.466151Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "      mfcc_q25    mfcc_q99  stft_mean  stft_std  stft_q25  mfcc_q25_w2   \n259 -18.582673  133.537021   0.391166  0.350493  0.037039   -25.548968  \\\n157  -2.432008  140.389436   0.618064  0.281252  0.400627   -11.883626   \n667 -10.434671  169.611666   0.499650  0.347630  0.142961   -18.150980   \n707 -11.989990  140.775630   0.500564  0.321720  0.203172   -19.689170   \n125  -6.579166   90.324497   0.475922  0.349201  0.106374   -15.118881   \n..         ...         ...        ...       ...       ...          ...   \n802 -10.531611  188.840487   0.448354  0.342674  0.105303   -16.788827   \n53  -10.841864  159.482310   0.512951  0.316919  0.221845   -20.016054   \n350  -7.651122  151.113206   0.543641  0.328328  0.233966   -13.594585   \n79  -10.683922  143.316089   0.513574  0.286984  0.275286   -11.417866   \n792  -2.116944  152.105091   0.636902  0.295871  0.413712   -10.847955   \n\n     mfcc_q50_w2  mfcc_q99_w2  stft_sum_w2  stft_q05_w2  stft_q25_w2   \n259   -14.335812   131.763970   316.827272     0.002076     0.019907  \\\n157     0.331137   157.141432   487.714941     0.047736     0.247174   \n667    -7.070016   177.324767   409.154710     0.007334     0.053486   \n707    -6.076445   132.367535   424.497157     0.012076     0.085660   \n125     0.000000    92.440168   351.456816     0.002707     0.027473   \n..           ...          ...          ...          ...          ...   \n802    -4.730709   181.582949   469.988087     0.016418     0.071749   \n53     -4.384253   176.553050   452.237700     0.045298     0.156050   \n350    -2.200245   156.181359   492.584031     0.025636     0.164514   \n79     -2.853683   147.437486   577.809521     0.057310     0.276032   \n792     0.000000   148.006489   482.397157     0.036796     0.246890   \n\n     stft_skew_w2   mfcc_sum_w3  mfcc_q25_w3  mfcc_q50_w3  mfcc_q75_w3   \n259      1.368237 -70611.711781   -25.377122   -12.167407    -1.477520  \\\n157     -0.016021 -37384.776127    -9.452207     0.308263     9.277478   \n667      0.865939 -39253.197492   -17.626914    -5.782738     6.776643   \n707      0.328339 -46073.398204   -21.128508   -10.204088     2.029520   \n125      0.804747 -39812.423944   -25.070787    -7.274005     9.855553   \n..            ...           ...          ...          ...          ...   \n802      0.886020 -54877.142055   -18.882193    -4.978764     7.866954   \n53       0.706239 -30872.660059   -18.504748    -4.311820    10.084295   \n350      0.347103 -38947.164248   -17.357152    -6.596020     6.551662   \n79       0.175891 -37772.767541   -16.525048    -5.833418     5.294950   \n792      0.027626 -28996.039009   -10.309630    -1.024038    10.095972   \n\n     mfcc_q99_w3  stft_q25_w3  sex_F  sex_M  \n259   141.949765     0.006469      1      0  \n157   208.015807     0.228734      0      1  \n667   182.314767     0.089444      0      1  \n707   174.004688     0.052809      1      0  \n125   124.347880     0.013650      1      0  \n..           ...          ...    ...    ...  \n802   207.137736     0.043049      0      1  \n53    166.648179     0.122665      0      1  \n350   192.158127     0.081348      1      0  \n79    171.602208     0.172040      0      1  \n792   213.165450     0.153596      0      1  \n\n[847 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mfcc_q25</th>\n      <th>mfcc_q99</th>\n      <th>stft_mean</th>\n      <th>stft_std</th>\n      <th>stft_q25</th>\n      <th>mfcc_q25_w2</th>\n      <th>mfcc_q50_w2</th>\n      <th>mfcc_q99_w2</th>\n      <th>stft_sum_w2</th>\n      <th>stft_q05_w2</th>\n      <th>stft_q25_w2</th>\n      <th>stft_skew_w2</th>\n      <th>mfcc_sum_w3</th>\n      <th>mfcc_q25_w3</th>\n      <th>mfcc_q50_w3</th>\n      <th>mfcc_q75_w3</th>\n      <th>mfcc_q99_w3</th>\n      <th>stft_q25_w3</th>\n      <th>sex_F</th>\n      <th>sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>259</th>\n      <td>-18.582673</td>\n      <td>133.537021</td>\n      <td>0.391166</td>\n      <td>0.350493</td>\n      <td>0.037039</td>\n      <td>-25.548968</td>\n      <td>-14.335812</td>\n      <td>131.763970</td>\n      <td>316.827272</td>\n      <td>0.002076</td>\n      <td>0.019907</td>\n      <td>1.368237</td>\n      <td>-70611.711781</td>\n      <td>-25.377122</td>\n      <td>-12.167407</td>\n      <td>-1.477520</td>\n      <td>141.949765</td>\n      <td>0.006469</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>-2.432008</td>\n      <td>140.389436</td>\n      <td>0.618064</td>\n      <td>0.281252</td>\n      <td>0.400627</td>\n      <td>-11.883626</td>\n      <td>0.331137</td>\n      <td>157.141432</td>\n      <td>487.714941</td>\n      <td>0.047736</td>\n      <td>0.247174</td>\n      <td>-0.016021</td>\n      <td>-37384.776127</td>\n      <td>-9.452207</td>\n      <td>0.308263</td>\n      <td>9.277478</td>\n      <td>208.015807</td>\n      <td>0.228734</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>-10.434671</td>\n      <td>169.611666</td>\n      <td>0.499650</td>\n      <td>0.347630</td>\n      <td>0.142961</td>\n      <td>-18.150980</td>\n      <td>-7.070016</td>\n      <td>177.324767</td>\n      <td>409.154710</td>\n      <td>0.007334</td>\n      <td>0.053486</td>\n      <td>0.865939</td>\n      <td>-39253.197492</td>\n      <td>-17.626914</td>\n      <td>-5.782738</td>\n      <td>6.776643</td>\n      <td>182.314767</td>\n      <td>0.089444</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>707</th>\n      <td>-11.989990</td>\n      <td>140.775630</td>\n      <td>0.500564</td>\n      <td>0.321720</td>\n      <td>0.203172</td>\n      <td>-19.689170</td>\n      <td>-6.076445</td>\n      <td>132.367535</td>\n      <td>424.497157</td>\n      <td>0.012076</td>\n      <td>0.085660</td>\n      <td>0.328339</td>\n      <td>-46073.398204</td>\n      <td>-21.128508</td>\n      <td>-10.204088</td>\n      <td>2.029520</td>\n      <td>174.004688</td>\n      <td>0.052809</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>-6.579166</td>\n      <td>90.324497</td>\n      <td>0.475922</td>\n      <td>0.349201</td>\n      <td>0.106374</td>\n      <td>-15.118881</td>\n      <td>0.000000</td>\n      <td>92.440168</td>\n      <td>351.456816</td>\n      <td>0.002707</td>\n      <td>0.027473</td>\n      <td>0.804747</td>\n      <td>-39812.423944</td>\n      <td>-25.070787</td>\n      <td>-7.274005</td>\n      <td>9.855553</td>\n      <td>124.347880</td>\n      <td>0.013650</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>802</th>\n      <td>-10.531611</td>\n      <td>188.840487</td>\n      <td>0.448354</td>\n      <td>0.342674</td>\n      <td>0.105303</td>\n      <td>-16.788827</td>\n      <td>-4.730709</td>\n      <td>181.582949</td>\n      <td>469.988087</td>\n      <td>0.016418</td>\n      <td>0.071749</td>\n      <td>0.886020</td>\n      <td>-54877.142055</td>\n      <td>-18.882193</td>\n      <td>-4.978764</td>\n      <td>7.866954</td>\n      <td>207.137736</td>\n      <td>0.043049</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>-10.841864</td>\n      <td>159.482310</td>\n      <td>0.512951</td>\n      <td>0.316919</td>\n      <td>0.221845</td>\n      <td>-20.016054</td>\n      <td>-4.384253</td>\n      <td>176.553050</td>\n      <td>452.237700</td>\n      <td>0.045298</td>\n      <td>0.156050</td>\n      <td>0.706239</td>\n      <td>-30872.660059</td>\n      <td>-18.504748</td>\n      <td>-4.311820</td>\n      <td>10.084295</td>\n      <td>166.648179</td>\n      <td>0.122665</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>-7.651122</td>\n      <td>151.113206</td>\n      <td>0.543641</td>\n      <td>0.328328</td>\n      <td>0.233966</td>\n      <td>-13.594585</td>\n      <td>-2.200245</td>\n      <td>156.181359</td>\n      <td>492.584031</td>\n      <td>0.025636</td>\n      <td>0.164514</td>\n      <td>0.347103</td>\n      <td>-38947.164248</td>\n      <td>-17.357152</td>\n      <td>-6.596020</td>\n      <td>6.551662</td>\n      <td>192.158127</td>\n      <td>0.081348</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>-10.683922</td>\n      <td>143.316089</td>\n      <td>0.513574</td>\n      <td>0.286984</td>\n      <td>0.275286</td>\n      <td>-11.417866</td>\n      <td>-2.853683</td>\n      <td>147.437486</td>\n      <td>577.809521</td>\n      <td>0.057310</td>\n      <td>0.276032</td>\n      <td>0.175891</td>\n      <td>-37772.767541</td>\n      <td>-16.525048</td>\n      <td>-5.833418</td>\n      <td>5.294950</td>\n      <td>171.602208</td>\n      <td>0.172040</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>792</th>\n      <td>-2.116944</td>\n      <td>152.105091</td>\n      <td>0.636902</td>\n      <td>0.295871</td>\n      <td>0.413712</td>\n      <td>-10.847955</td>\n      <td>0.000000</td>\n      <td>148.006489</td>\n      <td>482.397157</td>\n      <td>0.036796</td>\n      <td>0.246890</td>\n      <td>0.027626</td>\n      <td>-28996.039009</td>\n      <td>-10.309630</td>\n      <td>-1.024038</td>\n      <td>10.095972</td>\n      <td>213.165450</td>\n      <td>0.153596</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>847 rows Ã— 20 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_selector = SelectKBest(score_func=f_regression, k=20)\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "X_train = f_selector.transform(X_train)\n",
    "X_valid = f_selector.transform(X_valid)\n",
    "X_test = f_selector.transform(X_test)\n",
    "X_to_pred = f_selector.transform(X_to_pred)\n",
    "\n",
    "# selected columns\n",
    "selected_indices = f_selector.get_support(indices=True)\n",
    "df_train.iloc[:, selected_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:20:38.808171Z",
     "start_time": "2023-06-06T19:20:38.798106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_to_pred = scaler.fit_transform(X_to_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:20:38.815884Z",
     "start_time": "2023-06-06T19:20:38.807529Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 21:20:39,064] A new study created in memory with name: no-name-4455ae5f-e9d8-43e3-9b32-f17e684cf81b\n",
      "[I 2023-06-06 21:20:41,372] Trial 5 finished with value: 0.11142305073538443 and parameters: {'booster': 'gbtree', 'gamma': 4.215157000517739, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.5042406235832321}. Best is trial 5 with value: 0.11142305073538443.\n",
      "[I 2023-06-06 21:20:42,571] Trial 6 finished with value: 0.10285856116795626 and parameters: {'booster': 'gbtree', 'gamma': 3.222206059729562, 'max_depth': 14, 'min_child_weight': 3, 'subsample': 0.6271517834470747}. Best is trial 6 with value: 0.10285856116795626.\n",
      "[I 2023-06-06 21:20:43,357] Trial 1 finished with value: 0.11373634749746735 and parameters: {'booster': 'gbtree', 'gamma': 0.9786774847568069, 'max_depth': 16, 'min_child_weight': 3, 'subsample': 0.8962011730371828}. Best is trial 6 with value: 0.10285856116795626.\n",
      "[I 2023-06-06 21:20:43,404] Trial 0 finished with value: 0.09904424168240127 and parameters: {'booster': 'gbtree', 'gamma': 3.9139432645248924, 'max_depth': 16, 'min_child_weight': 3, 'subsample': 0.8350953717943012}. Best is trial 0 with value: 0.09904424168240127.\n",
      "[I 2023-06-06 21:20:44,244] Trial 2 finished with value: 0.11140407976065217 and parameters: {'booster': 'gbtree', 'gamma': 3.851778367925877, 'max_depth': 17, 'min_child_weight': 1, 'subsample': 0.8677658178934288}. Best is trial 0 with value: 0.09904424168240127.\n",
      "[I 2023-06-06 21:20:44,331] Trial 4 finished with value: 0.11868776204023711 and parameters: {'booster': 'dart', 'gamma': 0.31699905242259685, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.5709474497278519}. Best is trial 0 with value: 0.09904424168240127.\n",
      "[I 2023-06-06 21:20:44,941] Trial 11 finished with value: 0.09532180120233662 and parameters: {'booster': 'gbtree', 'gamma': 0.778911433994664, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.6327920310994558}. Best is trial 11 with value: 0.09532180120233662.\n",
      "[I 2023-06-06 21:20:45,152] Trial 3 finished with value: 0.10253025159741988 and parameters: {'booster': 'dart', 'gamma': 3.55815127269947, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.8988018775279638}. Best is trial 11 with value: 0.09532180120233662.\n",
      "[I 2023-06-06 21:20:45,349] Trial 7 finished with value: 0.10958347165763213 and parameters: {'booster': 'dart', 'gamma': 0.8328651219369232, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.40850891495044156}. Best is trial 11 with value: 0.09532180120233662.\n",
      "[I 2023-06-06 21:20:45,941] Trial 8 finished with value: 0.09235987813636917 and parameters: {'booster': 'dart', 'gamma': 1.3619634148987343, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.9106303369819501}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:46,299] Trial 15 finished with value: 0.11210131883401803 and parameters: {'booster': 'gbtree', 'gamma': 1.3086719038647239, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.5410749904538347}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:49,109] Trial 17 finished with value: 0.09774422131911893 and parameters: {'booster': 'dart', 'gamma': 2.031075745901317, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.9965620642623099}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:49,471] Trial 18 finished with value: 0.10111170147535278 and parameters: {'booster': 'dart', 'gamma': 1.7420644806854941, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.7424035097770093}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:49,589] Trial 9 finished with value: 0.11058800117172034 and parameters: {'booster': 'dart', 'gamma': 0.3151756883175777, 'max_depth': 17, 'min_child_weight': 2, 'subsample': 0.709800924835287}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:49,708] Trial 14 finished with value: 0.10246850035837696 and parameters: {'booster': 'gbtree', 'gamma': 2.186120702095976, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.8180801282040909}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:49,959] Trial 12 finished with value: 0.11006691351210883 and parameters: {'booster': 'dart', 'gamma': 2.279972427057808, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.5148738595377269}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:49,972] Trial 13 finished with value: 0.10859511198354538 and parameters: {'booster': 'dart', 'gamma': 4.471915253449109, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.9201531179851417}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:49,972] Trial 10 finished with value: 0.10729626616560538 and parameters: {'booster': 'dart', 'gamma': 1.723360438254985, 'max_depth': 20, 'min_child_weight': 3, 'subsample': 0.6790019659497899}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:51,204] Trial 21 finished with value: 0.09846526803010941 and parameters: {'booster': 'gbtree', 'gamma': 2.6219254476554332, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.7325201902051883}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:51,473] Trial 23 finished with value: 0.09676569719067615 and parameters: {'booster': 'gbtree', 'gamma': 2.846869117550706, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.6681434068533381}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:51,506] Trial 25 finished with value: 0.10010548836011712 and parameters: {'booster': 'gbtree', 'gamma': 2.848326891342316, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7695087203546844}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:51,549] Trial 24 finished with value: 0.11804362769551652 and parameters: {'booster': 'gbtree', 'gamma': 0.020290185819633155, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7664941492791385}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:51,935] Trial 16 finished with value: 0.10064775472083014 and parameters: {'booster': 'dart', 'gamma': 2.757765815309912, 'max_depth': 20, 'min_child_weight': 3, 'subsample': 0.631517474232982}. Best is trial 8 with value: 0.09235987813636917.\n",
      "[I 2023-06-06 21:20:52,477] Trial 28 finished with value: 0.09226141451002756 and parameters: {'booster': 'gbtree', 'gamma': 1.4786501235721907, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.6551737985865279}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:52,495] Trial 29 finished with value: 0.10111699071710592 and parameters: {'booster': 'gbtree', 'gamma': 1.2693401496650414, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.6644027340270638}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:52,768] Trial 26 finished with value: 0.12905904285780936 and parameters: {'booster': 'gbtree', 'gamma': 0.0125407655426093, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7730485473187289}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:52,882] Trial 30 finished with value: 0.09906328266539667 and parameters: {'booster': 'gbtree', 'gamma': 4.875335089997593, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.667242490187557}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:53,219] Trial 32 finished with value: 0.10267707718889263 and parameters: {'booster': 'gbtree', 'gamma': 0.8517867191269706, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.804889320475085}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:53,239] Trial 31 finished with value: 0.09316831833837871 and parameters: {'booster': 'gbtree', 'gamma': 1.2908429559732795, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6217543074182363}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:53,386] Trial 19 finished with value: 0.09893660771829327 and parameters: {'booster': 'dart', 'gamma': 0.09865224497386194, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7245614735774889}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:53,405] Trial 27 finished with value: 0.11665882489781777 and parameters: {'booster': 'gbtree', 'gamma': 0.05046025587385605, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.782428230469246}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:53,742] Trial 20 finished with value: 0.12726581969897252 and parameters: {'booster': 'dart', 'gamma': 0.18391394259310312, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7022226645369922}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:54,085] Trial 22 finished with value: 0.09529959578345 and parameters: {'booster': 'dart', 'gamma': 2.768601495099899, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6431974313909784}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:55,043] Trial 33 finished with value: 0.09687769779578217 and parameters: {'booster': 'gbtree', 'gamma': 0.7923249816457183, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.6121401769833749}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:55,233] Trial 34 finished with value: 0.1075809017678907 and parameters: {'booster': 'gbtree', 'gamma': 0.7829907480744089, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.7144451937598617}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:55,672] Trial 37 finished with value: 0.10365390104000911 and parameters: {'booster': 'gbtree', 'gamma': 1.5519522935271395, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.8302170260572247}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:55,686] Trial 38 finished with value: 0.09706713063890386 and parameters: {'booster': 'gbtree', 'gamma': 1.469650086584348, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.6079130390715854}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:55,913] Trial 39 finished with value: 0.09832478061452593 and parameters: {'booster': 'gbtree', 'gamma': 0.6283201199346768, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.623065459565917}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:56,940] Trial 36 finished with value: 0.10322855375620639 and parameters: {'booster': 'dart', 'gamma': 1.6414687919023074, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.7152394059761782}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:57,803] Trial 40 finished with value: 0.11602853933577358 and parameters: {'booster': 'dart', 'gamma': 1.7035922382903474, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.5914168684516722}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:58,398] Trial 35 finished with value: 0.10663763785456508 and parameters: {'booster': 'dart', 'gamma': 1.5430409710771609, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.7122686963781103}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:58,729] Trial 41 finished with value: 0.1134754107913673 and parameters: {'booster': 'dart', 'gamma': 1.7483872007549626, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.5867475345424038}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:58,954] Trial 42 finished with value: 0.10336650128434037 and parameters: {'booster': 'dart', 'gamma': 1.7848556979453056, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.5896096899553354}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:59,361] Trial 44 finished with value: 0.1098359843987119 and parameters: {'booster': 'dart', 'gamma': 1.869217567893005, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.5783996132306705}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:59,453] Trial 43 finished with value: 0.10764773083159213 and parameters: {'booster': 'dart', 'gamma': 1.8752891294765333, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.587251878173387}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:59,505] Trial 49 finished with value: 0.0979210796404824 and parameters: {'booster': 'gbtree', 'gamma': 1.1049346606296013, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.641154306309457}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:59,695] Trial 45 finished with value: 0.1093819815665176 and parameters: {'booster': 'dart', 'gamma': 1.0688701368762343, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.5745517651824523}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:20:59,754] Trial 50 finished with value: 0.09555337587994098 and parameters: {'booster': 'gbtree', 'gamma': 1.1275926004215864, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6458933960406978}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:00,543] Trial 46 finished with value: 0.11028024091179738 and parameters: {'booster': 'dart', 'gamma': 1.1049189118843143, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.584688230569498}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:01,907] Trial 48 finished with value: 0.10533564872992694 and parameters: {'booster': 'dart', 'gamma': 1.0605694105144128, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.5705934902460439}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:02,503] Trial 53 finished with value: 0.10370386556029149 and parameters: {'booster': 'gbtree', 'gamma': 1.1010008529577444, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.6819636194581761}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:02,788] Trial 51 finished with value: 0.10369345257929617 and parameters: {'booster': 'gbtree', 'gamma': 0.546755623135956, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.6331633887264886}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:02,890] Trial 52 finished with value: 0.09898052861946607 and parameters: {'booster': 'gbtree', 'gamma': 1.1259339412581773, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.6459508066599486}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:03,011] Trial 55 finished with value: 0.11104839255817121 and parameters: {'booster': 'gbtree', 'gamma': 0.4920723220019026, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.684212883478084}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:03,229] Trial 54 finished with value: 0.09776336069848021 and parameters: {'booster': 'gbtree', 'gamma': 1.2787988673949353, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.6918234112378526}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:03,334] Trial 56 finished with value: 0.11278903233964409 and parameters: {'booster': 'gbtree', 'gamma': 0.509251663405287, 'max_depth': 12, 'min_child_weight': 3, 'subsample': 0.6865748917160562}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:03,683] Trial 47 finished with value: 0.11503363780629983 and parameters: {'booster': 'dart', 'gamma': 1.989141015140737, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.5737442021079291}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:03,734] Trial 58 finished with value: 0.11234440648870431 and parameters: {'booster': 'gbtree', 'gamma': 0.5116564847740221, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6436348304374763}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:03,985] Trial 59 finished with value: 0.09812643020732033 and parameters: {'booster': 'gbtree', 'gamma': 1.301773678156612, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.6456886010192227}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:04,107] Trial 60 finished with value: 0.10119847138310194 and parameters: {'booster': 'gbtree', 'gamma': 1.4111982117596975, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.6953902301560433}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:04,225] Trial 61 finished with value: 0.09962762485159536 and parameters: {'booster': 'gbtree', 'gamma': 1.3399234682139494, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.6545507331587677}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:04,270] Trial 65 finished with value: 0.09464159162339288 and parameters: {'booster': 'gbtree', 'gamma': 2.316028888763335, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.7444862098276772}. Best is trial 28 with value: 0.09226141451002756.\n",
      "[I 2023-06-06 21:21:04,452] Trial 62 finished with value: 0.09078162272519734 and parameters: {'booster': 'gbtree', 'gamma': 2.2158723732357313, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6483015200684926}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:04,509] Trial 66 finished with value: 0.10802754493065725 and parameters: {'booster': 'gbtree', 'gamma': 2.1281307911056526, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.8616479289936615}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:04,646] Trial 63 finished with value: 0.10729570264924718 and parameters: {'booster': 'gbtree', 'gamma': 2.3045277608281873, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.648993169017409}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:04,818] Trial 69 finished with value: 0.11325212348812894 and parameters: {'booster': 'gbtree', 'gamma': 2.4106815727152133, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.9085132332130359}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:04,959] Trial 64 finished with value: 0.09574033889529446 and parameters: {'booster': 'gbtree', 'gamma': 2.285040197851626, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6505505243483697}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:04,992] Trial 70 finished with value: 0.10404701378361485 and parameters: {'booster': 'gbtree', 'gamma': 2.415638692746023, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.7527452334232541}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:05,085] Trial 57 finished with value: 0.09628622024375394 and parameters: {'booster': 'gbtree', 'gamma': 0.5092302103721704, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.6887188412155454}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:06,063] Trial 67 finished with value: 0.10245534916888106 and parameters: {'booster': 'gbtree', 'gamma': 2.3659362807547284, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.7395479660343549}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:06,087] Trial 68 finished with value: 0.10371232559979322 and parameters: {'booster': 'gbtree', 'gamma': 3.0553008129051777, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.6723121215158434}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:06,362] Trial 71 finished with value: 0.09956079661077814 and parameters: {'booster': 'gbtree', 'gamma': 2.3687175092677726, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.667253766505523}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:06,579] Trial 72 finished with value: 0.10028018046518308 and parameters: {'booster': 'gbtree', 'gamma': 2.3936551330998395, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.6170321841848427}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:06,808] Trial 78 finished with value: 0.111898195585431 and parameters: {'booster': 'gbtree', 'gamma': 2.6443371079132105, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.61326206555039}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:06,862] Trial 74 finished with value: 0.09846526803010941 and parameters: {'booster': 'gbtree', 'gamma': 2.6158758722612543, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.7325136474447258}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:06,877] Trial 73 finished with value: 0.09766154952527852 and parameters: {'booster': 'gbtree', 'gamma': 2.5215986449406036, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.7437809402810607}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:07,097] Trial 79 finished with value: 0.10712910153910658 and parameters: {'booster': 'gbtree', 'gamma': 0.9381652283617355, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.614869033200691}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:09,324] Trial 76 finished with value: 0.09825330789743002 and parameters: {'booster': 'dart', 'gamma': 2.961729099139837, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7326996537793257}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:09,838] Trial 75 finished with value: 0.09809398230430993 and parameters: {'booster': 'dart', 'gamma': 2.57293866751918, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.7330409073369147}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:10,083] Trial 80 finished with value: 0.11856491707054646 and parameters: {'booster': 'dart', 'gamma': 2.5929069348976834, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6057323679952327}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:10,268] Trial 81 finished with value: 0.10147939638367519 and parameters: {'booster': 'dart', 'gamma': 0.9559717760666682, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6295963261088843}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:10,355] Trial 82 finished with value: 0.10461747290674159 and parameters: {'booster': 'dart', 'gamma': 0.9320946280854256, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.7130033666201648}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:10,373] Trial 83 finished with value: 0.10193452520517268 and parameters: {'booster': 'dart', 'gamma': 1.547373919008496, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6218902907575282}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:10,754] Trial 77 finished with value: 0.11563406503533522 and parameters: {'booster': 'dart', 'gamma': 2.0125520936371757, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.6686675933729841}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:10,835] Trial 90 finished with value: 0.09880273834255346 and parameters: {'booster': 'gbtree', 'gamma': 2.167813035626902, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.65943440163842}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:11,836] Trial 89 finished with value: 0.09961375177705808 and parameters: {'booster': 'gbtree', 'gamma': 1.5917133250399194, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.6594657728104405}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:12,125] Trial 92 finished with value: 0.1053374848920158 and parameters: {'booster': 'gbtree', 'gamma': 1.452553464576706, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6999356071716161}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:12,469] Trial 84 finished with value: 0.1080902523838324 and parameters: {'booster': 'dart', 'gamma': 1.6136656734253916, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.629990423910637}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:12,550] Trial 85 finished with value: 0.10259246778388992 and parameters: {'booster': 'dart', 'gamma': 1.5751593263573318, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.7061710301124496}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:12,805] Trial 88 finished with value: 0.10663713836636858 and parameters: {'booster': 'gbtree', 'gamma': 2.215495450823444, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6617302247672601}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:13,228] Trial 86 finished with value: 0.10435166503739073 and parameters: {'booster': 'dart', 'gamma': 1.548051221583098, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.7056511937473329}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:13,331] Trial 91 finished with value: 0.09652829082217926 and parameters: {'booster': 'gbtree', 'gamma': 2.178210823750006, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6551354937310124}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:13,426] Trial 94 finished with value: 0.09906965289196548 and parameters: {'booster': 'gbtree', 'gamma': 2.2403305884032783, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6350658941127781}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:13,519] Trial 96 finished with value: 0.10956625811965812 and parameters: {'booster': 'gbtree', 'gamma': 1.8593570601722584, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.9381421801632979}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:13,851] Trial 95 finished with value: 0.10064934316500107 and parameters: {'booster': 'gbtree', 'gamma': 1.223155312897255, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.5999757672258875}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:14,109] Trial 93 finished with value: 0.10960005205273914 and parameters: {'booster': 'gbtree', 'gamma': 1.4015604091503167, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.7056548754069626}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:14,462] Trial 87 finished with value: 0.10107326943832864 and parameters: {'booster': 'dart', 'gamma': 1.5162365406359442, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.7117351429760735}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:14,850] Trial 98 finished with value: 0.10721179188646085 and parameters: {'booster': 'gbtree', 'gamma': 0.6704552139506821, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.6394247190291811}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:14,921] Trial 97 finished with value: 0.09870901600031175 and parameters: {'booster': 'gbtree', 'gamma': 1.8761592963252647, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.67863391803782}. Best is trial 62 with value: 0.09078162272519734.\n",
      "[I 2023-06-06 21:21:14,930] Trial 99 finished with value: 0.09924487815494792 and parameters: {'booster': 'gbtree', 'gamma': 0.6921661525931162, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.6827063023581339}. Best is trial 62 with value: 0.09078162272519734.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "\n",
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    booster = trial.suggest_categorical('booster', ['gbtree', 'dart'])\n",
    "    gamma = trial.suggest_float('gamma', 0, 5)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 3)\n",
    "    subsample = trial.suggest_float('subsample', 0.4, 1)\n",
    "\n",
    "    xgb = XGBRegressor(booster=booster, gamma=gamma, max_depth=max_depth, min_child_weight=min_child_weight, subsample=subsample)\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_valid)\n",
    "\n",
    "    error = mean_squared_error(y_valid, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective_fun, n_trials=100, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:21:14.934160Z",
     "start_time": "2023-06-06T19:20:38.816212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'gbtree', 'gamma': 2.2158723732357313, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6483015200684926}\n",
      "Root mean squared error = 0.4205\n",
      "R-squared = 0.6137\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "xgb = XGBRegressor(**best_params)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "print(best_params)\n",
    "print('Root mean squared error = %.4f' % np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('R-squared = %.4f' % r2_score(y_test, y_pred_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:21:15.153738Z",
     "start_time": "2023-06-06T19:21:14.935507Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.38810612e-02, 1.38810612e-02, 1.05644725e-02, ...,\n       1.63997887e-04, 9.66347143e-05, 9.66347143e-05], dtype=float32)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_to_pred)\n",
    "y_pred = np.power(10, y_pred)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:21:15.158875Z",
     "start_time": "2023-06-06T19:21:15.153882Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative values predicted\n",
    "np.count_nonzero(y_pred < 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:21:15.165022Z",
     "start_time": "2023-06-06T19:21:15.159378Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df_zero_xgb = df_zero.copy()\n",
    "df_xgb = df.copy()\n",
    "\n",
    "df_zero_xgb[TARGET] = y_pred\n",
    "df_xgb.update(df_zero_xgb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:21:15.197617Z",
     "start_time": "2023-06-06T19:21:15.163396Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df_xgb, x=TARGET)\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:21:15.354278Z",
     "start_time": "2023-06-06T19:21:15.197767Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df_xgb, x=TARGET, log_scale=True)\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:21:15.709238Z",
     "start_time": "2023-06-06T19:21:15.362727Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 21:21:18,789] A new study created in memory with name: no-name-427b03a1-7856-4e7b-a1e0-ba24cace0847\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x2b89f00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x2b89f00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x2bb4695e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x2bb4695e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[I 2023-06-06 21:21:21,855] Trial 3 finished with value: 0.5879583358764648 and parameters: {'n_hidden': 3, 'n_units': 72, 'learning_rate': 0.09025330772928067}. Best is trial 3 with value: 0.5879583358764648.\n",
      "[I 2023-06-06 21:21:21,881] Trial 6 finished with value: 0.1295609325170517 and parameters: {'n_hidden': 2, 'n_units': 77, 'learning_rate': 0.015440583637591314}. Best is trial 6 with value: 0.1295609325170517.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:22,020] Trial 5 finished with value: 0.1457328498363495 and parameters: {'n_hidden': 2, 'n_units': 124, 'learning_rate': 0.037177594161361405}. Best is trial 6 with value: 0.1295609325170517.\n",
      "[I 2023-06-06 21:21:22,049] Trial 4 finished with value: 0.5869560837745667 and parameters: {'n_hidden': 4, 'n_units': 59, 'learning_rate': 0.07295400440528209}. Best is trial 6 with value: 0.1295609325170517.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:22,171] Trial 7 finished with value: 0.16811975836753845 and parameters: {'n_hidden': 4, 'n_units': 49, 'learning_rate': 0.06747297620472728}. Best is trial 6 with value: 0.1295609325170517.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:22,354] Trial 0 finished with value: 0.2385604828596115 and parameters: {'n_hidden': 4, 'n_units': 119, 'learning_rate': 0.04915115480686236}. Best is trial 6 with value: 0.1295609325170517.\n",
      "[I 2023-06-06 21:21:22,407] Trial 2 finished with value: 0.12055036425590515 and parameters: {'n_hidden': 3, 'n_units': 109, 'learning_rate': 0.020307967392262025}. Best is trial 2 with value: 0.12055036425590515.\n",
      "[I 2023-06-06 21:21:22,599] Trial 1 finished with value: 0.5806435346603394 and parameters: {'n_hidden': 4, 'n_units': 110, 'learning_rate': 0.07003103664001649}. Best is trial 2 with value: 0.12055036425590515.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:25,179] Trial 9 finished with value: 0.14970672130584717 and parameters: {'n_hidden': 2, 'n_units': 34, 'learning_rate': 0.04998626974482037}. Best is trial 2 with value: 0.12055036425590515.\n",
      "[I 2023-06-06 21:21:25,234] Trial 10 finished with value: 0.1598963886499405 and parameters: {'n_hidden': 2, 'n_units': 42, 'learning_rate': 0.090898654459988}. Best is trial 2 with value: 0.12055036425590515.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:25,395] Trial 12 finished with value: 0.12789924442768097 and parameters: {'n_hidden': 3, 'n_units': 49, 'learning_rate': 0.0462289399578043}. Best is trial 2 with value: 0.12055036425590515.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:25,487] Trial 8 finished with value: 0.14077553153038025 and parameters: {'n_hidden': 3, 'n_units': 104, 'learning_rate': 0.064033136032363}. Best is trial 2 with value: 0.12055036425590515.\n",
      "[I 2023-06-06 21:21:25,493] Trial 11 finished with value: 0.20919421315193176 and parameters: {'n_hidden': 4, 'n_units': 74, 'learning_rate': 0.07192782527468135}. Best is trial 2 with value: 0.12055036425590515.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:25,928] Trial 15 finished with value: 0.5701675415039062 and parameters: {'n_hidden': 4, 'n_units': 57, 'learning_rate': 0.0987310424644127}. Best is trial 2 with value: 0.12055036425590515.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:26,763] Trial 14 finished with value: 0.11492446064949036 and parameters: {'n_hidden': 5, 'n_units': 109, 'learning_rate': 0.0015396687129878028}. Best is trial 14 with value: 0.11492446064949036.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:27,118] Trial 13 finished with value: 0.12142882496118546 and parameters: {'n_hidden': 5, 'n_units': 77, 'learning_rate': 0.03315781045854192}. Best is trial 14 with value: 0.11492446064949036.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:28,305] Trial 16 finished with value: 0.1261436939239502 and parameters: {'n_hidden': 2, 'n_units': 59, 'learning_rate': 0.02788436912145132}. Best is trial 14 with value: 0.11492446064949036.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:28,818] Trial 18 finished with value: 0.12349095195531845 and parameters: {'n_hidden': 3, 'n_units': 96, 'learning_rate': 0.013320009633712764}. Best is trial 14 with value: 0.11492446064949036.\n",
      "[I 2023-06-06 21:21:29,046] Trial 17 finished with value: 0.11268369853496552 and parameters: {'n_hidden': 5, 'n_units': 97, 'learning_rate': 0.013973814508736086}. Best is trial 17 with value: 0.11268369853496552.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:29,434] Trial 19 finished with value: 0.14081406593322754 and parameters: {'n_hidden': 5, 'n_units': 104, 'learning_rate': 0.0007076227410866762}. Best is trial 17 with value: 0.11268369853496552.\n",
      "[I 2023-06-06 21:21:29,456] Trial 20 finished with value: 0.12897567451000214 and parameters: {'n_hidden': 5, 'n_units': 94, 'learning_rate': 0.004058325580398668}. Best is trial 17 with value: 0.11268369853496552.\n",
      "[I 2023-06-06 21:21:29,565] Trial 21 finished with value: 0.12454239279031754 and parameters: {'n_hidden': 5, 'n_units': 95, 'learning_rate': 0.0036245744476991956}. Best is trial 17 with value: 0.11268369853496552.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:30,473] Trial 22 finished with value: 0.12408823519945145 and parameters: {'n_hidden': 5, 'n_units': 94, 'learning_rate': 0.0020605007167810094}. Best is trial 17 with value: 0.11268369853496552.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:30,928] Trial 23 finished with value: 0.16649167239665985 and parameters: {'n_hidden': 5, 'n_units': 94, 'learning_rate': 0.00037190931607322675}. Best is trial 17 with value: 0.11268369853496552.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:32,233] Trial 24 finished with value: 0.1291123777627945 and parameters: {'n_hidden': 5, 'n_units': 94, 'learning_rate': 0.0005472467230550808}. Best is trial 17 with value: 0.11268369853496552.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:32,377] Trial 26 finished with value: 0.13043318688869476 and parameters: {'n_hidden': 5, 'n_units': 92, 'learning_rate': 0.0064545591229984945}. Best is trial 17 with value: 0.11268369853496552.\n",
      "[I 2023-06-06 21:21:32,442] Trial 25 finished with value: 0.13985884189605713 and parameters: {'n_hidden': 5, 'n_units': 93, 'learning_rate': 0.0014446517420270422}. Best is trial 17 with value: 0.11268369853496552.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:33,075] Trial 28 finished with value: 0.13585332036018372 and parameters: {'n_hidden': 5, 'n_units': 89, 'learning_rate': 0.022478635218110433}. Best is trial 17 with value: 0.11268369853496552.\n",
      "[I 2023-06-06 21:21:33,140] Trial 27 finished with value: 0.1131039410829544 and parameters: {'n_hidden': 5, 'n_units': 91, 'learning_rate': 0.002898151775432644}. Best is trial 17 with value: 0.11268369853496552.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:33,315] Trial 29 finished with value: 0.11950328946113586 and parameters: {'n_hidden': 5, 'n_units': 114, 'learning_rate': 0.019079652298774705}. Best is trial 17 with value: 0.11268369853496552.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:34,109] Trial 30 finished with value: 0.10678078979253769 and parameters: {'n_hidden': 5, 'n_units': 116, 'learning_rate': 0.018008817000690232}. Best is trial 30 with value: 0.10678078979253769.\n",
      "[I 2023-06-06 21:21:34,261] Trial 31 finished with value: 0.13362330198287964 and parameters: {'n_hidden': 3, 'n_units': 115, 'learning_rate': 0.019339571428942343}. Best is trial 30 with value: 0.10678078979253769.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:35,747] Trial 32 finished with value: 0.17091818153858185 and parameters: {'n_hidden': 3, 'n_units': 114, 'learning_rate': 0.01926012558988652}. Best is trial 30 with value: 0.10678078979253769.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:35,998] Trial 33 finished with value: 0.1074121743440628 and parameters: {'n_hidden': 3, 'n_units': 116, 'learning_rate': 0.019898957035324474}. Best is trial 30 with value: 0.10678078979253769.\n",
      "[I 2023-06-06 21:21:36,013] Trial 34 finished with value: 0.1132381334900856 and parameters: {'n_hidden': 3, 'n_units': 114, 'learning_rate': 0.018976084933227874}. Best is trial 30 with value: 0.10678078979253769.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:36,406] Trial 35 finished with value: 0.1369384229183197 and parameters: {'n_hidden': 3, 'n_units': 113, 'learning_rate': 0.017699409849204942}. Best is trial 30 with value: 0.10678078979253769.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:36,667] Trial 37 finished with value: 0.13662497699260712 and parameters: {'n_hidden': 4, 'n_units': 85, 'learning_rate': 0.011280240812441767}. Best is trial 30 with value: 0.10678078979253769.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:37,547] Trial 36 finished with value: 0.14382727444171906 and parameters: {'n_hidden': 4, 'n_units': 117, 'learning_rate': 0.012102846090944072}. Best is trial 30 with value: 0.10678078979253769.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:37,772] Trial 38 finished with value: 0.12554435431957245 and parameters: {'n_hidden': 4, 'n_units': 127, 'learning_rate': 0.010465781647927146}. Best is trial 30 with value: 0.10678078979253769.\n",
      "[I 2023-06-06 21:21:37,792] Trial 39 finished with value: 0.13783665001392365 and parameters: {'n_hidden': 4, 'n_units': 125, 'learning_rate': 0.013296210167881652}. Best is trial 30 with value: 0.10678078979253769.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:39,240] Trial 40 finished with value: 0.11902926862239838 and parameters: {'n_hidden': 4, 'n_units': 83, 'learning_rate': 0.01084271123766423}. Best is trial 30 with value: 0.10678078979253769.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:39,500] Trial 42 finished with value: 0.10980198532342911 and parameters: {'n_hidden': 4, 'n_units': 126, 'learning_rate': 0.009399792410953626}. Best is trial 30 with value: 0.10678078979253769.\n",
      "[I 2023-06-06 21:21:39,581] Trial 41 finished with value: 0.10139342397451401 and parameters: {'n_hidden': 4, 'n_units': 127, 'learning_rate': 0.011341387681587212}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:39,961] Trial 43 finished with value: 0.11880344152450562 and parameters: {'n_hidden': 4, 'n_units': 126, 'learning_rate': 0.009778649968684074}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:40,300] Trial 44 finished with value: 0.11060607433319092 and parameters: {'n_hidden': 4, 'n_units': 126, 'learning_rate': 0.010624367967609134}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:41,150] Trial 45 finished with value: 0.14914308488368988 and parameters: {'n_hidden': 4, 'n_units': 127, 'learning_rate': 0.008629303656874228}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:41,440] Trial 46 finished with value: 0.15546782314777374 and parameters: {'n_hidden': 4, 'n_units': 122, 'learning_rate': 0.025216601078231243}. Best is trial 41 with value: 0.10139342397451401.\n",
      "[I 2023-06-06 21:21:41,566] Trial 47 finished with value: 0.1395202875137329 and parameters: {'n_hidden': 4, 'n_units': 103, 'learning_rate': 0.0269238731791906}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:42,807] Trial 48 finished with value: 0.15856744349002838 and parameters: {'n_hidden': 3, 'n_units': 121, 'learning_rate': 0.024599820203864715}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:43,320] Trial 49 finished with value: 0.13491126894950867 and parameters: {'n_hidden': 5, 'n_units': 121, 'learning_rate': 0.0073413759408393515}. Best is trial 41 with value: 0.10139342397451401.\n",
      "[I 2023-06-06 21:21:43,496] Trial 51 finished with value: 0.1330607831478119 and parameters: {'n_hidden': 4, 'n_units': 121, 'learning_rate': 0.025221076554212338}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:43,660] Trial 52 finished with value: 0.16676375269889832 and parameters: {'n_hidden': 4, 'n_units': 121, 'learning_rate': 0.02445821817250703}. Best is trial 41 with value: 0.10139342397451401.\n",
      "[I 2023-06-06 21:21:43,690] Trial 50 finished with value: 0.13013309240341187 and parameters: {'n_hidden': 4, 'n_units': 121, 'learning_rate': 0.024761514114622855}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:44,754] Trial 53 finished with value: 0.17882388830184937 and parameters: {'n_hidden': 4, 'n_units': 119, 'learning_rate': 0.02565167553652246}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:44,897] Trial 54 finished with value: 0.14149926602840424 and parameters: {'n_hidden': 3, 'n_units': 120, 'learning_rate': 0.028558547772873748}. Best is trial 41 with value: 0.10139342397451401.\n",
      "[I 2023-06-06 21:21:44,942] Trial 55 finished with value: 0.15908759832382202 and parameters: {'n_hidden': 3, 'n_units': 121, 'learning_rate': 0.031023667412281162}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:46,293] Trial 56 finished with value: 0.5692628622055054 and parameters: {'n_hidden': 4, 'n_units': 120, 'learning_rate': 0.032492615809739424}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:46,739] Trial 57 finished with value: 0.14404402673244476 and parameters: {'n_hidden': 4, 'n_units': 108, 'learning_rate': 0.02994076356802079}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:46,911] Trial 59 finished with value: 0.1282080113887787 and parameters: {'n_hidden': 3, 'n_units': 108, 'learning_rate': 0.01563050904083376}. Best is trial 41 with value: 0.10139342397451401.\n",
      "[I 2023-06-06 21:21:47,004] Trial 58 finished with value: 0.1137225553393364 and parameters: {'n_hidden': 4, 'n_units': 107, 'learning_rate': 0.015465091592608511}. Best is trial 41 with value: 0.10139342397451401.\n",
      "[I 2023-06-06 21:21:47,039] Trial 60 finished with value: 0.11549918353557587 and parameters: {'n_hidden': 3, 'n_units': 107, 'learning_rate': 0.015718483903072705}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:47,994] Trial 61 finished with value: 0.13138873875141144 and parameters: {'n_hidden': 3, 'n_units': 110, 'learning_rate': 0.015617596703588796}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:48,338] Trial 62 finished with value: 0.10351528227329254 and parameters: {'n_hidden': 3, 'n_units': 109, 'learning_rate': 0.017216696101018343}. Best is trial 41 with value: 0.10139342397451401.\n",
      "[I 2023-06-06 21:21:48,432] Trial 63 finished with value: 0.1338227093219757 and parameters: {'n_hidden': 4, 'n_units': 107, 'learning_rate': 0.01523878931842769}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:49,826] Trial 64 finished with value: 0.12154898792505264 and parameters: {'n_hidden': 2, 'n_units': 109, 'learning_rate': 0.015307649784147902}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:50,397] Trial 65 finished with value: 0.1387624889612198 and parameters: {'n_hidden': 5, 'n_units': 100, 'learning_rate': 0.01480968393633476}. Best is trial 41 with value: 0.10139342397451401.\n",
      "[I 2023-06-06 21:21:50,528] Trial 67 finished with value: 0.11271893978118896 and parameters: {'n_hidden': 2, 'n_units': 102, 'learning_rate': 0.0066857867985078675}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:50,595] Trial 66 finished with value: 0.1114758849143982 and parameters: {'n_hidden': 5, 'n_units': 101, 'learning_rate': 0.0061471253919825105}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:51,361] Trial 68 finished with value: 0.11966182291507721 and parameters: {'n_hidden': 5, 'n_units': 100, 'learning_rate': 0.005580411689554709}. Best is trial 41 with value: 0.10139342397451401.\n",
      "[I 2023-06-06 21:21:51,389] Trial 69 finished with value: 0.1164344772696495 and parameters: {'n_hidden': 5, 'n_units': 101, 'learning_rate': 0.005248322799413545}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:51,802] Trial 70 finished with value: 0.12506793439388275 and parameters: {'n_hidden': 2, 'n_units': 102, 'learning_rate': 0.0062185093448709474}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:52,148] Trial 71 finished with value: 0.11156672239303589 and parameters: {'n_hidden': 5, 'n_units': 69, 'learning_rate': 0.005719013676480941}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:53,262] Trial 72 finished with value: 0.11085164546966553 and parameters: {'n_hidden': 2, 'n_units': 101, 'learning_rate': 0.0059154675286514635}. Best is trial 41 with value: 0.10139342397451401.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:53,886] Trial 73 finished with value: 0.10170727223157883 and parameters: {'n_hidden': 3, 'n_units': 128, 'learning_rate': 0.007153267465715828}. Best is trial 41 with value: 0.10139342397451401.\n",
      "[I 2023-06-06 21:21:54,259] Trial 75 finished with value: 0.11294132471084595 and parameters: {'n_hidden': 3, 'n_units': 128, 'learning_rate': 0.006414669535761154}. Best is trial 41 with value: 0.10139342397451401.\n",
      "[I 2023-06-06 21:21:54,358] Trial 74 finished with value: 0.09776069223880768 and parameters: {'n_hidden': 5, 'n_units': 128, 'learning_rate': 0.005187552646504159}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:54,839] Trial 77 finished with value: 0.15880265831947327 and parameters: {'n_hidden': 3, 'n_units': 68, 'learning_rate': 0.02088652916016938}. Best is trial 74 with value: 0.09776069223880768.\n",
      "[I 2023-06-06 21:21:55,005] Trial 76 finished with value: 0.11518462002277374 and parameters: {'n_hidden': 3, 'n_units': 117, 'learning_rate': 0.008140473291607562}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:55,843] Trial 78 finished with value: 0.11216453462839127 and parameters: {'n_hidden': 5, 'n_units': 117, 'learning_rate': 0.008069762622151474}. Best is trial 74 with value: 0.09776069223880768.\n",
      "[I 2023-06-06 21:21:55,977] Trial 79 finished with value: 0.1764407753944397 and parameters: {'n_hidden': 5, 'n_units': 75, 'learning_rate': 0.020800258365546425}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:56,966] Trial 80 finished with value: 0.1307932585477829 and parameters: {'n_hidden': 2, 'n_units': 117, 'learning_rate': 0.020891294984071603}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:57,311] Trial 82 finished with value: 0.11518535017967224 and parameters: {'n_hidden': 2, 'n_units': 124, 'learning_rate': 0.02149883924988203}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:57,626] Trial 81 finished with value: 0.13517440855503082 and parameters: {'n_hidden': 2, 'n_units': 128, 'learning_rate': 0.02132081097439146}. Best is trial 74 with value: 0.09776069223880768.\n",
      "[I 2023-06-06 21:21:57,778] Trial 83 finished with value: 0.14773397147655487 and parameters: {'n_hidden': 3, 'n_units': 124, 'learning_rate': 0.020704708070915734}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:58,282] Trial 84 finished with value: 0.11974996328353882 and parameters: {'n_hidden': 3, 'n_units': 124, 'learning_rate': 0.009485944182386918}. Best is trial 74 with value: 0.09776069223880768.\n",
      "[I 2023-06-06 21:21:58,413] Trial 85 finished with value: 0.12614800035953522 and parameters: {'n_hidden': 3, 'n_units': 124, 'learning_rate': 0.010774599163073275}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:21:59,303] Trial 86 finished with value: 0.11316471546888351 and parameters: {'n_hidden': 3, 'n_units': 124, 'learning_rate': 0.011873688135366552}. Best is trial 74 with value: 0.09776069223880768.\n",
      "[I 2023-06-06 21:21:59,346] Trial 87 finished with value: 0.12213139981031418 and parameters: {'n_hidden': 3, 'n_units': 124, 'learning_rate': 0.011760339481353464}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:00,568] Trial 88 finished with value: 0.11324772983789444 and parameters: {'n_hidden': 3, 'n_units': 124, 'learning_rate': 0.012370054524017227}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:00,842] Trial 89 finished with value: 0.1405600756406784 and parameters: {'n_hidden': 3, 'n_units': 124, 'learning_rate': 0.012482736697497348}. Best is trial 74 with value: 0.09776069223880768.\n",
      "[I 2023-06-06 21:22:01,004] Trial 90 finished with value: 0.11472736299037933 and parameters: {'n_hidden': 3, 'n_units': 112, 'learning_rate': 0.011677609277577546}. Best is trial 74 with value: 0.09776069223880768.\n",
      "[I 2023-06-06 21:22:01,120] Trial 91 finished with value: 0.12496931105852127 and parameters: {'n_hidden': 3, 'n_units': 112, 'learning_rate': 0.011392679999227112}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:01,974] Trial 92 finished with value: 0.11040046811103821 and parameters: {'n_hidden': 3, 'n_units': 113, 'learning_rate': 0.012062119025570677}. Best is trial 74 with value: 0.09776069223880768.\n",
      "[I 2023-06-06 21:22:02,134] Trial 93 finished with value: 0.155609592795372 and parameters: {'n_hidden': 4, 'n_units': 112, 'learning_rate': 0.012103978356543092}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:03,089] Trial 94 finished with value: 0.15562300384044647 and parameters: {'n_hidden': 4, 'n_units': 111, 'learning_rate': 0.0030607295859154393}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:03,382] Trial 95 finished with value: 0.12032917141914368 and parameters: {'n_hidden': 4, 'n_units': 112, 'learning_rate': 0.0031455885335810174}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:04,112] Trial 96 finished with value: 0.11402996629476547 and parameters: {'n_hidden': 4, 'n_units': 111, 'learning_rate': 0.0040020534241151096}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:04,376] Trial 97 finished with value: 0.10408058017492294 and parameters: {'n_hidden': 4, 'n_units': 112, 'learning_rate': 0.0030375875254129024}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:04,600] Trial 98 finished with value: 0.11153806000947952 and parameters: {'n_hidden': 5, 'n_units': 112, 'learning_rate': 0.002385158345792459}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:04,918] Trial 99 finished with value: 0.10640221834182739 and parameters: {'n_hidden': 5, 'n_units': 116, 'learning_rate': 0.0025508845759727996}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:05,414] Trial 100 finished with value: 0.15684139728546143 and parameters: {'n_hidden': 4, 'n_units': 115, 'learning_rate': 0.0033743954012006652}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:05,842] Trial 101 finished with value: 0.11581837385892868 and parameters: {'n_hidden': 4, 'n_units': 116, 'learning_rate': 0.017415354567073486}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:06,815] Trial 102 finished with value: 0.15741866827011108 and parameters: {'n_hidden': 4, 'n_units': 116, 'learning_rate': 0.018073644863776266}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:07,105] Trial 103 finished with value: 0.10885246098041534 and parameters: {'n_hidden': 4, 'n_units': 118, 'learning_rate': 0.009144595719207484}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:08,128] Trial 105 finished with value: 0.12169286608695984 and parameters: {'n_hidden': 4, 'n_units': 115, 'learning_rate': 0.017780762756921878}. Best is trial 74 with value: 0.09776069223880768.\n",
      "[I 2023-06-06 21:22:08,156] Trial 104 finished with value: 0.12845495343208313 and parameters: {'n_hidden': 3, 'n_units': 115, 'learning_rate': 0.00041648679383093565}. Best is trial 74 with value: 0.09776069223880768.\n",
      "[I 2023-06-06 21:22:08,281] Trial 106 finished with value: 0.15036575496196747 and parameters: {'n_hidden': 4, 'n_units': 116, 'learning_rate': 0.017542301080037317}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:08,603] Trial 107 finished with value: 0.1429237574338913 and parameters: {'n_hidden': 5, 'n_units': 116, 'learning_rate': 0.00020638183941476887}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:09,005] Trial 108 finished with value: 0.12289813905954361 and parameters: {'n_hidden': 5, 'n_units': 116, 'learning_rate': 0.017282630861800045}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:09,973] Trial 109 finished with value: 0.15285517275333405 and parameters: {'n_hidden': 5, 'n_units': 105, 'learning_rate': 0.0002549597396626843}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:10,588] Trial 110 finished with value: 0.11188919097185135 and parameters: {'n_hidden': 5, 'n_units': 127, 'learning_rate': 0.0007232096706874416}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:10,875] Trial 111 finished with value: 0.10680782794952393 and parameters: {'n_hidden': 5, 'n_units': 119, 'learning_rate': 0.0015728377880455278}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:11,963] Trial 112 finished with value: 0.10848448425531387 and parameters: {'n_hidden': 5, 'n_units': 119, 'learning_rate': 0.008664822197060475}. Best is trial 74 with value: 0.09776069223880768.\n",
      "[I 2023-06-06 21:22:12,078] Trial 114 finished with value: 0.1083257794380188 and parameters: {'n_hidden': 5, 'n_units': 119, 'learning_rate': 0.009013497827728957}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:12,405] Trial 115 finished with value: 0.11516756564378738 and parameters: {'n_hidden': 5, 'n_units': 119, 'learning_rate': 0.0086836035240903}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:13,041] Trial 116 finished with value: 0.12756216526031494 and parameters: {'n_hidden': 5, 'n_units': 119, 'learning_rate': 0.009655711486739}. Best is trial 74 with value: 0.09776069223880768.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:13,590] Trial 117 finished with value: 0.09465885907411575 and parameters: {'n_hidden': 3, 'n_units': 119, 'learning_rate': 0.00861062543452765}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:14,224] Trial 118 finished with value: 0.10190275311470032 and parameters: {'n_hidden': 4, 'n_units': 119, 'learning_rate': 0.009737135565920004}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:14,366] Trial 113 finished with value: 0.10335748642683029 and parameters: {'n_hidden': 5, 'n_units': 119, 'learning_rate': 0.008632774140657102}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:14,713] Trial 119 finished with value: 0.10152744501829147 and parameters: {'n_hidden': 5, 'n_units': 119, 'learning_rate': 0.008365169580406156}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:15,620] Trial 120 finished with value: 0.12312810122966766 and parameters: {'n_hidden': 5, 'n_units': 118, 'learning_rate': 0.00954665362694068}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:16,013] Trial 121 finished with value: 0.12591299414634705 and parameters: {'n_hidden': 5, 'n_units': 118, 'learning_rate': 0.008368601681961938}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:16,088] Trial 122 finished with value: 0.09879165887832642 and parameters: {'n_hidden': 5, 'n_units': 122, 'learning_rate': 0.007667297660826064}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:16,894] Trial 123 finished with value: 0.09764651209115982 and parameters: {'n_hidden': 5, 'n_units': 119, 'learning_rate': 0.007919110624840579}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:17,524] Trial 124 finished with value: 0.11098914593458176 and parameters: {'n_hidden': 5, 'n_units': 122, 'learning_rate': 0.004342360647682181}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:17,979] Trial 125 finished with value: 0.10827797651290894 and parameters: {'n_hidden': 5, 'n_units': 122, 'learning_rate': 0.0037135523818038864}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:18,210] Trial 126 finished with value: 0.14160043001174927 and parameters: {'n_hidden': 5, 'n_units': 122, 'learning_rate': 0.004283441784511985}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:18,422] Trial 127 finished with value: 0.1431887000799179 and parameters: {'n_hidden': 5, 'n_units': 33, 'learning_rate': 0.003909205207591355}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:19,589] Trial 128 finished with value: 0.12380959838628769 and parameters: {'n_hidden': 5, 'n_units': 122, 'learning_rate': 0.004242890435287409}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:20,032] Trial 130 finished with value: 0.1628350466489792 and parameters: {'n_hidden': 5, 'n_units': 122, 'learning_rate': 0.004384410232361652}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:20,222] Trial 129 finished with value: 0.10823051631450653 and parameters: {'n_hidden': 5, 'n_units': 122, 'learning_rate': 0.003972151415541817}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:21,204] Trial 131 finished with value: 0.10767757892608643 and parameters: {'n_hidden': 5, 'n_units': 128, 'learning_rate': 0.004260329914620034}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:21,788] Trial 132 finished with value: 0.1249711662530899 and parameters: {'n_hidden': 5, 'n_units': 128, 'learning_rate': 0.01402818745390054}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:22,269] Trial 134 finished with value: 0.09618785232305527 and parameters: {'n_hidden': 5, 'n_units': 128, 'learning_rate': 0.013448792439374493}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:22,377] Trial 135 finished with value: 0.1327788382768631 and parameters: {'n_hidden': 5, 'n_units': 38, 'learning_rate': 0.007290230567623843}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:22,948] Trial 133 finished with value: 0.11856425553560257 and parameters: {'n_hidden': 5, 'n_units': 126, 'learning_rate': 0.013757625987383795}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:23,627] Trial 136 finished with value: 0.13186432421207428 and parameters: {'n_hidden': 5, 'n_units': 128, 'learning_rate': 0.013991479215503849}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:24,006] Trial 137 finished with value: 0.1176547184586525 and parameters: {'n_hidden': 5, 'n_units': 128, 'learning_rate': 0.00711614427496883}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:24,327] Trial 138 finished with value: 0.1030794158577919 and parameters: {'n_hidden': 5, 'n_units': 126, 'learning_rate': 0.007144483112016604}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:25,286] Trial 139 finished with value: 0.10817769914865494 and parameters: {'n_hidden': 5, 'n_units': 126, 'learning_rate': 0.006865873865677023}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:25,742] Trial 140 finished with value: 0.10258413106203079 and parameters: {'n_hidden': 5, 'n_units': 126, 'learning_rate': 0.007216917507801928}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:26,430] Trial 141 finished with value: 0.12613709270954132 and parameters: {'n_hidden': 5, 'n_units': 125, 'learning_rate': 0.007164237390951577}. Best is trial 117 with value: 0.09465885907411575.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 21:22:26,733] Trial 142 finished with value: 0.15159013867378235 and parameters: {'n_hidden': 5, 'n_units': 125, 'learning_rate': 0.007067646639404077}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:27,136] Trial 143 finished with value: 0.12381739914417267 and parameters: {'n_hidden': 5, 'n_units': 126, 'learning_rate': 0.00721160726622526}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:27,559] Trial 144 finished with value: 0.13635313510894775 and parameters: {'n_hidden': 5, 'n_units': 126, 'learning_rate': 0.007341910160547453}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:27,928] Trial 146 finished with value: 0.12297644466161728 and parameters: {'n_hidden': 5, 'n_units': 126, 'learning_rate': 0.006605849622185683}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:27,956] Trial 145 finished with value: 0.1505243182182312 and parameters: {'n_hidden': 5, 'n_units': 124, 'learning_rate': 0.006199274602935631}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:28,155] Trial 147 finished with value: 0.10368102788925171 and parameters: {'n_hidden': 5, 'n_units': 125, 'learning_rate': 0.00632858039012216}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:28,285] Trial 148 finished with value: 0.1395796537399292 and parameters: {'n_hidden': 5, 'n_units': 125, 'learning_rate': 0.00666519482631607}. Best is trial 117 with value: 0.09465885907411575.\n",
      "[I 2023-06-06 21:22:28,434] Trial 149 finished with value: 0.11850348860025406 and parameters: {'n_hidden': 5, 'n_units': 126, 'learning_rate': 0.010239426615055646}. Best is trial 117 with value: 0.09465885907411575.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_model(trial):\n",
    "\n",
    "    n_hidden = trial.suggest_int('n_hidden', 2, 5)\n",
    "    n_units = trial.suggest_int('n_units', 32, 128)\n",
    "    learn_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_units, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "    for i in range(n_hidden):\n",
    "        model.add(Dense(n_units, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "                  metrics=tensorflow.keras.metrics.MeanSquaredError())\n",
    "    return model\n",
    "\n",
    "\n",
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_valid, y_valid), verbose=False)\n",
    "\n",
    "    error = model.evaluate(X_valid, y_valid, verbose=False)[1]\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective_fun, n_trials=150, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:22:28.438361Z",
     "start_time": "2023-06-06T19:21:15.711758Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_hidden': 3, 'n_units': 119, 'learning_rate': 0.00861062543452765}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:22:28.441390Z",
     "start_time": "2023-06-06T19:22:28.439564Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 415us/step\n",
      "Root mean squared error = 0.4476\n",
      "R-squared = 0.5624\n"
     ]
    }
   ],
   "source": [
    "model = create_model(study.best_trial)\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_valid, y_valid), verbose=False)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "print('Root mean squared error = %.4f' % np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('R-squared = %.4f' % r2_score(y_test, y_pred_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:22:29.255427Z",
     "start_time": "2023-06-06T19:22:28.442346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 411us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.01597912],\n       [0.01480416],\n       [0.01156535],\n       ...,\n       [0.00012735],\n       [0.00014895],\n       [0.00011582]], dtype=float32)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_to_pred)\n",
    "y_pred = np.power(10, y_pred)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:22:29.298297Z",
     "start_time": "2023-06-06T19:22:29.256740Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df_zero_ann = df_zero.copy()\n",
    "df_ann = df.copy()\n",
    "\n",
    "df_zero_ann[TARGET] = y_pred\n",
    "df_ann.update(df_zero_ann)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:22:29.323133Z",
     "start_time": "2023-06-06T19:22:29.302709Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAHFCAYAAAAQU+iSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2CElEQVR4nO3deVhV1f7H8c9RRsUR1DLNShJNERFEzZmsHLNQKyvtZtchMeu55ZRlpXhJRRuUUtMss5uzVqZp2VzmgIqZWtpIOUHOgkzu3x/G+XkE9IAHDizer+fxeTpr773W+p4F+XHvffaxWZZlCQAAwDDl3D0BAACAokDIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADlEEl4RmgJWEOxcGZOsvKewEUN0IOUML0799fQUFB9j8NGzZUaGiooqKitGDBAmVlZTnsHxkZqTFjxjjd/4YNGzR69OjL7jdmzBhFRkYWepz8nDx5UqNGjdLWrVvtbf3791f//v2vuG9XycrK0pgxYxQaGqrmzZvru+++K1Q/r776qubNm+fQNnXqVEVERKhZs2ZatWqV0+vhKkFBQZoxY0axjQe4k4e7JwAgt5tuuknPPvusJCk7O1snTpzQl19+qdjYWG3dulUvvfSSypU7/2+UmTNnys/Pz+m+33zzTaf2GzZsmAYMGFDguV/Onj179N5776l37972tpxaS4qvvvpKK1eu1LBhw3TzzTfrpptuKlQ/L7/8soYPH25//dNPP2nu3Lm6++671atXL91www167LHHXDVtpyxevFhXXXVVsY4JuAshByiB/Pz81KxZM4e2yMhI3XDDDZo0aZJWr16tO+64Q5IK/Rfw5Vx77bVF0m9eAgMDi20sZxw/flySFBUVpbp167q83+7duys8PNxl/RbExT9XgMm4XAWUIg888IBq1aqlRYsW2dsuvoyUE4CaNm2qVq1a6cknn9Thw4clnb8stHnzZm3evFlBQUHatGmTNm3apKCgIC1atEidOnVS8+bN9c033+S6XCVJmZmZiomJUYsWLRQeHq7Ro0fr6NGj9u15XXbK6T9nrJyzQwMGDLDve/Fx6enpio+PV5cuXRQcHKzbbrtNc+bM0blz5xzGGjdunObMmaOOHTsqODhY9957r3bu3HnJ9zA7O1vvvPOOevbsqaZNm6pjx46Ki4tTenq6pPOX6XLez86dO+d7Ge3cuXN68cUXFRkZqSZNmigyMlLTpk1TZmampPOXhaTzZ9pyLhHl9PXggw8qMjIyz/VwVlBQkN59912NGTNGYWFhioiIUExMjM6ePavJkyerVatWatmypcaNG2evLee4nMtVOWuzceNGDRw4UCEhIWrTpo2mTp2q7Oxsp+cClFScyQFKkXLlyql169b68MMPlZWVJQ8Px1/hhIQEjRo1SsOGDVOLFi106NAhTZ06VU888YQWLlyoZ599ViNHjpR0/hJRYGCgfvjhB0nn/zJ++umndfbsWYWGhuqDDz7INf7atWsVEhKiF154QUePHlVcXJz279+vJUuWqHz58pedf+PGjTV+/HhNmDBB48ePV8uWLXPtY1mWhg4dqh07dmj48OFq2LChNm3apJdeeklJSUmaOHGifd9169apfv36evrpp2VZliZPnqxHH31Un376ab7zGT9+vN577z0NGjRI4eHh2r17t+Lj47Vnzx7NnTtXw4YN01VXXaXXXntNM2fO1PXXX59nP6+//rreffddjR49WnXr1lViYqJefPFFeXp6asSIEVq8eLHuuece9enTR3379tVVV12l6tWr22sPDQ2Vl5dXrvUoiKlTp6pHjx6aOXOmPvvsM7311lv6+uuv1bBhQ8XFxWnHjh2aMWOGrr/+ev373//Ot58nn3xS9913nwYNGqTPP/9cc+fOVd26dXXvvfcWaD5ASUPIAUqZgIAAZWZm6vjx4woICHDYlpCQIB8fHw0ePFheXl6SpKpVq+r777+XZVkKDAy0379z8WWL++67T126dLnk2NWqVdO8efNUoUIF++vo6Gh9+eWX6tSp02Xn7ufnZ/+LPDAwMM+/1L/88kt9++23mj59urp37y5JatOmjXx8fPTyyy9rwIABuvHGGyWdv0F43rx59prOnDmj0aNHa8+ePWrSpEmuvvfv369ly5bpiSee0ODBg+1916xZU6NGjdKXX36pDh062C/VNWrUSHXq1Mmzls2bN6tJkyb2e4siIiLk6+urSpUqSfr/9/eqq66y//eFtedcZsxvPZwRGBioCRMm2MdfunSpMjMzFRcXJw8PD7Vt21br1q3Ttm3bLtlP3759FR0dLUlq3bq1PvnkE33++eeEHJR6XK4CSpmcjxvbbLZc21q0aKG0tDT16NFD06ZN09atW9W2bVsNHz48z/0v1KhRo8uO3aFDB3vAkc5fKvPw8NCWLVsKWEX+Nm/eLA8Pj1yBK+cepM2bN9vbLgxtklSrVi1JUlpaWr59S7KHpxzdu3dX+fLlC3S5qGXLlvrmm2903333ae7cudq/f78eeOAB9erVy+k+rlRoaKj9v8uXL69q1aqpcePGDmf4qlatqlOnTjndj3Q+mKWmprp2soAbEHKAUubw4cPy8fFR1apVc20LDQ3VnDlzVLduXc2fP1/333+/2rdvr7fffvuy/V4YXvJTo0YNh9flypVTtWrVdPLkSafnfzknTpxQtWrVcl1uyhn7wr+wfX19c81HksO9Oxf3fWFfOTw8PFStWrXLhoEL/fvf/9b48eN19uxZxcXFqXv37urRo0ehP25eGHl9qs6ZdbyYj4+Pw+ty5crx7B4YgZADlCJZWVnatGmTmjdvnu89J+3atdO8efO0ZcsWzZo1Sw0aNFBMTMxlb8h1Rs6ng3JkZ2fr2LFj8vf3d2i7UEHPCFSpUkXHjh3L1c+RI0cknb9EVlhVqlSRJCUnJzu0Z2Zm6tixYwXqu1y5crr//vu1YsUKffPNN4qNjVVGRoYeffRRZWRkFHqOAFyHkAOUIosXL1ZycrL69euX5/bJkyerd+/esixLvr6+6tSpk/1BcwcOHJD0/2c7CuObb75xeBjhunXrlJWVZb+B2M/PT4cOHXI4JiEhweH15W5QjoiIUFZWlj766COH9vfff1+SFBYWVuj5R0RESJI+/PBDh/YPP/xQ2dnZBer73nvvVUxMjCTJ399fUVFRuv/++3Xy5EmdPn1aknPv9ZWsB4BL48ZjoAQ6ffq0duzYIen8pZdjx47p66+/1uLFi3XHHXfotttuy/O4Vq1aaf78+RozZozuuOMOZWZmau7cuapatapatWolSapcubK2b9+ujRs3FvgZO8nJyXr00UfVv39//fbbb5o+fbratGmj1q1bS5I6deqkTz/9VLGxsYqMjNTWrVu1atUqhz5ybsz9/PPPVaVKFTVs2NBhe/v27dWyZUs9/fTTOnz4sBo2bKjNmzfr9ddf11133XVFz9QJDAzUXXfdpVdeeUVpaWlq0aKF9uzZo5kzZ6ply5Zq166d0321aNFCb7zxhgICAhQaGqrDhw9r/vz5ioiIUPXq1SWdf6+3bdumLVu25PtcnIvXI+dsE4ArR8gBSqDdu3frnnvukXT+BuOKFSuqQYMGeu6559S3b998j+vQoYPi4uL0xhtv2G82DgsL04IFC+z38Nx///3atWuXBg0apNjYWNWsWdPped133306deqUoqOj5eXlpZ49e2rkyJH2m5p79+6tP/74QytXrtSiRYvUokULvfLKKw5nnm688Ub16NFD77zzjr766iutXr3aYQybzabZs2frlVde0ZtvvqmjR4+qTp06+s9//qOHHnrI6bnmZ9KkSapXr56WL1+u119/XTVr1tSAAQM0bNiwAp1Veeyxx+Tl5aXly5crPj5elSpVUmRkpJ544gn7PkOHDtWrr76qQYMGac2aNXn2c/F69OzZ84prBHCezeLuMgAAYCDO5ABACXHu3Ll8Pxl2oYsfAgkgb5zJAYASYsyYMVq5cuVl9/vxxx+LYTZA6UfIAYAS4s8//9SxY8cuu19wcHAxzAYo/Qg5AADASDygAQAAGImQAwAAjETIAQAARiLkAAAAI5X5hy38/fcpufLWa5tN8vev5PJ+SxJqNENZqFEqG3VSoxmosWB9OKPMhxzLUpH8MBVVvyUJNZqhLNQolY06qdEM1Og6XK4CAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGMnD3RMw0eGTZ3XwdIasC9qq+XqqYjmb2+YEAEBZQ8gpAn+fTtfED/c4tD3dvZEqVvRy04wAACh7uFwFAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARnJryDl48KCGDBmi5s2bKzIyUm+++aZ92+7du9W3b1+FhISod+/e2rVrl8Oxq1evVufOnRUSEqLo6GgdPXq0mGcPAABKMreGnMcff1wVKlTQihUr9NRTT+mll17Sxx9/rNTUVA0ePFjh4eFasWKFQkNDNWTIEKWmpkqSdu7cqXHjxmn48OFavHixTp48qbFjx7qzFAAAUMK4LeScOHFCO3bs0COPPKLrrrtOnTt3Vrt27bRx40atWbNG3t7eGjVqlOrXr69x48apYsWK+uijjyRJCxcuVNeuXXXnnXeqYcOGmjJlir744gslJSW5qxwAAFDCuC3k+Pj4yNfXVytWrFBmZqZ++eUXbdu2TY0aNVJiYqLCwsJks9kkSTabTc2bN9eOHTskSYmJiQoPD7f3dfXVV6t27dpKTEx0RykAAKAE8nDXwN7e3ho/frwmTpyoBQsWKDs7W1FRUerbt682bNigwMBAh/39/f21b98+SdKRI0dUs2bNXNsPHTpU4Hn8k6NcJr/+bEUwlrvk1GFKPXmhRnOUhTqp0QzUWLA+nOG2kCNJP//8szp16qSHHnpI+/bt08SJE9W6dWulpaXJy8vLYV8vLy9lZGRIks6ePXvJ7QXh71+p8AXk4/CBE/L0LO/Q5uXloYAA14/lTkXx3pU01GiOslAnNZqBGl3HbSFn48aNWrZsmb744gv5+PgoODhYhw8f1muvvaa6devmCiwZGRny8fGRdP4sUF7bfX19CzyPv/8+JcsqfB0Xy0mYmZnZDu0ZGVlKSTnluoHcyGY7/wPq6veuJKFGc5SFOqnRDNRYsD6c4baQs2vXLtWrV88eXCTppptu0qxZsxQeHq6UlBSH/VNSUuyXqGrVqpXn9ho1ahR4HpalYvlhslQ84xSn4nrv3IkazVEW6qRGM1Cj67jtxuOaNWvq999/dzgj88svv6hOnToKCQnR9u3bZf3zDliWpW3btikkJESSFBISooSEBPtxBw8e1MGDB+3bAQAA3BZyIiMj5enpqaefflq//vqrPv30U82aNUv9+/dXly5ddPLkSU2aNEn79+/XpEmTlJaWpq5du0qS+vXrp/fee09Lly7V3r17NWrUKHXs2FF169Z1VzkAAKCEcVvIqVSpkt58800lJyerT58+io2N1SOPPKJ77rlHfn5+mj17thISEhQVFaXExETNmTNHFSpUkCSFhoZqwoQJio+PV79+/VSlShXFxsa6qxQAAFACufXTVYGBgZo/f36e25o2baqVK1fme2xUVJSioqKKamoAAKCU4ws6AQCAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACO5NeRkZGTo+eefV4sWLXTzzTdr+vTpsixLkrR792717dtXISEh6t27t3bt2uVw7OrVq9W5c2eFhIQoOjpaR48edUcJAACghHJryImJidG3336refPmadq0aVqyZIkWL16s1NRUDR48WOHh4VqxYoVCQ0M1ZMgQpaamSpJ27typcePGafjw4Vq8eLFOnjypsWPHurMUAABQwni4a+Djx49r+fLlmj9/vpo2bSpJGjhwoBITE+Xh4SFvb2+NGjVKNptN48aN05dffqmPPvpIUVFRWrhwobp27ao777xTkjRlyhR16tRJSUlJqlu3rrtKAgAAJYjbzuQkJCTIz89PERER9rbBgwcrNjZWiYmJCgsLk81mkyTZbDY1b95cO3bskCQlJiYqPDzcftzVV1+t2rVrKzExsVhrAAAAJZfbzuQkJSXpmmuu0apVqzRr1ixlZmYqKipKjzzyiJKTkxUYGOiwv7+/v/bt2ydJOnLkiGrWrJlr+6FDhwo8j39ylMvk15+tCMZyl5w6TKknL9RojrJQJzWagRoL1ocz3BZyUlNT9fvvv2vRokWKjY1VcnKyxo8fL19fX6WlpcnLy8thfy8vL2VkZEiSzp49e8ntBeHvX6nwReTj8IET8vQs79Dm5eWhgADXj+VORfHelTTUaI6yUCc1moEaXcdtIcfDw0OnT5/WtGnTdM0110iSDhw4oHfffVf16tXLFVgyMjLk4+MjSfL29s5zu6+vb4Hn8fffp/TPB7pcIidhZmZmO7RnZGQpJeWU6wZyI5vt/A+oq9+7koQazVEW6qRGM1BjwfpwhttCTo0aNeTt7W0POJJ0/fXX6+DBg4qIiFBKSorD/ikpKfZLVLVq1cpze40aNQo8D8tSsfwwWSqecYpTcb137kSN5igLdVKjGajRddx243FISIjS09P166+/2tt++eUXXXPNNQoJCdH27dvtz8yxLEvbtm1TSEiI/diEhAT7cQcPHtTBgwft2wEAANwWcm644QZ17NhRY8eO1d69e/XVV19pzpw56tevn7p06aKTJ09q0qRJ2r9/vyZNmqS0tDR17dpVktSvXz+99957Wrp0qfbu3atRo0apY8eOfHwcAADYufVhgHFxcbr22mvVr18/jR49Wvfff7/69+8vPz8/zZ49WwkJCYqKilJiYqLmzJmjChUqSJJCQ0M1YcIExcfHq1+/fqpSpYpiY2PdWQoAAChh3HZPjiRVqlRJU6ZMyXNb06ZNtXLlynyPjYqKUlRUVFFNDQAAlHJ8QScAADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYyeUh5+jRo67uEgAAoMAKFXIaNWqUZ5j566+/dMstt1zxpAAAAK6Uh7M7rlq1SitWrJAkWZal6OhoeXp6Ouxz5MgR1ahRw7UzBAAAKASnQ86tt96qP//8U5K0efNmNWvWTBUrVnTYp0KFCrr11ltdO0MAAIBCcDrkVKxYUcOHD5ckXXPNNerWrZu8vb2LbGIAAABXwumQc6G77rpLv//+u3bt2qXMzMxc2++8884rnRcAAMAVKVTImTt3ruLi4lSlSpVcl6xsNhshBwAAuF2hQs4bb7yhkSNH6uGHH3b1fAAAAFyiUB8hT09P12233ebquQAAALhMoUJOz5499b///U+WZbl6PgAAAC5RqMtVp0+f1rJly7R69WrVqVMn1/NyFixY4JLJAQAAFFahQs51112noUOHunouAAAALlOokJPzvBwAAICSqlAhZ+zYsZfcHhsbW6jJAAAAuIpLvoU8KytLv/76q9asWaPq1au7oksAAIArUqgzOfmdqZk7d65++umnK5oQAACAK7jkTE6OLl266OOPP3ZllwAAAIXispCTmpqqJUuWqFq1aq7qEgAAoNAKdbmqYcOGstlsudq9vb0VExNzxZMCAAC4UoUKORc/7M9ms8nT01OBgYHy8/NzycQAAACuRKFCTkREhCTpt99+088//6xz587p+uuvJ+AAAIASo1Ah5+TJkxo7dqw2bNigKlWqKDs7W2fOnFGLFi0UHx+vSpUquXqeAAAABVKoG49jYmJ06NAhrVmzRps2bdLWrVv1wQcfKDU1lQcBAgCAEqFQIefTTz/Vc889pxtuuMHeFhgYqPHjx2vDhg0umxwAAEBhFSrkeHt7q1y53IfabDZlZ2df8aQAAACuVKFCTmRkpJ5//nn98ccf9rbffvtNMTEx6tChg8smBwAAUFiFuvF45MiRio6O1u23367KlStLkk6cOKH27dvrmWeecekEAQAACqPAIef3339X7dq19fbbb+vHH3/Uzz//LG9vb1133XWqX79+UcwRAACgwJy+XGVZlmJiYtS1a1dt375dkhQUFKRu3bpp+fLl6tGjh1544QVZllVkkwUAAHCW0yFnwYIFWrNmjeLj4+0PA8zx6quvKj4+XitXrtS7777r8kkCAAAUlNMhZ8mSJXrmmWfUqVOnPLdHRkbqySefJOQAAIASwemQ89dff6lp06aX3KdVq1ZKSkq64kkBAABcKadDjr+/v/76669L7nPo0CFVrVr1SucEAABwxZwOObfeeqtmzJihzMzMPLdnZWVp5syZatu2rcsmBwAAUFhOf4R82LBh6tOnj6KiotS/f381adJElSpV0okTJ/TDDz9o4cKFOnPmjKZMmVKU8wUAAHCK0yGncuXKWrJkieLi4vTCCy8oLS1N0vmPlleqVEndunXTo48+qoCAgCKbLAAAgLMK9DDAqlWrKiYmRuPHj1dSUpJOnjypqlWr6tprr1X58uWLao4AAAAFVqivdfDy8uLpxgAAoEQr1Bd0AgAAlHSEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAI5WYkDN48GCNGTPG/nr37t3q27evQkJC1Lt3b+3atcth/9WrV6tz584KCQlRdHS0jh49WtxTBgAAJViJCDkffvihvvjiC/vr1NRUDR48WOHh4VqxYoVCQ0M1ZMgQpaamSpJ27typcePGafjw4Vq8eLFOnjypsWPHumv6AACgBHJ7yDl+/LimTJmi4OBge9uaNWvk7e2tUaNGqX79+ho3bpwqVqyojz76SJK0cOFCde3aVXfeeacaNmyoKVOm6IsvvlBSUpK7ygAAACWM20PO5MmT1atXLwUGBtrbEhMTFRYWJpvNJkmy2Wxq3ry5duzYYd8eHh5u3//qq69W7dq1lZiYWKxzBwAAJVehvrvKVTZu3KitW7fqgw8+0HPPPWdvT05Odgg9kuTv7699+/ZJko4cOaKaNWvm2n7o0KECz+GfHOUy+fVnK4Kx3CWnDlPqyQs1mqMs1EmNZqDGgvXhDLeFnPT0dD377LMaP368fHx8HLalpaXJy8vLoc3Ly0sZGRmSpLNnz15ye0H4+1cq8DGXc/jACXl6On4ru5eXhwICXD+WOxXFe1fSUKM5ykKd1GgGanQdt4WcmTNnqkmTJmrXrl2ubd7e3rkCS0ZGhj0M5bfd19e3wPP4++9TsqwCH5avnISZmZnt0J6RkaWUlFOuG8iNbLbzP6Cufu9KEmo0R1mokxrNQI0F68MZbgs5H374oVJSUhQaGipJ9tCybt069ejRQykpKQ77p6Sk2C9R1apVK8/tNWrUKPA8LEvF8sNkqXjGKU7F9d65EzWaoyzUSY1moEbXcVvIefvtt5WVlWV/HRcXJ0l68skntWXLFr3++uuyLEs2m02WZWnbtm0aOnSoJCkkJEQJCQmKioqSJB08eFAHDx5USEhI8RcCAABKJLeFnGuuucbhdcWKFSVJ9erVk7+/v6ZNm6ZJkybp3nvv1aJFi5SWlqauXbtKkvr166f+/furWbNmCg4O1qRJk9SxY0fVrVu32OsAAAAlk9s/Qp4XPz8/zZ492362JjExUXPmzFGFChUkSaGhoZowYYLi4+PVr18/ValSRbGxsW6eNQAAKEnc+hHyC73wwgsOr5s2baqVK1fmu39UVJT9chUAAMDFSuSZHAAAgCtFyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjebh7AmWFl0d5/Xkmw6Gtmq+nKpazuWlGAACYjZBTTE6ezVTcuh8d2p7u3kgVK3q5aUYAAJiNy1UAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwkltDzuHDhzVixAhFRESoXbt2io2NVXp6uiQpKSlJ//rXv9SsWTN169ZNX3/9tcOx3377rXr06KGQkBANGDBASUlJ7igBAACUUG4LOZZlacSIEUpLS9M777yjF198UZ999pleeuklWZal6OhoBQQEaPny5erVq5eGDx+uAwcOSJIOHDig6OhoRUVFadmyZapevbqGDRsmy7LcVQ4AAChhPNw18C+//KIdO3bom2++UUBAgCRpxIgRmjx5stq3b6+kpCQtWrRIFSpUUP369bVx40YtX75cjz76qJYuXaomTZpo4MCBkqTY2Fi1adNGmzdvVsuWLd1VEgAAKEHcdianRo0amjt3rj3g5Dh9+rQSExN10003qUKFCvb2sLAw7dixQ5KUmJio8PBw+zZfX181btzYvh0AAMBtZ3IqV66sdu3a2V+fO3dOCxcuVKtWrZScnKyaNWs67O/v769Dhw5J0mW3F4TNVojJu6g/WxGMXxxy5lwa5+4sajRHWaiTGs1AjQXrwxluCzkXmzp1qnbv3q1ly5bpzTfflJeXl8N2Ly8vZWRkSJLS0tIuub0g/P0rFX7S+Th84IQ8Pcs7tJUrVy5Xm5eXhwICXD9+cSmK966koUZzlIU6qdEM1Og6JSLkTJ06VW+99ZZefPFFNWjQQN7e3jp+/LjDPhkZGfLx8ZEkeXt75wo0GRkZqly5coHH/vvvU3Ll/co5CTMzM9uh/dy5c7naMjKylJJyynWDFxOb7fwPqKvfu5KEGs1RFuqkRjNQY8H6cIbbQ87EiRP17rvvaurUqbr99tslSbVq1dL+/fsd9ktJSbFfoqpVq5ZSUlJybW/UqFGBx7csue2HyZL7xnYFd753xYUazVEW6qRGM1Cj67j1OTkzZ87UokWLNH36dHXv3t3eHhISoh9++EFnz561tyUkJCgkJMS+PSEhwb4tLS1Nu3fvtm8HAABwW8j5+eef9eqrr2rQoEEKCwtTcnKy/U9ERISuvvpqjR07Vvv27dOcOXO0c+dO9enTR5LUu3dvbdu2TXPmzNG+ffs0duxY1alTh4+PAwAAO7eFnA0bNig7O1uvvfaa2rZt6/CnfPnyevXVV5WcnKyoqCi9//77io+PV+3atSVJderU0YwZM7R8+XL16dNHx48fV3x8vGwm35IOAAAKxG335AwePFiDBw/Od3u9evW0cOHCfLd36NBBHTp0KIqpAQAAA/AFnQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwktu+uwqSl0d5/Xkmw6Gtmq+nKpbji0YBALhShBw3Onk2U3HrfnRoe7p7I1Ws6OWmGQEAYA4uVwEAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARuJhgCUMT0EGAMA1CDklDE9BBgDANbhcBQAAjETIAQAARiLkAAAAIxFyAACAkbjxuBTgE1cAABQcIacU4BNXAAAUHJerAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkvruqlMrrSzv9fDx1+mxmrn35Mk8AQFlEyCml8vrSzidvD8rVJvFlngCAsonLVQAAwEicySkD8rq0xSUsAIDpCDllQF6XtriEBQAwHZerAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABG4jk5uKQz5ywdS3P8PqzqFTwV4Kb5AADgLEJOGeXsF3xmW1Lsmj0Obc90b6R6RT5DAACuDCGnjHL2Cz6fvD2oOKcFAIDLcE8OAAAwEiEHAAAYiZADAACMxD05KDBPj/LafeCEMjKyZP3TltdNy9V8PVWxnK34JwgAgAg5KISTZzP18qf7lZmZbW/L66blp7s3UsWKXsU9PQAAJBFyUISc/Zg6Z3wAAEWBkIMi4+zH1Cf0aqJjWdkObQQfAMCVIuTA7fIKQ85e6srricx5nS3iDBIAlD2EHJRIeV3qyiuUHEvLVMyHjk9kzu+hhq6+ZyivgEVwAoCSo1SHnPT0dD3//PNav369fHx8NHDgQA0cONDd04IL5HV2J6/LWtmWCi2vICWdP+tz5mymjmT8/yfInA1Yec2Rs0gA4B6lOuRMmTJFu3bt0ltvvaUDBw5o9OjRql27trp06eLuqaEI5HePjyv7y+kzbt2P8vQsb/8EmbNnfZy9Dymv/pw9M8QZJABwTqkNOampqVq6dKlef/11NW7cWI0bN9a+ffv0zjvvEHLgcnmd9XH1WaS8vgw1v7NXzux3uXuTbJKOZJyQV3mbThXyvibpygIWgQ1AUSq1IWfv3r3KyspSaGiovS0sLEyzZs3SuXPnVK4cD3OG6xTHWaS8+rvS/S7X5ulZXo9FBhbq2BxXconO1Zf88gpN1St4KuCiORfHDet5jVGQ453ts5qvp/zKl/5QmN/7lbMGOaE8IyNLFV18CZiwba5SG3KSk5NVrVo1eXn9/yn/gIAApaen6/jx46pevbpT/ZQrJ1lX8C/yi9lsUjmb5OtZ3qG9vM3mlrYiGafc+TaPwhxbwtsubPe8oMaSNEdXtnl6lrevZ2H6k6Qz6Vl6ZcM+h7YRt9yYq21c90Y6mXXOoc3Ko88r6S9L0vT1Pzm0jepyPhRe+Lt+MjVL0y7aL68xnB23oq+HzqRlXXYuBTne2T5H3R6kypU8HWo8c87S8dTL9+dsW9UKHnkGSmfGyOvYvOS1JpLjGuRcQs5rXUbdHqRKfp6XHcfZsZ3tL6/3wdmaL2b75xBX/71UHJx9H1xRo60Ab63NskrbW3neqlWr9PLLL+uzzz6ztyUlJalz58764osvdNVVV7lxdgAAwN1K7TUdb29vZWQ43tOQ89rHx8cdUwIAACVIqQ05tWrV0rFjx5SV9f+nx5KTk+Xj46PKlSu7cWYAAKAkKLUhp1GjRvLw8NCOHTvsbQkJCQoODuamYwAAUHpDjq+vr+68804999xz2rlzpz755BO98cYbGjBggLunBgAASoBSe+OxJKWlpem5557T+vXr5efnp4cfflj/+te/3D0tAABQApTqkAMAAJCfUnu5CgAA4FIIOQAAwEiEHAAAYCRCTh7S09P11FNPKTw8XG3bttUbb7yR7767d+9W3759FRISot69e2vXrl0O21evXq3OnTsrJCRE0dHROnr0qH2bZVmKi4tTq1atFBERoSlTpujcuXMXD1EkiqvG3bt3KygoyOFPVFRUkdV1IVfWmOO1117TmDFjHNrcuY5S8dVpwlpalqU5c+YoMjJSzZs314MPPqj9+/c7bC/tv5OXq9GEdczOzlZcXJzatGmj0NBQPfbYY0pJSbFvN2EdL1ejCet4obVr1yooyPF7+QoyTr4s5DJhwgSrZ8+e1q5du6z169dboaGh1tq1a3Ptd+bMGatNmzbWCy+8YO3fv9+aOHGidfPNN1tnzpyxLMuyEhMTraZNm1orV6609uzZYz3wwAPW4MGD7cfPmzfP6tChg7VlyxZr48aNVtu2ba25c+caVeN7771n9erVyzpy5Ij9z9GjR0tVjTk++OADq1GjRtbo0aMd2t25jpZVfHWasJb/+9//rJYtW1qffvqp9csvv1hPPfWU1bFjRys1NdWyLDN+Jy9Xownr+Oqrr1qdOnWyNm/ebO3bt8968MEHrYceesh+vAnreLkaTVjHHCdOnLDatGljNWjQoFDjXAoh5yJnzpyxgoODre+++87eFh8fbz3wwAO59l26dKkVGRlpnTt3zrIsyzp37px16623WsuXL7csy7JGjhzp8BfFgQMHrKCgIOuPP/6wLMuyOnToYN/Xsixr1apVVqdOnYqkrgsVZ43Tp0+3/vOf/xRlOXlyZY2ZmZnW+PHjreDgYOu2227L9Ze/u9bRsoq3ThPWsm/fvtbs2bPt+2dkZFjNmjWzvv76a8uyzPidvFyNJqzjjBkzrPXr19v3/+STT6ymTZvaX5uwjper0YR1zDFu3Djr3nvvdQg5BRnnUrhcdZG9e/cqKytLoaGh9rawsDAlJibmOt2ZmJiosLAw2f75SlSbzabmzZvbn8KcmJio8PBw+/5XX321ateurcTERB0+fFgHDx5UixYtHMb566+/dOTIkSKssPhqlKSff/5Z1113XZHWkxdX1piamqoff/xRS5YscehPklvXUSq+OiUz1nLUqFG644477PvbbDZZlqVTp04Z8zt5qRolM9Zx+PDhuvXWWyVJf//9t5YuXaqIiAhJ7v2dLK4aJTPWUZI2b96szZs3a+jQoYUe51IIORdJTk5WtWrV5OXlZW8LCAhQenq6jh8/nmvfmjVrOrT5+/vr0KFDkqQjR47kuz05OVmSHLYHBARIkv34olJcNUrnfxH37Nmjnj17qmPHjho/frxOnz5dBFU5cmWNlStX1qJFi9SwYcM8x5Hcs4454xdHnZIZaxkeHq6rrrrKvm3p0qXKyspSWFiYMb+Tl6pRMmMdc7zyyiu6+eabtW3bNvs9ZKasY468apTMWMeMjAw988wzGj9+fK4v1i7IOJdCyLlIWlqaw5sqyf764m89z2/fnP3Onj2b7/azZ8869H2pcVytuGrMzMxUUlKSMjMz9d///leTJk3Stm3bNHLkSFeXlIsra7wUd66jVHx1mriWiYmJmjx5sh5++GHVqFHDmN/JC11co2nr2KtXLy1btkytW7fWwIEDdfr0aePWMa8aTVnH+Ph4NW7cWG3btr2icS7Fw+k9ywhvb+9cb2DO64uTZn775uyX33ZfX1+HxfL29nYYx9fX10XV5K24avT09NR3330nb29veXp6SpJeeOEF9e7dW4cPH1atWrVcWpcz85YKXuOluHMdpeKr07S13L59uwYNGqT27dvrsccek+TetSyuGk1bx3r16kmSpkyZovbt22v9+vUKDAy072/COuZVY1RUVKlfx59++klLlizRBx98cMXjXApnci5Sq1YtHTt2TFlZWfa25ORk+fj4qHLlyrn2vfAjfZKUkpJiPz2X3/YaNWrYfwhzTq1e+N81atRwXUF5KK4aJcnPz8/+SyhJ9evXl3T+unlRcmWNlxsnp+8Lx5GKfh1zxi+OOiVz1nLTpk0aOHCgWrVqpWnTpqlcuXL2Y3P6vnAcqXT9Tkr51yiZsY6fffaZw3y9vb1Vt25dHTt2zJh1vFSNUulfx/Xr1+vEiRO69dZbFRoaqkGDBkmSQkND9f777xdonEsh5FykUaNG8vDwcLgxKiEhQcHBwQ7/o5CkkJAQbd++XdY/X/9lWZa2bdumkJAQ+/aEhAT7/gcPHtTBgwcVEhKiWrVqqXbt2g7bExISVLt2baf/0ims4qpx//79Cg0NVVJSkn37nj175OHhYf/XSVFxZY2X4s51lIqvTlPW8qefftIjjzyidu3a6aWXXnL4S8KU38lL1WjKOk6ePFmrVq2y73/69Gn99ttvql+/vjHreKkaTVjHBx54QGvXrtWqVau0atUqxcTESJJWrVqlyMjIAo1zSQX6LFYZ8cwzz1jdu3e3EhMTrY8//thq3ry5tW7dOsuyLOvIkSNWWlqaZVmWderUKatVq1bWxIkTrX379lkTJ0602rRpY38GwLZt26zGjRtbS5YssT9DZsiQIfZxZs+ebbVt29b67rvvrO+++85q27at9cYbbxhTY3Z2ttWrVy/rwQcftH788Udry5YtVrdu3axnn322VNV4odGjR+f6aLU719GyiqdOU9bynnvusbp162YdOHDA4fkiOceb8Dt5qRpNWccFCxZYLVq0sD7//HPrp59+soYOHWrdddddVnZ2tmVZZqzjpWo0ZR0v9N133+V6Ts6lxnEWIScPqamp1qhRo6xmzZpZbdu2tebPn2/f1qBBA4fP+CcmJlp33nmnFRwcbPXp08f64YcfHPpavny51aFDB6tZs2ZWdHS0w8OasrKyrP/+979WeHi41bJlS2vq1Kn25wkUteKq8cCBA1Z0dLQVHh5uRUREWBMnTrTS09OLvD7Lcm2NOfIKOe5cR8sqvjpL+1oeOXLEatCgQZ5/co4v7b+TztRY2tfRss6H7tmzZ1sdO3a0mjZtaj3yyCPWoUOH7NtL+zo6U6MJ63ihvELOpcZxls2y/jmPBAAAYBDuyQEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQA6DE2bhxo37++Wf76xkzZigsLEzh4eE6ffq01q5dq7///tvl427atElBQUEu7xeAe/AwQAAlTlBQkBYsWKCWLVvqxIkTioiI0MSJE9WmTRtJUmRkpDZs2KA6deq4dNyMjAydOHGiWL5cFUDR40wOgBLt9OnTkqTWrVvrmmuuUVH+u8zLy4uAAxiEkAPAbRYsWKBOnTopODhYUVFR2rp1qyIjIyVJAwYM0JgxY+yvO3furDFjxuiWW26RJN1yyy1asWLFZcfo37+/5s2bp4ceekhNmzZVnz599Pvvv+uZZ55RaGiobrvtNm3evFmS4+WqP//8U0FBQVq/fr06d+6s4OBgDRkyRMePHy+CdwJAUSDkAHCL3bt3a8qUKXr22We1du1ahYeH6/HHH9eSJUsknb8PZ9y4cVq6dKkkaenSpbled+vWzamx4uPjdffdd2vFihU6deqU+vTpo4CAAC1btkw33nijYmJi8j121qxZmj59uhYuXKjvv/9e8+fPv8LKARQXD3dPAEDZ9Ndff8lms6l27dqqU6eOHn/8cXXq1ElVq1aVJFWpUkWVKlVS9erVJUnVq1fP9drHx8epsTp16qSuXbtKOn9GaM2aNRoxYoRsNpvuvvtuRUdH53vsiBEj1LRpU0lSz5499f333xe2ZADFjJADwC3atm2rBg0aqGfPnrrpppt0yy23qG/fvvLwcP3/li68QdnHx0e1a9eWzWazv87MzMz32Hr16tn/28/P75L7AihZuFwFwC18fX21dOlSvfXWW4qIiNCKFSsUFRWlw4cPu3ysi4NTuXLO/6/P09PT1dMBUEwIOQDcYvv27Zo9e7ZatWqlsWPH6qOPPlJ6eroSEhIueVzOGRgAuBwuVwFwCx8fH8XHxysgIECtW7fWli1blJqaqqCgIFWoUEH79u3TTTfdlOs4X19fSdLevXtVrVo1VaxYsbinDqCU4EwOALdo1KiRJk2apLlz56pr166aNWuWpk6dqvr166t///6aMmWKZsyYkeu46tWr64477tDjjz9u/6QVAOSFJx4DAAAjcSYHAAAYiXtyAJRakyZN0rJly/LdPmTIEA0dOrQYZwSgJOFyFYBS6+jRozp16lS+26tUqWJ/uCCAsoeQAwAAjMQ9OQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkf4PjnjuVr8kPZcAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df_ann, x=TARGET)\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:22:29.474098Z",
     "start_time": "2023-06-06T19:22:29.334365Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df_ann, x=TARGET, log_scale=True)\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T19:22:29.844943Z",
     "start_time": "2023-06-06T19:22:29.483475Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

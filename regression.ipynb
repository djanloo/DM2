{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:48:12.657763Z",
     "start_time": "2023-06-06T16:48:12.436603Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.core.dtypes.common import is_numeric_dtype\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression, SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'dataset'\n",
    "DATASET = os.path.join(DATA_FOLDER, 'outliers_removed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:48:12.659924Z",
     "start_time": "2023-06-06T16:48:12.658197Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   frame_count       sum          mean       std       min       max   \n0       158558  0.145081  9.150000e-07  0.004001 -0.038422  0.040588  \\\n1       160160  0.114319  7.137790e-07  0.004283 -0.042603  0.048157   \n2       156956  0.149963  9.554485e-07  0.005084 -0.037018  0.058472   \n3       152152  0.139618  9.176213e-07  0.004886 -0.036652  0.062683   \n4       169769  0.137665  8.108948e-07  0.002956 -0.026245  0.026215   \n\n        q01       q05       q25  q75  ...  actor_actor_24  actor_actor_3   \n0 -0.012586 -0.005890 -0.000031  0.0  ...               0              0  \\\n1 -0.013550 -0.006104 -0.000031  0.0  ...               0              0   \n2 -0.015822 -0.007294  0.000000  0.0  ...               0              0   \n3 -0.014923 -0.006714 -0.000031  0.0  ...               0              0   \n4 -0.009399 -0.004364 -0.000031  0.0  ...               0              0   \n\n   actor_actor_4  actor_actor_5  actor_actor_6  actor_actor_7  actor_actor_8   \n0              0              0              0              0              0  \\\n1              0              0              0              0              0   \n2              0              0              0              0              0   \n3              0              0              0              0              0   \n4              0              0              0              0              0   \n\n   actor_actor_9  sex_F  sex_M  \n0              0      0      1  \n1              0      0      1  \n2              0      0      1  \n3              0      0      1  \n4              0      0      1  \n\n[5 rows x 285 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame_count</th>\n      <th>sum</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>q01</th>\n      <th>q05</th>\n      <th>q25</th>\n      <th>q75</th>\n      <th>...</th>\n      <th>actor_actor_24</th>\n      <th>actor_actor_3</th>\n      <th>actor_actor_4</th>\n      <th>actor_actor_5</th>\n      <th>actor_actor_6</th>\n      <th>actor_actor_7</th>\n      <th>actor_actor_8</th>\n      <th>actor_actor_9</th>\n      <th>sex_F</th>\n      <th>sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>158558</td>\n      <td>0.145081</td>\n      <td>9.150000e-07</td>\n      <td>0.004001</td>\n      <td>-0.038422</td>\n      <td>0.040588</td>\n      <td>-0.012586</td>\n      <td>-0.005890</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>160160</td>\n      <td>0.114319</td>\n      <td>7.137790e-07</td>\n      <td>0.004283</td>\n      <td>-0.042603</td>\n      <td>0.048157</td>\n      <td>-0.013550</td>\n      <td>-0.006104</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>156956</td>\n      <td>0.149963</td>\n      <td>9.554485e-07</td>\n      <td>0.005084</td>\n      <td>-0.037018</td>\n      <td>0.058472</td>\n      <td>-0.015822</td>\n      <td>-0.007294</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>152152</td>\n      <td>0.139618</td>\n      <td>9.176213e-07</td>\n      <td>0.004886</td>\n      <td>-0.036652</td>\n      <td>0.062683</td>\n      <td>-0.014923</td>\n      <td>-0.006714</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>169769</td>\n      <td>0.137665</td>\n      <td>8.108948e-07</td>\n      <td>0.002956</td>\n      <td>-0.026245</td>\n      <td>0.026215</td>\n      <td>-0.009399</td>\n      <td>-0.004364</td>\n      <td>-0.000031</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 285 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET)\n",
    "\n",
    "categorical_attr_list = [col for col in df.columns if not is_numeric_dtype(df[col])]\n",
    "\n",
    "# one hot encoding\n",
    "df_reg = df.drop(columns=categorical_attr_list)\n",
    "df_reg = df_reg.join(pd.get_dummies(df[categorical_attr_list], columns=categorical_attr_list).astype(int))\n",
    "\n",
    "df_reg.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:48:12.742581Z",
     "start_time": "2023-06-06T16:48:12.662093Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "stft_min    False\nsc_min      False\ndtype: bool"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_correct = ['stft_min', 'sc_min']\n",
    "(df[features_to_correct] < 0).any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:48:12.753223Z",
     "start_time": "2023-06-06T16:48:12.744619Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# stft_min"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['mfcc_q50',\n 'sc_q01',\n 'sc_q05',\n 'stft_q01',\n 'stft_q05',\n 'mfcc_q25_w1',\n 'mfcc_q50_w1',\n 'sc_q05_w1',\n 'sc_q25_w1',\n 'stft_q05_w1',\n 'q50_w2',\n 'q50_w3',\n 'lag1_q50_w3',\n 'q75_w4']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET = 'stft_min'\n",
    "\n",
    "# drop quantile columns with high percentage of zeros (20%)\n",
    "zero_percentage = (df_reg == 0).mean()\n",
    "to_drop = [col for col in df_reg.columns if zero_percentage[col] > 0.2 and re.search(r'q\\d{2}', col)]\n",
    "df_reg = df_reg.drop(columns=to_drop)\n",
    "to_drop"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:48:12.753439Z",
     "start_time": "2023-06-06T16:48:12.747685Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x=df[TARGET])\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:48:12.957919Z",
     "start_time": "2023-06-06T16:48:12.754260Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847, 270) (212, 270) (361, 270) (1009, 270)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# rows to be fixed, do not reset indexes!\n",
    "df_zero = df_reg[df_reg[TARGET] == 0]\n",
    "df_nz = df_reg[df_reg[TARGET] != 0].reset_index(drop=True)\n",
    "\n",
    "# dataframe has been one hot encoded\n",
    "split_index = df_nz.index[df_nz['actor_actor_19'] == 1][0]\n",
    "\n",
    "df_train = df_nz[:split_index]\n",
    "df_test = df_nz[split_index:]\n",
    "\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.2, random_state=100)\n",
    "\n",
    "y_train = np.log10(df_train[TARGET].to_numpy())\n",
    "y_valid = np.log10(df_valid[TARGET].to_numpy())\n",
    "y_test = np.log10(df_test[TARGET].to_numpy())\n",
    "\n",
    "df_zero = df_zero.drop([TARGET], axis=1)\n",
    "df_train = df_train.drop([TARGET], axis=1)\n",
    "df_valid = df_valid.drop([TARGET], axis=1)\n",
    "df_test = df_test.drop([TARGET], axis=1)\n",
    "\n",
    "X_to_pred = df_zero.to_numpy()\n",
    "X_train = df_train.to_numpy()\n",
    "X_valid = df_valid.to_numpy()\n",
    "X_test = df_test.to_numpy()\n",
    "\n",
    "print(X_train.shape, X_valid.shape, X_test.shape, X_to_pred.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:48:12.971918Z",
     "start_time": "2023-06-06T16:48:12.963657Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x400 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAFzCAYAAADSYPP5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIhUlEQVR4nO3deXwV1f3/8ffMvWSDhECAyFZURECBEIlQFypQbBVRaYR+xVZLrcUFfrj0KxJxZf0W6gZolS/ihhVEUKu1bmhdiopfkCBG2gAqkaCEJWwJCeTO7w96r0nIcm8y987ce1/Px8OHZOYun7lz5sz5zDlzxrAsyxIAAAAAoFlMpwMAAAAAgFhAcgUAAAAANiC5AgAAAAAbkFwBAAAAgA1IrgAAAADABiRXAAAAAGADkisAAAAAsAHJFQAAAADYgOQKAAAAAGxAcgUAAAAANvA6HYCb7d59QJbldBTHGIaUkZHqqpgQeZQD+FEWIFEO8APKAiTKQbj4f9dgkFw1wLLkuoLpxpgQeZQD+FEWIFEO8APKAiTKgZMYFggAAAAANiC5AgAAAAAbkFwBAAAAgA1IrgAAAADABiRXAAAAAGADkisAAAAAsAHJFQAAAADYgOQKAAAAAGxAcgUAAAAANiC5AgAAAAAbkFwBAOAg0zTk9ZoyTcPpUAAAzeR1OgAAAOKVaRpqnZ4ir8fU0Sqf9pWWyeeznA4LANBE9FwBAOAQ0zTk9Ziat6pQXg+9VwAQ7UiuAABw2PbScqdDAADYgOQKAAAAAGxAcgUAAAAANiC5AgAAAAAbkFwBAAAAgA1IrgAAAADABiRXAAAAAGADkisAAAAAsAHJFQAAAADYwOt0AAAAxBvTNGSahgzDcDoU2/m3zeez5PNZTocDABFFcgUAQASZpqHW6SnyekwdrfI5HY6tam/bvtIyEiwAcYVhgQAARJBpGvJ6TM1bVSivJ7ZOw7W3zTRjr2cOABoSW7U6AABRYntpudMhhE0sbxsANITkCgAAAABs4IrkqrKyUiNHjtQnn3wSWFZUVKRx48apf//+GjFihD788MMa71m9erVGjhyprKwsXXXVVSoqKqqx/sknn9TgwYOVnZ2t22+/XeXlXEUDAAAAED6OJ1cVFRW65ZZbVFhYGFhmWZYmTJigdu3aacWKFbr00ks1ceJEFRcXS5KKi4s1YcIE5ebm6oUXXlDbtm11ww03yLKO3TT7xhtvaMGCBZo2bZqeeuop5efna+7cuY5sHwAAAID44GhytXnzZv3yl7/Utm3baiz/+OOPVVRUpGnTpql79+669tpr1b9/f61YsUKStHz5cvXp00dXX321evToodmzZ2v79u1as2aNJOnpp5/Wb37zGw0dOlT9+vXTvffeqxUrVtB7BQAAACBsHE2u1qxZo0GDBmnZsmU1lufn5+u0005TSkpKYNmAAQO0fv36wPqcnJzAuuTkZJ1++ulav369qqqq9Pnnn9dY379/fx05ckSbNm0K7wYBAAAAiFuOPufqiiuuqHN5SUmJOnToUGNZRkaGvvvuu0bX79+/XxUVFTXWe71epaenB94PAADsE8sPRQaAULjyIcLl5eVKSEiosSwhIUGVlZWNrj98+HDg7/reHyw3nSP8sbgpJkQe5QB+lIXYFco+dUM5ME1Daa3rfygyZTQy3FAW4DzKQXiE8nu6MrlKTExUaWlpjWWVlZVKSkoKrK+dKFVWViotLU2JiYmBv2uvT05ODimOjIzUECMPPzfGhMijHMCPshBb2rRp2aT3uaEczFtVqEk/7VFjWVO3B03nhrIA51EOnOPK5CozM1ObN2+usWzXrl2BoX6ZmZnatWvXcet79+6t9PR0JSYmateuXerevbsk6ejRoyotLVX79u1DimP37gP6zwSEjjOMYweKm2JC5FEO4EdZiF4ej1lv0rF37yFV1dH7Ux83lAP/9tT14OBQtwdN54ayAOdRDsLD/7sGw5XJVVZWlhYuXKjDhw8HeqvWrl2rAQMGBNavXbs28Pry8nIVFBRo4sSJMk1Tffv21dq1azVo0CBJ0vr16+X1etWrV6+Q4rAsua5gujEmRB7lAH6UhdjTlP3p5nLg1rhilZvLAiKHcuAcx59zVZeBAweqY8eOysvLU2FhoRYuXKgNGzZo9OjRkqTLLrtM69at08KFC1VYWKi8vDx16dIlkExdccUVevzxx/X2229rw4YNuueee/TLX/4y5GGBAAAAABAsVyZXHo9HjzzyiEpKSpSbm6u//vWvevjhh9WpUydJUpcuXTR//nytWLFCo0ePVmlpqR5++OHALEUXXXSRrr32Wt111126+uqr1a9fP916661ObhIAAACAGOeaYYH/+te/avzdrVs3LVmypN7Xn3feeTrvvPPqXT9+/HiNHz/etvgAAAAAoCGu7LkCAAAAgGhDcgUAAAAANiC5AgAAAAAbkFwBAAAAgA1IrgAAAADABiRXAAAAAGADkisAAAAAsAHJFQAAAADYgOQKAAAAAGxAcgUAAAAANvA6HQAAZ5mmIdM05PNZ8vksp8MBAABxqHp7xP93NLZNSK6AOGaahlqnp8jrMXW0yqd9pWVRV4kBAIDoVrs9Iilq2yYMCwTimGka8npMzVtVKK/HlGkaTocEAADiTO32SDS3TUiuAGh7abnTIQAAgDhXvT0SrW0TkisAAAAAsAHJFQAAAADYgOQKAAAAAGxAcgUAAAAANiC5AgAAAAAbkFwBAAAAgA1IrgAAAADABiRXAAAAAGADkisAAAAAsIHX6QAARJ5pGjJNQ4ZhOB0KALiav770+Sz5fJbT4QBwOZIrIM6YpqHW6SnyekwdrfI5HQ4AuFbt+nJfaRkJFoAGMSwQiDOmacjrMTVvVaG8HqoAAKhP7frSNOntB9AwWlZAnNpeWu50CAAQFagvAQSL5AoAAAAAbEByBQAAAAA2ILkCALiSaRryernPBQAQPZgtEADgOszSBgCIRvRcAQBch1naAADRiOQKAOBazNIGAIgmJFcAAAAAYAOSKyAI3FgPAACAxjChBdAIbqwHAABAMOi5AhrBjfUAAAAIBskVECRurAcAAEBDSK4AAAAAwAYkVwAAAABgA5IrAAAAALAByRUAAAAA2IDkCgAAhIWHGVYBxBlXJ1c7duzQtddeqzPOOEPDhg3Tk08+GVhXUFCgMWPGKCsrS5dddpk2btxY472vvvqqhg8frqysLE2YMEF79uyJcPQAAMSn9OQWqvJZSktLVuv0FBIsAHHD1cnVTTfdpJSUFK1cuVK33367HnzwQb311lsqKyvT+PHjlZOTo5UrVyo7O1vXXnutysrKJEkbNmzQ1KlTNXHiRC1btkz79+9XXl6ew1sDAEB8SEn0ymMaPB8QQNxxbXK1b98+rV+/Xtdff71OPPFEDR8+XIMHD9ZHH32k1157TYmJiZo8ebK6d++uqVOnqmXLlnr99dclSUuWLNGFF16oUaNGqVevXpozZ47ee+89FRUVObxVAADED54PCCDeuDa5SkpKUnJyslauXKkjR45o69atWrdunXr37q38/HwNGDBAhnHsSphhGDrjjDO0fv16SVJ+fr5ycnICn9WxY0d16tRJ+fn5TmwKAAAAgDjgdTqA+iQmJuquu+7S9OnT9fTTT6uqqkq5ubkaM2aMVq1apVNOOaXG6zMyMlRYWChJ2rlzpzp06HDc+u+++y6kGAwXjWLwx+KmmOKZU/shEuWAMhYd4rFOiJdtDWU7o6kcREOMwXDrdkRTWUD4xGo5cHp7Qvl+1yZXkrRlyxYNHTpUv/3tb1VYWKjp06frrLPOUnl5uRISEmq8NiEhQZWVlZKkw4cPN7g+WBkZqc3bgDBwY0zxpk2blk6HELZy4IZtQ2jipU6Il7LZ1O10ezmIlf0XDdvh9rKAyIilchANx111rk2uPvroI73wwgt67733lJSUpL59++r777/Xn//8Z3Xt2vW4RKmyslJJSUmSjvV61bU+OTk5pBh27z4gy2redtjFMI4dKG6KKV54PGaNA3vv3kOqqvI5Eosd5aD29lTn5LYhNLFeJ7jpuLObncegG8pBQ9vjF637L5rKoRvKApwXreXA7W0T/+8aDNcmVxs3blS3bt0CCZMknXbaaXr00UeVk5OjXbt21Xj9rl27AkMBMzMz61zfvn37kGKwLLmuYLoxpnjk9D4IZzlwetsQmniqE9jOht/j9t/H7fEFy+3bEQ1lAeEXa+UgmrbFtRNadOjQQd98802NHqitW7eqS5cuysrK0meffSbrP7+0ZVlat26dsrKyJElZWVlau3Zt4H07duzQjh07AusBAAAAwG6uTa6GDRumFi1a6I477tBXX32ld955R48++qiuvPJKXXDBBdq/f79mzpypzZs3a+bMmSovL9eFF14oSRo7dqxefvllLV++XJs2bdLkyZM1ZMgQde3a1eGtAgAAABCrXJtcpaam6sknn1RJSYlGjx6t2bNn6/rrr9d//dd/qVWrVnrssce0du1a5ebmKj8/XwsXLlRKSookKTs7W9OmTdPDDz+ssWPHqnXr1po9e7bDWwQAAAAglrn2nitJOuWUU/TEE0/Uua5fv3568cUX631vbm6ucnNzwxUaAAAAANTg2p4rAAAAAIgmJFcAAAAAYAOSKwAAAACwAckVAAAAANiA5AoAAAAAbEByBQAAAAA2ILkCAAAAABuQXAEAAACADUiuAAAAAMAGTU6uCgsL9dZbb6msrExFRUWyLMvOuAAAAAAgqnhDfcO+fft04403as2aNZKkN954QzNnzlRRUZEWLlyozp072x4kAAANMU1DpmnI57Pk83GxDwDgjJB7rmbMmKHk5GR9/PHHSkxMlCTNmjVLJ5xwgmbMmGF7gAAANMQ0DbVOT1GbNi3VOj1Fpmk4HRIAIE6FnFx98MEHuuWWW5SWlhZY1rZtW+Xl5enTTz+1NTgAABpjmoa8HlPzVhXK6zFJrgAAjmnSPVcVFRXHLduzZ4+83pBHGQIAYIvtpeVOhwAAiHMhJ1cjR47UzJkzVVhYKMMwVFZWpo8//lh33nmnRowYEY4YAQAAAMD1Qu5qmjx5su6//37l5ubqyJEjuvTSS+XxeDRmzBhNnjw5HDECAAAAgOuFnFwlJCRoypQpuummm1RUVKSqqip17dpVLVu2DEd8AAAAABAVQk6u6pq0oqCgIPDvM888s3kRAQAAAEAUCjm5uvLKK+tcnpCQoPbt22vVqlXNDgoAAAAAok3IydWmTZtq/F1VVaVt27Zp+vTpuvjii20LDAAAAACiSZOmYq/O4/HopJNO0pQpU/TQQw/ZERMAAAAARJ1mJ1d+u3fv1v79++36OAAAAACIKiEPC8zLyztu2aFDh7R69WpdcMEFtgQFAECsME1DpmnI57Pk81lOhwMACKOQk6u6pKen67bbbtOll15qx8cBABATTNNQ6/QUeT2mjlb5tK+0zOmQAABhFHJyNXv27HDEAQBAzDFNQ16PqXmrCjXppz1kmobTIQEAwiio5GrBggVBf+DEiRObHAwAALFoe2m50yEAACIgqOTqk08+CerDDIMrcgAA+xmGIa/X5L4lAICrBZVcPfPMM+GOAwCAeqWmJslT7b4lEiwAgBs1aUKLL7/8UoWFhfL5fJIky7JUWVmpgoIC3XvvvbYGCACAp9Z9SyRXAAA3Cjm5WrBggRYsWKB27dpp9+7dyszM1K5du1RVVaXzzz8/HDECAMB9SwAA1wv5IcLLli3Tvffeqw8//FAdO3bUM888o9WrV+vss8/Wj370o3DECAAAAACuF3JytXfvXg0ePFiS1Lt3b3322WdKS0vTzTffrNdee832AAEAAAAgGoScXGVmZqqoqEiS1L17dxUUFEiSWrVqpT179tgbHQBbmaYhjyfkwx4AAABBCPmeqzFjxuiWW27RrFmzNHz4cI0bN04dOnTQ6tWr1atXr3DECLieaRqBm+zdeqO9aRpqnZ4iL8kVAABAWIScXF133XU64YQTlJycrH79+ikvL09Lly5Venq6Zs2aFY4YAVernrS4eZpo0zTk9Zh6bs02jR3I/ZEAAAB2Czm5WrdunUaNGhX4e8yYMRozZoydMQFRxZ+0RMs00TsPVDgdAgAAQEwKObkaN26cMjIydMEFF+iiiy5Snz59whEXEHWYJhoAACC+hZxcffTRR3r33Xf15ptv6sorr1T79u114YUXasSIEerZs2c4YgQAAAAA1ws5uWrZsqVGjhypkSNH6vDhw3r//ff19ttv64orrlDHjh316quvhiNOAAAAAHC1Zk0b9u9//1v5+fn64osvZJqm+vbta1dcAAAAABBVQu65WrNmjd588029/fbb2rdvn4YOHaqbb75ZP/nJT5SQkBCOGAEAAADA9UJOrq655hr95Cc/0eTJkzV06FAlJyeHIy4AAAAAiCohDwtcvXq1FixYoBEjRoQ9saqsrNS9996rM888U2effbbuv/9+WdaxKa4LCgo0ZswYZWVl6bLLLtPGjRtrvPfVV1/V8OHDlZWVpQkTJmjPnj1hjRUAAABAfAs5uWrVqlU44qjTjBkztHr1aj3++OO677779Pzzz2vZsmUqKyvT+PHjlZOTo5UrVyo7O1vXXnutysrKJEkbNmzQ1KlTNXHiRC1btkz79+9XXl5exOIGAAAAEH9CHhYYKaWlpVqxYoWeeOIJ9evXT5J09dVXKz8/X16vV4mJiZo8ebIMw9DUqVP1/vvv6/XXX1dubq6WLFmiCy+8MPCw4zlz5mjo0KEqKipS165dHdwqAAAAALGqWbMFhtPatWvVqlUrDRw4MLBs/Pjxmj17tvLz8zVgwAAZhiFJMgxDZ5xxhtavXy9Jys/PV05OTuB9HTt2VKdOnZSfnx/RbQAAADWZpiGv15RpGk6HAgC2c23PVVFRkTp37qyXXnpJjz76qI4cOaLc3Fxdf/31Kikp0SmnnFLj9RkZGSosLJQk7dy5Ux06dDhu/XfffRdSDIaL6n1/LG6KKZ41th/CtZ8iUQ4oY9Eh3usEp47BSAgl9mgqB4ZxLLFKa50ir8fU0Sqf9u8rk89nOR1aSNz6W0dTWUD4xGo5cHp7Qvn+oJKrK6+8MtBL1Jinn346+G9vQFlZmb755hstXbpUs2fPVklJie666y4lJyervLz8uGnfExISVFlZKUk6fPhwg+uDlZGR2ryNCAM3xhRv2rRp2az1dghXOYhE7LBXPNYJbjgGmypcsbu9HNTernmrCjXppz3Utm3k7uO2g5vLlp/bywIiI5bKQTQcd9UFlVwNGjQo8O+9e/dq2bJlGj58uPr27asWLVroyy+/1GuvvaZf/epX9gXm9ergwYO677771LlzZ0lScXGxnnvuOXXr1u24RKmyslJJSUmSpMTExDrXhzq74e7dB2S55IKaYRw7UNwUU7zweMwaB/bevYdUVeULer2dmlMOasdZl3DGDnvFep3QUHl18hgMVV2xSfU3FkKN3Q3lIJS6xf/a7aXlNZa7lZvLVm1uKAtwXrSWg1DqfCf4f9dgBJVcTZw4MfDvcePG6fbbb9cVV1xR4zVnnnmmli1bFkKYDWvfvr0SExMDiZUknXTSSdqxY4cGDhyoXbt21Xj9rl27AkMBMzMz61zfvn37kGKwLLmuYLoxpnjU2D4I9z4KZzmgfEWXeK0TnD4Gw6kpsUdDOagvPrfHXZvb442GsoDwi7VyEE3bEvKEFuvXr9dZZ5113PKsrCz961//siUo/+dVVFToq6++CizbunWrOnfurKysLH322WeBZ15ZlqV169YpKysr8N61a9cG3rdjxw7t2LEjsB4AAAAA7BZycnXaaadp4cKFqqioCCw7ePCg5s2bp/79+9sW2Mknn6whQ4YoLy9PmzZt0gcffKCFCxdq7NixuuCCC7R//37NnDlTmzdv1syZM1VeXq4LL7xQkjR27Fi9/PLLWr58uTZt2qTJkydryJAhTMMOAAAAIGxCni1w+vTpGj9+vM455xx169ZNlmXp66+/VqdOnfTYY4/ZGtyf/vQnTZ8+XWPHjlVycrJ+9atfBSbXeOyxx3T33Xfr+eefV8+ePbVw4UKlpKRIkrKzszVt2jTNmzdP+/bt0znnnKPp06fbGhsAAAAAVBdyctW9e3f9/e9/1+rVq7VlyxZJUo8ePXT22WfL67V3ZvfU1FTNmTOnznX9+vXTiy++WO97c3NzlZuba2s8AAAAAFCfJmVDCQkJ6ty5s44cOaKzzz5be/bskcfjsTs2AAAAAIgaISdX+/bt04033qg1a9ZIkt544w3NnDlTRUVFWrhwYY3Z/QAAAAAgXoQ8ocWMGTOUnJysjz/+WImJiZKkmTNn6oQTTtCMGTNsDxAAAAAAokHIydUHH3ygW265RWlpaYFlGRkZysvL06effmprcAAAAAAQLUJOriTVmIbdb8+ePbZPaAEAAAAA0SLk5GrkyJGaOXOmCgsLZRiGysrK9PHHH+vOO+/UiBEjwhEjAACIENM05PWaMk3D6VAAIOqE3NU0efJk3X///crNzdWRI0c0atQoeTwejR49WpMnTw5HjAAAIAJM01Dr9BR5PaaOVvm0r7RMPp/ldFgAEDVCTq4SEhI0ZcoU3XTTTSoqKlJVVZW6du2qli1bas+ePUpKSgpHnAAAIMxM05DXY2reqkJN+mkPmaZBcgUAIQh5WGDv3r0DSVSPHj3Uq1cvtWzZUtu3b9dPf/rTcMQIAAAiaHtpudMhAEBUCqrn6qWXXtLKlSslSZZlacKECWrRokWN1+zcuVPt27e3P0IAAAAAiAJBJVfnn3++vv32W0nSmjVr1L9/f7Vs2bLGa1JSUnT++efbHyEAAHHC4zHl81kMxQOAKBVUctWyZUtNnDhRktS5c2dddNFFSkhICGtgAADEi/TkFqryWUpLS2YiCQCIYiFPaPGLX/xCX375pQoLC+Xz+SQdGypYWVmpgoIC3XvvvbYHCQBALEtJ9MpjGkwk4QDTNAK/N785gOYKOblasGCBFixYoHbt2mn37t3KzMzUrl27VFVVxbBARC1OrgDcgIkkIoup5wHYLeTZApctW6Z7771XH374oTp27KhnnnlGq1ev1tlnn60f/ehH4YgRCCv/ybVNm5ZqnZ7CgzMBIE5Un3re6+HByQCaL+Tkau/evRo8eLCkY9Oyf/bZZ0pLS9PNN9+s1157zfYAgXDj5AoA8Y0eQwB2CTm5yszMVFFRkSSpe/fuKigokCS1atVKe/bssTc6III4uQIAAKA5Qr7nasyYMbrllls0a9YsDR8+XOPGjVOHDh20evVq9erVKxwxAgBiUDze6+ifah0AEJtCTq6uu+46nXDCCUpOTla/fv2Ul5enpUuXKj09XbNmzQpHjACAGBNvEwnUnmodABCbQk6uJGnUqFGBf48ZM0ZjxoyxKx4AQByofq9jPEw9Xnuqdbibv1fVMLgHF0BoQk6udu7cqUWLFmnr1q2qrKw8bv3TTz9tS2AAgNgXb/c6xtv2RqPavaoAEIqQk6ubb75ZJSUl+tnPfqakpKRwxAQAAOCI2r2qABCKkJOrL774QkuXLmXyCgAAELPoZQTQFCFPxZ6VlaVt27aFIxYAAAAAiFoh91zNnDlTY8eO1TvvvKPOnTsfd7PnxIkTbQsOAAAAAKJFyMnVAw88oL1792rr1q3avn17jXXMqgMAAAAgXoWcXK1atUqLFy/WwIEDwxEPAAAAAESlkO+56tSpk5KTk8MRCwAAAABErZB7riZNmqQpU6Zo3Lhx6tKli7zemh9x5pln2hYcAAAAAESLkJOrm266SZJ05513HrfOMAx9+eWXzQ4KAAAAAKJNyMnVpk2bwhEHAAAAAES1oJKr4uJidezYUYZhqLi4uMHXdurUyZbAAAAAACCaBJVcDRs2TP/85z+VkZGhYcOGyTAMWZYVWO//m2GBAAAAAOJVUMnVqlWr1KZNm8C/AQAAAAA1BTUVe+fOnWWax16al5en1NRUde7cucZ/ycnJ+n//7/+FNVgAAAAAcKugeq7ef/99bdiwQZL06aef6tFHH1VKSkqN13zzzTfavn27/RECAAAAQBQIKrk66aSTtGjRIlmWJcuytG7dOrVo0SKw3jAMpaSkaObMmWELFAAAAADcLKjkqmvXrnr66aclHRsWOHXqVLVq1SqsgQGIPMMw5PWa8vks+XxW428AAABAQMjPuZo9e7a2bNkiy7KUmpqqDz74QO+8845OO+00jRkzJhwxAoiQ1NQkeTymjlb5tK+0jAQLAAAgBEFNaFHdsmXLdMkll+jLL79UQUGBrr/+ehUVFemhhx7SQw89FI4YAUSIx2Nq3qpCeT2mTNNwOhwAAICoEnJytWjRIv3xj3/UwIEDtWLFCvXu3VuLFi3SAw88oOXLl4cjRgARtL203OkQAAAAolLIydX333+vAQMGSJLeffddDR8+XJJ0wgkn6NChQ/ZGBwAAAABRIuR7rk4++WS98soratu2rYqLizV8+HAdOXJEixcvVq9evcIRIwAAAAC4Xsg9V7fddpsef/xx3XHHHbriiivUvXt3zZ49W2+99ZamTp0ajhglSePHj9eUKVMCfxcUFGjMmDHKysrSZZddpo0bN9Z4/auvvqrhw4crKytLEyZM0J49e8IWGwAAAACEnFydddZZ+uijj/TJJ5/orrvukiTdcMMNevfdd9WnTx/bA5Skv/3tb3rvvfcCf5eVlWn8+PHKycnRypUrlZ2drWuvvVZlZWWSpA0bNmjq1KmaOHGili1bpv379ysvLy8ssQEAAACAFGRy9emnn+ro0aM/vMk01bp168Df7dq109GjR/Xoo4/aHmBpaanmzJmjvn37Bpa99tprSkxM1OTJk9W9e3dNnTpVLVu21Ouvvy5JWrJkiS688EKNGjVKvXr10pw5c/Tee++pqKjI9vgAAAAAQAoyubrqqqu0b9++Gssuvvhi7dixI/D3oUOHwjIV+x//+EddeumlOuWUUwLL8vPzNWDAABnGsamiDcPQGWecofXr1wfW5+TkBF7fsWNHderUSfn5+bbHBwBArPI/WJxHMwBAcIKa0MKyjn+Q6LffflujNyscPvroI/3f//2fXnnlFd1zzz2B5SUlJTWSLUnKyMhQYWGhJGnnzp3q0KHDceu/++67kL7fcNG5xB+Lm2KKZY39zs1d31SRLgeUN/eKxTohlG1x6hiMpGC2IdzloPqDxffva96DxeuLMdr2lVvjjcU6AaGL1XLg9PaE8v0hzxYYKRUVFbr77rt11113KSkpqca68vJyJSQk1FiWkJCgyspKSdLhw4cbXB+sjIzUJkQeXm6MKda0adMyrOvtEIlyEIntQPPFSp0QSnlzwzEYbqFuQ7jKgf/B4pN+2kNt27Zq8ufUtz1u21exULZipU5A88RSOYiG46461yZXCxYsUJ8+fTR48ODj1iUmJh6XKFVWVgaSsPrWJycnhxTD7t0HVEennSMM49iB4qaYYoXHY9Y4cPfuPaSqKp9t6+3UnHJQO87GhHM70HzRXieEelxV5+QxGKpQjzu/YLfB7nJQV7z+B4vXF1Mw2+h/r9v2VV3xSPU35pyOtyHRXifAHtFaDkKp853g/12D4drk6m9/+5t27dql7OxsSQokS2+88YZGjhypXbt21Xj9rl27AkMBMzMz61zfvn37kGKwLLmuYLoxpljU2G/c3PXNFalyQFlzv1iqE0LZDqePwUgI9fdwe51Q33ujbV+5Pd5YqhPQdLFWDqJpW4JOrv7+97+rVasfhgT4fD699dZbatu2rSTpwIEDtgb2zDPP1Lin609/+pMk6b//+7/16aef6n//939lWZYMw5BlWVq3bp2uu+46SVJWVpbWrl2r3NxcSdKOHTu0Y8cOZWVl2RojAKB+pmkEJkLw+axm3a8DAEA0CCq56tSpkxYvXlxjWUZGhpYsWVJjWceOHW0LrHPnzjX+btnyWFdht27dlJGRofvuu08zZ87U5ZdfrqVLl6q8vFwXXnihJGns2LG68sor1b9/f/Xt21czZ87UkCFD1LVrV9viAwDUzzQNtU5PkddzbFLao1U+7Stt3oQIAAC4XVDJ1TvvvBPuOELSqlUrPfbYY7r77rv1/PPPq2fPnlq4cKFSUlIkSdnZ2Zo2bZrmzZunffv26ZxzztH06dMdjhoA4odpGvJ6TN249DNJ0kOXZ8s0DZIrAEBMc+09V7X9z//8T42/+/XrpxdffLHe1+fm5gaGBQIAnLF550GnQwAAIGKCeogwAAAAAKBhJFcAAAAAYAOSKwAAAACwAckVAAAAANiA5AoAAAAAbBA1swUCAACEk2H88OBrAGgKkisAAABJqalJ8ngY1AOg6ahBAAAAJHk8pp5bs83pMABEMZIrAACA/9h5oMLpEABEMZIrAAAAALAByRUAAAAA2IDkCgAAAABsQHIFAAAAADYguQIAAAAAG5BcAQAAAIANSK4ABMU0DXm9pkzTcDoUAAAAV/I6HQAA9zNNQ63TU+T1mDpa5dO+0jL5fJbTYQEAALgKPVcAGmWahrweU/NWFcrrofcKAACgLiRXAIK2vbTc6RAAAABci+QKAAAAAGxAcgUAAAAANiC5AgAAAAAbkFwBAICg8VgGAKgfU7EDAKKKx2PK57N4HIAD6nosAwDgB/RcIWpwtRSIb+nJLVTls5SWlqzW6SnUBQ7gsQwA0DCSK0QF/9XSNm1a0qgC4lRKolce06Bh7wI8lgEA6kZyhajA1VIAfjTsAQBuRXKFqEKjCgAAAG5FcgUAAAAANiC5AgAAAAAbkFwBAAAAgA14zhXQRKZpyDQNGQaTawAAAIDkCmiS2g/SBAAAABgWCDRB7anhAQAAAFqFQDPE8tTwHp4nBgAAEBKSKwA1pCe3UJXPUlpaslqnp5BgAQAABInkCgiRYRjyxPBQwJRErzymERjySHIFAAAQHCa0AEKUmpoU08mVXywPeQQAAAiH2G8hAjbzeEw9t2ab02EAAADAZUiugCbYeaDC6RAAAADgMiRXAAAAAGADkisAAAAAsIGrk6vvv/9ekyZN0sCBAzV48GDNnj1bFRXHhmMVFRVp3Lhx6t+/v0aMGKEPP/ywxntXr16tkSNHKisrS1dddZWKioqc2AQAAADYwDQNeb3MYgt3c21yZVmWJk2apPLycj377LN64IEH9O677+rBBx+UZVmaMGGC2rVrpxUrVujSSy/VxIkTVVxcLEkqLi7WhAkTlJubqxdeeEFt27bVDTfcIMuyHN4qAAAAhMo0DbVOT1GbNi15BiNczbXJ1datW7V+/XrNnj1bPXr0UE5OjiZNmqRXX31VH3/8sYqKijRt2jR1795d1157rfr3768VK1ZIkpYvX64+ffro6quvVo8ePTR79mxt375da9ascXirAAAAECrTNOT1mDyDEa7n2uSqffv2WrRokdq1a1dj+cGDB5Wfn6/TTjtNKSkpgeUDBgzQ+vXrJUn5+fnKyckJrEtOTtbpp58eWA8AAIDoU/sZjP6hggwXhFu49iHCaWlpGjx4cOBvn8+nJUuW6Mc//rFKSkrUoUOHGq/PyMjQd999J0mNrg+W4aJj1B+Lm2JyWjC/hWkaMgxDlmXJ5wt+WGhzf+dw7Sc3lQM3xBDP3FQWQtFQvE3ZlvreE22/S12C2YZoKgexsq/cGm80lQW7eDyG0lqnyOs51ldwtMqn/fvKQjrfx5pYLQdOb08o3+/a5Kq2uXPnqqCgQC+88IKefPJJJSQk1FifkJCgyspKSVJ5eXmD64OVkZHavKDDwI0xOaFNm5ZBva7KZ8ljGoH/2/nZ4Xp/MCJZDurankhsI4ITTXVCQ+WmKWWqvvfEQvkMdRsiUQ6aUxfEyr6KhnijqU5ojur74saln0mSHro8W23btnIqJFeJpXIQDcdddVGRXM2dO1dPPfWUHnjgAZ166qlKTExUaWlpjddUVlYqKSlJkpSYmHhcIlVZWam0tLSQvnf37gNyyxwYhnHsQHFTTJHk8Zg1Dq69ew+pqsoX1HvmrSrUpJ/2OO49plnzild9n137uxsTTGxN1ZxyEOp2+O3de0iSQv79EV5urxPqKm/Vy01jx3Qw5dX/nqbUD5HSnOMumG2wuxw0FG99dUHtZfW91437yk31e3O5vU5orrrKjnSs7G3eebDGcrfuo0iI1nLQWN3j9D71/67BcH1yNX36dD333HOaO3eufv7zn0uSMjMztXnz5hqv27VrV2AoYGZmpnbt2nXc+t69e4f03ZYl1xVMN8bklGB/h+rjs6u/xzCO3Rz73JptGjvwR3V+tmka8nhCvzUx3PvIDeXA6e+PF6ZpBO4j8PmOH97qhrIQioZibcp21PeeaPpN6hPKNkRDOYiVfeX2eKOhLIRbvG+/FHvlIJq2xbUTWkjSggULtHTpUt1///266KKLAsuzsrL0xRdf6PDhw4Fla9euVVZWVmD92rVrA+vKy8tVUFAQWA9Ut/NARZ3L/dO+pqUlRzgi4JjqUw8z/TAAAO7n2uRqy5YteuSRR/T73/9eAwYMUElJSeC/gQMHqmPHjsrLy1NhYaEWLlyoDRs2aPTo0ZKkyy67TOvWrdPChQtVWFiovLw8denSRYMGDXJ4qxBN/NO+Prdmm9OhIE75y+CNSz/TjUs/Y/phAPgPw2jayBIg3FxbKletWqWqqir9+c9/1rnnnlvjP4/Ho0ceeUQlJSXKzc3VX//6Vz388MPq1KmTJKlLly6aP3++VqxYodGjR6u0tFQPP/ywDKenGkFUqq9nC4iUzTsP1rinIFp5bE4ODePYFMzU7UD8SU1NYmQJXMm191yNHz9e48ePr3d9t27dtGTJknrXn3feeTrvvPPCERoAIATtWyWqymcpLS1ZR6t82ldaZsvnpqYmyeMxdTSOb14H4pWnnnumAae5tucKgD38D1jk6j6ckpbslcc0NG9Voa1DGz0eM/CZcDd6GREOsT6yxH/+Zjh4dHFtzxUQLv7Z1+LhJO+fEMHL1X24QPWZO938mQieYRhBNfzoZQRCU/v8va80vh+OHE243Ie4Un32tVapSXW+JpausPonRODqPqKF/0otN6pHh2Dve6GXEQhN7fM3vVfRg1oOcSWYZCM1NanB5CsacXUf0aD6xQ9uVI8OnhBmVKUeAkLHcRN9SK4QlxqqrLjCCjij+tTzc9/Y5HQ4CFKs3/cCAKHgniugDlwpApyzeedBWRb3FgAAog+X5gEAAADABiRXaBRTgQIAAACNY1ggGsRUoAAA6dj9qNT/cDt/OaWswin0XKFBTAUKAPEtPbmFqnyW0tKSY2oWVcSW9q0SA+W0dXoK7RU4huQKQWGCB8AdPFzkQISlJHrlMQ1mUYWrpSXXLKfUk3AKtSSiEg1MxBuuysJpXGRDNKCcwmkkV4gq1YentE5PkddrMtkG4kLtq7KGQZkHAMBtSK6ihD95iPckovbwlLS0ZLVp05Ir+RFmGMwg6ZRgrsr6Z/hkH0WvSB1jbpsN1u1ll7oPQGOYLTAKmKahtNYpkqS01inM2KcfGpie/0y2MemnPWSaRtz/LpGSmpokDzNIulL1GT4lRWwfmaYROAYpD80XiWOsrtlgneRU2Q0FdR+AxtBzFQUiOWOf265iBqP2lXz/NjBsKnw8zCDpWv764saln+nGpZ9FZB/5G8XB9iIbhiFPBCdGiMZ6LRLHmNtmg3Wi7IYqUnVfNJZZAMfQcxVFwn2TptuuYjZF7W1A+HDTsLtt3nmwye8NtReqeiPd34vcEP/V/0iI5mf1ReoYc9ux3JyyGwlOnIujpcwCoOcK1bjtKmZT1N4GIFqZZmR7d6p/byi9UNUF2+j0eEw9t2ZbU0MMSSzUa4gvlFnEg1junaX1GWeCKcxuu4oZrOpDjaJ1GwDphwQnLS3Zke+ORMNu54GKsHxufagTEG3CVWZjuVGL6NCci3jRgOQqjsR6YU5NTXKkMQrYzZ/gRKp3py4kI4C72JEUxXo7ANEh1ntnSa7iSKwX5kgONYL7xOLV2Ej37jg1FBFAw+xIikzTUIsWnphuByC6xOpFPM6icShWC7MU+cYo3IGrsU1X/blCTg1FRGTE4gWIeNHci6O1hxrHcjsAcBrJVQzghIl4F+u9suFSPSlNTUt2fCgiGtacup4LELGhqUmRG4YaA/GC5CrKhfOE6fHwrChEF67GNqx247yu2TXp/XWn5tb1XICAxPENRALJVZQL5oQZ6kN105NbqMpnKS0tWa1Sk+wOGYADGmqcuyEpjfSDhaONXcmRG/Y1AMQyzmQxor4TZvUGVbCJUkqiVx7T4FlRcBWGvzaP23sumO0zOCRHqE/1HmkAzqHlHOOa81DdSJzEaTAjGNwvYh+3Ns6Z7TM0hvHDRCQSDep4Z5qG0lqnSJLSWlNHAk4iuYoTbmhQ1XW/Bw1mBMPtvS6wB/eDBC81Nek/E5HEb4Oai3M/oI4E3IPkKo55mlEBVz+pNXaC8z9bo3YixckAoXLDRQLADfw9fdWHcMdTHcrFubpRRwLOI7mKQ9UnrGjqrFPVT2oNneD8r01PT6k3kfKfDPzDXDhJuks0TzTAlW3EMn9Pn10Nao/HjJpjnYtzANwqOmpR2Kr2hBXNndK3+r9btPDU6M3y/Ge9/16KhhoB/mEuXIV0l2idaKD2RYAWLTwkWkAdql9wi7ZjnZ6a5ql+757/P+pIoHlIruJYc09K1d9/qOJojd6w2jMUBnMvhYerkK4UrRMN+C8CLP7wKxmGoXSGEAF18l9wu3HpZ5r7xianw2kSj4fEoCn8FzXTWh+rH6kjgeYjuYItaveGuXmGQoQumicaOFBxNNBwvHHpZyTvQD027zyooj1lTocRkuq9bvGYGIT6HMvaqt+7F6t1JMPDEWlepwNAbKmeHJEowU027zwY1Ov8w1p9Pks+nxXmqJrO35gyTUNVVe6NMxZES5mIR9V73STpocuzA/sq1vmHPns9po5W+Zr8Of6LZ8HWkdGk9m90YP+xdom/fHBcR0a81aH0XMWYaJkUIponSUDsCmYGsrqugjpxZTT1P0NumzoFt8fT9Kvdsaah/dfUWema26OA0GzeeTCQHDRnJtxo0pznWMaL2r9R9R5OZpuMjHic2ZOjMcZEy6QQ0TpJAmJbYzOQ1XWScOrE0dR7FKsPo/LfExnPGtt/TZmVrvpn8hvbq6GktX2rxGbNhButGCXSOP9v5KlnMq54KStOiMeZPUmuYkz1isPN0+pG6yQJkcQ48caFq3egvsZKXSeJ2ssieWN9UxpVte+PjHfBnvgb+q3rekA6PQr2ayxpTUtu3ky4sYge1OPF+u0L1eshN4nF37o+3HMVg/wFODU1ybXJlRT5SRKc/C1CHW9ce5z4wQOHZVmWLCv2xyoHy677DZqirpNE7ePuaJVP+0rLXDu+PJ5OdMFo6u9R17Hqb9TwG9uretI66ac96n0dv/sxzakjPR6z2ffHxNt9Nm5gmobSWqdIOjZk3M3noFjm3pY3mo3eoWOcfoZLfcOOGrvPo65pxP2VZrDf6+bkurki0TvQlF4oHikQX+o6Vp0a8hwt99w2F8lTcJpSR9o1tDIe77Nxg3gcgudGsdvygiT7e4ciNdTQzkaC089wqW8oWTAnnrqmEQ/2O1s72MiLpLoaWs2drCHY6Z3r+55IN/7CeQN/U47FeJywpvqx6tSzouq655ZhYQilPrJraCWNfGdxAcJZ8XX2Q5NFuvcnHBNzOP0Ml+qVXagnnuozYQXD//nx1nNp12QN1RPyup77Euz3hHvWsupxhOvqcFOOxXiesMbJeqZ2rykTa6Cp7GqcO9nIj+WLPNyT7W6xWepgu0j3/sTL0Kpwn3jc/vBfu08Qdk/WUF9S29j3RCLpqSuOcPQsN+VYZEiycxq6iFNdtEzFb/cFCjc3SuvrZYyWfRVOTRnmHqsXeWqPfGnRwhNV5bkusZYIx86WICIieVU2Vru17ThRurEiDVXtE4TXG/z9TY39ho2VHbsabPV9T11JTzgbdNUn0whHY6Ipx6LbE/t4Un3/RctU/OGYVt3p+4CCfZ6af780Z1/FUkLW1GHuTl7kqb6v7U7o67rPM5jyHMkLCw31mteVSMVaIhyzyVVFRYVuv/125eTk6Nxzz9XixYudDsm1/PdUxEpF7FbNbdT4GxvSsVmAQklG3Kj2VfXG7m+S7PsNazfYwj2le6SeP+dEY8KNE6fEy0NkmyJapuK3496f2vcL1vXYBDvKbjCN1sYSu7p6GZuyr8KVPIfSMLe7TmjOMHcnLvLU3td2JfS122r++zwbOkb87/F6zYheWGio17yuRCrWRju4t2Ztpjlz5mjjxo166qmndPfdd2vBggV6/fXXnQ7LlfwNP7dexYyVK3ANnSiDmTSgdmMjmGQkkpp6VayuhzvW9xnNbRjW1WCLxH0pjW2bnVcUI9GY8MfrP2G75YpjpIZjStE/UUS0jAxoTpz1XdSws6c32N6wuhK7uo75hh7zEIxwJM8NbWP1uqChOsGOSaqipTe89r62a2KP+tpqDZUP/3tS05LDOsFIfeew+iacqiuRipb9G4yYTK7Kysq0fPlyTZ06VaeffrrOP/98XXPNNXr22WedDs2VPPVcXXBatAxfCVVdlU0oPRt1JSP+MddONfjsGm4TbCOiuQ3DYO9LsVNDDyaOpimLq8frP2G75Ypj7YZlc35L/7FU1xV4JoqIDo1d1LDjannt+qNFC0+DSUSkerPtTJ7rm4Cp+nGQ1rrhOqGx7a2rce7kBQw7Lng152HFdfX+NaWtVvs91dsPdg5TrD3Ev7Gey1hKpOrirta0TTZt2qSjR48qOzs7sGzAgAHKz8+XzxfZh41GCzdexYyW4St2aOoEHocqjta4Uu9Ugy/Yq7JuU33sd6SOgdontfoaLm5VVzLqthOlf1/WNba/+hX0uhowhmGoRQvPD43GOno2IpWQxwP/8dDYULKm3vDe2HHdnLJbfVRF9bo4mKSp9sUxtw2trUv148rfgPYnUrXP1bV/V08d54favV3Vf7dIX8CoXg6rH/+17wduKAn0/2fHPdX1jQhoynmqvnsug33uZjDx1h7i75bRDE7xOh1AOJSUlKhNmzZKSEgILGvXrp0qKipUWlqqtm3bBvU5pilZLnqw9UkZLSUdqwSs/wTmr5D962r/u1PrpKCWBfue0zulqXN6sq2f2dh7EqqddKIhdv+Jx7Ikw1Cgom3se/zb6fGYgSeqNxb7KR1ayWMaevmz7bo0u7Mk1fi33fu/vu31V8j+bUhNTZLHY+polU+HDh6Wz2cFfo9gym5Tf8NQ978/zobe41fXfgkljj6d0gIntaNVPh3Y/0NDpfpvF8r+b2x77Yq9et3j/5zGjsvmxm7HsVrX/q1eNg0dXw6rv+fRf2xRRqsEjcnp2mB5D0fs1f9d/XcP5T3Bfo8T9Xvt46H6vmjqsVpX7E35DUONXfqhLn70H1skSdcN6a4WLTw6erQq8P21P6dNyg8N3bq+J9h6N5zn97q+p/oxJEneBo6Hus5x/vdX+Sx5TENHq3zyeszAuatFC498PqvGsqbEHszv0VA59H93WlrycXVG9XObv7eu+vbU953V22+GYQTOcZJqnO+8HlP/2LRTQ3p1CHpf1lcmGmozHLvvUGqVmiTvf7bLf26qK866lvl/r+rnsFBjD2ZfmQ5ffwglZzYsy03pgz1eeuklPfTQQ3r33XcDy4qKijR8+HC99957OuGEExyMDgAAAEAscn8/dBMkJiaqsrKyxjL/30lJjI8HAAAAYL+YTK4yMzO1d+9eHT16NLCspKRESUlJSktLa+CdAAAAANA0MZlc9e7dW16vV+vXrw8sW7t2rfr27SvT6UGbAAAAAGJSTGYaycnJGjVqlO655x5t2LBBb7/9thYvXqyrrrrK6dAAAAAAxKiYnNBCksrLy3XPPffozTffVKtWrfS73/1O48aNczosAAAAADEqZpMrAAAAAIikmBwWCAAAAACRRnIFAAAAADYguQIAAAAAG5BcuVxFRYVuv/125eTk6Nxzz9XixYudDgkR8tZbb6lnz541/ps0aZIkqaCgQGPGjFFWVpYuu+wybdy40eFoEQ6VlZUaOXKkPvnkk8CyoqIijRs3Tv3799eIESP04Ycf1njP6tWrNXLkSGVlZemqq65SUVFRpMOGzeoqBzNmzDiufliyZElg/auvvqrhw4crKytLEyZM0J49e5wIHTb5/vvvNWnSJA0cOFCDBw/W7NmzVVFRIYk6IZ40VA6oE9yD5Mrl5syZo40bN+qpp57S3XffrQULFuj11193OixEwObNmzV06FB9+OGHgf9mzJihsrIyjR8/Xjk5OVq5cqWys7N17bXXqqyszOmQYaOKigrdcsstKiwsDCyzLEsTJkxQu3bttGLFCl166aWaOHGiiouLJUnFxcWaMGGCcnNz9cILL6ht27a64YYbxLxF0auuciBJW7Zs0R/+8Ica9cNll10mSdqwYYOmTp2qiRMnatmyZdq/f7/y8vKcCB82sCxLkyZNUnl5uZ599lk98MADevfdd/Xggw9SJ8SRhsqBRJ3gKhZc69ChQ1bfvn2tjz/+OLDs4Ycftn796187GBUi5Q9/+IN13333Hbd8+fLl1rBhwyyfz2dZlmX5fD7r/PPPt1asWBHpEBEmhYWF1iWXXGJdfPHF1qmnnhqoA1avXm3179/fOnToUOC1v/nNb6x58+ZZlmVZDz74YI36oayszMrOzq5RhyB61FcOLMuyBg8ebH3wwQd1vu/WW2+1brvttsDfxcXFVs+ePa1t27aFPWbYb/Pmzdapp55qlZSUBJa98sor1rnnnkudEEcaKgeWRZ3gJvRcudimTZt09OhRZWdnB5YNGDBA+fn58vl8DkaGSNiyZYtOPPHE45bn5+drwIABMgxDkmQYhs444wytX78+sgEibNasWaNBgwZp2bJlNZbn5+frtNNOU0pKSmDZgAEDAvs+Pz9fOTk5gXXJyck6/fTTKRtRqr5ycPDgQX3//fd11g/S8eWgY8eO6tSpk/Lz88MZLsKkffv2WrRokdq1a1dj+cGDB6kT4khD5YA6wV28TgeA+pWUlKhNmzZKSEgILGvXrp0qKipUWlqqtm3bOhgdwsmyLH311Vf68MMP9dhjj6mqqkoXXHCBJk2apJKSEp1yyik1Xp+RkXHcsCFEryuuuKLO5SUlJerQoUONZRkZGfruu++CWo/oUl852LJliwzD0KOPPqr3339f6enp+u1vf6tf/OIXkqSdO3dSDmJIWlqaBg8eHPjb5/NpyZIl+vGPf0ydEEcaKgfUCe5CcuVi5eXlNRIrSYG/KysrnQgJEVJcXBzY/w8++KC+/fZbzZgxQ4cPH663XFAmYl9j+56yER+2bt0qwzB08skn69e//rU+/fRT3XnnnWrVqpXOP/98HT58mHIQw+bOnauCggK98MILevLJJ6kT4lT1cvDFF19QJ7gIyZWLJSYmHlfw/X8nJSU5ERIipHPnzvrkk0/UunVrGYah3r17y+fz6dZbb9XAgQPrLBeUidiXmJio0tLSGsuq7/v66oy0tLRIhYgIGDVqlIYOHar09HRJUq9evfT111/rueee0/nnn19vOUhOTnYgWthp7ty5euqpp/TAAw/o1FNPpU6IU7XLQY8ePagTXIR7rlwsMzNTe/fu1dGjRwPLSkpKlJSURMUYB9LT0wP3VUlS9+7dVVFRofbt22vXrl01Xrtr167juvwRezIzMxvc9/Wtb9++fcRiRPgZhhFoRPmdfPLJ+v777yVRDmLV9OnT9cQTT2ju3Ln6+c9/Lok6IR7VVQ6oE9yF5MrFevfuLa/XW+PG07Vr16pv374yTXZdLPvggw80aNAglZeXB5Z9+eWXSk9P14ABA/TZZ58FptK1LEvr1q1TVlaWU+EiQrKysvTFF1/o8OHDgWVr164N7PusrCytXbs2sK68vFwFBQWUjRjz0EMPady4cTWWbdq0SSeffLKk48vBjh07tGPHDspBFFuwYIGWLl2q+++/XxdddFFgOXVCfKmvHFAnuAstdBdLTk7WqFGjdM8992jDhg16++23tXjxYl111VVOh4Ywy87OVmJiou644w5t3bpV7733nubMmaNrrrlGF1xwgfbv36+ZM2dq8+bNmjlzpsrLy3XhhRc6HTbCbODAgerYsaPy8vJUWFiohQsXasOGDRo9erQk6bLLLtO6deu0cOFCFRYWKi8vT126dNGgQYMcjhx2Gjp0qD799FM9/vjj2rZtm/7yl7/opZde0tVXXy1JGjt2rF5++WUtX75cmzZt0uTJkzVkyBB17drV4cjRFFu2bNEjjzyi3//+9xowYIBKSkoC/1EnxI+GygF1gss4PBU8GlFWVmZNnjzZ6t+/v3XuuedaTzzxhNMhIUL+/e9/W+PGjbP69+9vnXPOOdb8+fMDz7bKz8+3Ro0aZfXt29caPXq09cUXXzgcLcKl9vONvv76a+tXv/qV1adPH+uiiy6y/vnPf9Z4/T/+8Q/rZz/7mdWvXz/rN7/5Dc8xiRG1y8Fbb71lXXzxxVbfvn2tCy64wHrjjTdqvH7FihXWeeedZ/Xv39+aMGGCtWfPnkiHDJs89thj1qmnnlrnf5ZFnRAvGisH1AnuYVgWj+kGAAAAgOZiWCAAAAAA2IDkCgAAAABsQHIFAAAAADYguQIAAAAAG5BcAQAAAIANSK4AAAAAwAYkVwAAAABgA5IrAIAjhg0bpp49ex7339ixY235/I8++khbtmyx5bMas3LlSg0bNqzJ7x82bJhWrlxpY0QAACd4nQ4AABC/br/9do0YMaLGshYtWtjy2ePGjdPTTz+t7t272/J5DRkxYoSGDBkS9u8BALgbyRUAwDGpqalq376902E0W1JSkpKSkpwOAwDgMIYFAgBcybIsPfzwwzr33HOVk5Oj6667TsXFxYH1mzdv1u9+9ztlZ2erb9++uuKKKwLDAP1D9K666irNnz+/zmF7V155pebPny9JmjJliqZMmaJLLrlEZ511lr7++mvt379ft956q8444wyde+65mj59ug4fPlxnrNU//5NPPtGwYcP0l7/8RYMHD1b//v116623qrKyMvD6pUuXasiQITrjjDP0yCOPBL3dH330kXr16qVPP/1UkrRnzx4NGjRITz31VJN/ZwCAfUiuAACutGTJEr3yyiu67777tGzZMmVkZOjqq6/WkSNH5PP5dN1116lz5856+eWXtXTpUlVVVWnu3LmSpBdeeEGSNH/+fF199dVBfd/LL7+sm266SY899phOPPFETZ06VQcOHNBzzz2nRx55RJ9//rmmTZsW1Gft3LlTb7zxhhYtWqT58+frzTff1EsvvSRJ+uCDDzRz5kzddNNNWrZsmT7//HNt3749qO0+66yzdOmll2rGjBmqqqrSrFmzdPLJJ+vKK68M4ZcFAIQLyRUAwDF33323srOza/xXVlYmSVq0aJEmT56sQYMGqXv37po2bZr27dunDz74QIcPH9bll1+uKVOm6Ec/+pFOP/10/eIXv9DmzZslSW3btpUktW7dWi1btgwqlr59+2rYsGHq16+ftm3bprfffltz585Vz5491a9fP02fPl0vvviiDhw40OhnHTlyRHfccYd69uypwYMHa/Dgwfr8888lScuXL9fFF1+sUaNGqUePHpo1a5YSExMD721ou6VjvWw7d+7U5MmT9dZbb2nWrFkyTU7nAOAG3HMFAHDMpEmT9LOf/azGsuTkZB06dEjfffedbr755hqJw+HDh/X1119r2LBhGjt2rF566SVt3LhRW7duVUFBgdq1a9fkWDp37hz495YtW+Tz+fSTn/ykxmt8Pp+++eYb9enTp9HP69atW+DfrVq10tGjRwOfffnllwfWtWnTRl27dpWkRrfb//rJkydrypQpmjRpkk466aTQNxYAEBYkVwAAx2RkZNRIQvyqqqokSQ899NBxyUPr1q116NAhjR49Wm3atNGwYcM0cuRIbd26VYsXL67zewzDOG6ZP9nxq957VFVVpdTUVK1YseK492VmZja+YZISEhJq/G1ZVp3/ln6YIbGx7fbbtGmTPB6PPvnkE02YMCGoeAAA4cc4AgCA66SlpSkjI0MlJSXq1q2bunXrpo4dO2ru3Ln66quvtGbNGu3cuVNPP/20rrnmGp199tkqLi4+Lmnxa9GihQ4dOhT427Isffvtt/V+/0knnaQDBw7IMIzA9x8+fFhz5sypMTFFU/To0SMwRFCSDh48qG+++Sao7ZakjRs36tlnn9UjjzyigoKCOhNAAIAzSK4AAK40btw4Pfjgg3rnnXf09ddf64477tC6det08sknKz09XWVlZXr77bf17bffavny5Xr22WdrJD4pKSkqLCzUgQMH1KdPH5WWluqZZ55RUVGRZs+erX379tX73d27d9fgwYP13//939qwYYO++OIL5eXlqaysTGlpac3arl//+tf6+9//rueff15btmzRXXfdVWMWwoa2u6qqSnfeeadyc3M1ZMgQ3XjjjZozZ452797drJgAAPYguQIAuNLvfvc7jR49WnfddZdGjRql4uJiPf7442rdurWys7M1YcIE3Xvvvbrkkku0cuVK3XXXXdq9e7e+//57ScemWp8zZ47mz5+vE088Ubfddpv+/Oc/a9SoUbIsSz//+c8b/P45c+aoS5cuGjdunH7729/qpJNO0v3339/s7crJydHs2bP12GOPafTo0Wrbtq169+4d1HY/9dRTKi4u1s033yxJuuKKK5SZmalZs2Y1Oy4AQPMZVn1jKAAAAAAAQaPnCgAAAABsQHIFAAAAADYguQIAAAAAG5BcAQAAAIANSK4AAAAAwAYkVwAAAABgA5IrAAAAALAByRUAAAAA2IDkCgAAAABsQHIFAAAAADYguQIAAAAAG5BcAQAAAIAN/j9FTe5R+jjmQQAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_selector = SelectKBest(score_func=f_regression, k='all')\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar([i for i in range(len(f_selector.scores_))], f_selector.scores_)\n",
    "plt.xlabel('Feature index')\n",
    "plt.ylabel('Estimated value')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:48:13.425625Z",
     "start_time": "2023-06-06T16:48:12.977020Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "      mfcc_q25    mfcc_q99  stft_mean  stft_std  stft_q25  mfcc_q25_w2   \n259 -18.582673  133.537021   0.391166  0.350493  0.037039   -25.548968  \\\n157  -2.432008  140.389436   0.618064  0.281252  0.400627   -11.883626   \n667 -10.434671  169.611666   0.499650  0.347630  0.142961   -18.150980   \n707 -11.989990  140.775630   0.500564  0.321720  0.203172   -19.689170   \n125  -6.579166   90.324497   0.475922  0.349201  0.106374   -15.118881   \n..         ...         ...        ...       ...       ...          ...   \n802 -10.531611  188.840487   0.448354  0.342674  0.105303   -16.788827   \n53  -10.841864  159.482310   0.512951  0.316919  0.221845   -20.016054   \n350  -7.651122  151.113206   0.543641  0.328328  0.233966   -13.594585   \n79  -10.683922  143.316089   0.513574  0.286984  0.275286   -11.417866   \n792  -2.116944  152.105091   0.636902  0.295871  0.413712   -10.847955   \n\n     mfcc_q50_w2  mfcc_q99_w2  stft_sum_w2  stft_q05_w2  stft_q25_w2   \n259   -14.335812   131.763970   316.827272     0.002076     0.019907  \\\n157     0.331137   157.141432   487.714941     0.047736     0.247174   \n667    -7.070016   177.324767   409.154710     0.007334     0.053486   \n707    -6.076445   132.367535   424.497157     0.012076     0.085660   \n125     0.000000    92.440168   351.456816     0.002707     0.027473   \n..           ...          ...          ...          ...          ...   \n802    -4.730709   181.582949   469.988087     0.016418     0.071749   \n53     -4.384253   176.553050   452.237700     0.045298     0.156050   \n350    -2.200245   156.181359   492.584031     0.025636     0.164514   \n79     -2.853683   147.437486   577.809521     0.057310     0.276032   \n792     0.000000   148.006489   482.397157     0.036796     0.246890   \n\n     stft_skew_w2   mfcc_sum_w3  mfcc_q25_w3  mfcc_q50_w3  mfcc_q75_w3   \n259      1.368237 -70611.711781   -25.377122   -12.167407    -1.477520  \\\n157     -0.016021 -37384.776127    -9.452207     0.308263     9.277478   \n667      0.865939 -39253.197492   -17.626914    -5.782738     6.776643   \n707      0.328339 -46073.398204   -21.128508   -10.204088     2.029520   \n125      0.804747 -39812.423944   -25.070787    -7.274005     9.855553   \n..            ...           ...          ...          ...          ...   \n802      0.886020 -54877.142055   -18.882193    -4.978764     7.866954   \n53       0.706239 -30872.660059   -18.504748    -4.311820    10.084295   \n350      0.347103 -38947.164248   -17.357152    -6.596020     6.551662   \n79       0.175891 -37772.767541   -16.525048    -5.833418     5.294950   \n792      0.027626 -28996.039009   -10.309630    -1.024038    10.095972   \n\n     mfcc_q99_w3  stft_q25_w3  sex_F  sex_M  \n259   141.949765     0.006469      1      0  \n157   208.015807     0.228734      0      1  \n667   182.314767     0.089444      0      1  \n707   174.004688     0.052809      1      0  \n125   124.347880     0.013650      1      0  \n..           ...          ...    ...    ...  \n802   207.137736     0.043049      0      1  \n53    166.648179     0.122665      0      1  \n350   192.158127     0.081348      1      0  \n79    171.602208     0.172040      0      1  \n792   213.165450     0.153596      0      1  \n\n[847 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mfcc_q25</th>\n      <th>mfcc_q99</th>\n      <th>stft_mean</th>\n      <th>stft_std</th>\n      <th>stft_q25</th>\n      <th>mfcc_q25_w2</th>\n      <th>mfcc_q50_w2</th>\n      <th>mfcc_q99_w2</th>\n      <th>stft_sum_w2</th>\n      <th>stft_q05_w2</th>\n      <th>stft_q25_w2</th>\n      <th>stft_skew_w2</th>\n      <th>mfcc_sum_w3</th>\n      <th>mfcc_q25_w3</th>\n      <th>mfcc_q50_w3</th>\n      <th>mfcc_q75_w3</th>\n      <th>mfcc_q99_w3</th>\n      <th>stft_q25_w3</th>\n      <th>sex_F</th>\n      <th>sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>259</th>\n      <td>-18.582673</td>\n      <td>133.537021</td>\n      <td>0.391166</td>\n      <td>0.350493</td>\n      <td>0.037039</td>\n      <td>-25.548968</td>\n      <td>-14.335812</td>\n      <td>131.763970</td>\n      <td>316.827272</td>\n      <td>0.002076</td>\n      <td>0.019907</td>\n      <td>1.368237</td>\n      <td>-70611.711781</td>\n      <td>-25.377122</td>\n      <td>-12.167407</td>\n      <td>-1.477520</td>\n      <td>141.949765</td>\n      <td>0.006469</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>-2.432008</td>\n      <td>140.389436</td>\n      <td>0.618064</td>\n      <td>0.281252</td>\n      <td>0.400627</td>\n      <td>-11.883626</td>\n      <td>0.331137</td>\n      <td>157.141432</td>\n      <td>487.714941</td>\n      <td>0.047736</td>\n      <td>0.247174</td>\n      <td>-0.016021</td>\n      <td>-37384.776127</td>\n      <td>-9.452207</td>\n      <td>0.308263</td>\n      <td>9.277478</td>\n      <td>208.015807</td>\n      <td>0.228734</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>-10.434671</td>\n      <td>169.611666</td>\n      <td>0.499650</td>\n      <td>0.347630</td>\n      <td>0.142961</td>\n      <td>-18.150980</td>\n      <td>-7.070016</td>\n      <td>177.324767</td>\n      <td>409.154710</td>\n      <td>0.007334</td>\n      <td>0.053486</td>\n      <td>0.865939</td>\n      <td>-39253.197492</td>\n      <td>-17.626914</td>\n      <td>-5.782738</td>\n      <td>6.776643</td>\n      <td>182.314767</td>\n      <td>0.089444</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>707</th>\n      <td>-11.989990</td>\n      <td>140.775630</td>\n      <td>0.500564</td>\n      <td>0.321720</td>\n      <td>0.203172</td>\n      <td>-19.689170</td>\n      <td>-6.076445</td>\n      <td>132.367535</td>\n      <td>424.497157</td>\n      <td>0.012076</td>\n      <td>0.085660</td>\n      <td>0.328339</td>\n      <td>-46073.398204</td>\n      <td>-21.128508</td>\n      <td>-10.204088</td>\n      <td>2.029520</td>\n      <td>174.004688</td>\n      <td>0.052809</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>-6.579166</td>\n      <td>90.324497</td>\n      <td>0.475922</td>\n      <td>0.349201</td>\n      <td>0.106374</td>\n      <td>-15.118881</td>\n      <td>0.000000</td>\n      <td>92.440168</td>\n      <td>351.456816</td>\n      <td>0.002707</td>\n      <td>0.027473</td>\n      <td>0.804747</td>\n      <td>-39812.423944</td>\n      <td>-25.070787</td>\n      <td>-7.274005</td>\n      <td>9.855553</td>\n      <td>124.347880</td>\n      <td>0.013650</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>802</th>\n      <td>-10.531611</td>\n      <td>188.840487</td>\n      <td>0.448354</td>\n      <td>0.342674</td>\n      <td>0.105303</td>\n      <td>-16.788827</td>\n      <td>-4.730709</td>\n      <td>181.582949</td>\n      <td>469.988087</td>\n      <td>0.016418</td>\n      <td>0.071749</td>\n      <td>0.886020</td>\n      <td>-54877.142055</td>\n      <td>-18.882193</td>\n      <td>-4.978764</td>\n      <td>7.866954</td>\n      <td>207.137736</td>\n      <td>0.043049</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>-10.841864</td>\n      <td>159.482310</td>\n      <td>0.512951</td>\n      <td>0.316919</td>\n      <td>0.221845</td>\n      <td>-20.016054</td>\n      <td>-4.384253</td>\n      <td>176.553050</td>\n      <td>452.237700</td>\n      <td>0.045298</td>\n      <td>0.156050</td>\n      <td>0.706239</td>\n      <td>-30872.660059</td>\n      <td>-18.504748</td>\n      <td>-4.311820</td>\n      <td>10.084295</td>\n      <td>166.648179</td>\n      <td>0.122665</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>-7.651122</td>\n      <td>151.113206</td>\n      <td>0.543641</td>\n      <td>0.328328</td>\n      <td>0.233966</td>\n      <td>-13.594585</td>\n      <td>-2.200245</td>\n      <td>156.181359</td>\n      <td>492.584031</td>\n      <td>0.025636</td>\n      <td>0.164514</td>\n      <td>0.347103</td>\n      <td>-38947.164248</td>\n      <td>-17.357152</td>\n      <td>-6.596020</td>\n      <td>6.551662</td>\n      <td>192.158127</td>\n      <td>0.081348</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>-10.683922</td>\n      <td>143.316089</td>\n      <td>0.513574</td>\n      <td>0.286984</td>\n      <td>0.275286</td>\n      <td>-11.417866</td>\n      <td>-2.853683</td>\n      <td>147.437486</td>\n      <td>577.809521</td>\n      <td>0.057310</td>\n      <td>0.276032</td>\n      <td>0.175891</td>\n      <td>-37772.767541</td>\n      <td>-16.525048</td>\n      <td>-5.833418</td>\n      <td>5.294950</td>\n      <td>171.602208</td>\n      <td>0.172040</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>792</th>\n      <td>-2.116944</td>\n      <td>152.105091</td>\n      <td>0.636902</td>\n      <td>0.295871</td>\n      <td>0.413712</td>\n      <td>-10.847955</td>\n      <td>0.000000</td>\n      <td>148.006489</td>\n      <td>482.397157</td>\n      <td>0.036796</td>\n      <td>0.246890</td>\n      <td>0.027626</td>\n      <td>-28996.039009</td>\n      <td>-10.309630</td>\n      <td>-1.024038</td>\n      <td>10.095972</td>\n      <td>213.165450</td>\n      <td>0.153596</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>847 rows Ã— 20 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_selector = SelectKBest(score_func=f_regression, k=20)\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "X_train = f_selector.transform(X_train)\n",
    "X_valid = f_selector.transform(X_valid)\n",
    "X_test = f_selector.transform(X_test)\n",
    "X_to_pred = f_selector.transform(X_to_pred)\n",
    "\n",
    "# selected columns\n",
    "selected_indices = f_selector.get_support(indices=True)\n",
    "df_train.iloc[:, selected_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:48:13.544230Z",
     "start_time": "2023-06-06T16:48:13.427847Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_to_pred = scaler.fit_transform(X_to_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:48:13.553107Z",
     "start_time": "2023-06-06T16:48:13.545344Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:48:13,822] A new study created in memory with name: no-name-47de5b95-f785-4575-937e-71c91ba78fb2\n",
      "[I 2023-06-06 18:48:14,678] Trial 5 finished with value: 0.10261708364203294 and parameters: {'booster': 'gbtree', 'gamma': 0.6268810019553667, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.8200330731543249}. Best is trial 5 with value: 0.10261708364203294.\n",
      "[I 2023-06-06 18:48:15,116] Trial 4 finished with value: 0.10883986807935933 and parameters: {'booster': 'gbtree', 'gamma': 3.0801100597549826, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.4065722713762269}. Best is trial 5 with value: 0.10261708364203294.\n",
      "[I 2023-06-06 18:48:15,658] Trial 3 finished with value: 0.11255240937717126 and parameters: {'booster': 'gbtree', 'gamma': 3.093530088610705, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.4520935569072523}. Best is trial 5 with value: 0.10261708364203294.\n",
      "[I 2023-06-06 18:48:17,625] Trial 1 finished with value: 0.11652148166761961 and parameters: {'booster': 'dart', 'gamma': 4.809611005231674, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.5456738424875959}. Best is trial 5 with value: 0.10261708364203294.\n",
      "[I 2023-06-06 18:48:18,699] Trial 0 finished with value: 0.11061498725983064 and parameters: {'booster': 'dart', 'gamma': 2.4686180066300505, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.4859771710469393}. Best is trial 5 with value: 0.10261708364203294.\n",
      "[I 2023-06-06 18:48:19,070] Trial 8 finished with value: 0.10621693051330547 and parameters: {'booster': 'gbtree', 'gamma': 1.8769674715451972, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.560163114542738}. Best is trial 5 with value: 0.10261708364203294.\n",
      "[I 2023-06-06 18:48:19,303] Trial 11 finished with value: 0.09275929539857534 and parameters: {'booster': 'gbtree', 'gamma': 0.37310528600881354, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.8473285219742799}. Best is trial 11 with value: 0.09275929539857534.\n",
      "[I 2023-06-06 18:48:19,392] Trial 7 finished with value: 0.1070637460319155 and parameters: {'booster': 'dart', 'gamma': 1.2899431851052179, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.5614598098719955}. Best is trial 11 with value: 0.09275929539857534.\n",
      "[I 2023-06-06 18:48:19,980] Trial 10 finished with value: 0.11297370425380934 and parameters: {'booster': 'dart', 'gamma': 0.23717084282878165, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.6599736265842615}. Best is trial 11 with value: 0.09275929539857534.\n",
      "[I 2023-06-06 18:48:20,394] Trial 12 finished with value: 0.10626024252176691 and parameters: {'booster': 'gbtree', 'gamma': 1.5998521042378033, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.5437580552724697}. Best is trial 11 with value: 0.09275929539857534.\n",
      "[I 2023-06-06 18:48:20,777] Trial 9 finished with value: 0.11343359031999525 and parameters: {'booster': 'dart', 'gamma': 4.657724265510394, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.4015082027741275}. Best is trial 11 with value: 0.09275929539857534.\n",
      "[I 2023-06-06 18:48:20,885] Trial 2 finished with value: 0.09079516129717453 and parameters: {'booster': 'dart', 'gamma': 1.2453061954147782, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.923799177370367}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:21,064] Trial 6 finished with value: 0.09618194771885945 and parameters: {'booster': 'dart', 'gamma': 0.7403473888226803, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.8921483954604705}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:21,309] Trial 18 finished with value: 0.10039134081476128 and parameters: {'booster': 'gbtree', 'gamma': 0.028429852575662218, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.9083566595141732}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:22,178] Trial 15 finished with value: 0.0979427506747582 and parameters: {'booster': 'gbtree', 'gamma': 0.8971419994152491, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.7819564119186071}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:22,966] Trial 13 finished with value: 0.11509375118962313 and parameters: {'booster': 'dart', 'gamma': 2.8494509848085308, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.48787136636418127}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:23,738] Trial 16 finished with value: 0.10051580611317766 and parameters: {'booster': 'gbtree', 'gamma': 3.015798917621483, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.7610900389749877}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:23,933] Trial 17 finished with value: 0.12765317598741166 and parameters: {'booster': 'gbtree', 'gamma': 0.05538813925103103, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.9532828550447666}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:24,725] Trial 14 finished with value: 0.11926537312219594 and parameters: {'booster': 'dart', 'gamma': 1.7240677163657074, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.41550460747863066}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:25,242] Trial 19 finished with value: 0.10578985223423625 and parameters: {'booster': 'gbtree', 'gamma': 0.26166786318597723, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.9859157479877556}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:26,281] Trial 20 finished with value: 0.11747377124273989 and parameters: {'booster': 'gbtree', 'gamma': 0.004657506606684736, 'max_depth': 19, 'min_child_weight': 2, 'subsample': 0.9900309358139314}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:29,102] Trial 22 finished with value: 0.10197244492388821 and parameters: {'booster': 'dart', 'gamma': 1.1550115906429088, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.9652438969866693}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:29,408] Trial 21 finished with value: 0.09743307840400989 and parameters: {'booster': 'dart', 'gamma': 0.973392961946324, 'max_depth': 19, 'min_child_weight': 2, 'subsample': 0.9742496146732185}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:30,794] Trial 23 finished with value: 0.11959994937626713 and parameters: {'booster': 'dart', 'gamma': 0.06635577182232222, 'max_depth': 20, 'min_child_weight': 2, 'subsample': 0.9974743894347275}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:31,108] Trial 24 finished with value: 0.12401613683781203 and parameters: {'booster': 'dart', 'gamma': 0.0011608782548017116, 'max_depth': 20, 'min_child_weight': 2, 'subsample': 0.9988194810441297}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:31,334] Trial 25 finished with value: 0.09196529002657276 and parameters: {'booster': 'dart', 'gamma': 1.1179928971673283, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.9449133077221556}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:32,591] Trial 26 finished with value: 0.09666793814524227 and parameters: {'booster': 'dart', 'gamma': 1.1696263680446795, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.9945320312554419}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:32,822] Trial 27 finished with value: 0.10002577272173717 and parameters: {'booster': 'dart', 'gamma': 1.087292854781846, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.8526648837389169}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:32,831] Trial 28 finished with value: 0.10275410191697862 and parameters: {'booster': 'dart', 'gamma': 0.8572601480998643, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.8816462642445028}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:35,577] Trial 29 finished with value: 0.09982769380672653 and parameters: {'booster': 'dart', 'gamma': 0.8260258125191298, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.8684912783144341}. Best is trial 2 with value: 0.09079516129717453.\n",
      "[I 2023-06-06 18:48:35,762] Trial 30 finished with value: 0.09035060496078469 and parameters: {'booster': 'dart', 'gamma': 0.721255558636881, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.8932654675063618}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:37,731] Trial 31 finished with value: 0.11039287862632924 and parameters: {'booster': 'dart', 'gamma': 0.6227738394517306, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.9005889475627167}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:37,799] Trial 32 finished with value: 0.10628118668826836 and parameters: {'booster': 'dart', 'gamma': 0.6673877118943268, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.8825423927029038}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:38,034] Trial 33 finished with value: 0.10125400108641716 and parameters: {'booster': 'dart', 'gamma': 0.6392270713689893, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.8774579969385838}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:39,403] Trial 34 finished with value: 0.10507775095145828 and parameters: {'booster': 'dart', 'gamma': 0.6593989077182274, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.8969778280772449}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:39,623] Trial 35 finished with value: 0.10057399545349513 and parameters: {'booster': 'dart', 'gamma': 0.5905389771059206, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.9174369815391941}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:40,184] Trial 36 finished with value: 0.1022132945140641 and parameters: {'booster': 'dart', 'gamma': 2.12268315007002, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.9354291885403394}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:42,294] Trial 37 finished with value: 0.10084019798439552 and parameters: {'booster': 'dart', 'gamma': 0.44272001732576316, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.9258210492153733}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:42,577] Trial 43 finished with value: 0.09297246573889334 and parameters: {'booster': 'gbtree', 'gamma': 1.4141397954568922, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.9429456610689171}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:42,813] Trial 38 finished with value: 0.09721518930633467 and parameters: {'booster': 'dart', 'gamma': 0.598969369736032, 'max_depth': 16, 'min_child_weight': 1, 'subsample': 0.9232439257390045}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:43,450] Trial 40 finished with value: 0.10331980779062365 and parameters: {'booster': 'dart', 'gamma': 0.4576796467204737, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.9177261304488388}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:43,687] Trial 44 finished with value: 0.10169577387745636 and parameters: {'booster': 'gbtree', 'gamma': 1.4105074559415351, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.931451767775316}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:44,503] Trial 39 finished with value: 0.10379276701098171 and parameters: {'booster': 'dart', 'gamma': 0.3848059685357761, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.9403555889780681}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:44,900] Trial 47 finished with value: 0.09950012072086363 and parameters: {'booster': 'gbtree', 'gamma': 1.4673186932646987, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.8379777366609603}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:45,521] Trial 49 finished with value: 0.09879001754819752 and parameters: {'booster': 'gbtree', 'gamma': 1.3200513287297149, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.8460714395596451}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:45,599] Trial 41 finished with value: 0.10662343507331169 and parameters: {'booster': 'dart', 'gamma': 1.4784729465236623, 'max_depth': 17, 'min_child_weight': 2, 'subsample': 0.9342728405042037}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:45,621] Trial 42 finished with value: 0.11023005280470481 and parameters: {'booster': 'dart', 'gamma': 1.4811836433593766, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.9340400149598478}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:45,753] Trial 45 finished with value: 0.1007323975382302 and parameters: {'booster': 'gbtree', 'gamma': 1.4721874355596931, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.8419581702087491}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:45,981] Trial 48 finished with value: 0.10667336977123891 and parameters: {'booster': 'gbtree', 'gamma': 1.4057317982074282, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.9552098054719447}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:46,164] Trial 46 finished with value: 0.10832064773063363 and parameters: {'booster': 'gbtree', 'gamma': 1.467139297825529, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.8097845351543922}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:46,246] Trial 50 finished with value: 0.10219219383048112 and parameters: {'booster': 'gbtree', 'gamma': 1.4005502536078782, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.8181019896416994}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:47,331] Trial 57 finished with value: 0.0974846329696833 and parameters: {'booster': 'gbtree', 'gamma': 1.948882171645766, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.9652430086104242}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:47,718] Trial 51 finished with value: 0.10333488721651374 and parameters: {'booster': 'gbtree', 'gamma': 1.2876013573675738, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.954815152831332}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:47,956] Trial 55 finished with value: 0.09439261161701946 and parameters: {'booster': 'gbtree', 'gamma': 1.0455070145774488, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9590381308540734}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:48,015] Trial 54 finished with value: 0.09753161449686337 and parameters: {'booster': 'gbtree', 'gamma': 0.9867676625966059, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.9602849301900425}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:48,215] Trial 53 finished with value: 0.10671036970640171 and parameters: {'booster': 'gbtree', 'gamma': 1.8118440822194186, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.9580654080712349}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:48,433] Trial 52 finished with value: 0.10467795179882354 and parameters: {'booster': 'gbtree', 'gamma': 1.0690969075169954, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.9558581746586977}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:48,913] Trial 56 finished with value: 0.0923699972390186 and parameters: {'booster': 'gbtree', 'gamma': 1.0249750020564314, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.8144734248502914}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:48,977] Trial 62 finished with value: 0.0999403915445242 and parameters: {'booster': 'gbtree', 'gamma': 0.9800227898602961, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8993879395033524}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:49,307] Trial 58 finished with value: 0.09935805986957472 and parameters: {'booster': 'gbtree', 'gamma': 0.9830587255469303, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.9564127005454702}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:50,717] Trial 61 finished with value: 0.10377213785515378 and parameters: {'booster': 'gbtree', 'gamma': 0.9957666465641091, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.8909432440355383}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:50,949] Trial 63 finished with value: 0.10098857218108455 and parameters: {'booster': 'gbtree', 'gamma': 1.0270635754697455, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.905622619617705}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:51,440] Trial 64 finished with value: 0.1205557188527491 and parameters: {'booster': 'gbtree', 'gamma': 0.8277997983275109, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.9020930525103009}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:51,705] Trial 66 finished with value: 0.10849730262419889 and parameters: {'booster': 'gbtree', 'gamma': 0.8005544287495654, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.8719219193565886}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:52,276] Trial 65 finished with value: 0.1092470476610639 and parameters: {'booster': 'gbtree', 'gamma': 0.9530208012896747, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.8959496008197261}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:52,663] Trial 68 finished with value: 0.10315351844783452 and parameters: {'booster': 'gbtree', 'gamma': 0.7469006783678112, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.856094832812807}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:52,668] Trial 59 finished with value: 0.10542871273207499 and parameters: {'booster': 'dart', 'gamma': 1.1110213054104587, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.8946543171707925}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:52,751] Trial 67 finished with value: 0.10657372713080197 and parameters: {'booster': 'gbtree', 'gamma': 0.818596731911517, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.8666209861068394}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:53,803] Trial 72 finished with value: 0.10453099460385257 and parameters: {'booster': 'gbtree', 'gamma': 1.252538568760446, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.9791793378785506}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:54,186] Trial 69 finished with value: 0.09522641317467397 and parameters: {'booster': 'gbtree', 'gamma': 0.825894077384441, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.8649649216018667}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:54,219] Trial 60 finished with value: 0.09697648809757219 and parameters: {'booster': 'dart', 'gamma': 0.8401060709065925, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.9019789579946038}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:54,715] Trial 70 finished with value: 0.09861888372379518 and parameters: {'booster': 'gbtree', 'gamma': 1.2394935054752714, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.8724512106026083}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:55,188] Trial 79 finished with value: 0.09192928357832679 and parameters: {'booster': 'gbtree', 'gamma': 0.24113592838045006, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.9772339037876211}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:55,434] Trial 71 finished with value: 0.09082970042524399 and parameters: {'booster': 'gbtree', 'gamma': 1.2190090703755387, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.9804665120622813}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:56,077] Trial 74 finished with value: 0.10003845808375045 and parameters: {'booster': 'gbtree', 'gamma': 1.2399366823827174, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.9739158876276955}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:56,786] Trial 75 finished with value: 0.09573941599296562 and parameters: {'booster': 'dart', 'gamma': 0.23419632569570858, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.9775183353615873}. Best is trial 30 with value: 0.09035060496078469.\n",
      "[I 2023-06-06 18:48:56,932] Trial 73 finished with value: 0.08547292199501176 and parameters: {'booster': 'dart', 'gamma': 1.1430440610880634, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8721463985710389}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:48:56,952] Trial 76 finished with value: 0.08958762061731482 and parameters: {'booster': 'dart', 'gamma': 0.26326049585442446, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.9824560909429457}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:48:57,379] Trial 77 finished with value: 0.10026564943883827 and parameters: {'booster': 'dart', 'gamma': 0.24359584616568997, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.9856111543380528}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:48:57,982] Trial 78 finished with value: 0.10072720942551266 and parameters: {'booster': 'gbtree', 'gamma': 1.1667135400443036, 'max_depth': 14, 'min_child_weight': 3, 'subsample': 0.8284565598927301}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:48:58,462] Trial 80 finished with value: 0.08882747706897225 and parameters: {'booster': 'dart', 'gamma': 0.20224829669574912, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.9814558103329875}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:48:58,901] Trial 81 finished with value: 0.1011550793258448 and parameters: {'booster': 'dart', 'gamma': 0.21918068710719468, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9709203249420023}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:00,222] Trial 83 finished with value: 0.09285075924628058 and parameters: {'booster': 'dart', 'gamma': 0.31143332311670724, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.9983379955397773}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:00,370] Trial 85 finished with value: 0.09668874547709208 and parameters: {'booster': 'dart', 'gamma': 0.46147552726028573, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.9985131643368511}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:00,411] Trial 84 finished with value: 0.10905264053468235 and parameters: {'booster': 'dart', 'gamma': 0.4246801194896882, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.924616722576284}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:00,990] Trial 86 finished with value: 0.09419516055635249 and parameters: {'booster': 'dart', 'gamma': 0.4550540897200672, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9960952384195085}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:01,729] Trial 87 finished with value: 0.1015860929055106 and parameters: {'booster': 'dart', 'gamma': 0.5304356049710894, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9212051034646426}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:02,147] Trial 88 finished with value: 0.10509400868155465 and parameters: {'booster': 'dart', 'gamma': 0.41779014593011987, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9207574269665018}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:02,359] Trial 82 finished with value: 0.10017139425110429 and parameters: {'booster': 'dart', 'gamma': 0.23845292352365588, 'max_depth': 14, 'min_child_weight': 3, 'subsample': 0.999326073589671}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:02,547] Trial 89 finished with value: 0.09108277916288399 and parameters: {'booster': 'dart', 'gamma': 0.5758035133541064, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9930472404982547}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:03,797] Trial 90 finished with value: 0.1101594458309121 and parameters: {'booster': 'dart', 'gamma': 0.11547630853043837, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9150855566413056}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:03,921] Trial 91 finished with value: 0.10769409539656159 and parameters: {'booster': 'dart', 'gamma': 0.5372519285934017, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9432528878597276}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:03,992] Trial 92 finished with value: 0.103718449967651 and parameters: {'booster': 'dart', 'gamma': 0.1356155308909759, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9416378654680093}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:04,405] Trial 93 finished with value: 0.10373755834666426 and parameters: {'booster': 'dart', 'gamma': 0.6132539784399516, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9412466533454362}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:04,836] Trial 94 finished with value: 0.10515290371669209 and parameters: {'booster': 'dart', 'gamma': 0.6898464987067645, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9416348782049089}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:05,288] Trial 96 finished with value: 0.1006354367143697 and parameters: {'booster': 'dart', 'gamma': 0.10628249913534138, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.946402399988309}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:05,339] Trial 97 finished with value: 0.10341250513338196 and parameters: {'booster': 'dart', 'gamma': 0.6674327249109779, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.9427975928599678}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:05,750] Trial 98 finished with value: 0.10498248084714003 and parameters: {'booster': 'dart', 'gamma': 0.7026302003798772, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.9416450291398243}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:05,757] Trial 99 finished with value: 0.10078841713205217 and parameters: {'booster': 'dart', 'gamma': 0.6942590499716942, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.9460613745459839}. Best is trial 73 with value: 0.08547292199501176.\n",
      "[I 2023-06-06 18:49:05,989] Trial 95 finished with value: 0.10612433099242906 and parameters: {'booster': 'dart', 'gamma': 0.10036622107171073, 'max_depth': 17, 'min_child_weight': 3, 'subsample': 0.9353129788262262}. Best is trial 73 with value: 0.08547292199501176.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "\n",
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    booster = trial.suggest_categorical('booster', ['gbtree', 'dart'])\n",
    "    gamma = trial.suggest_float('gamma', 0, 5)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 3)\n",
    "    subsample = trial.suggest_float('subsample', 0.4, 1)\n",
    "\n",
    "    xgb = XGBRegressor(booster=booster, gamma=gamma, max_depth=max_depth, min_child_weight=min_child_weight, subsample=subsample)\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_valid)\n",
    "\n",
    "    error = mean_squared_error(y_valid, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective_fun, n_trials=100, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:49:05.994136Z",
     "start_time": "2023-06-06T16:48:13.553495Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'dart', 'gamma': 1.1430440610880634, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8721463985710389}\n",
      "Root mean squared error = 0.3941\n",
      "R-squared = 0.6607\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "xgb = XGBRegressor(**best_params)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = xgb.predict(X_test)\n",
    "\n",
    "print(best_params)\n",
    "print('Root mean squared error = %.4f' % np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('R-squared = %.4f' % r2_score(y_test, y_pred_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:49:06.413132Z",
     "start_time": "2023-06-06T16:49:05.996756Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([9.4917472e-03, 1.1043926e-02, 6.4646387e-03, ..., 1.4944229e-04,\n       1.0015884e-04, 9.6195610e-05], dtype=float32)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_to_pred)\n",
    "y_pred = np.power(10, y_pred)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:49:06.454893Z",
     "start_time": "2023-06-06T16:49:06.413505Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative values predicted\n",
    "np.count_nonzero(y_pred < 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:49:06.461513Z",
     "start_time": "2023-06-06T16:49:06.433860Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df_zero[TARGET] = y_pred\n",
    "df.update(df_zero)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:49:06.473211Z",
     "start_time": "2023-06-06T16:49:06.442951Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x=TARGET)\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:49:06.649819Z",
     "start_time": "2023-06-06T16:49:06.474807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x=TARGET, log_scale=True)\n",
    "plt.xlabel(f'{TARGET}')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of {TARGET}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:49:07.191990Z",
     "start_time": "2023-06-06T16:49:06.652343Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 18:49:10,232] A new study created in memory with name: no-name-e6b61905-19ef-4b28-aef7-dd584b25a269\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x2b301bb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x2b301bb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x2b301b1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x2b301b1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x2b5794b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x2b5794b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x2b577ee50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x2b577ee50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[I 2023-06-06 18:49:13,184] Trial 6 finished with value: 0.5722910165786743 and parameters: {'n_hidden': 3, 'n_units': 61, 'learning_rate': 0.0861124286573181}. Best is trial 6 with value: 0.5722910165786743.\n",
      "[I 2023-06-06 18:49:13,242] Trial 5 finished with value: 0.14224965870380402 and parameters: {'n_hidden': 2, 'n_units': 108, 'learning_rate': 0.012781010224557948}. Best is trial 5 with value: 0.14224965870380402.\n",
      "[I 2023-06-06 18:49:13,260] Trial 3 finished with value: 0.1511123776435852 and parameters: {'n_hidden': 2, 'n_units': 69, 'learning_rate': 0.0546399947227726}. Best is trial 5 with value: 0.14224965870380402.\n",
      "[I 2023-06-06 18:49:13,292] Trial 0 finished with value: 0.1116970106959343 and parameters: {'n_hidden': 1, 'n_units': 114, 'learning_rate': 0.00534608884042498}. Best is trial 0 with value: 0.1116970106959343.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:13,345] Trial 7 finished with value: 0.16930976510047913 and parameters: {'n_hidden': 2, 'n_units': 87, 'learning_rate': 0.049741053795613575}. Best is trial 0 with value: 0.1116970106959343.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:13,580] Trial 1 finished with value: 0.14819711446762085 and parameters: {'n_hidden': 2, 'n_units': 91, 'learning_rate': 0.0726211248342219}. Best is trial 0 with value: 0.1116970106959343.\n",
      "[I 2023-06-06 18:49:13,597] Trial 4 finished with value: 0.5745859146118164 and parameters: {'n_hidden': 2, 'n_units': 109, 'learning_rate': 0.06437877593032275}. Best is trial 0 with value: 0.1116970106959343.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:13,706] Trial 2 finished with value: 0.18900775909423828 and parameters: {'n_hidden': 3, 'n_units': 112, 'learning_rate': 0.038296573011269104}. Best is trial 0 with value: 0.1116970106959343.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:16,352] Trial 9 finished with value: 0.570334792137146 and parameters: {'n_hidden': 3, 'n_units': 49, 'learning_rate': 0.08274718759445585}. Best is trial 0 with value: 0.1116970106959343.\n",
      "[I 2023-06-06 18:49:16,363] Trial 10 finished with value: 0.11654044687747955 and parameters: {'n_hidden': 2, 'n_units': 44, 'learning_rate': 0.05174396854915265}. Best is trial 0 with value: 0.1116970106959343.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:16,483] Trial 13 finished with value: 0.11717982590198517 and parameters: {'n_hidden': 1, 'n_units': 77, 'learning_rate': 0.04261377169999922}. Best is trial 0 with value: 0.1116970106959343.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:16,548] Trial 8 finished with value: 0.5700016617774963 and parameters: {'n_hidden': 3, 'n_units': 77, 'learning_rate': 0.031215953234737505}. Best is trial 0 with value: 0.1116970106959343.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:16,725] Trial 15 finished with value: 0.11984498798847198 and parameters: {'n_hidden': 2, 'n_units': 53, 'learning_rate': 0.00561404521178156}. Best is trial 0 with value: 0.1116970106959343.\n",
      "[I 2023-06-06 18:49:16,803] Trial 12 finished with value: 0.5697786808013916 and parameters: {'n_hidden': 2, 'n_units': 76, 'learning_rate': 0.0762852954105988}. Best is trial 0 with value: 0.1116970106959343.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:16,955] Trial 11 finished with value: 0.5709702968597412 and parameters: {'n_hidden': 2, 'n_units': 54, 'learning_rate': 0.09743358083194133}. Best is trial 0 with value: 0.1116970106959343.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:17,104] Trial 14 finished with value: 0.09247603267431259 and parameters: {'n_hidden': 2, 'n_units': 101, 'learning_rate': 0.01424765027925242}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:19,242] Trial 18 finished with value: 0.15392319858074188 and parameters: {'n_hidden': 1, 'n_units': 34, 'learning_rate': 0.0037389424825197554}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:19,275] Trial 17 finished with value: 0.13749800622463226 and parameters: {'n_hidden': 1, 'n_units': 126, 'learning_rate': 0.002557227411760375}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:19,438] Trial 20 finished with value: 0.12387596070766449 and parameters: {'n_hidden': 1, 'n_units': 36, 'learning_rate': 0.022690237492447453}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:19,514] Trial 16 finished with value: 0.5682973265647888 and parameters: {'n_hidden': 3, 'n_units': 117, 'learning_rate': 0.07716115560654582}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:19,526] Trial 19 finished with value: 0.126266747713089 and parameters: {'n_hidden': 1, 'n_units': 126, 'learning_rate': 0.002295405080592741}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:19,526] Trial 21 finished with value: 0.13802990317344666 and parameters: {'n_hidden': 1, 'n_units': 35, 'learning_rate': 0.02277900831401771}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:19,990] Trial 22 finished with value: 0.14079086482524872 and parameters: {'n_hidden': 1, 'n_units': 33, 'learning_rate': 0.028053738769454127}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:20,121] Trial 23 finished with value: 0.13085918128490448 and parameters: {'n_hidden': 1, 'n_units': 127, 'learning_rate': 0.019993936020861285}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:22,502] Trial 24 finished with value: 0.11831072717905045 and parameters: {'n_hidden': 1, 'n_units': 125, 'learning_rate': 0.0204687849409097}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:22,527] Trial 25 finished with value: 0.1262473165988922 and parameters: {'n_hidden': 1, 'n_units': 96, 'learning_rate': 0.021278473633136032}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:22,581] Trial 28 finished with value: 0.10258854925632477 and parameters: {'n_hidden': 1, 'n_units': 97, 'learning_rate': 0.01555459973889044}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:22,582] Trial 26 finished with value: 0.12144359201192856 and parameters: {'n_hidden': 1, 'n_units': 97, 'learning_rate': 0.01839517089220011}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:22,828] Trial 27 finished with value: 0.12646153569221497 and parameters: {'n_hidden': 1, 'n_units': 101, 'learning_rate': 0.018756062877686268}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:23,238] Trial 30 finished with value: 0.10351231694221497 and parameters: {'n_hidden': 2, 'n_units': 96, 'learning_rate': 0.01617691577202551}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:23,360] Trial 29 finished with value: 0.13579925894737244 and parameters: {'n_hidden': 1, 'n_units': 99, 'learning_rate': 0.014713319712223907}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:23,554] Trial 31 finished with value: 0.1610444039106369 and parameters: {'n_hidden': 2, 'n_units': 97, 'learning_rate': 0.01479056699675068}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:25,730] Trial 35 finished with value: 0.12615609169006348 and parameters: {'n_hidden': 1, 'n_units': 103, 'learning_rate': 0.008923751567313537}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:25,759] Trial 34 finished with value: 0.10959550738334656 and parameters: {'n_hidden': 1, 'n_units': 102, 'learning_rate': 0.010612404541675034}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:25,851] Trial 33 finished with value: 0.13139015436172485 and parameters: {'n_hidden': 2, 'n_units': 101, 'learning_rate': 0.011786345051461146}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:25,884] Trial 32 finished with value: 0.11849384754896164 and parameters: {'n_hidden': 2, 'n_units': 98, 'learning_rate': 0.012856383105922206}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:25,885] Trial 36 finished with value: 0.14207693934440613 and parameters: {'n_hidden': 1, 'n_units': 88, 'learning_rate': 0.011428408626756283}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:26,421] Trial 37 finished with value: 0.12855704128742218 and parameters: {'n_hidden': 2, 'n_units': 84, 'learning_rate': 0.011285181123920799}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:27,128] Trial 38 finished with value: 0.14273414015769958 and parameters: {'n_hidden': 2, 'n_units': 89, 'learning_rate': 0.00925863983956143}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:27,141] Trial 39 finished with value: 0.11751396209001541 and parameters: {'n_hidden': 2, 'n_units': 87, 'learning_rate': 0.008379882909322216}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:29,055] Trial 41 finished with value: 0.11705450713634491 and parameters: {'n_hidden': 2, 'n_units': 89, 'learning_rate': 0.009874639381314072}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:29,183] Trial 43 finished with value: 0.17472481727600098 and parameters: {'n_hidden': 2, 'n_units': 117, 'learning_rate': 0.0003867216798147787}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:29,313] Trial 44 finished with value: 0.23332726955413818 and parameters: {'n_hidden': 2, 'n_units': 116, 'learning_rate': 0.027297911793751725}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:29,408] Trial 42 finished with value: 3.8574771881103516 and parameters: {'n_hidden': 2, 'n_units': 117, 'learning_rate': 2.29782195061614e-05}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:29,757] Trial 40 finished with value: 0.11549805849790573 and parameters: {'n_hidden': 2, 'n_units': 116, 'learning_rate': 0.010129133148618106}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:29,799] Trial 45 finished with value: 0.15244822204113007 and parameters: {'n_hidden': 2, 'n_units': 116, 'learning_rate': 0.0005596373694064915}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:30,478] Trial 46 finished with value: 0.1454218178987503 and parameters: {'n_hidden': 3, 'n_units': 116, 'learning_rate': 0.027985902767366913}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:30,538] Trial 47 finished with value: 0.13668519258499146 and parameters: {'n_hidden': 3, 'n_units': 114, 'learning_rate': 0.028680948531431744}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:32,437] Trial 48 finished with value: 0.20672070980072021 and parameters: {'n_hidden': 3, 'n_units': 113, 'learning_rate': 0.0016293157092683464}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:32,437] Trial 49 finished with value: 0.18832893669605255 and parameters: {'n_hidden': 3, 'n_units': 109, 'learning_rate': 0.032871977287664465}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:32,570] Trial 50 finished with value: 0.22959759831428528 and parameters: {'n_hidden': 3, 'n_units': 109, 'learning_rate': 0.03441496626666572}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:32,650] Trial 51 finished with value: 0.5819512605667114 and parameters: {'n_hidden': 3, 'n_units': 107, 'learning_rate': 0.0346131695754385}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:33,091] Trial 52 finished with value: 0.14878208935260773 and parameters: {'n_hidden': 3, 'n_units': 108, 'learning_rate': 0.0347946824180143}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:33,420] Trial 53 finished with value: 0.1704348772764206 and parameters: {'n_hidden': 3, 'n_units': 108, 'learning_rate': 0.03257549881392792}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:33,554] Trial 55 finished with value: 0.12320263683795929 and parameters: {'n_hidden': 1, 'n_units': 107, 'learning_rate': 0.0337751334509908}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:33,752] Trial 54 finished with value: 0.13564054667949677 and parameters: {'n_hidden': 3, 'n_units': 108, 'learning_rate': 0.03485881199047545}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:35,546] Trial 56 finished with value: 0.14469373226165771 and parameters: {'n_hidden': 1, 'n_units': 105, 'learning_rate': 0.005714138171616384}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:35,556] Trial 57 finished with value: 0.11010932922363281 and parameters: {'n_hidden': 1, 'n_units': 106, 'learning_rate': 0.005635902111651596}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:35,633] Trial 58 finished with value: 0.10803032666444778 and parameters: {'n_hidden': 1, 'n_units': 105, 'learning_rate': 0.0161413715741947}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:35,651] Trial 59 finished with value: 0.11473499983549118 and parameters: {'n_hidden': 1, 'n_units': 104, 'learning_rate': 0.006755132119254291}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:36,259] Trial 61 finished with value: 0.11770497262477875 and parameters: {'n_hidden': 1, 'n_units': 121, 'learning_rate': 0.005112754913253588}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:36,381] Trial 62 finished with value: 0.1251237839460373 and parameters: {'n_hidden': 2, 'n_units': 93, 'learning_rate': 0.006489431153012941}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:36,769] Trial 63 finished with value: 0.11433053761720657 and parameters: {'n_hidden': 2, 'n_units': 94, 'learning_rate': 0.0075481623200756385}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:37,032] Trial 60 finished with value: 0.161698579788208 and parameters: {'n_hidden': 1, 'n_units': 94, 'learning_rate': 0.01634093417195384}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:38,473] Trial 65 finished with value: 0.12840889394283295 and parameters: {'n_hidden': 1, 'n_units': 94, 'learning_rate': 0.01678758231279019}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:38,477] Trial 66 finished with value: 0.14782683551311493 and parameters: {'n_hidden': 1, 'n_units': 93, 'learning_rate': 0.005557080478335723}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:38,512] Trial 64 finished with value: 0.14380943775177002 and parameters: {'n_hidden': 1, 'n_units': 93, 'learning_rate': 0.005402297130423653}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:38,513] Trial 67 finished with value: 0.13470321893692017 and parameters: {'n_hidden': 1, 'n_units': 95, 'learning_rate': 0.015813366077247922}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:39,530] Trial 69 finished with value: 0.11482766270637512 and parameters: {'n_hidden': 1, 'n_units': 93, 'learning_rate': 0.01372474320644966}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:39,564] Trial 68 finished with value: 0.11391466110944748 and parameters: {'n_hidden': 1, 'n_units': 94, 'learning_rate': 0.015394856837018757}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:39,844] Trial 70 finished with value: 0.11662079393863678 and parameters: {'n_hidden': 1, 'n_units': 71, 'learning_rate': 0.016238799562860052}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:40,229] Trial 71 finished with value: 0.11614888906478882 and parameters: {'n_hidden': 1, 'n_units': 72, 'learning_rate': 0.016574049901190484}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:41,494] Trial 73 finished with value: 0.14565132558345795 and parameters: {'n_hidden': 1, 'n_units': 80, 'learning_rate': 0.014847741006290074}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:41,579] Trial 75 finished with value: 0.12104354053735733 and parameters: {'n_hidden': 1, 'n_units': 83, 'learning_rate': 0.013382769020746269}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:41,629] Trial 74 finished with value: 0.1517995297908783 and parameters: {'n_hidden': 1, 'n_units': 101, 'learning_rate': 0.01343742800112185}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:42,181] Trial 72 finished with value: 0.11731275171041489 and parameters: {'n_hidden': 1, 'n_units': 66, 'learning_rate': 0.01597931880702808}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:42,335] Trial 76 finished with value: 0.15368814766407013 and parameters: {'n_hidden': 1, 'n_units': 82, 'learning_rate': 0.022961887810664623}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:42,368] Trial 77 finished with value: 0.12119150906801224 and parameters: {'n_hidden': 1, 'n_units': 68, 'learning_rate': 0.024641103559905703}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:42,804] Trial 78 finished with value: 0.12265077978372574 and parameters: {'n_hidden': 1, 'n_units': 81, 'learning_rate': 0.023027814210184495}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:43,123] Trial 79 finished with value: 0.1170821338891983 and parameters: {'n_hidden': 1, 'n_units': 81, 'learning_rate': 0.02382057721135141}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:44,387] Trial 80 finished with value: 0.12445830553770065 and parameters: {'n_hidden': 1, 'n_units': 101, 'learning_rate': 0.019555163580846007}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:44,497] Trial 82 finished with value: 0.12957501411437988 and parameters: {'n_hidden': 1, 'n_units': 121, 'learning_rate': 0.021368338689182732}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:44,546] Trial 81 finished with value: 0.1364925354719162 and parameters: {'n_hidden': 1, 'n_units': 101, 'learning_rate': 0.01989732762891096}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:45,069] Trial 85 finished with value: 0.14546096324920654 and parameters: {'n_hidden': 1, 'n_units': 100, 'learning_rate': 0.019699961412398312}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:45,207] Trial 83 finished with value: 0.10027435421943665 and parameters: {'n_hidden': 1, 'n_units': 100, 'learning_rate': 0.02416923426896072}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:45,370] Trial 84 finished with value: 0.1520703285932541 and parameters: {'n_hidden': 1, 'n_units': 101, 'learning_rate': 0.02023127782206318}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:46,344] Trial 86 finished with value: 0.1098366305232048 and parameters: {'n_hidden': 1, 'n_units': 99, 'learning_rate': 0.019268686021062104}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:46,721] Trial 87 finished with value: 0.11352474242448807 and parameters: {'n_hidden': 1, 'n_units': 100, 'learning_rate': 0.01918419883358275}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:47,975] Trial 88 finished with value: 0.1294373720884323 and parameters: {'n_hidden': 2, 'n_units': 111, 'learning_rate': 0.008713398476202639}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:48,003] Trial 89 finished with value: 0.10749787092208862 and parameters: {'n_hidden': 2, 'n_units': 99, 'learning_rate': 0.008807682677641985}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:48,025] Trial 90 finished with value: 0.1120646595954895 and parameters: {'n_hidden': 2, 'n_units': 104, 'learning_rate': 0.0030882521677645693}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:48,309] Trial 92 finished with value: 0.13103578984737396 and parameters: {'n_hidden': 1, 'n_units': 111, 'learning_rate': 0.011316811627789393}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:48,569] Trial 93 finished with value: 0.11422062665224075 and parameters: {'n_hidden': 1, 'n_units': 112, 'learning_rate': 0.01097355970242593}. Best is trial 14 with value: 0.09247603267431259.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "[I 2023-06-06 18:49:48,920] Trial 91 finished with value: 0.13371703028678894 and parameters: {'n_hidden': 2, 'n_units': 90, 'learning_rate': 0.009625786701510212}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:49,253] Trial 94 finished with value: 0.1110798716545105 and parameters: {'n_hidden': 1, 'n_units': 111, 'learning_rate': 0.01089304585718361}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:49,557] Trial 95 finished with value: 0.11075204610824585 and parameters: {'n_hidden': 2, 'n_units': 111, 'learning_rate': 0.011690250497034625}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:49,889] Trial 96 finished with value: 0.10219892114400864 and parameters: {'n_hidden': 1, 'n_units': 104, 'learning_rate': 0.025825046712967654}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:49,986] Trial 97 finished with value: 0.11669429391622543 and parameters: {'n_hidden': 2, 'n_units': 105, 'learning_rate': 0.0031625310241259587}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:50,002] Trial 98 finished with value: 0.10242875665426254 and parameters: {'n_hidden': 2, 'n_units': 98, 'learning_rate': 0.011188361969640254}. Best is trial 14 with value: 0.09247603267431259.\n",
      "[I 2023-06-06 18:49:50,053] Trial 99 finished with value: 0.10168787091970444 and parameters: {'n_hidden': 2, 'n_units': 97, 'learning_rate': 0.011295128390710618}. Best is trial 14 with value: 0.09247603267431259.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_model(trial):\n",
    "\n",
    "    n_hidden = trial.suggest_int('n_hidden', 1, 3)\n",
    "    n_units = trial.suggest_int('n_units', 32, 128)\n",
    "    learn_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_units, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "    for i in range(n_hidden):\n",
    "        model.add(Dense(n_units, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "                  metrics=tensorflow.keras.metrics.MeanSquaredError())\n",
    "    return model\n",
    "\n",
    "\n",
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_valid, y_valid), verbose=False)\n",
    "\n",
    "    error = model.evaluate(X_valid, y_valid, verbose=False)[1]\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective_fun, n_trials=100, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:49:50.063551Z",
     "start_time": "2023-06-06T16:49:07.194577Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 348us/step\n",
      "Root mean squared error = 2.9393\n",
      "R-squared = -17.8740\n"
     ]
    }
   ],
   "source": [
    "model = create_model(study.best_trial)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "print('Root mean squared error = %.4f' % np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print('R-squared = %.4f' % r2_score(y_test, y_pred_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:49:50.153230Z",
     "start_time": "2023-06-06T16:49:50.059266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 375us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.8809721 ],\n       [0.87001026],\n       [0.8895209 ],\n       ...,\n       [0.89220524],\n       [0.8727819 ],\n       [0.87922364]], dtype=float32)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_to_pred)\n",
    "y_pred = np.power(10, y_pred)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:49:50.198906Z",
     "start_time": "2023-06-06T16:49:50.154071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T16:49:50.200434Z",
     "start_time": "2023-06-06T16:49:50.199274Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:19:33.191372Z",
     "start_time": "2023-05-30T13:19:33.188437Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.core.dtypes.common import is_numeric_dtype\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import default_style\n",
    "\n",
    "# This is for reloading custom modules in case they are modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:19:33.194825Z",
     "start_time": "2023-05-30T13:19:33.192067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocal_channel</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotional_intensity</th>\n",
       "      <th>statement</th>\n",
       "      <th>repetition</th>\n",
       "      <th>actor</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speech</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>1st</td>\n",
       "      <td>actor_1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speech</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>2nd</td>\n",
       "      <td>actor_1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>speech</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>Dogs are sitting by the door</td>\n",
       "      <td>1st</td>\n",
       "      <td>actor_1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speech</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>Dogs are sitting by the door</td>\n",
       "      <td>2nd</td>\n",
       "      <td>actor_1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speech</td>\n",
       "      <td>calm</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>1st</td>\n",
       "      <td>actor_1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>song</td>\n",
       "      <td>fearful</td>\n",
       "      <td>normal</td>\n",
       "      <td>Dogs are sitting by the door</td>\n",
       "      <td>2nd</td>\n",
       "      <td>actor_24</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>song</td>\n",
       "      <td>fearful</td>\n",
       "      <td>strong</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>1st</td>\n",
       "      <td>actor_24</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>song</td>\n",
       "      <td>fearful</td>\n",
       "      <td>strong</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>2nd</td>\n",
       "      <td>actor_24</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>song</td>\n",
       "      <td>fearful</td>\n",
       "      <td>strong</td>\n",
       "      <td>Dogs are sitting by the door</td>\n",
       "      <td>1st</td>\n",
       "      <td>actor_24</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>song</td>\n",
       "      <td>fearful</td>\n",
       "      <td>strong</td>\n",
       "      <td>Dogs are sitting by the door</td>\n",
       "      <td>2nd</td>\n",
       "      <td>actor_24</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2429 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     vocal_channel  emotion emotional_intensity                     statement  \\\n",
       "0           speech  neutral              normal  Kids are talking by the door   \n",
       "1           speech  neutral              normal  Kids are talking by the door   \n",
       "2           speech  neutral              normal  Dogs are sitting by the door   \n",
       "3           speech  neutral              normal  Dogs are sitting by the door   \n",
       "4           speech     calm              normal  Kids are talking by the door   \n",
       "...            ...      ...                 ...                           ...   \n",
       "2424          song  fearful              normal  Dogs are sitting by the door   \n",
       "2425          song  fearful              strong  Kids are talking by the door   \n",
       "2426          song  fearful              strong  Kids are talking by the door   \n",
       "2427          song  fearful              strong  Dogs are sitting by the door   \n",
       "2428          song  fearful              strong  Dogs are sitting by the door   \n",
       "\n",
       "     repetition     actor sex  \n",
       "0           1st   actor_1   M  \n",
       "1           2nd   actor_1   M  \n",
       "2           1st   actor_1   M  \n",
       "3           2nd   actor_1   M  \n",
       "4           1st   actor_1   M  \n",
       "...         ...       ...  ..  \n",
       "2424        2nd  actor_24   F  \n",
       "2425        1st  actor_24   F  \n",
       "2426        2nd  actor_24   F  \n",
       "2427        1st  actor_24   F  \n",
       "2428        2nd  actor_24   F  \n",
       "\n",
       "[2429 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FOLDER = 'dataset'\n",
    "DATASET = os.path.join(DATA_FOLDER, 'outliers_removed.csv')\n",
    "\n",
    "df = pd.read_csv(DATASET)\n",
    "numerical_attr_list = [col for col in df.columns if is_numeric_dtype(df[col])]\n",
    "\n",
    "possible_targets = [col for col in df.columns if not is_numeric_dtype(df[col])]\n",
    "df[possible_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:19:33.304718Z",
     "start_time": "2023-05-30T13:19:33.303682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kids are talking by the door', 'Dogs are sitting by the door']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_COLUMN = 'statement'\n",
    "values = df[TARGET_COLUMN].unique().tolist()\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:19:43.895220Z",
     "start_time": "2023-05-30T13:19:43.866505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zc_sum\n",
      "zc_mean\n",
      "zc_std\n",
      "zc_kur\n",
      "zc_skew\n",
      "zc_mean_w1\n",
      "zc_sum_w2\n",
      "zc_skew_w2\n",
      "zc_sum_w3\n",
      "zc_kur_w3\n",
      "zc_sum_w4\n",
      "zc_mean_w4\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    excluded_prefixes = ['zc']\n",
    "    columns_to_remove = []\n",
    "    for column in df[numerical_attr_list].columns:\n",
    "        if column.startswith(tuple(excluded_prefixes)) or column == TARGET_COLUMN:\n",
    "            columns_to_remove.append(column)\n",
    "\n",
    "    columns_to_remove;\n",
    "    df = df.drop(columns=columns_to_remove, axis=1)\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "    \n",
    "for col in columns_to_remove:\n",
    "    try:\n",
    "        print(col)\n",
    "        numerical_attr_list.remove(col)\n",
    "    except ValueError as e:\n",
    "        print(e, f\"raised by column '{col}'\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:19:43.895376Z",
     "start_time": "2023-05-30T13:19:43.875940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target variable: (array([0, 1]), array([1216, 1213]))\n",
      "X has shape (2429, 231)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df[numerical_attr_list])\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "y = label_enc.fit_transform(df[TARGET_COLUMN])\n",
    "\n",
    "# print(f\"numerical_attr_list is {numerical_attr_list}\")\n",
    "print(f\"target variable: {np.unique(y, return_counts=True)}\")\n",
    "print(f\"X has shape {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1449, 231)\n",
      "Val: (363, 231)\n",
      "Test: (617, 231)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide in train, test, validation\n",
    "df[\"actor_number\"] = df.actor.apply(lambda x: int(x.split(\"_\")[1]))\n",
    "test_mask = df.actor_number >= 19\n",
    "df.drop(columns=\"actor_number\", inplace=True)\n",
    "\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[~test_mask], y[~test_mask], test_size=0.2)\n",
    "print(f\"Train: {X_train.shape}\\nVal: {X_val.shape}\\nTest: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the decision boundaries in the embedding\n",
    "def boundaries_on_embedding(reducer, predictor, \n",
    "                            embedding=None, n_pts=30, \n",
    "                            **kwargs):\n",
    "    \n",
    "    global X, y, X_train, X_test,X_val, y_train, y_test, y_val\n",
    "    cmap, title = kwargs.get(\"cmap\", \"viridis\"), kwargs.get(\"title\", \"Decision boundaries on embedding\")\n",
    "    if embedding is None:\n",
    "        embedding =  reducer.fit_transform(X)\n",
    "        \n",
    "    # Generate a grid in embedding\n",
    "    xx = np.linspace(np.min(embedding[:,0]), np.max(embedding[:,0]), n_pts)\n",
    "    yy = np.linspace(np.min(embedding[:,1]), np.max(embedding[:,1]), n_pts)\n",
    "\n",
    "    XX, YY = np.meshgrid(xx, yy)\n",
    "    points_in_embedding = np.array(np.meshgrid(xx, yy)).T\n",
    "    old_shape = points_in_embedding.shape[:-1]\n",
    "    \n",
    "    # Maps them back in the big space\n",
    "    points_in_embedding = points_in_embedding.reshape(-1,2)\n",
    "    points_in_gigaspace = reducer.inverse_transform(points_in_embedding)\n",
    "\n",
    "    # Gets results\n",
    "    results = predictor.predict(points_in_gigaspace).reshape(old_shape)\n",
    "    plt.contourf(XX, YY, results.T, cmap=cmap, alpha=0.6, levels=len(np.unique(y))-1)\n",
    "    plt.scatter(*embedding[test_mask].T, c=y_test, marker=\"o\", edgecolor=\"k\", s=5,cmap=cmap, label=\"test\")\n",
    "    plt.scatter(*embedding[~test_mask].T, c=y[~test_mask], marker=\"+\",  s=5, cmap=cmap, label=\"train+val\")\n",
    "    plt.legend()\n",
    "    plt.axis(\"off\");\n",
    "    plt.title(title);   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now prepare an  so it saves time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "2023-07-08 15:11:48.161375: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-08 15:11:48.262866: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-08 15:11:48.263796: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-08 15:11:49.849308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "reducer = UMAP(n_neighbors=20)\n",
    "embedding = reducer.fit_transform(X)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# reducer = PCA(n_components=2)\n",
    "# embedding = reducer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_cfm(y_true, y_pred, title=\"Confusion matrix\"):\n",
    "    fig, ax = plt.subplots(figsize=default_style.SHORT_HALFSIZE_FIGURE)\n",
    "    cf = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cf, annot=True, cmap='Greens', fmt=\".4g\", cbar=False, ax=ax)\n",
    "    ax.set_xlabel('True')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ticks = np.unique(y_true)\n",
    "    ax.set_xticks(ticks + 0.5, labels=label_enc.inverse_transform(ticks))\n",
    "    ax.set_yticks(ticks + 0.5, labels=label_enc.inverse_transform(ticks))\n",
    "    \n",
    "    plt.savefig(f\"images/{title.replace(' ', '_')}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:12:14,706] A new study created in memory with name: no-name-dcbdd95a-477b-4d85-afd6-e15699ec429c\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[W 2023-07-08 15:12:14,721] Trial 3 failed with parameters: {'penalty': 'l1', 'C': 9.712429211543306, 'solver': 'newton-cg'} because of the following error: ValueError(\"Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:14,724] Trial 3 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2023-07-08 15:12:15,118] Trial 0 finished with value: 0.9366391184573003 and parameters: {'penalty': 'none', 'C': 4.816235483930136, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.9366391184573003.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2023-07-08 15:12:15,470] Trial 5 finished with value: 0.9559228650137741 and parameters: {'penalty': 'l2', 'C': 3.9608839258530666, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.9559228650137741.\n",
      "[W 2023-07-08 15:12:15,477] Trial 6 failed with parameters: {'penalty': 'l1', 'C': 0.28163360275440497, 'solver': 'newton-cg'} because of the following error: ValueError(\"Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:15,486] Trial 6 failed with value None.\n",
      "[W 2023-07-08 15:12:15,501] Trial 7 failed with parameters: {'penalty': 'l1', 'C': 2.6572263801973626, 'solver': 'lbfgs'} because of the following error: ValueError(\"Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:15,506] Trial 7 failed with value None.\n",
      "[W 2023-07-08 15:12:15,515] Trial 8 failed with parameters: {'penalty': 'elasticnet', 'C': 7.039653188313176, 'solver': 'newton-cg'} because of the following error: ValueError(\"Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:15,526] Trial 8 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:12:16,317] Trial 2 finished with value: 0.9614325068870524 and parameters: {'penalty': 'none', 'C': 1.1241217317693213, 'solver': 'sag'}. Best is trial 2 with value: 0.9614325068870524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:16,326] Trial 10 failed with parameters: {'penalty': 'elasticnet', 'C': 0.23267393100585917, 'solver': 'lbfgs'} because of the following error: ValueError(\"Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:16,328] Trial 10 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:12:16,673] Trial 4 finished with value: 0.953168044077135 and parameters: {'penalty': 'none', 'C': 4.879498618696519, 'solver': 'saga'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2023-07-08 15:12:16,768] Trial 11 finished with value: 0.9366391184573003 and parameters: {'penalty': 'none', 'C': 4.605333084022572, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "[W 2023-07-08 15:12:16,782] Trial 13 failed with parameters: {'penalty': 'l1', 'C': 2.530375211324355, 'solver': 'newton-cg'} because of the following error: ValueError(\"Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:16,785] Trial 13 failed with value None.\n",
      "[W 2023-07-08 15:12:16,798] Trial 14 failed with parameters: {'penalty': 'elasticnet', 'C': 2.626142812917501, 'solver': 'lbfgs'} because of the following error: ValueError(\"Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:16,801] Trial 14 failed with value None.\n",
      "[W 2023-07-08 15:12:16,814] Trial 15 failed with parameters: {'penalty': 'l1', 'C': 5.46868651659126, 'solver': 'lbfgs'} because of the following error: ValueError(\"Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:16,823] Trial 15 failed with value None.\n",
      "[I 2023-07-08 15:12:16,945] Trial 9 finished with value: 0.9393939393939394 and parameters: {'penalty': 'none', 'C': 1.0723050348789647, 'solver': 'newton-cg'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:12:17,201] Trial 12 finished with value: 0.9476584022038568 and parameters: {'penalty': 'l2', 'C': 0.9021134810737809, 'solver': 'newton-cg'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "[I 2023-07-08 15:12:17,586] Trial 16 finished with value: 0.9504132231404959 and parameters: {'penalty': 'l2', 'C': 1.8800661330974064, 'solver': 'newton-cg'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "[W 2023-07-08 15:12:17,600] Trial 19 failed with parameters: {'penalty': 'l1', 'C': 8.80383003657923, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:17,609] Trial 19 failed with value None.\n",
      "[W 2023-07-08 15:12:17,629] Trial 20 failed with parameters: {'penalty': 'elasticnet', 'C': 8.936330958859246, 'solver': 'saga'} because of the following error: TypeError(\"unsupported operand type(s) for -: 'int' and 'NoneType'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:17,642] Trial 20 failed with value None.\n",
      "[W 2023-07-08 15:12:17,656] Trial 21 failed with parameters: {'penalty': 'elasticnet', 'C': 5.48618766169249, 'solver': 'saga'} because of the following error: TypeError(\"unsupported operand type(s) for -: 'int' and 'NoneType'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[W 2023-07-08 15:12:17,675] Trial 21 failed with value None.\n",
      "[I 2023-07-08 15:12:17,699] Trial 1 finished with value: 0.9614325068870524 and parameters: {'penalty': 'l1', 'C': 2.1110824383892326, 'solver': 'saga'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "[W 2023-07-08 15:12:17,712] Trial 23 failed with parameters: {'penalty': 'elasticnet', 'C': 2.6439738034006406, 'solver': 'saga'} because of the following error: TypeError(\"unsupported operand type(s) for -: 'int' and 'NoneType'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "[W 2023-07-08 15:12:17,714] Trial 23 failed with value None.\n",
      "[I 2023-07-08 15:12:17,862] Trial 18 finished with value: 0.9614325068870524 and parameters: {'penalty': 'l2', 'C': 7.487040446428264, 'solver': 'liblinear'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "[I 2023-07-08 15:12:18,774] Trial 24 finished with value: 0.9614325068870524 and parameters: {'penalty': 'l2', 'C': 9.135177956193221, 'solver': 'newton-cg'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "[W 2023-07-08 15:12:18,856] Trial 26 failed with parameters: {'penalty': 'l1', 'C': 0.04519797832632966, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:18,876] Trial 26 failed with value None.\n",
      "[W 2023-07-08 15:12:18,915] Trial 27 failed with parameters: {'penalty': 'l1', 'C': 0.2187654166218116, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:18,920] Trial 27 failed with value None.\n",
      "[W 2023-07-08 15:12:18,949] Trial 28 failed with parameters: {'penalty': 'l1', 'C': 2.5181474640966863, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:18,957] Trial 28 failed with value None.\n",
      "[W 2023-07-08 15:12:18,989] Trial 29 failed with parameters: {'penalty': 'l1', 'C': 2.1722196263042943, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:18,996] Trial 29 failed with value None.\n",
      "[W 2023-07-08 15:12:19,040] Trial 30 failed with parameters: {'penalty': 'l1', 'C': 0.023506852143516443, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:19,041] Trial 30 failed with value None.\n",
      "[W 2023-07-08 15:12:19,065] Trial 31 failed with parameters: {'penalty': 'l1', 'C': 0.19789703160123562, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:19,067] Trial 31 failed with value None.\n",
      "[W 2023-07-08 15:12:19,089] Trial 32 failed with parameters: {'penalty': 'l1', 'C': 0.07973422870593794, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:19,092] Trial 32 failed with value None.\n",
      "[W 2023-07-08 15:12:19,114] Trial 33 failed with parameters: {'penalty': 'l1', 'C': 0.005936441040957696, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:19,116] Trial 33 failed with value None.\n",
      "[W 2023-07-08 15:12:19,139] Trial 34 failed with parameters: {'penalty': 'l1', 'C': 2.279279673453604, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:19,141] Trial 34 failed with value None.\n",
      "[W 2023-07-08 15:12:19,162] Trial 35 failed with parameters: {'penalty': 'l1', 'C': 2.3033344434945513, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:19,164] Trial 35 failed with value None.\n",
      "[W 2023-07-08 15:12:19,184] Trial 36 failed with parameters: {'penalty': 'l1', 'C': 0.1165875790216182, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:19,186] Trial 36 failed with value None.\n",
      "[W 2023-07-08 15:12:19,207] Trial 37 failed with parameters: {'penalty': 'l1', 'C': 0.1301860854827792, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:19,209] Trial 37 failed with value None.\n",
      "[W 2023-07-08 15:12:19,230] Trial 38 failed with parameters: {'penalty': 'l1', 'C': 0.17438005471752493, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[W 2023-07-08 15:12:19,255] Trial 38 failed with value None.\n",
      "[I 2023-07-08 15:12:19,250] Trial 17 finished with value: 0.9586776859504132 and parameters: {'penalty': 'none', 'C': 7.638598289667361, 'solver': 'sag'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "[W 2023-07-08 15:12:19,368] Trial 40 failed with parameters: {'penalty': 'l1', 'C': 0.014803838438678829, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:19,372] Trial 40 failed with value None.\n",
      "[W 2023-07-08 15:12:19,370] Trial 39 failed with parameters: {'penalty': 'l1', 'C': 0.11917554688568233, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:19,376] Trial 39 failed with value None.\n",
      "[W 2023-07-08 15:12:19,424] Trial 42 failed with parameters: {'penalty': 'l1', 'C': 2.6367746143860873, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:19,434] Trial 42 failed with value None.\n",
      "[W 2023-07-08 15:12:19,477] Trial 43 failed with parameters: {'penalty': 'l1', 'C': 0.1533709268172584, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:19,479] Trial 43 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:12:19,703] Trial 22 finished with value: 0.9559228650137741 and parameters: {'penalty': 'l2', 'C': 5.20168212171048, 'solver': 'sag'}. Best is trial 2 with value: 0.9614325068870524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:12:20,345] Trial 44 finished with value: 0.7823691460055097 and parameters: {'penalty': 'l1', 'C': 0.028430233736842503, 'solver': 'saga'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[W 2023-07-08 15:12:20,439] Trial 46 failed with parameters: {'penalty': 'elasticnet', 'C': 2.8179915703313627, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[I 2023-07-08 15:12:20,445] Trial 25 finished with value: 0.9586776859504132 and parameters: {'penalty': 'l1', 'C': 9.864063694298398, 'solver': 'saga'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "[W 2023-07-08 15:12:20,452] Trial 46 failed with value None.\n",
      "[W 2023-07-08 15:12:20,522] Trial 47 failed with parameters: {'penalty': 'elasticnet', 'C': 2.5533839091529345, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,549] Trial 47 failed with value None.\n",
      "[W 2023-07-08 15:12:20,534] Trial 48 failed with parameters: {'penalty': 'elasticnet', 'C': 2.797903175859739, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,571] Trial 48 failed with value None.\n",
      "[W 2023-07-08 15:12:20,601] Trial 49 failed with parameters: {'penalty': 'elasticnet', 'C': 2.6126892495619494, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,625] Trial 49 failed with value None.\n",
      "[W 2023-07-08 15:12:20,644] Trial 50 failed with parameters: {'penalty': 'elasticnet', 'C': 2.640725939244344, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,658] Trial 50 failed with value None.\n",
      "[W 2023-07-08 15:12:20,692] Trial 52 failed with parameters: {'penalty': 'elasticnet', 'C': 2.545068281908682, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,695] Trial 52 failed with value None.\n",
      "[W 2023-07-08 15:12:20,699] Trial 51 failed with parameters: {'penalty': 'elasticnet', 'C': 2.19428453319013, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:20,705] Trial 51 failed with value None.\n",
      "[W 2023-07-08 15:12:20,748] Trial 54 failed with parameters: {'penalty': 'elasticnet', 'C': 2.8462917202018683, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,755] Trial 54 failed with value None.\n",
      "[W 2023-07-08 15:12:20,750] Trial 53 failed with parameters: {'penalty': 'elasticnet', 'C': 2.463962232877881, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,773] Trial 53 failed with value None.\n",
      "[W 2023-07-08 15:12:20,812] Trial 55 failed with parameters: {'penalty': 'elasticnet', 'C': 2.2787901388633083, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,827] Trial 55 failed with value None.\n",
      "[W 2023-07-08 15:12:20,832] Trial 56 failed with parameters: {'penalty': 'elasticnet', 'C': 2.5030052333580457, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,836] Trial 56 failed with value None.\n",
      "[W 2023-07-08 15:12:20,895] Trial 57 failed with parameters: {'penalty': 'elasticnet', 'C': 2.5301179389617854, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,902] Trial 57 failed with value None.\n",
      "[W 2023-07-08 15:12:20,915] Trial 58 failed with parameters: {'penalty': 'elasticnet', 'C': 2.5704265227795178, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,928] Trial 58 failed with value None.\n",
      "[W 2023-07-08 15:12:20,957] Trial 59 failed with parameters: {'penalty': 'elasticnet', 'C': 2.350898653542951, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:20,960] Trial 59 failed with value None.\n",
      "[W 2023-07-08 15:12:20,970] Trial 60 failed with parameters: {'penalty': 'elasticnet', 'C': 2.6197760857554524, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:20,991] Trial 60 failed with value None.\n",
      "[W 2023-07-08 15:12:21,000] Trial 61 failed with parameters: {'penalty': 'elasticnet', 'C': 2.65548137114784, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,024] Trial 61 failed with value None.\n",
      "[W 2023-07-08 15:12:21,048] Trial 62 failed with parameters: {'penalty': 'elasticnet', 'C': 2.519917141692889, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,054] Trial 62 failed with value None.\n",
      "[W 2023-07-08 15:12:21,082] Trial 63 failed with parameters: {'penalty': 'elasticnet', 'C': 2.399102397873635, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,096] Trial 63 failed with value None.\n",
      "[W 2023-07-08 15:12:21,091] Trial 64 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4196257800240915, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,118] Trial 64 failed with value None.\n",
      "[W 2023-07-08 15:12:21,155] Trial 65 failed with parameters: {'penalty': 'elasticnet', 'C': 2.223876674910712, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,156] Trial 65 failed with value None.\n",
      "[W 2023-07-08 15:12:21,195] Trial 66 failed with parameters: {'penalty': 'elasticnet', 'C': 2.427198240371633, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,197] Trial 66 failed with value None.\n",
      "[W 2023-07-08 15:12:21,217] Trial 67 failed with parameters: {'penalty': 'elasticnet', 'C': 2.291680650430549, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,220] Trial 67 failed with value None.\n",
      "[W 2023-07-08 15:12:21,263] Trial 69 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3284436440072183, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:21,271] Trial 69 failed with value None.\n",
      "[W 2023-07-08 15:12:21,270] Trial 68 failed with parameters: {'penalty': 'elasticnet', 'C': 2.6267265136202846, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,288] Trial 68 failed with value None.\n",
      "[W 2023-07-08 15:12:21,311] Trial 70 failed with parameters: {'penalty': 'elasticnet', 'C': 2.592149405936623, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,321] Trial 70 failed with value None.\n",
      "[W 2023-07-08 15:12:21,340] Trial 71 failed with parameters: {'penalty': 'l1', 'C': 2.4686399648484807, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:21,343] Trial 71 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:12:21,375] Trial 41 finished with value: 0.9393939393939394 and parameters: {'penalty': 'l1', 'C': 0.14968345537850425, 'solver': 'saga'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "[W 2023-07-08 15:12:21,388] Trial 72 failed with parameters: {'penalty': 'elasticnet', 'C': 2.5167202224112177, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,457] Trial 72 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[W 2023-07-08 15:12:21,476] Trial 73 failed with parameters: {'penalty': 'elasticnet', 'C': 2.635819104169833, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,536] Trial 73 failed with value None.\n",
      "[W 2023-07-08 15:12:21,557] Trial 74 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4808210979110514, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,587] Trial 74 failed with value None.\n",
      "[W 2023-07-08 15:12:21,574] Trial 75 failed with parameters: {'penalty': 'elasticnet', 'C': 2.411809739999238, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:12:21,576] Trial 45 finished with value: 0.9559228650137741 and parameters: {'penalty': 'l1', 'C': 0.28200853087243194, 'solver': 'saga'}. Best is trial 2 with value: 0.9614325068870524.\n",
      "[W 2023-07-08 15:12:21,617] Trial 77 failed with parameters: {'penalty': 'elasticnet', 'C': 2.5131216644081023, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,617] Trial 75 failed with value None.\n",
      "[W 2023-07-08 15:12:21,624] Trial 76 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4735839830605792, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,649] Trial 78 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4333421468549616, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,650] Trial 77 failed with value None.\n",
      "[W 2023-07-08 15:12:21,655] Trial 76 failed with value None.\n",
      "[W 2023-07-08 15:12:21,682] Trial 79 failed with parameters: {'penalty': 'elasticnet', 'C': 2.375630708305276, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,731] Trial 79 failed with value None.\n",
      "[W 2023-07-08 15:12:21,710] Trial 80 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4107306435756497, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,758] Trial 80 failed with value None.\n",
      "[W 2023-07-08 15:12:21,683] Trial 78 failed with value None.\n",
      "[W 2023-07-08 15:12:21,730] Trial 81 failed with parameters: {'penalty': 'elasticnet', 'C': 2.273656215748948, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,789] Trial 81 failed with value None.\n",
      "[W 2023-07-08 15:12:21,773] Trial 82 failed with parameters: {'penalty': 'elasticnet', 'C': 2.450838666173325, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,809] Trial 82 failed with value None.\n",
      "[W 2023-07-08 15:12:21,828] Trial 83 failed with parameters: {'penalty': 'elasticnet', 'C': 2.392838658663448, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:21,851] Trial 84 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4498259128916944, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,879] Trial 84 failed with value None.\n",
      "[W 2023-07-08 15:12:21,874] Trial 85 failed with parameters: {'penalty': 'elasticnet', 'C': 2.41875678161716, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,898] Trial 85 failed with value None.\n",
      "[W 2023-07-08 15:12:21,851] Trial 83 failed with value None.\n",
      "[W 2023-07-08 15:12:21,876] Trial 86 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3401082542208593, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,900] Trial 87 failed with parameters: {'penalty': 'elasticnet', 'C': 2.2469798857494316, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,928] Trial 87 failed with value None.\n",
      "[W 2023-07-08 15:12:21,925] Trial 86 failed with value None.\n",
      "[W 2023-07-08 15:12:21,937] Trial 89 failed with parameters: {'penalty': 'elasticnet', 'C': 2.172446145475886, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,972] Trial 90 failed with parameters: {'penalty': 'elasticnet', 'C': 1.7346128021888778, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,007] Trial 90 failed with value None.\n",
      "[W 2023-07-08 15:12:22,003] Trial 89 failed with value None.\n",
      "[W 2023-07-08 15:12:22,006] Trial 91 failed with parameters: {'penalty': 'elasticnet', 'C': 2.407324109201969, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:21,996] Trial 88 failed with parameters: {'penalty': 'elasticnet', 'C': 2.271836673667835, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:22,051] Trial 91 failed with value None.\n",
      "[W 2023-07-08 15:12:22,060] Trial 92 failed with parameters: {'penalty': 'elasticnet', 'C': 2.322876346424796, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,071] Trial 93 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3480586448636678, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,107] Trial 93 failed with value None.\n",
      "[W 2023-07-08 15:12:22,101] Trial 92 failed with value None.\n",
      "[W 2023-07-08 15:12:22,104] Trial 94 failed with parameters: {'penalty': 'elasticnet', 'C': 2.210620792130338, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,073] Trial 88 failed with value None.\n",
      "[W 2023-07-08 15:12:22,163] Trial 94 failed with value None.\n",
      "[W 2023-07-08 15:12:22,187] Trial 95 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3645958580727466, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,197] Trial 95 failed with value None.\n",
      "[W 2023-07-08 15:12:22,203] Trial 96 failed with parameters: {'penalty': 'elasticnet', 'C': 2.5301414121897645, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,232] Trial 96 failed with value None.\n",
      "[W 2023-07-08 15:12:22,255] Trial 97 failed with parameters: {'penalty': 'elasticnet', 'C': 2.5175288431577902, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,269] Trial 97 failed with value None.\n",
      "[W 2023-07-08 15:12:22,290] Trial 98 failed with parameters: {'penalty': 'elasticnet', 'C': 2.303026407441508, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,310] Trial 98 failed with value None.\n",
      "[W 2023-07-08 15:12:22,329] Trial 99 failed with parameters: {'penalty': 'elasticnet', 'C': 2.2402374673240546, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:22,357] Trial 100 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4628529954267884, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,393] Trial 100 failed with value None.\n",
      "[W 2023-07-08 15:12:22,366] Trial 101 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3405627928477, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,364] Trial 99 failed with value None.\n",
      "[W 2023-07-08 15:12:22,395] Trial 102 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3117795702728245, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,420] Trial 102 failed with value None.\n",
      "[W 2023-07-08 15:12:22,410] Trial 101 failed with value None.\n",
      "[W 2023-07-08 15:12:22,506] Trial 104 failed with parameters: {'penalty': 'elasticnet', 'C': 2.337482441782073, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,532] Trial 104 failed with value None.\n",
      "[W 2023-07-08 15:12:22,518] Trial 105 failed with parameters: {'penalty': 'elasticnet', 'C': 2.0660524657095305, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,557] Trial 105 failed with value None.\n",
      "[W 2023-07-08 15:12:22,509] Trial 103 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3522408192434816, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,582] Trial 103 failed with value None.\n",
      "[W 2023-07-08 15:12:22,579] Trial 107 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4057938589098273, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,622] Trial 107 failed with value None.\n",
      "[W 2023-07-08 15:12:22,628] Trial 108 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4988811764631707, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:22,647] Trial 108 failed with value None.\n",
      "[W 2023-07-08 15:12:22,531] Trial 106 failed with parameters: {'penalty': 'elasticnet', 'C': 2.5032915515899714, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,660] Trial 106 failed with value None.\n",
      "[W 2023-07-08 15:12:22,664] Trial 109 failed with parameters: {'penalty': 'elasticnet', 'C': 2.417137695297879, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,693] Trial 109 failed with value None.\n",
      "[W 2023-07-08 15:12:22,743] Trial 112 failed with parameters: {'penalty': 'elasticnet', 'C': 2.324634660034167, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,753] Trial 112 failed with value None.\n",
      "[W 2023-07-08 15:12:22,761] Trial 111 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4565979540890295, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,763] Trial 110 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3856126061038405, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,777] Trial 113 failed with parameters: {'penalty': 'elasticnet', 'C': 2.508545732466793, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,781] Trial 111 failed with value None.\n",
      "[W 2023-07-08 15:12:22,802] Trial 110 failed with value None.\n",
      "[W 2023-07-08 15:12:22,806] Trial 114 failed with parameters: {'penalty': 'elasticnet', 'C': 2.299953177049111, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,850] Trial 114 failed with value None.\n",
      "[W 2023-07-08 15:12:22,847] Trial 116 failed with parameters: {'penalty': 'elasticnet', 'C': 2.18899350996849, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:22,856] Trial 116 failed with value None.\n",
      "[W 2023-07-08 15:12:22,808] Trial 113 failed with value None.\n",
      "[W 2023-07-08 15:12:22,848] Trial 115 failed with parameters: {'penalty': 'elasticnet', 'C': 2.0391064749449423, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,888] Trial 115 failed with value None.\n",
      "[W 2023-07-08 15:12:22,894] Trial 117 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4723060510216435, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,937] Trial 117 failed with value None.\n",
      "[W 2023-07-08 15:12:22,954] Trial 118 failed with parameters: {'penalty': 'elasticnet', 'C': 2.30396154384609, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,970] Trial 119 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3655434190772993, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,987] Trial 118 failed with value None.\n",
      "[W 2023-07-08 15:12:22,990] Trial 120 failed with parameters: {'penalty': 'elasticnet', 'C': 2.694624315044945, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:22,994] Trial 119 failed with value None.\n",
      "[W 2023-07-08 15:12:23,004] Trial 121 failed with parameters: {'penalty': 'elasticnet', 'C': 2.5402258524409023, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,033] Trial 122 failed with parameters: {'penalty': 'elasticnet', 'C': 2.431756414747344, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,043] Trial 122 failed with value None.\n",
      "[W 2023-07-08 15:12:23,040] Trial 121 failed with value None.\n",
      "[W 2023-07-08 15:12:23,036] Trial 120 failed with value None.\n",
      "[W 2023-07-08 15:12:23,126] Trial 126 failed with parameters: {'penalty': 'elasticnet', 'C': 2.410254431509343, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:23,128] Trial 123 failed with parameters: {'penalty': 'l1', 'C': 2.3676661479639574, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "[W 2023-07-08 15:12:23,142] Trial 124 failed with parameters: {'penalty': 'elasticnet', 'C': 2.396358983530078, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,151] Trial 125 failed with parameters: {'penalty': 'elasticnet', 'C': 2.761040245336564, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,151] Trial 126 failed with value None.\n",
      "[W 2023-07-08 15:12:23,154] Trial 123 failed with value None.\n",
      "[W 2023-07-08 15:12:23,157] Trial 124 failed with value None.\n",
      "[W 2023-07-08 15:12:23,159] Trial 125 failed with value None.\n",
      "[W 2023-07-08 15:12:23,183] Trial 128 failed with parameters: {'penalty': 'elasticnet', 'C': 2.289605560318084, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,241] Trial 127 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3450624513274736, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,243] Trial 128 failed with value None.\n",
      "[W 2023-07-08 15:12:23,266] Trial 129 failed with parameters: {'penalty': 'elasticnet', 'C': 2.337705472098632, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,266] Trial 127 failed with value None.\n",
      "[W 2023-07-08 15:12:23,267] Trial 130 failed with parameters: {'penalty': 'elasticnet', 'C': 2.2800788843579474, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,285] Trial 129 failed with value None.\n",
      "[W 2023-07-08 15:12:23,287] Trial 131 failed with parameters: {'penalty': 'elasticnet', 'C': 2.0567036991677043, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:23,302] Trial 130 failed with value None.\n",
      "[W 2023-07-08 15:12:23,312] Trial 131 failed with value None.\n",
      "[W 2023-07-08 15:12:23,315] Trial 132 failed with parameters: {'penalty': 'elasticnet', 'C': 2.454122308315063, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,387] Trial 134 failed with parameters: {'penalty': 'elasticnet', 'C': 2.2759318295348057, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,388] Trial 133 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3956064992938177, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,391] Trial 135 failed with parameters: {'penalty': 'elasticnet', 'C': 1.8858964673276974, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,392] Trial 132 failed with value None.\n",
      "[W 2023-07-08 15:12:23,393] Trial 134 failed with value None.\n",
      "[W 2023-07-08 15:12:23,394] Trial 133 failed with value None.\n",
      "[W 2023-07-08 15:12:23,395] Trial 135 failed with value None.\n",
      "[W 2023-07-08 15:12:23,439] Trial 137 failed with parameters: {'penalty': 'elasticnet', 'C': 2.424869094964295, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,444] Trial 136 failed with parameters: {'penalty': 'elasticnet', 'C': 2.3525369285146724, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,493] Trial 136 failed with value None.\n",
      "[W 2023-07-08 15:12:23,489] Trial 139 failed with parameters: {'penalty': 'elasticnet', 'C': 2.517588839627507, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,506] Trial 139 failed with value None.\n",
      "[W 2023-07-08 15:12:23,469] Trial 138 failed with parameters: {'penalty': 'elasticnet', 'C': 2.37398517203739, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:23,517] Trial 138 failed with value None.\n",
      "[W 2023-07-08 15:12:23,489] Trial 137 failed with value None.\n",
      "[W 2023-07-08 15:12:23,609] Trial 141 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4322678115854797, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,611] Trial 140 failed with parameters: {'penalty': 'elasticnet', 'C': 2.282755520702842, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,622] Trial 140 failed with value None.\n",
      "[W 2023-07-08 15:12:23,616] Trial 143 failed with parameters: {'penalty': 'elasticnet', 'C': 2.589307518536594, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,618] Trial 141 failed with value None.\n",
      "[W 2023-07-08 15:12:23,613] Trial 142 failed with parameters: {'penalty': 'elasticnet', 'C': 3.113434573058541, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,637] Trial 142 failed with value None.\n",
      "[W 2023-07-08 15:12:23,628] Trial 143 failed with value None.\n",
      "[W 2023-07-08 15:12:23,676] Trial 144 failed with parameters: {'penalty': 'elasticnet', 'C': 2.337886066609898, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,695] Trial 145 failed with parameters: {'penalty': 'elasticnet', 'C': 2.697446765176796, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,703] Trial 146 failed with parameters: {'penalty': 'elasticnet', 'C': 2.2116639628665773, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,705] Trial 144 failed with value None.\n",
      "[W 2023-07-08 15:12:23,723] Trial 145 failed with value None.\n",
      "[W 2023-07-08 15:12:23,729] Trial 147 failed with parameters: {'penalty': 'elasticnet', 'C': 2.4063831149602546, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:12:23,729] Trial 146 failed with value None.\n",
      "[W 2023-07-08 15:12:23,757] Trial 147 failed with value None.\n",
      "[W 2023-07-08 15:12:23,771] Trial 149 failed with parameters: {'penalty': 'elasticnet', 'C': 2.32409485311983, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,773] Trial 148 failed with parameters: {'penalty': 'elasticnet', 'C': 2.520912161304809, 'solver': 'sag'} because of the following error: ValueError(\"Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/441388116.py\", line 14, in objective_fun\n",
      "    logr.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "[W 2023-07-08 15:12:23,775] Trial 149 failed with value None.\n",
      "[W 2023-07-08 15:12:23,778] Trial 148 failed with value None.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "\n",
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    penalty = trial.suggest_categorical('penalty', ['none', 'elasticnet', 'l1', 'l2'])\n",
    "    C = trial.suggest_float('C', 0.001,10)\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg',  'sag', 'saga'])\n",
    "\n",
    "    logr = LogisticRegression(solver=solver, penalty=penalty, C=C)\n",
    "\n",
    "    logr.fit(X_train, y_train)\n",
    "    y_pred = logr.predict(X_val)\n",
    "\n",
    "    error = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective_fun, n_trials = 150, n_jobs = -1, catch=(ValueError, TypeError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'none', 'C': 1.1241217317693213, 'solver': 'sag'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       309\n",
      "           1       0.96      0.90      0.93       308\n",
      "\n",
      "    accuracy                           0.93       617\n",
      "   macro avg       0.93      0.93      0.93       617\n",
      "weighted avg       0.93      0.93      0.93       617\n",
      "\n",
      "Accuracy 0.9303079416531604\n",
      "F1-score [0.93228346 0.92821369]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "logr = LogisticRegression(**best_params)\n",
    "\n",
    "# Trains on test AND validation\n",
    "logr.fit(np.concatenate((X_train, X_val)), np.concatenate([y_train, y_val]))\n",
    "\n",
    "y_pred_test = logr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(best_params)\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred_test))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred_test, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose liblinear solver beacause for small datasets is a good choice. \n",
    "The key difference between these l1(ridege) and l2(lasso) is that Lasso shrinks the less \n",
    "important featureâ€™s coefficient to zero thus, removing some feature altogether. \n",
    "So, this works well for feature selection in case we have a huge number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAADoCAYAAACnz4zGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADD/klEQVR4nOydd3gUVdvGf7M12U0nld5D6L0JKIi944uiIkYUVCxgARVs2BVUEGxg4UVELNixovQmSO+9BUivu9k+3x+Tmcy2ZNMA3y/3dXGRnXLmTDnPec5T7kcQRVGkHvWoRz3qcdagOdcdqEc96lGP/2+oF7z1qEc96nGWUS9461GPetTjLKNe8NajHvWox1lGveCtRz3qUY+zjHrBW4961KMeZxn1grce9ahHPc4y6gVvPepRj3qcZdQL3nrUox71OMuoF7xnEampqaSmpmK322u13SeeeILU1FS++eabSo+dNWsWs2bNCtiv6l43NTWVtLQ0Bg4cyNSpU3E4HFVu61yiKs/vXEN+3qmpqXTs2JFLL72UTz75xOuYr776imHDhtGlSxe6d+/OTTfdxOrVq5X9oihy8cUXk5qaSo8ePSgtLT3bt/H/Hrpz3YF61By33HILAwcOpHPnzpUeO3v2bAAefPBBZdubb75Zo+v/5z//oUePHnz00UcsXLiQZs2akZ6eXqM2A8HlcqHT1f4nW5Xnd77gtddew2azMWvWLF599VWSkpK48soreeWVV5g3bx4JCQncf//9REVFsXXrVnbu3MmAAQMA+Pvvvzl58iRarZaSkhJ+//13rrvuunN8R/+/UK/xnifYsGEDI0aMoHv37gwYMIAnnniC3NxcAKxWK4899hjdu3fn2muv5dlnnyU1NZUnnngCgM8//5xHHnmEjRs3AjB37lwuuugiOnbsSJ8+fbjtttsAvLTa1NRUhgwZAsAjjzzCI488ouxbsWIFN998M927d6d79+48//zzFfa9Y8eODBs2jOHDhwNw9OhRZd/SpUsZNmwY3bp148ILL+T1119XNOJjx45xyy230KVLF+69917uuusuL81zyJAhpKam8vrrrzNkyBCefvppQNLorr76arp06cLQoUOZO3eucr1g956fn8+9995Lr1696NixI0OGDOHjjz8O+PxOnDjBQw89RL9+/ejZsyfp6ens3r1beU+pqakMGzaMRx99lF69enHZZZexbdu2gM/G7Xbz7rvvcskll9ClSxeuuOIKPvvsM2W/fI9vvvkmF198Mb169VImx4pwxRVXMGLECK699loA/vnnHzIyMpg/fz46nY7//ve/jB07lhEjRvDqq68yduxY5dxvv/0WgHHjxgH8KzT9/zXUC97zACdOnGDs2LHs27eP8ePHM3jwYL799lsefvhhAN5//31+/PFH0tLSuPXWW/nzzz+DtlVUVMT06dMxm8288MIL3HfffSQkJADemu2bb77JU0895Xf+tm3buO+++zhw4AD33HMPkyZNIi4ursL+l5aWcubMGdavXw9At27dANiyZQsPPvggoihy77330qdPHz766CNFsDz++ONs3ryZq6++mu7du7Nu3bqA7a9evZr77ruPyy67jJ9//pmnnnqK2NhY7r//flq3bs306dP54osvKrz377//nmXLlnHZZZfxwgsvcP311yMIgt+13G439957L7/99hvXX389Y8eOZdOmTdx1113k5+crx+3atYvk5GQuueQSjh49yvTp0wP2/cMPP2TmzJk0aNCAp556Cp1Ox/PPP893333nddymTZu48847cTgczJ49mxMnTlT4zAsKCjh27BgbNmwAoFGjRmzfvh2Px0PLli1p1aqV1/EajTTULRYLv/32G7Gxsdxzzz20adOGDRs2kJGRUeH16lG7qDc1nAdYuXIlNpuNm266iTvuuAOPx8Mvv/zChg0bKCwsVOxzjz76KN27dyc/P58ZM2YEbMtkMpGSksLp06dZvXo1bdq04Z577gHgqquuUjTbq666KuD5v//+O263mzvuuEM5rzK89tprvPbaawDcdtttyrJ16dKleDwedu/erWiMAMuXL2fs2LFs2bKFsLAwpk6dik6nY926daxdu9av/WeeeYaePXsCMGHCBEBaLv/9999ebd54441B710WRJs3b0an05GWlsYVV1zhd60jR45w8OBBmjVrxuOPP66cs2zZMjZt2kRUVBQArVu3ZuLEiRw9epTFixdz7NixgM/mjz/+AGDSpEl0796dqKgoHnroIUWwy3jiiSfo3LkzP/30E1u2bOHEiRM0adIk6DMfNGiQ8veAAQO49dZbWbZsWdDjZfz2229YrVaGDBlCZmYmAwYM4MCBA3z77bc88MADlZ5fj9pBveD9FyGQhuYLnU7H999/z9KlSzlw4ABffPEFM2fOZPHixbRv375O+jVq1Cjatm3LtGnT+Pzzz7nkkkvo16+fsn/48OFceeWVym+9Xq/8LQhCpfeVnJzst+2+++6jd+/eyu+IiIgK733gwIF8//33rF27lgMHDvDss8+yaNEiZdnti8r6JK8CZJuz2+2u8PjK2pXbk5+Ny+WqsJ05c+ZgMplo2LAhjRo1AqBLly5oNBoOHz7M4cOHadmypXK8x+NBo9Eo9/vTTz/x008/Kfu/++477r///pC+sXrUHPWC9xxg9uzZytKvcePGDBo0iPDwcJYsWUKbNm04ePAgxcXF9OnTh+joaAYMGMCuXbt48803ueqqq7xshL4oKSnh+eefp3v37rRr146tW7dy6tQpMjMzad++PTExMRQUFPDZZ5/Rpk0bL+EFcMkll/DJJ5/w3//+l7CwMGJiYsjOzq5QG2rZsiXDhw9Ho9EwefJkXnzxRX744QeGDh3Kxx9/zF9//UWbNm0wGo1s374dg8FAr1696NatG1u2bGHq1Kk0btxYWTZXhEsvvZRffvmFJUuWkJSUhMfjYePGjaSmptKyZcug9378+HF27NhB8+bN6dixIz///DOnTp3ya79Fixa0adOGAwcO8PrrrxMbG8vq1auJi4ujZ8+e7N+/v9I++vZ3x44dTJs2jWHDhvHpp58CcNlll1WpHV/07dsXo9Hota1hw4bccccdfPLJJ9xxxx2MGjWK6Ohotm7dSrNmzbjyyivZuHEjjRo1YvLkycp57777Lrt27WLjxo1+30M96gb1gvccYM6cOcrfvXv3Zvjw4XzwwQe89dZbvPXWW5hMJq6//nomTZoEwL333supU6dYtmwZFouF/v378/333xMdHe3Xtk6nIzc3l1mzZlFcXExsbCy33347AwcOBCSHyrvvvsvzzz/PgAED/AZa165dmT17Nu+//z7vv/8+giB4LYkrwg033MCCBQvYvXs333zzDcOHD2fWrFm8//77zJgxA61WS6tWrbjjjjsAyUTx+OOPs2TJEkUQb9q0KeB9ybjyyiuxWCzMnz+fV199lbCwMFJTU+natWuF975mzRpWrVrFwoULcbvdNGvWjPHjx/u1r9Vqee+993j99df55ptvcLlc9OzZk4kTJxIbGxvSc1DjrrvuwuVy8c033/Diiy+SkpLC008/HfIzrSqeeOIJWrZsyaJFi5g1axZarZYWLVpwxRVX8N133yGKIkOHDmXo0KHKOcePH2fXrl18++239YL3LEGor0Bx/iM/P5/vv/+etm3bUlBQwFtvvcWJEyf45JNPvJb0/zZs27aNQ4cOkZKSwuHDh3nttdcIDw/nl19+qdShV496/JtRr/H+CyCKIt999x2HDx9Gp9PRvHlz3njjjX+10AUpTO7dd9/lzJkzRERE0Lt3bx566KF6oVuP/3nUa7z1qEc96nGWUR/HW4961KMeZxn1grce9ahHPc4y6gVvPepRj3qcZdQL3nrUox71OMuoF7z1qEc96nGWEXI4mWvp+ZnHvWftIQDW56Wf246cZ+gbNw+AtP6tKjwu2PMbO3MkCQmRnM6SuHs/f9GOs8iEy1G1lNJQ+1HX2LP2UK1+IxsPrWXJ5q+Rg4LcbjdarRaA5klmVk7zz0w7377VUN6N3GcIvd994+ad8/ddFVTnHiHw89MNrZxZDqoQTna+Cd7qPqz/T5A/DPAfXJUJgbEzR+ISy8+3WOyYzUY+nlD10O+K+nG2UNuC9+CZPXy6UspAdDic2O0OIiPNCteBIIBBr2XaXd1o6yknhj/fvtWKhG91J4p/k+Ct6WTo+/z+pwXv+aY5nO9QfxyhTlgZuSd55P1YoiO8GcreGz8XoyGsypqvuh9yX84malPwuj1uCix5zPr1FURRRBRFReB26tyIIUPSeHumRN2p0cCi29uz23p3rVy7rhDoG6mJMDrfBW9tyxD5+XV65peQjv9XZa6dLwJXLUDOF1T0TJR9a+dVeqyMG9ssZfmr/i6A6yaXkpioZ/4kbZWFr3zdvnHzvCaAUHEuB7PT7eDP7T/zz5F1ON1ONBpBEbiZmTmEhRmJiYli2LDuxDWIAECn0+ByeViZeS3xkcHbVn9Ptf1ty21X1u76vHSv93Kux5jcj9p+51VdKVfl+QF0CrEf/wrBe76YFc6HJXMg7Fl7iL5x80L+OCqC+h57dksB8LL1RpnHUmSZE+jUkFGddygLhXP13Bes/ICj2YcRBIHomDAQoaCgFFEUiY6OQquVJqnnp0pUizqdBrfbQ8O4RsRFxAds0/d7quw9ekQPJbYizMZItBpthf31+1ZDmHTPtbAFb+VKPRHUxnuvyqTiuwIIVQCHiloRvG50uDQmRGqfy/PwluNgjmdr4Q0AGKNq/RIhoWv0t4jE07JbUwBsZ/HaAiIa0YFOtAV8wspHWQWNNhAC2fsKfrqbiKsGKL/Dw/W+p50V+GrtZ1MAW+0WjmUfQRAkLbcgXyoOWVpqJzzcSFiYAaNRx+dfjOXVV35m65YTGAQTPdv254LUwWgE/5VDoGdd0XsstOazYPX7ZBdmExMRw20X3ENCVFLA/gZruy4ESG0hkHLlu0Kq7juvjsCF8ucn/1+bz6/GNl6LNoEM8wWIWiPUouB12p0A2D0RtdZmdWDUlACgN54bgSNBBNGDyXGa5NLN6EVr0COr64WG4MJMGFpOxhNlHovV6mDWuA8x6sNCar+2UZ2VR01svJ8sn8Wx7COIiLhdHgQBnE4XeXmFNGgQg8GgR6/X0LFjY3buzMDl8tC+cRcuSB1Mo7im1eq7/B41JgPtHrsJgJTEB8nOLqZLl1bE6ZtyywV3BWy7upEstYWq2Hir8r1WNUKmumaFmjy/MTNuDqlvNdJ43ejIMF+A3hxPZFjtCCaHtcwDbACLJxZjxYfXOcwaHQaT4Rz3AlwekWKriaO6WFoVLUGDp8LjqzOogmkV4vKNWHt1plXzR/F4pOs++O7dvJT+JgnRiVW+Tm3hbGm9p/JPKmFjpaWliCJERppJSIhDr5eGkMslsnNnBoJGQBBg98lt7MnYzo19RtKxSbcqTxbyMfu2SrXXsrKKyM4uBmDbtkMUlkxi8VTRz84u6LXs3XiUdn1agqfib6SusD4vPaSVSXU10VDh60wOFRVp19VpLxBqpPHaNVEcjb6CBjFxGHQ1y8WwldiVv0vcgW1i5wIR2hzCIs61+Jdgd3nIK8ijeeHPGD3FXvtqww4eTDjs3XiUpg8Nw2w2ohO8254zfkG1rlUd1MTGXhON99NV73HozAHFmSYPGZ1OiyiKJMc0Irckk7h4ExpBwGQ2suTnh0gf9QmnDnp4/4aIavW57CIIF/Xye+6nMt/m1+mxfoJ39IzykkHHFv1J03iT8vtsO86Cva/qaLm+bVQFtaX5hvL8zorGK9l0a25ekIXu+SRwz0eURYgi+iQc1taAqijq4OuXNdzxUo2arzbOtVPzxt6jeOe31ym05FNYWEJMTBR6nR6toCUpriE39hrJu3+8RphRz5EjOURGhrF48T8cPZJNCzNAhH+/NRqEIX0AEFdsBKdL2a6gAo21YdJDvDd+LlrCA+63WOxc88IKrmobw+3dylclZ9O2W9H3tD4vnaLSQiz2DBKjkgM6C2sr+aaqNlpfx556e23hnEY1VFXLjdDmVHr8wi//y3+uvwWDoXrmgZqefzZRVxqM/OGp29YZRMDNzt0vEddAio1q1fxR4OyEQ53LKBKT0UyDyAQKivNxudwIQMcmXRnW5zblmGYNWnHgyF6efvYq5n6wiicf/4ZGMUZefeRCmiaayxvT6xAu7OXVvnBhL8Sl67yEMSBtc7kQl66j4OexCIN6+MVV++LFMYd5am5L5bjdu49zUatBZLjGVnqfNQmTDCVaQo7YyMg/wSd/TcItutBoBNxukS5Ne3JDn1v9+lGb791XAIfaZ/Xv2sI5EbzVFbjykt9WYle2+Z7/+VfzufaqG6stOGt6/tnA4S3HESzS/deVBhOs3Y7tp3j99hOMNYys8G3Xq+1ziEFpQzmZe5SkpAbotXr6th3ktb9Pm0EcOLOX2NgIbh7Ri5kz/uSb5waTHOutkfoK3ZAhSM41k8mAtcwP0iP2S7o/Kwn/hU9psZUIlBS5aNpoktep24quQWVx8ENNn3Wo4Yyrc0ayas+vrNj9u7LN7ZYSULYd30SnhOOM7Jlc7X6EiqpEeNTV+DrrglcWukXOODweD7oKeqDWcNV2Vl8BLAvfd+a8BcATT09Ao9Hw1OMv8MXiBRw5egin00Fqm/bcc9eD6PV6vli8gOWr/kSvk5yCTz3+Al99u9Dr/Oeffo2I86gKjcPqwGl3ouHshwO5HAILn/JfDvoOkJqGLZ1vAldG6+R2PHD5k2QVnaZhbGOiwmO89t/Sbh37j0fxyIQvCA/Xc9+17UhuYA7JwSUu3+i/bYX3NmFgD05n9QAkAQzQtm8LZf+tL7r5eIKOVkmptEpuw6lTWcq+9BeNJCa6Aia91MaKItRJ97u/P2fXya2AFJZYXGwBQKczIIoim04U89JDF1S7H1VBXYSIVQU1cq7ZNNEci76CBjGxlTrX1FruD39u5o1Zr2C327j5xpHcnT5OSbmE4AK3snZL3PFcM/xiPp/3PRHmCGa//ybt0zoy5MJLEUWRWe+/QeOGTbj04iu5+/7b+O+crzAajdjsNjSCBoPB4HW+3JfzwblmK7Hj8oicLnSx7/cT2IucZ70POoNIytBtXHHZdACWvXENAzo3DHp8VU0hIQmBMhtoVkEprUd+Rmlp+XPI+HIUibGBbZ61zdUgQz1RpPZtye6MYjrdWU6QIy5d532CbMPV6xAGSoJU/GuDv4D2sQHrL3pH2dWggZnMnHfwxe7nF7A+Lx2P6OFo1iEMOgOPvh+P2Sx9v2rBW9mzdro8vP/zAbYfyadvu3juvKQVGk3l/pxg79zmLGX6T8/QqFEM4SYdvy99VNmX2noKVquDuy9rxTO3dan0GnWB2jLbnRXnWijwFYylpVZee+t5Bg9uS/OW8Xzw3nz69rqATh27Av5mhcoQyPwgY/3GNezdv5vvfvwaAIfDjkajITzcREpKY96Y9QrduvSgV/e+xDdIqOmt1inCIoyUFNkwakroGv0tG4quPif9uOTSjgp5zu7ng0c01DRoPRiEIX3IyiqiUdJDFJZ84GXzbHTTfJx/eNtA69KTH0h4dWwWE/hgX6eZ3aEI5az8UhrdNB+Agh9GY/ZJUqnMPCH+tcH7UoKGtk1aA2A2u5XtezN20CwujUJrPhazm56D2wZtc8Z3e3nnx33YHU5+33waQYDRl7ausB8VPevc4mxcLjfPv3Qtlwx5DZ2QTmHJB5jNRpxOF4IgMPaK4P2pa9S2qawy1KngDRStUFpaisPhZPDF7ejevSkfvLeCgsKCKmm5gaA+J0KbC0QgiiJPPvYsjRo28Tt++kuz2Lt/Fzt2beOxyQ8wccIUOqR1rvJ1zyYMJgN6hx43hGRTq0ssfEpLV4N/zGOdCFwfp1NiYhQucR4Wiz3oKXWZZh7q8jwl8UEOzLsZs8mIcFG58FQ03DJHWxKQkPCtEqcbCG/cP4hH31kJwB/Trilva9U/fsfqDCKjXi8XuB3TnsXpdFFa6iTcEE6po5TPoozMSIzlok5JAc0ha3ZnYS21kZ9fREJ8LOv35gQVvJU9aynVuRiDTs8lQ17z26/X6xjaJZ7kuMCrlbOJs5XhVyeCt6LwsNjYOAb0H8QTkxYD0LRxQwb2aAlUT+D6wmQKp8RiJdmcw8A+PVj83SLuv+cRtFotJSXFFBUXERMTS2mplQ5pnemQ1pnjJ45y6MhBOqR1JjzchNVqUUwN5yNadmvKkdU5Z9025XIIvHe/HCfqYgUjMJuNCBslzVd0ukPuT01tixaLnbTUJ5TfBz4fSYLZcFYELlTQb49Hibk1mQxEXDnA/5gy7VetycpcGFAeXib+tYFim5MbX1zFoZOFNGyYiEYjMOKllXxiddI7LdFrQmL1gYBdKioq5Yuv72H7tpO89MIS3p8zkiuvKlcy/MwhQI82Ddh6KB8QMBj0dG0ZG7Bt+Xl/deAiVu1disBHXNj+MhrGNuZ0QQa/b/uOMwUZWGylnDmT7XXuRYNeR7QbeeSCFEbf2i1g++cCVYl+qC5q1cYbarSCy+Vi5eq/8DiyGTKgP4kptRe/+9Gni/jtr5WEGQ288PhEFn33A1t37gJBj0ar5c6RY2ncqCmvvjEVm82GIEBKSmPG3/cYZnMEn381n+WrlmI0hPH806/ROM59Xth4ARwuD7kF+TQr/IUwTyFQN5qdb1iRut2xM0cqf5tMBi/CnFC4eqsjcK0aHeYhvRRO4KNHsmndcqKyXzYvnG2zQjDIpgPf51MViEvX4XJ7mPHtHmb9uJ8flzzIwYNZPDz+C9LSkolwO/n66Yu8BO/cO99h3maRSLOJX9eOBqBrp+fIy7MiiiLtOzRk757TxMWZ2LL9Oa9r+cLmcDNt8W62HMxjQIdEHrouFZ223FyiftYWewmzfn2J5i3jcLk8nDpZzH1DJzHzlxdxuV2IoojHI5KZWb6qLSz5gLHDlnJR6tVcEP/peeVI9UVVvqtQbby1Jng9NsnJUZ3wsLpGTRI0zhfnGgQWvDJqS+gEEjBy25tK7mD0tNuV7VURvNWJVrCUOmk4YgFFljlYLHaiI+4hISHSb0m+fepQ5e/zJY746Oki2oz6XPmtJpVXIyVxPFarjcKSD7y2e/5Yy10z1vPn1jMAJCZG0qFjI9asPkinTg3xFJbw3bODFcF75KvlDHnkF/r0bUVubgkZx0uw2qw4nE6Ki0uIiopEq9Wg1WowGLTsOyhlw7iXb0TjchEqAk30R7MPMW/5Oyz59SGsVifDh73Hhe0vY8Xu3xS+YhAUjTcpKZ6b+o+iU9PuwL+LvxfOg8w1kMhsHFYHNrFy51RN7bjVhXKtksCxv/8LqKlzoCIBI9u9esUGd6YFCjULpe3KILOhyfbcYHbQc2JWCAJLqdNL6IJk71WbEwAev3MOer2RmGgjQwe9ztKV5fG3h8+U8OfWM7zx5k0kJEYyauRH5K7Yh9stsnP7ST54sA94PIq2uvdQLm6PyLQ3/8OunacYe/d8jLowbHYbdrsDj8eDVqshPj6CJyZf4dXXSH1o2afBJvfEqGRMxnDuv3chbreHiPAI7E6Jvy8hMZKc7BKKikqIioogIsKETqOneULFjrrzDbVtfqi24N2z9hCiOR76SWQ22ipkDp8rDTIswlhh8oUvfKMk/g0IhdfVF6EIxrT+rUCj8dPMKjMv1NSWGx5uIDnhAQ4dfcNru8lk4JcJA9htvZX1ebXLklZpn1XZZ36hYHodEUP7AR97nZKdXUzmV3+SGGvyimL45KlLsdo9XNgxQbENh4frWff29QBs+uco0dFS9sPse3uyenc2TeLN9G/vrehE5BdhDtMxfNgH5OVJjHp2lw29Xk9ycgKtWiewbMVEsrKKaJj0ECDxPSRe0Z8zXy8jKabiZ1hROJ7JaOb2gfexet9fCAhcM/ASMvKOA3Dppe1Z+NnfuFxutFppcf2fviOJDPfmdz2XXMtVgVrBqYnwrZapQZ75trjGkHppE6IiE9AKocnws21mCIbKzA/nSz/VqMjUADUr2hfyR19G2iKjKnZdqLoAzrI4aHT9J4AkbJdNGohGr6Pb5Fuq1IdQUKnA1WhAo8Haq7OigZs2bsditWMuY+eLuEbKaNu9K4POHb2z/DK+vB1zmJ6Ya8uFshxSJZtS1Hjv0Yt5+YudeESR9KGtWLLpFIVWJw6Hi8Fdkvl4Ql/2rjusHP/d4UtYu28ZB7J3KKaErp2eIyenhJOnpdhrX7IdlziPR0fMpl9aAmmNo2gfJByuqnHQNqeNuX+9QW5RrldppDB9OI9f96JX3D6cH6nhVUGw51EnpgbfpUZ1SMlL3PFEaHMUwXcutV+pQ97a7/kocCvDWa3Q4XIpcaN7Nxymb1zlkQw1IbROjAxTtGw5EaC2EdLEoAppMyOZDuTUXTVcoiR4mzX3n9Ab3fSp3zZZ2B48PM1v392Xt+bWwc1xe0T+2nqGT/44xNoNT7JyxX4mPfY1hksl+/r0Me8QZYomOQaGdr6GfX9sV9rYuuM5vxRiNQb0e5Xs7GJ+2nQarVbgovYJzB7Xy08wVhVh+jDuHvwwezJ2cCr/BCeyjxIX2YDreo0I2HZdVJw4nxGy4K2K80adxhsIaiGnjoQIFbUpFH3ND7XdPlCtewwEl0fEaXd6cTXIOKsxvWVL63a9mgNVKz1UrXprqw94EYKrUZFtuTLUdnqyySSZRQCsVgeJifHMfvcWbvrPrErOxCtKA+DA/FuwlDqVZIqUshjXD95bwYH9mZiN5REGj829X6HnNOqMXtEDAAZj+TCXJ7HoiHvo0KEZp08VcOjYq8r+1NZT2HIon+6ta54rH24w0b1FH7q36FP5wQRmM6sLAXw+mDVCFryhClzfv0MRwFVBXWjLdaXd1jbHsFt0Yfe42Fd4wzlJGVbgY+OsimOvuhOEYLHRrlpnBkZdLG3VER7fvPglE97bVCFVw7a5w+ky5ivlt/OPe7CUOom59mPFOSeHyvVOjef2nkl89t/VHM8I3ffQsvmjHFbZx9WrhpRIAweKS72O33fwJda9tyTk9usCtVXyxxfqCf9ca9a1Yhwza/LRleVxq4VYVRxZocJXWz5fTQL/yxzDwVJY6zLrZ8zrdzN+tsQYN/OBd7nzNenTlclhQkW1tVyPB/GvDVjKwiZPf3Mn5svKSyL17vmC1+FX9m7MlyuO8ciEL0hOTuDhG9oxcnBzL3NDs6RICn4YrfyWhW4g7Fl7iNt6JPHaDzv89k0f483bYLU6vJI4AiE5OYHdxws5dSrLTzj3qAVttzZQW+aHYKa4c2naqLHglWqSxQQUgMFYxGoDSlsl3jbZD+d/zu0jbsRYRVrH7Nw8nn5pGu+/+UqN+lVTgetL0vNvQ12yPsk2VaujEGhQpXNrxazg8WA2SKYNdR06gGUrJnmFjBl1Wj6beAH7ThbR+a5FPP5eNo+/t8qvSTUvg6XUexWT8eWoACa+pcr+6WPewag38uC7dyu/o0zRitnB7rShCzIMhnaI5689uQDk+ITo6fU6qEJsb12ipuaHikykdaVZh4Ia1evpGv0teqO+0ppkslCM0ObUeoiWLOBsJXZsJXY+WvAFDkcAp4fb7bdNjYQGcdUSui9Mm8nmbTuU66v79G9CVeyu4l8blH/B1tJp/VspH3JNCLbVMJkMuMR53P9WA75+WWDhFA3zJ1XNxlvR4LKUOpV/VUFWVhHREfeQnV2MTkiXtE2PB41GIK1ptNexGV/eTsEPowOS4fhCZlpTC42X0t9U/jbqpXFlMhkwmQw889nDXucb9WFoxbCAz2je0sfRagXS0prQrJlPtWLVO5Wfh9Xhpl/Sp4ye4WL0DBdhESEFQ9Ua1uelV3kClyMPQvE9rM9LZ8/aQyGNg9qou3bW+HhDITGvLuR25syVBOe9j0xGq9EQ3yCOuLhYMjJOk1dQyBcfv8Ozr7zJ8ZMZOF0ukhLimfzIAzSIi+X0mUxG3fcwf5Rx8va79HruufM2Vq79m4KCQkaPvJmrL7vY79pulwdHqXfWns1uY/S9I3jnzY+JjZWWbQu//C8Wq4Ux6eP4aP777Ny9HbfLhclk4oF7HqVxI38in7OFKpdOr0IRxboyP1wxXgrQXzhFE7T8jRrqe8wtcTB4mkQ4oxaA6mV+hYLRWK5oiKu30HDgTK/dGV+O8vstx+2aw/RB2zWH671MD4GQEJ3oVefO7rR52ZbnT/IvgAmw+GWBGyd7C8vs7HxOnJCUlCjzWL/0Zl/Tx46Xy+kuq2ri+TegMtNGbUYPnfUnFxZhBMFNdNNtJAFHd/XD7a6dag9jxzzJj78vZeYLzxFhNjPtvffZd+AQ77/5CmaTNDgn3HcXsTGSFjJ/0WI+/HQRj4+/L2B7Br2ej2dN4+jxk9z14GNcPvQidNpy7UHWcEs90V6TSJgxjP59BrFs1VKGXXsToijy5/LfefpxyQ74n+tGcNeoewFYueYv5n7yDlOfepVzjboK6akN88OscR96MW6pY16rUmp+fV66F99EdSDz6AIIA7zJXTK+vN2PEzgxNtyPrjIYZBsyUKlGDJTdt7dZQM4aA8mZpn5uMlISH8RmK18Zqu3CwSaddn1aev0+1wx5dYFA5oe6CNc851NW8w7ryNzVoZbtvw2IwIbb5WFQn95oPeUEPkt+/Ys/VqzC4XDgcDqJjozEVmLHbnUgit6RCBf16YetxE5yXAIajZbTJzJJiG/AnE8X8veWrQBkZuexffcBwsKkwXbfmPGkpXZg6ODLePv9Nxh27U3s2LWVqMgomjeTPtwt2//hp1++pdRWiujxUFwSnA6wNlGVUidnQwBX5SM2m438NF3k5merXrJcZxCxi4XcN10K9QoP1ysE6ns3HMFUZrddNnGQognv3XAEs9lA2pNSosa+6V/htkrfRnuVfTcrq8jrWvs3HmM/KO1URM7uC0up08v5Vpn2K2PhU1pufVESrpKQ1RFlHovV6ijTUm/xOl7eFwzCkD6weSf4mFz0F79HwU9OL6FcHTPSv0FY+64C/ydqrgVCXZgfnB4jGmO80uauPTtYvOR3pr00i5joWDZsXMtnX8yjxB2Pxe0CBK/rO7TJlLglJ5eg0VLkjCbcHc+ttz7ErVJdPt6a/RpDB19Gpw5dva7fLrUDoiiy/8Be/lz+G0MHS8u0rOxMPvhoFm+++i4pyQ05cuwQTz7jbZurbahDp6paa6ouHA9V5ZXw5Zed+7C/40cURfItuXh0ViZ/MJn4+AjOZM8G8GMze2X0DLSiZPraXuKtKc8ZP7ZsO+gcImlI1019bLiytN7ziocbn5QmADn9VoYscGU0umk+26cO9Xt+lZGfA2QXWMktcXjdv1xbTQ1bicDHE3Repd3jEyK9IhUAxPXbwGrj0PwRpPxnvt/11BAG9sC8dB0FP4z2jrTweBRTU13WZztfUFf9rJFzrdoQtRQe76L8C4swejngagKZTzcQLJZiwsNMREZE4XQ6+fWPn2p0rcowdPBl/PjLt2zcvIELB0j2YavVgk6nJTY2DlEUWfLL93V2/b5x8/ziVavq9JI/vFAdD1WBuh81ccAZdEZ++GcRb//yMpM/mOy1z2Kx+yUnGFWufvWyPBToDCKWfIH5k7RVsnGqn5+k2VYs+ADajFrE4GkrsTvK+yhrtpXBV+gCCH27YLM5iY8O57dp19KvSzO6tm/MZ09f7meXlqE2fdQG5O+vpu/8345zp/GK/p7W2mARu+Ga4Tz9wkSMhjDi4rxDjrp37c2ylX9y3/h0IiOj6NKpO7l5dUeEM3jQJYy+7xb69xlIRIRUEr15s5YM7D+Y+x++i6jIKPr2rpvifpUlCFQn6eF8Mz+AFEJ1Kv8EW45sZMrTV3H/fZ9UePzsh2ajJZz73i238wazEbscgldEgK/m/fEEHS+nv8nkeY94nffcba/w3GdPKv1bnyf5FOTn1/nZpQSCOVzvlUQho8haRLDwOZ2h3GG25xUp6aJdn5beBOkq3PDSKhY9OYCGDUy4RIGsAgdfrznO5T0b4lx+vxKjfeS7VTzx3gYW/75TOffA/BEh2Z1DQXXInP6XEDJJztwJXyh/y4NaNMejveiekIpdVhW2Evu/MiyrLuEWXRQVZ4dU7DKUzKyakOpU1nZVUVlKulrA+Hrtj+cc4eNls3hzxs2cPJHLY49KkSnx8RFs3/WyYg54Kf1NEqITAW9C91Cdc4EEbzBHnTrywBe+5/g63gIlUnw8sdz2q75/tXlh7/QvEZ1uRKebtAtTK6zVdu3Al/l59X6vbQVL7vYrU6Qm1QklBK4qqKu6fNW9Rm2gzvh41YPOponmWFUbqMdZQWUhYjX5IGsz+iHUfgQKkZLRuEEzUhu255Ey5eDK/ldxY/+bEQSBX6cHFoLTx7zDY3Pvr3a/a8IRocbPE7xXPHvWHsLq8DcnVHT/MmQui93PL2DPin2kOV1+iR7KdX2EbtAyRXWAqk74NZnoz1YNtaoiZI13x/Pl5MnyA6hKefeqol7j9UdVNF41AtnS6qJMUHU0kdrqi0f0cDL3GBpBQ6O4piGxa4miyIEze8gpzqJVUipJ0SlVvm6RtdBPgMsZZGqobcnF1iLFPLF+ymAlqkLGiswRSjaaDHnykK9XUVmh+ZO0AUPIZJT8to6Yy715lcPD9RRb53ptS0l8kOzsYpo0TuS3ly6mTcNq0BGqcDYFbkXXr0vhWyca77lm9DlfUF0HYG1PJGqhF6qNtrJja9J2VZ1vtTkANIKGm9quqNI5X2zJYuHfZwARjaDjriEP0iiuaZXaUKfoyghUs+7Bd+/24k2Qz9leUn6O/DzCI2x+petlVKalB9LE97zyOXkWF+74SIY8/B0ARz+/jea3fKYcc/DzcvOHuGIjh4/nKdU+Ppt4Qa0J3bo0K1QGX79G3aCWBW+gByAgAmc3dfBcosZcvTUuPSQiitA1ajGCLg+oXohYRfDVMmqz7bpEdbSj378+gNVaSkFBMQ1T4snOXECjuMkVnmN32vy4ESrqh/r5VZRhpn5+6a/psFjKNVZfEpxAUEdYqO3hAOsyb6dv3Dw6lwldgLtnrvc6xqTVeBW9bJkSFXLSR0WoipZbVwLXF+eDAlmjqAadx4rgtlNscxIZVntGd5C4Z93i+UHUYdbkA+DygMFkwOGqehA/gCZMj8PqIEyQiv5ZPIFLZgeCKLqxOUowOk9DaaHXx1MbmWHBPvqzUeq6JqjJcjQpJoyT2UZimodz8MjrAKye8iEXvbwcqNzppubB7Rs3D63JSOpjkuYo81jI/Vo2MXjCgoywCFEJFzObjUqBTLVQlW3TVquDKPNYZt//UYVtyhqw9N7Koym2Hsz3KuOU8+NqIsJqL8jpXJsVznfU6ElrcdHIsoYMLiDXZgRqxlovw2mX7Jd2z7kXvEZNCXZAbyybWByBY4SrCukeC7B7QmAhE8EgFCHkHKJd5EH0/ZoHPKy6QjLkmmtQ41pTtYXa0I5evbMb/3l5FTsPvKRsG/BSOqYZayvM7ArWl9THhgc9ZsClaeyb/pVyjGyDnT9Jq2i+vjG6C6docDm9x5RRb/QyWdhsbnQa/2Esh8EFc8rl5OTRpuXjaDQazOZwlr/sz0NSXZwPZoXzHTWe4szubFoV/YRLY0KsBcF7eMtxNMDWwhuA/Bq3VxvoGv0tbqBlt6rZ/0LB4S1SUUDpfoNABLfDTQ/zdxxEDClE7H9Vywg0ULccyuPbtSdIjAnjrktbEW6s/LM+kW1h5PS1FFmDOyl7xX6G2WxgY76kxbocAkZ9GLPGfeh1nBzlURHk91KZ40uNvMJiTLpyU4bOILI/d5eXyeLGC7/nqm43ep2nbl8W7DZnKX079GX9rnITg64skWTcFa1JjgstrTkUhBKj+/9V4MqolbWFFhdaT1HlB1YA+cMUkIXGOayw4IMNRVcDIFjmAbX7obTvEs2etYfoppM8yhUJzA32O6Q/AoSI/X/QMgJNFHtPFPKfF1fi9ngAgc0Hc/n44f6VtjVt8W6sTg+RkWE4nW70+nKn1KmvRoHbg9lsRBjSR0kblpf8gcwP6/PSEV6RYm2tDhep3ZsBcLxsYpWP8bW/2h027ps5BgCHMJt73ypfAT0w2wy4WPiUFpdDFqhdvM4/lnOg0nsF+GvnLxzJLj82KSmeVskRzJnQl9YpkSG1URVUlKDzb5zwaxvnnKvhrBZqBFxuFy6PkzB91Wf4s8XeVd3aZf+rWm4b41zcHhEw0CAtBf0lkm2ya7vGNE404/J4OHUqG7PZxLJteFW1DYYiq5OGjWI4fDiHfr1fxmKxc32/xrx8R7cysnP/6IDK3s26zNsB7wSJZRMHsdMyCp0BjAYRnd5b8KpNCQ/MeIB735pHy+aPYrXYFa6JW190B+TUHdDvNZKi/FdhatIcud/fWw+RmZWrbHO73Rw+U8KP60/y8A1pQe+ppvB1/srb/r+jysUu6wJ1LXALLHlsOrSOfad2klOchYhIm5Q0brngLjSCJmD4T2V9PdfkMdV1nv2bPvq+cfNYsCmT5/7JBOCmgU2ZoUq33br3JFlFiYgixMVFo9fraJ5kDimG946LW3L3zPW43CI52cXcclFznrulU1CuYXHFRqVPEPrzHzxtJSbT+jLzQLldtxz+foxAPAtq3H/TSrbu2058REsu7XK9336ZNKdv3Dx6linQl/VvypJNR5RjPB4PIiI5haXKRFbbmWky6vKbq6lcOlfjoVopw/8mHM0+yLzl7yq/bTY7druD6OhILm8Xy4QLJQJytdYp41xqkLW1EqhtTUNm9a9r9I2bR47FycgFeygpseLxeIiKiuDUqSyv47RaLbGxURiNBjQC/P7SxbRuWPHSubjUybs/7ufg6WJaN4zghv5Nadso9DjVisw6OoPI5Y/lK2nK4eF6EhIiOXysvHKEOkpBHZ52KvNtEhP9+6F2wIWCQO9cFq4ACQlx6HRaBEHwep51JXjrArUxPupi7OqGzg7tuFq74nmK7/7+HEEAUQStVoPJFEZJiRWA5QcL+ODJi7yOr+my/3whD/+3Lu3U/W7WpQks2IPb7cbtljRRs9mExSK9v4SEOIqKStBoBHQ6DU0TTJUKXYCxM9ezbm8OHreHpToN1/SpWvWPylYmiYlRuMR5ZGUVeVX1BfhiqneGp1EfxpzxC9AZRH6ZJnLHNH+NuzpCV+7jqVwrb327x+sYUfRw+nQeDRp4xyCj1ykpxuKKjeA891FFgVBbGWhVrrxSizg3tJBnCduObaLAmo8owg3DuvHc89ciiiLx8bF4PB5iIoMnQqjp6yqDuq5TXVEnVgXqwfdvFLpyv5f8fRJRFImOjiQuLhpRFHE6nURFmWncOJHwcAMNGsSg0+nQiCKv3dkteOMaDcLQfghD+7E/S0qaOH0mB48H1u3JrlZ/K6LXtFjsNEx6iOiIe7wy0OyWwELU5RA4mXWK1NZT+HzhBj7/bD19e7/EG/eEniXpK3QLShxc/ewyFi474nVcTk4B4eFhhBkN3H1tF6UGXMTl5U7Jigh2ziXqIu23rsZuRfif1nhX7fld+fvbb7bw7TdbFMdLuFHLa6O71+r1QgkrqirOl2iFs5Hn7rt6ePfng/xneHdmvf0bIHni4+OlpBNTWchYictDk0QzXz4hUR2Ggs3bn6Vpw8cwlFWibtckupIzgsO3NIzLIdlX7dXQFgVBoLTUSVGRDafTzamMQlwdBUIoKQeUP79fftrF9lMluKPN5BY7yFI51WSUltro3KMZz43sopgXsrKKFBNJYckHhPY0zz7q4husi7FbEc5rwWtz2nC5nUSEVS/cxSW6MBq12O1uiopKKC21k5TUgEeHtePuy9sog/d8xPkmcEPtS00hX0NXMgubw8WJE+Wx3JmZOfzn4g5EmXQ8N7ILEeE6TueV0izRjFHv7/WvCBd2SiazwMaooS25oH1Cbd4CAHan3W9bZcTpSdEN6ZvWjzenSwpDz5b9SG6QgCBIbphQTA5f7BvE/JXvggBut6dCR+MPz17k9VtdTcOz7G/2ZlvwiJDWJCokh2U9QkfIkqeqs0FNB+nGQ2v5ectiRFGkZWJbckuy0YjFjOqVxBVpgUmhfXFNOyOfbipAFEUMhnKnQauUyPNW6J4vzj11X0LtR03fucvjYtWepRzLOsza7RsAKLV5a46fP+FNXRjZqOrOIHHFRuZPvKDs/qqX/l0Z5NLrMmY/YPFKhggEvRG+XHoDICXTfDReyx3T/JMhAJxuJ38fXEVxaRGdmnZXyH3+ObKesHA9sXEm7n9wME9O+oaYmCj0eh2CIOB2uxFFD82To5Qy9oEcas/O38oXK4+RmSmZOvK/v5MIk3dR2uoszf9Npq+6RI1IcoKhpvyXNqeNJZu/xmaz43a7OZS5D6fDidvj4e2VLq6+rB1tG1fuhX6hX0sGbj7N8wt3cCIbwsKMdG8dxxU9G1W5T2cD55uWW9V+VPTO1TwEgeqGAfy142f+PryKtqmJyrbMzBwSEhrw0lUt6Nyo6isfNal4xpcWpfCkWmjUtmPUF9PHvFOp0A2EirTMbzYsYE/GDkQP/H1wNfdc8ghJ0Q0xGczY7U6iIsOIjZGMBVZrKYIglNnDtWgF2Lz7pPJcZDIcubjm4cwSrn52uSJ0Af45mMeFnZOV39UxPdWFE/p8gXxfnYaGdnydqH018ch7RA87jv2DKIqEhUlagyiKlFhKcblchIeHcSLHGpLgFQSBy3o05NLuKRzPtqDTamhYi6mRtYXzTeBWtS++GXSB3rk6oP/WF90Bl93H8w5z5VWdeGLy5TRvUl5OJzs7F5vpVUyGL2o0cOXCkzJ8s6lqMy5bjlaoLmRyG99kCJDGw95TOykqKqGkxErDhokcPLOXpOiGDEobyuGsfezde4Z7xy5AFEUaNIhBQKB5rJHHBjeh2wUtaKGihJQha76BVoNDH/2egh9GK5l41SXQh/8tAew7ZjqFeF6drrerEpoliiKn80/y2/YfOJZ9CEEQyMnJx2g0EBlpJi4uGgFoEGWkZ5u4KvVDEASaJUawcNkRpi7cjijClBGduGNoyxrcXc1xvpgVarMfaf1bKVqmybQyKFl3IDRJaMLsd68LuC9MH15rySuB7vFchhbJkB1zasjJEGoIgkCcOR63y41OJwnoBpHSKsFkNDPu0kn8sf1H1uxbRm5uARERZsLDw7jlwmfJ0YaRubOc0SxQkcuWyRHcNrg5n/4pcuZMecTH3g1HMBm0tRbGVRdJSGcTNXE4nxVDZ0WcsSW2YpZs/po9GTsAKdZWo5ESiHQ6LVqtBgGYcEM7RBFuHtSMaLPB/yKVICPXyuR5W7FYbYDIs59uY3DnJJommis9NxT7ZXU9olVlEKsr1Kbj7PctpwCIjjEpNbsKSz5g8dSK/eQXtr9U+VtNWeibLhuykNTrEPp1B6QltbrwZDBUNS77bIYgqTHigtF8v3ERRaWF9GzVn9SUDl77ZUEsJUpAuD5c4ZjYXnIX66dA35eW0eim+WR8OUoxwYAk2F+6oyvpl7TinzWHGDX3bwB2Om8j/UUd7XFVOamjNlGX9KShTAS1EeFz1jxMwcwPizfM50jWIQQBjEYdNpuLn38dz+MTv2bHDkkTvnlQMyZcX7N88rwiOyJSGI0oiphM4WQX2SoVvKGk8Z6NdNzzSUtQCyfffhzLLGHC+/8AcPpUgbLdYrHjclT8rPVavXKsHPt6KvNtjPrAK5zKhKRwYS/MgEucVyVBEcqzPttFFH2REJXE3RePD7q/c9Me7D6xjYPsRafVc33vW7z2b8y/DVgGSCYYX9JzQRBwH8umW4tYhRe4NlHdMVOVtPqqorLvqTYjfM66a99XAD+ffViJrU1MiuL4sTzenvkniUmRsEP6AKbcEqrlJDjaNYmmY7No5GLVqY2j6NQ8dCLyQFp7TQWu1eFWCFUCVTMIhPNhSRysH3vWHmLT8WI8AZLQ771lCYPb3oDZWM6+pa7aKzncwvh4ArhVzHQNkx5izvgFnMo/waHM/SRFp9A2pb1fP9RCUh4g7YMUeqzpPfrtPw+h0+q4beAYrA4LBp1RmdRASlP2DXdTCxv1PW7MH6mws9UGaktJqasilhV9T7V5nZC5GlxLH6iVC6qRkWOl/6NScLynjNbPaNQgiiJarZbCQiumcCM7378Gcy2w41tsLr5fdwIRuK5vYyKqmZeufhHV/oA0Gqx9unplNYUqfGXUlqOtpvwL5dUXJJLvtq0mY7E4MBo1HD8ucQEkJSXQKrkN6ReNA/xLpUN5nKuavwBg8q3P8enK99HptdjtTi7tci39214UtC/gT8EYSNutixp0/wao2dOmj3kHo96IUR8W8B4DvSeATyY56Rv7NQCis2qC+d+U3FNVwV5n5d1rE7N+2AdI5gQQvAz5AC1apHBxp6SQhe7eE4UcySyhZ5sGJESXc6baHG6yCm00jAvn1sEtatzvutIy5UKGVdV+z7X5YV3uHdz1TPnga9M2iR3bM4iMNJGSksDp09lYrVYy8o5X0Eo5fMnGf9v2A40ax7J81WNMeGgRf6/aGFTwqgdIMNOC34RVB2xw/xbIQhcqv8dPn3Jy/1v3c/DIdMZMk5Ittu98ibTTob3XukJdmx/qAueUq6HU4SY8XI8gCISF+Wce2e1Oft50ij82n/bb53R5eGHhdi6ZvJRJH23mo98OctlTf3HvrL8Z/PgfHD4jVUjddayAPhN+ZuBjvzNo4u+cziut8/sKFWazkVOZb/ttf2zu/RRZC0NuR+aK2LP20Flz9ugMIqNnuBg9w8Xhwm1e+05lFHD9Dd1wutycODUNlziPk6ff5NiJk4ydOTLgvfk60Iz6MOVfVHg0Z84U8v57K9i08TiRxuqn+AbisVBzLpzNtFGQ4pvl5+hLkl5XCKV4pgw50uLjCTrSWIgoil4Zbp07TlH+/udgLr9uOlVhVY+6xLl8j1XFOTU1bD6Yx40vrcDjgT37X/ArZx0ericuNoYHrm3HYze299r39vd7ee+Xg1hLbYSHh1FqdYAgYLWWYjKFMeby1kSG63nz2z3Id6jRCLRrHMXiKYNAo8Fic2IO04PHU+t0eKIo8uWqY/y9L5euLWO5bXALNBpvDWzvxqP8efIaJrzr/WzlmlpvjH0XrRi82GIgVMf8UB1Tg+8SVI5eePiRK/nm6y04XW5aN2nJX+vvBbwdZoDCyGV32ACJEDxYYUmHy863Gz/jwOm9JMUkc2PvO4iLCC17UUaotsWz7TQbPaM8M+9cRgrIEEWRvw+uZsfxzTSITODSLtdiNkbQOeIj+r4kOePUNd+sVgcZX46i0U3zAUhOTiDMoOWrKQPp2rJqYZ+1iXPl/DwvTQ3qLKJTmW/TY2gU9+/IZNZ3e72qqgI0bTQJp9OJiEDfdv7l0A9lWfhn2zPKYE5KikcQpGgFgJM5pfyy6RClpfYyMhQRQdCy61ih0gc1Mr68XRLCBE6hrAz5JXZ2HSukVUokKXHhfPrXEZ6evw2P283Xq49TYnNx31VtAW8bsa/QhYrLgFeGqpgf6kI7fuvNnwFp0oiNjlQoHC0Wf+4Ci8XOg++OUX4HSzgw6Izc3G90rfTvXEeEnO/YnbGdX7Z+i81m56TxGCW2Ym4fVD5hmkwGr+9TJ6QrQhekZJfExAaMfms9G2degVZzbiYSX6fY+YazbuOVZ8vWLR6jyDKHS7o35L2f9nPXnfP46JN0AC4Z+Bp3DG1JZoGNa/s2ZkCHRL92fIlNMjNzSEqStKC4CD1bDuXh8XjIzy8iMtKM2SwJZLUdubDkA8xmI5GmMTS66VNlu29oTWU4cKqIYS+spMjqRKcV+PjhfqzYnonD7iAnt4C4uGiWbTvDfVe1Ze/Gowh6LRvzR+JyCCQkbOB01iwAkuLvJze3dqoYVxb9UJsaQUrig37bDDoDLofgt4oBaamrM4jc/JKb57+KVO5/7sO2Kmv4oaKyCelcaUhqE8u51nbDIkTe+LoDb/A6UeaxOJ0uxS6vDj+rCHq9ZDrMK7Yz9u31zH2or99Krx51LHhlEg4o1yJ9M5lSylJ4t2w+Tu8eL3H7qL4czSjk0o7xPH+7d2E/NYYPaIa/tVZAECDf4sTlsqHVahW2fZCdeLWPj349RJHFTlZ2PrExUbyxeDcDOiby51YDMTGRGI0GGggetqw5TPdnbwMgDSltVhY6IIXOFZZ8gMVi9yPQDgW+NkKXQ6hRfTaQIgxkqE0B6iyrZ4a/BUCxtYjJ8x6hIpQ7DqW+qu//bMB3Qgq4r45QZC1UHKizxn2IUR+GyyEE3F6bqCy6A6T3fPOTbiwWyfeQ2q4JG/95GpBWXSD1SW1mkCfcA/NH8OXqE7z9/T60Wg3h4Xo6dGzEmp0Z7DhaQJeWoYdt/n9BrQte9QDvrKqPtX7KYEwGLe2v8T4+b+8prmoXy5K9+Vx6WQfGPTCYbxZvDuwE05T7AgXAtG4zv027ltFvrcftEYmKCmPAwNb8+ssu8vIKMRj0REdHKgJXEASSkuK9yD8Alj8+iD7P/QnAN+P6epVJkftdEYqzixFF0Gg0IMCe44VMvCCZY+3j2HaqhMPZhbz/55N+5/kKykNH31AE7mdTndzxnLQMf23MG8SakirsA+AX9iNrU2ptT/07FKjDuoIJBXmbMdqfn2D6mHcUoQKS43DRff0otQuYzWO9jn10zjiev+2tKoXUVRfqOOyzpeWqn0Mo22sDvrb4YNSUD757Nw+WVcgqLPlAEbpqzLj/nbLKxxJ+HNuTvi8to82oRQBMuaMvi1afYN/Bl5Rjdn/8a23cxjlBVWoxVhW1JnjVAnfxgaFMXfCE1/6N+bdh1Iex9Slflqrb6ZYGUWGv8emSHXRIfRqb3cXzN/qX6BaG9PH6nfnVX1w28Qfld0xME377dRdaAWJjJa1KFEX0ei1GfTiNYprRv+1gmiW0RG+ExVOl81yOO5kz/k4AhqliHAFMtwylWfN4Fk81BdUWWjXLRdj9EvHxsYSF6XHYXSzc1Z7eHcbSqa2NUa+7/bTYlMQHOXhkOlHmB9m152WaNI3HbDYqx+VnldtEH5/7aLUIV+QBJw+2mn44YWYR0eG9LZhGXL7N6Cd8Jy05gsvl4avdr/HDisexWOykJD6I1ergsbn314hcpir4Xw0Rqyp8Bcy+mYvpPvlWv+OiTFGgSqaYu6UtavPDJ38cZkiPhl7ntGsSei278wm+zthQS4GFihoL3kBZHVMXjAxydGDSD4BWLR5navzbHMm10bVRREC7ri/URn2AvXtP8MLwrrjCbua7jZ+TVXgarVZDp06NSUiI4I8/9nBh+0vZeGgNHtFD56Y9MBkrTmOVw2Xi4yPIySkJqPXFmOMIN4TRtWcjht3YnYmPfoVOK92jryZhNhuVCACQvMItmj2m/P548lxwVo3UW0YgJquaYsa42YoD8KZnPXwxxXt/ZRqxen9KcgIDBrbm9OlCDh/OYe/J8rAyq9VHolcAi70Eh8tOjCnuX0XQrY5NVj+n98bPVf7WUjc2bihnPFNDFjCnMt9WwsTadmmK+NcG9m44DEDPCLefwHn+/p28+WV3PipLRJQLdfbr/bJyjLhi47/q/UDw6JfazpSrkeBVOyQkZ4nkGBo70//YUOxWYuRDNI+EdkEcIOKKjUotKLncti+SGkpCTGd0ccWVnVj21x7uGtOfVq2S+P333Xy9/lPyLVIplA0HVnFV9xsx6Iw0btAMh8vh9QGq/1ZDzS0L0pL+ym7D+X7DQtatPUSLpNZ0atrD77zkhAeUD7FBg8AC31IgYNQLXkTab4yruNy3DHlS8+W+rQmizNG1lqsvAqPS+3PPmE8pLbVht2vokPoUa964jA3PXYzo9JQ5cYJj06G1LNm8GBGRNslpjLhgNFpNze7xbCHQGAgze7j1pfIomo8n1O41AzGegb+AEcoKdAKIf20Aj4d2vZoD3trexxN0iKLIM+90lNr3+TbW/T2Zhx74nPWr97Nh+qX8m1BZyGFtar81juOVhe+avJu5b+YYv/3PjnyV+Kj4KjsM+sbNqzjsR6Mhu2OaIhiXTRxEuEGr0NbJ8ZFq7bJ500Y4XE5ycwvweDwkJJTHGcaaG5BvySUqMpwL067g09+lkDOrVRLGrVs8htXqYNa4D7nvHe8PWY6/LHVYKXVYiTU3UASs2nHii1njPsTutHvtrwvnSnUhmxF0ehGjQeqTr7mlMseQen/XDk0psbuxWp1kZeWi1Wpp0CCGuTe3pUlM5dlTLreLl799ghKLFYfDQUxMFDf1S6d94861cr/nApLgLa+CUVl5oNqEV8z3oFSEiySlxvLbOqIv/8DrWHU2pSiK3DWz8pWVuHRdrfW1OqhqfHooMfCVRb+ctTjeBh0b0eb2z4GVmEwGZclY13a6TQdy6TWkfJaePX4eV3ZuiO1wZtkD9Dd32BwOtBoNZnM4brcbj0ekqKgEeTV0190DOHWqkF9++4G37n2fu96QnHmfTnHyWrpkL5AES+BChuEGE+EGb+rDKFM0c8YvUISY3WlXtFmjPswrfnnhU1oK8+2V2k3PFkJxrMn3Fwzy/r5x88j3aOg68UYAunV6FrvdTbNYIw2jjCENEI/owSN6cLvduFzSwHd5Ks6SUvM+VIULo64jDc4HqJ2ue9cdJK1M8Jov6wd4C17fZ3HPtSv558RyNm155iz2uG5REVF7bRPl1EzwRphIGtqPomGDyxsU0lnx7MXsK6hhzyrAsm1nGPf+Jvbec6WybfaSA7z38wGWPHcRh7YcZ3T351m/+Rkvc0Hz5g3IzXTg8YicPpNFYWGJcr7FUkrPns04cTKfX37ega3UxccTZCGqw6jKqVDbUi0WO3aHJmjmVWUDv8hSiE6QVhOFJR/4xb1+PPHTcx7fWVPYnTZWZI5g1Otur/u7rFtTfttynG67TjBr3C1ez8/tcbPx0BqyizJpk5JGu4YdMegMXJA6hDX7/iIy0kxiVAqpDTt6XUdGoHdRFcddbUcaqAX5e+PnYjRIoWQuZ/m7ralZqLpYn5dOv6RPKz8Q0BmkFdAF7QaTX1RMamvJ6B9uDCd98FgmzJZ8M8FMgf8GBBLA6u21gWoJXkupkzZ3fRUwBtMlzmPPK5/XGVlxQYmDZxdsRxAE3n9vGTPf+pMHHhzCxi1P063TVH7fchrQczqzxMvMALB+/V4AoqMj/BsG7hm7AI1GoFvzXn6aqxpqB+HYmeXX6Nu5N4lRKQztfDVheik+uVdseYmVQANfdlyFB8mWG/V64DI5dQl5ybVs4iAGT1tZo7bUE4/sZJTx25bg5CpLdyxh3f7liB43u09v4vUvpRClsKeuon3jzpQ6rFJ0itZAWITIdU9a/VKSK4KvJ3955gj0Wn2d2YvVgvzWlzyYzdJ7DWaDrQjBJnPfiacq4VBq+scPHrXwUvqbyr4pqtjsMW/pUCIbJl1Ls/iWvLX4NWnf3yqlohrl7WX4xpyfc+rTEFD+rOvQ1GCxOQMK3ZTEBzmdNYt2fVqCVkP7C6WHX5s56I9/soX8UjcXXpTKyy/+gl6v5acft1NUbMPhdNMkKRKPx4NWF/x6ak1Xjf7tLyC1UQdaJbWlkhVsQDRvr+efTZuxu0qZdoVkt2varQXqkJtgE1JpqdNP2w1EoFPX8HUwOC9NKxsIi6o1karNFeHhel6881UeffdRv+N8XQ1HTq/BYimlsLCYVi3KQ5Skem1SRV2704bdY2P0izosIST8yeQw6nu0OdzcMvUvNp+cTIRBw/D+42iW0DJoBEJV4EtvWRdQT+bqa62fMhjQVlj/UC2oIYyPJ+jK+uyt7cvUkYEgC93aQCDt8lwz74WC6nAMV13wajS0Sf+CouEXAygxmCA5omSDujrmVo4nrQ0BvPN4ITfe1IPnpl5L314vYy8ppTinkPkfreaeq1O5YqJUGvu6J36ssJ3ExAZkZUnRDWZzOImJsXz55/Vle8UKvcvqxIcZ97/DhHekD/WDD0fx2iu/8Nu3/wCpyouQq7dCWQafir5OHuDqQSOHnUHtLj/Vy11fs0dlddSqE0rjmyByJns2ZrOR8e/Mo2mjSRQUFGG1SoNfdkbK1/itQTiZxWUhZj4pp7LjNCXxYbKzi7nvnXle+9XsW+qik4Hu8fMVR9l8soSCgiJc5nC+2/AeD1/UBG34OHRaHQ6Xg0VrPuHgmb0kRqdwc/87CNOHozPI7RtD/qbfGz+3TNs11ui9hkVIK8ujR7Jp3XIiY2eO5LnbXvE6pl2fFl6cI4EEsDrBqSI7tlq4L3xKrDRkcd/0r2jbtXHI91PRcv58If4PhJqQuldL4xVFkSjzWEwmA6IohhyD2St2Aesybw/5OoFmugvaxbPw0/Vs3nSM06cLubp3I+KjjYwY1Jy0KlSUkIUuQIQ5gp4t/RM2gsE7Q8zM4dOP8fX6+dwx8mO2bzvB1b0aevXbi3RHr6P9M5LjT3jlU+V5zB4/mwdmlkeO1IV5wTeDrCKB5ItATobKMOp1N5c/Fjgkr1PT7uxgM0kJidzcL91raZzWvxXvdGzME59sYe+JQi7r0RDXn+vRCoLXhH46axY6IZ2osgy4iuzhwe6xyOJEAGw2O2azifxSN8/8cpRGsbO5c8gDrNn3F3tP7aCoqASny8mSzYtZ/s9yVRiVO2SFQku4Xxx0dWDUGQAPrVtOVLY995l3ZmR2QWlAsqdg71Fy+lau2ctmNrvTxvNfPag8h7kPu/hiinR+t0Q3Qln1jz9mL+GSB64Cyuy+QUwQlU3mFZWbqgh1ZfKsaSWNqoeTaTQca9HS66VDuVanvOyy9F71QKmqxhsovMPmcPPuT/s5dLqIHUcLOZ5tAVHEaNDy52uX0uSmIQD8vf4Q/fu94NVesLhcGbKm+eVUDTaL1M9A/VVT+YEkJDcf2cC+UzvpnJDFC/f3JTxAiWxA+SAB9s/8hrbjhwGwcIqmVsKK/MvpCH7bUxIfJDu72MsOWlkoTXVIZHyfkwy5X063E61Gi9MlTdyt9J9w5cw1APz82jVs2JdLuyZR3HhBU0UjFnzK+ch2/FAiFgLd4/EsC1c+8xfFpVJfCwuLcbncNGgQw8iB97DzxBb+ObSezMwcYmOjaJrYjG37dnjFr1b0XddFhIocgubrw/BFwQ+j/YSv+j3mFGZ5cWvI34NvCGSgZ2t32rzCKtXPINh7h+AhZhV9XzWptFKXpZoC9Us3dHZI51YrjtdidxNzdbkNzLdKKZTfsMzEBdVnXwo0uxRaHHQetwS73YHH4yE8PIw3xnSnZXIkt7y2GqvN5cVEdn3vFmzLtnHkiESqnpwcj+iBzKxy3gZ5uVUZR6pvgkIg4eY3u+t1SvJHIKgF7yeTnIyZJsVEV7UcULDcfN/t793vCigIAqVKyqjqh6t+ThUJJ3UpGjXt4KVD3mDvvkwevr4dE24oK3aqeo77pn/FmpO3+LVXGfrGzeNUoZ1cs5nUxlEUH8pk9eEC3ll9CqvVitvtITo6ktGDH8TpdvDpyjkginjE8nLnDRqYycx5p9J7qyuEmT3YHXayirKYMiewGr1+ymB6XORPRaq28apNXFUJAQ0meH23+6Ki2N5gNl6ouYnhbAjgtP6tQha81VKrzEatv91Shdqm2AvEsGV1uNHpNCSnJBAepufYsVx2bsvgja8K0AkwsFU0N97QiuZx4Uxbk8C6/cvRajWk33kRl17WnltHSC72x4ZPYfpXkse8V+xnbC+5q9L+BEt7lmGx2Mlu2lxZFWR8eTtJZTZxGeJfG7xWAy6noKo5Vi6wa8pd4HDZ2X96TxmrVNtKjw/E3lXd92grEZTQu1Gvh74kl/H7X48y4aFF/LLxULngdbqUweu2+nP8hoJvDl3MvBXv4HBKmvYjFzUmqdFEzpwpnwAGdR5MkwbNEQSB0YMf4HDWfuLM8cz+TmJiy821oBPSg76buiTgUdq2pHMk4wSNGiay6KuxfPnFJma97U1KE6rAqUpVCpC097kPl2vzWrE8Rd7X5i6jshCzQHbo2rLp1hXnAniPmU5DQzun2obEQPajuuQ09W0zq/AM0dFH+XuTNNv36/MyU799lKnAc8/8wMcfraZ109vIpDHrDzzFPfddyIL564iMDFeELkCzhBZsn1r+tPrGzWPhU3fUiPNAHZ1gMGhodNOnFJYM8CLJcThcfH7/R6S/Iwl6nT444bm8XA1lqepyCAormdPt5MM/3yarSNLyt/TvzKptUniY1eqoUKDX1jsM5TmqSXQOfOqtwa5asY/uzWqXreyfw+tISDTz6x9TmPDQIhZtLmSs97zIld2GKeaNpvEtaBrfwicKIDjUS9DaHOS+4WF94+bxjyYVBIH8/FIsFgctmzVhwpXPIAgC20vCOHBmD5sOrSFMb2JIx3yiTeV+EKM+jI8nquN3q0a6H4w7OdI0htIySljZfLfmnZ/onxpa1ZC6dKDVdX22UOuhVy9lWEXPiMdTJ2q8y+1i3+ldCEDblA4K6YwMh8vOvbMr9wwnJzxAZGQUd9zZn9wcC4u//odTp7LK+6tajsmobALJt+Ty544llDpK6dtmEG1S0pR9qeaPufDlvwKeV/DT3ZjD9YiiyO2vr2LVzmyOZ7yu7J/7sAuLxe4VeVCTdOIDp/fw2eq55OTko9NpiYqK9DK/nA0WsFBL2zhcdv7Y9BK7c+3sOSCtQC4e8CoNI/RMu7s7STH+913d6sh/bP+JrSfW8NwL1/LeOysQLVHcMWhcSNlq6npx6kKREHxZXBsKSaC296w9hM3p4alfj7LzVAlajZbreo6gczOJJySz8DRzlr5Bh46NOH26AK3LzD0XT/Qirgnkr1CjqjZqX/uwTJ4j8z+okZVfqhBdBbJH1zXqQm7VXcpwWVlyGcfe+Aqo3ZnDarcy4X3JU52UFE+LpNakXzQOjaCh1FHK79u/J6f4DPdSeR24M9nlNpeunZ7DoDOSnJxApFFg/OBmWBLjWPx3BvmFdkodbi7vllRh+JRH9PDf5e+RX5KLy+XmcOZ+7rt0IonRyQBownWEh+uVGd8LHg94PBzPLGHVzmzy872LPj46Z5xXhEiw2MnKIA8WTVkygNFoQKvVIFA+4CpbWoZqn60MoVZYWLp9CeuPFuF2u2nScCKIIhEmPfNfHhpQ6NYEF7QbzPHcQ0x89CtiImK4pf/1gJTe/Pa4D/l+4+fM/Pkl2jZuww+rJHpE2ZYfyN5emfOnJsxWlYX5AbyuE8gotBNl1LGntJycKSPvOG6Phy++HsuSn7bz2CNfYXfZlOSeQBg9w+Vlr/W1AVc2OQXzRwhD+vjZd33ZBc826tL8UBmqZWpQL6XXTxlcqV00mKc9GM4UZCh/Z2bmoNVq2Juxk7RGnfh5y9ccydvDRYPbktp6Cpd3vYEeLSVbaYnNwri3gw/SrTueo0nKREpKLIiiiXs/8U8LTWs1mSVTBwd9KTZHKQXWPAoKi7HZ7KSkJHAq/4QieFuNvRrhleUcPDzNL/JDRqRJjyCA0WhUkk6CwVfrDYZgwfrDLhzO+gMr0Agarug2jF6tQgubqy16yYqErfxdWCx2xkZ8o2w3mcIoLZWe7YodmdxyUYta6YvSvsHM6Isewua0YdQb0QjlK7hlO39hT8YOSkqsiJrySVBK3Kh4uFQWjldXNcA6XNAajdy2qn5Ao7gmaDQabrlpLqcyCkiMScKo8x4fgahEZXu8PYDuUNVU6upUUjnbUJsfzpbwrXGwaNqTI+hpdoXsYb71RTfv3V++vJFnzNySbL5c+19yS7KJj/Dm4hVFkS/XzSPGFIsbJ9fc0JnXXv8PFw2czvHM43Rp3BcAwa3zEmSBSug4XS5KSqwYjQYCweHy8OfWM9x9eWtEUWR5vptf/zlNrOZ57u3XkF3iaOIipIgIV4QLQdDQKK6pcr7ZbMRqdShCt+CnuzEby7U+efBd0+MmlmxejNPp8gqJiok1kv6a9FrmT9JidPhXdagKLu96HRd1uAyNoMGgC3zP5xtMpnAMBmnZ+c/BvFoXvCAlbIQb/DW/3OJs7HYHRUUlREcHTxtXw9f5G8zUIB9bFYTadqB2k6IbMqL/aDYeWkNyeAJDel/px48rO4oDhYDp9OVWyKo439ZPGUy7Pi1Ao1HGXyDHmro68f83VF3wejxkfH0Hjf7zX6/NqY8Nx/38PKDyj0utmcmEId//vYjT+RlYLFZcLmdZ1WABj8eDIAg4nS4KrPkAfLloE7t2nObw4Sz+0/cypS2jPoyXbn2PjydI2pTRFMbNz5V/PN06T0Wv15GSkkB8vD9fw7h7FuB0efhhw0n+2HqG9k0i+fj3w1x1dWfWrj7AWytP8txl82lzXTzTVzen1FFKnzYDSYgqL8uzZLr3YN677hA9hrRTIhi0W0+y5uQtdG8BXZr1QkREpyl/DemvlQ+AihxuoUAeLGHViB+t7SKModT9Asm0pNEIxMZF0KCBmbzi0AnSawNpjTtxMHMvKcmJuN0wYfg/dG/Ru9LzgqW41oZ9N1DboQrztintaZvSvtJrzJ+k9SsdNWaGnjEz5in7QVTil+c97sJjD/xdmQxaxV5bUfhYYmx4lQvL/q+gSoLXUuqk4YgFFFnm4BIH++0PZsuSPe12h79XWCYMGfX6faS2fpIzZyyYTeFS0cr8AqKiInG73ej15V0VPQLFZ8Jom9IBj8eDKIp+M3nPiP8i6LVAuRaek11MfkEx0dERbNn+rNfxrZo/gdmoJTrCQIFbwBhp5pPfD5OcHMW779/GC1N/Ysk3/0gDau0hXrvcwfo8fxNLSb7Gb9veDYdJKxO8qY8NZ80EaXtlhCy3vuRhzyufITpDW/ZL+fkSpDpx34Z0XoVt1pRp3yCi04sBk0PKIzBMfDzxU9rpP+azfYV8t/4kHTs05O+/j3B7v45BWq59uNwuth/7BwBBA52b9aBzoz64qiD7fcPx6ipsKdS292bs5Jet3yKKHoZ2vprOAQj6wTsaRv6txmvfP027hh0ZxX8ASH9NV+uk7YBXnHZFmW7nIyS5d5b4eMXlZUuIMo9lMNuoxWLnwXf9idLV2HfwFZo2nAQCRMeEc/L0dABSW0+mtNSF0+nC6XRiMoVzJOsgiCL7T+8itySbwR0uV9qRBX+7Xs0R/9rAsawS3l2yH0GjITLShE7rL/DcLpGXx3Zl3DsbeeHVyxh0YVu6dprKmTNFXHnZTA4eyOSa3o287jHYAFATrGwvCUPnEBXmp2CQ+7znFS1pT5ZPFu36tJSebYAEjECe4lpHDQWIrxblC/UAj4jQMn1MD9o2jmLroXymjOjIXZe2rtZ1K4MoiljsJRh0Bgw6aTm87/QujuUcJi+vEKNRz45jm7mmx3D02qqbaOrSVhhq2xZ7CV+u+y+ltlJEUeTbDQuJi0jA5rCSEJVMtCnG63hfYau2/xYUFrLTvQXKBG8gHM85woncI5iblZAW9KiKIVzYi6ysIiXD9FxEO1QVvmF+oSB0wavRgFbjVd4ZQGat1wnpXg/JV/tdkTnC67w54xcQFiFiNnsPzMEdL8eoD2fOkvLU0Li4CNb9PRmAZo0nIqDB5XZz5kw20dGRbDu2icEdLg/oAT54spDrnl+BrUxrTG0Sy9V9GvHHzB+5ZLxU8lhOob3n7Q00jDcx9ZnviWsQgdGgZfJNHfjnYB5Dr2jDuKtVYWcaDc0eHV7maFzKsomDOOCQIjF8Pb2+2oQvfPutLnEE0kpD6Ncdqln2vSao7VpTlZHD6LQaxl2dWqNrVAa3x83XG+az5+QO9Dod3Zv3Y0/GdhxuSbUVRRFRBBHp/38rikoL8YhuPGWTs4jIJ8tm4/a40Gq03D7oHponBJ/YbCUC7Vu9SGZuJoWFxWg0etq3eQa36CYltjE39b5biZDYfXI7X66bB8Af2yGscQOu7Rs6UQ7AD+tPct1QvNP6NZry8NW6VjKqgeomevivi4NAGNKHiCsHIIoiOiGdo5//Uek5af1bKR1S89LKtkdbib9AurjrJfRo2ddrmyx0AcLCDKQ16oxGIxAZacYUHkbLGEfQB7Bw2RHQati+6znuvOsCCqxOHh3WnovbN2Dmg5+Q1upJsrOLASmCIjEmjMu7JJIWZ+CziReQfkkrZt3Xi0eGpRGmLvOu956zBk9bqfThdP5JFm9YwHcbPye3RIqbdTkE5Z+MvnHzlBJHXv0uy84Sl67DYrETc+3HREfc40cbGSpO55Wy/2QRHk/1pIi6f1WZ3e1OG59McmKxSBlm8ydVHtFyNrD75Hb2nNzB69P/w+Chqew6s4H4FD3JDU2ASIMGMUREmBBFkazC0+e6u14QRRGPGJoAijXHISBgNBowGPSIIjgcDrKycrHZ7azcs9TvHJ1BZPQMF6NnuNAYbWVVUsJJSUkARPILSzh1KofDp46w4cAqpU9/bP8Rh8PJqVNZOOwOvlhxVGpQo0EY2k/i2JDHjCxMNd7iZ+6vB+jQ7imvbcJFvRCG9PGrMH6uIY9dOEvsZIIg+BW4k2khK4LJoPXyztudNnR6kZuf9QDeWpxeq+ep23ezdOcPUiWCbY8r+/YdlILrr7rQzoFjR0mISmLChWHKzZ/JK2XWj/uw2Fz8Z0BTvlh5DIvdxfz/rmPd2kMY9RrlPh66rh25RTZePlw+uBrGmXg5vVvlz2FgD7D4p6yW2Ir5eNls7A4bgiBw4PReJlw1xWu5WhPSDy/TTggawNxfD/Di5zsBGNQpkY8n9EOvC3m+9UJuiaOMGH1ppRwS6vC2MdNCS9ZYn5ceEv1fTR1WDpeN8HA9I27pzYhbJMfZ5n+OAXD9te/QvUdTNv8jkbRvPLSGxg2aVes6tY2MvBMsWvMRxbYi2jfuwrA+t3k5Zn1RaM1HRCQ/vxC320NiYgMEjYBGoyE7O4/s7NUKM1wgpL+m45XF+dhsNsKMYei0emy2YhwOF4jl8eIHz+wl35KLXq/DbA5Hp9eRFOcfMSJc2MsvVd7zx1rFPxNjNlB0KI+wMCOxMZGMvqLtWVnhVeV7qsnYVaPGNt7Mr/5UNEaLTTKEx1wrFYpcNnEQDSIkgaO+KfWgvG+md6VS2SbYvcNicgry0WsNvDj6BF+t/4RmLWL4YYm0DFmy4k4e+89u2jfuTGKkdL7bIzLi1VUczSzB7fbw4/qTuDwidruDV1/+Ba1Wg9vtYd4fh0i/RHpojwxrz+ZD+Ww7lI9WJ7B6Zyazf9jL/dekVlqa2mw2UljyAQfn/ETrsVdjNhv5duxRnG4HObn5UtKCRiCvJJek6BSgZqQfGV+OAlfozgabw82rX+7iltt6069fKx564HOWbj3NFT0bVem6ezceBeCqd9Yr2x6be79fAL06XvuTSd7atd1pCynzqaLwqdrKNEpr3Jk9Oeu9tk0YvwjRI6LRCIrQBapl360rfLNhAfkl+Vitpew+uY0WiW2CxmXbnTbC9Ca0go7oqCg8ogcBAb1Wh8MROsv/voMvoRPSiYvTEBcdQViYg/Bw6T0WWQspKi2k2FYEQNduTdm+7QQej8j461JxuDwsXHmUO1WCduHyw9xx8XuAlNX27a8HGXtFGwCeua0TIzOKEDQa2jWJ4oHr2inn1UUpoap+T7XJH1FjwWsOKzd8N7ppvhd5zuBpK6sdg1pSWkJ+fhFRUREsXrOI/JISxlx+gdcxv2z51qvCbE6hjSOZFvLyinA4nCQnxwPg8Yg4HA4iIsLxeODz5UcVwRttNpBT7CA+MYLcHAsFJXamLd6D0aBlzOVtgvZvzyufA2B1uGj32E3KcnrCWym8/5NIfHwsogeMujBizHHVfmnmcH3VQm5UTjjPr2vwiGA2GYmOljQQtzt0c4P8Ycr8wUVP3kKUeaySXWfzlBCu1+Nx+tttb3rWw5hpoXdbjYrCp2rDaWUymBk58F6vbUePlPMzWyxWPB6RyEgzzRJa1vh6tYUSm5S0Y7GUEhUZQUmZwFPD7rT5Va7u3bEXBdZ8SmxFOF0VC91AoX4pKYkIAogaO+DG5fKg0xk4VrCHBatPMXLAPUSaItm18xSiCIPbxNIsMYJJH23mi5XHePWLHQgagc8mDWDFjkyl3YZJD9GpXRMOny7h4WFptGkYxbo3L6e41EmUSY8gCHVWqfhcaLlqVFnwqlNat77yBS6Ld4iYrO1WqRNlCQTqygsgEhsbhaARyC3JRqOB6a//zkdzV2O1OoiLN1NsK+RQ5j76llVpj4s0YjZqcUWZFXtmRJmzT6/XMuTidvz6yy4ax5cHxns8IgVWJ6ntkrHbHJw8WUBYWDhLt5wJKnjVL23szJHw3J9e+yMiTJhM4YQbTUy/tjFtEiQhfTbY89VOOZNBx0PXpjJj7io+nLuKHm0aMLRbSkjtqO+xfZCqyrdN1ZCYKDJjXDZRhgSvfWazkdfGvsnjcyS+VzXRtvpDrujDV4dP1XaUgE4MQ64d1q3zVIqKiomKikQURczm8u+jYWyTWr1uIIT6PHq3HsCqvUuJiDCh1+rp2MTfJOabvZiQEMnaHZIQbtroMc5k5hAfH0tOTn7Q66ijGZ67ax/9Uy8kKS6RV+Z3VvwMSUnxpN91AbNm/gkIjBnyMAezdxJuMHFHp10A/Lwxg+JiC6dOWWjUMIGl/2TQREUfazIZ2LJH4sy++aq3+HxCHzQagWhzBasMdbhZWVRPdTICz5XAlRGy4JWdYC+nv6kISnmpOWvcbQB+M22wbBejPixoKqycbWazuzGZDHTp2piszGIOH85Gp9Owet0TfDR3NTPe+gODQUtGnmpZqNMw8uIWzPnlIC1bJWAyGcjJyGf2fT154L1N/PH7HponmXlzrBTLaCl1glbD3jJSFuWhCOl881chlgl9vUJZQl2alJRY0Wg0xJr1tEkwSS/Nh1hIvr48UQXiNPZDgDYqw8M3pHFVr0YUWh20aRhJ5FUfVni9QJqAeiC+PvZNHpghcWSovc+zxn2IzuBtj3v0gzge/WAeUeaxPDb3foUFLjMigi9XHkNbamNkjw/Zba24LlldhGbJkSYut5soQwLNm0sTtccjsmfPcSIjzURHRtIgMqGSlqoP34FdWfTIkI5X0KhBUwosebRNaU9cRHyl11Cno4eHGYmOjsRg0DPy0nQGpQXmMFTTnjaN7EDTLh0wmtxAuZKVmZnDj99vI9ocjdkYgcEoMPsD2Snemal3fyjxdsdEoNPpEBFonRLJlb0aUeRws2p3NqWO8tXXF0sepvCHlUSZKg4dUysWq//cR6xB4O/8Oyt9DlVFbdNS+iJkwSsvQUz6GD/zQTDbXVxMVNDgc7szMJeq2Wxk1qNZmML17D3worI9tfUUSkudvPXGH6xYsR+9XktpqZOGsU3YdHwvloRcerSO44Fr2rFmdw47D2Zj0GmYcW9PBndJZtf7VyuCLv76I0q6okS8PaDCe69I4AaaQFKS4xE0Gm69uDwaQO1QCBR/2+im+ZWaFCprQ9kuo2x/28ZRQNlEE+R6Fd2jeiCKzuB2WnXF3GBVCFwpcaRPXY7L6UKn03LKLvLikHkBr1uXUJMAjWYcgGIuatV8IqAlMrx26ShlBNOkKiNtEQSBdg0rTihRf4/qeHKAdo06clhzlLYpafRPvahKfQ7k77Dm6zAZDfy0bSHfr/CmC1i4/AgPPDiEFcv3sWf3acZe3pob+jdBEASmLRgX8BqR4d7iqDLF5O4v9hFnSmbkAGuFVcGrgroWuDJqtbCXUR9GYckHym+5hDX408s5fATv9p0vKWaGB99I5ME3XvTar9FKL/7jD9cgIuJwONFqtfyw6UsWlBbAL0fo0SaOuy5tzXdPD+LwGQsJ0UbiIgN7RYPliPtGaFRmCzLqjV4f+0d39+Zgnp2OHZIZPqQ1cpxzTWF1gzmUA6sR61gb9tMiaxFRJtmkYGTe4yicE1A+cD767SCiCJlZeZjN4fxzQKDt5EHsX3/4rDJE+RLDWCx2r3C9Ro2SubpH8GSB6qIq9e2qk7wSZYr2Uozmq5yc13UPvd6hL1xOf8F7Jv80Qy9JY//+o377tFoNd48diF6vZeeODB4dlhbUWf3QzbN5bFh74kzl34tv0oQ8XldMPsDLf50gLCmOaW8MZ+IjX7P+wEqvBKrq4mwJXaih4A3E1Rks/ENte3p25KtM9SnO17njFN4bP5cxM8of+Csv/cyTU64EwOMW0QgCLreb4mILxcUWkpPjKSotICcnH4NBzz8H4J8Df3P35a15+pbKKYllrVcnpNOudQp7D0phZcMvTuPRvskc33K8SrwTAHd9+Lf0xzfbuO2F3xQ+0lD6oiCAScF8WT+CweX2sD+jmPgoI4mBKBQ1GikOGyj4RaekYVZH4Mpmomc+e1jZZrU6ePGLx/2oMD32BfSNm0fh9+VLwU7NYwBo0CAGo0FPuyZRaDVCnbJ3VQei6OHbvxcyevCDtW5uCHVg18Yzqa2SRC6HwOKp3lqlXq/ho0/S+fij1cq2uR+s5JWXf0anEejZ7QUcDjdJMUYmz9vKEzd1ICbC4JUgJK7YyMwxPcjKt3r5h4Kt/q6YsZqBPVoSExPGsOtnANAuudzJGConSDCcrSrGNRK8aqEjx3Wq7YHBspSmLngi4HaXU/A6f/5/1/HZf7dQZCnkjvT+OJ1uPluwnogIE+HhRmUG1el06HRaNBqB9NEXsGjBen/Bq9EQcc0gCkv6IK76B5wur4iBM3ml/Pj3SaynChjSJhadVqgV7ath0kNKuJyvhzZYxILapBBlHsuBeSNIUu2PMo9VhFlxqZNbXlvDjiP56LQC0+/uwQ39gzuEIi7vz+7nyzWiqtxj+fLczIQ5c5TtOiGdM9mzSU54wEv4yoNAbeLonRrPW2N78NmyIyTGhIU0QdYFPpui4bYy/ojU1lPYvO0ZZV94uJ7s7DzEBiKr9/3FdT1Dy7//X4evIHM6PVx+yQyOH8/lxed/Ij4qkQJLPm2TO3JR+8tZu38ZW49u5HhmMYtW2DidZ+W/j13gVb5JRqObPvX6LX8zBT/djbVXZ8WfINfjA/jqq3VYrQ6WrP2By7tei04vMvr1csWtLip11xZqrWdybbBg9chC5ZWVz3e6HcSFJ3MiRwpsv2hwKna7i4WfSTZMrVaLIAi0adyak+HHEEWR/he0Zu2ag9hcHibPXMPtvZL9ZjCz2QiX9/d78clx4QyI0kBUXMjCSGcQmTFuNhPerZyQXVyzJaQ2A6FN+iJORYXReuRCrFYHB+aVp19/tyGDozlWPv3sLhbMX8+Li3ZWKHhl1KRwpQx1Tr0vTmW+za/Tpdp4vprMsAuaMuyCpgHPO1v4ZuW3PJ4iaWpOpw2z2ahMkFHmsTidTjyiSIgFWv7fQLYbuzxu5vzxBvv2nQEgOjyGMUMewaAzeMXpyyu+Ni0f5++9OV6TsDlc71WFQg35mylYcjeJiVFeJsxAUJJ1ytjUgIDkWecL6mxK8CU/h2hmjftQeUCFJR8QHXGPV1VZiSRdOn9vxi5O5Bzjw4/vYPIT33DnHZ8A0LRZHMeP5eF0uoiONvHnhrHKNZs1nkR0tImrr+nMZ99upX+LKDpfIr2w5ZMvYoBKk/RdwpVnZcGscSNCCvaX7i+CO1//IGg6r/zBCBd0Y/fzC0JayvhyNcjP50x2/3KnWllYzaih/RhVZg7/8YetOBwuv3sT9FqFHU16xumV9sEXgYjRfYVuoKxGX/gOvHMBm6OU71dLzG3q7w/wKpmemZmDvs35k0BRVfimd/tOtnaXnZyiTGLNDTAZQ/IgKOPiwrh59L65Ib/uCcMjQnzyuIB8z/KK78Dh17ih91SvSbh4yd2V8/GWmd0CmTD1eh0NGoSTm1vot69b56l0SOnFhe0vVSq7qLMt7S47LrcTs9GfHrY6kMdcnRe7BG8tdsa42UE92TJ7v1FfTuptNrv8ZjE1y788Uzmdbi4cnMpXX2zCbNKTnVWMTi9w6lQ+0VHeXk5RhFdeG4Yoivz26y7WnBkCrAVg+Nx/OP1SOgBfTNVgyZf+DlS5QY64qEj46gyi4gUPBPnefD8YNVdrUJQtxSylTq+4aRn/LN9Pzxfv8Nv+0487GJJ2Pevz/LOZ1k2o+JJVRZR5rN+2l+98i4VTyu3TLocAqrGY8eUor4GX9W06WQV2kmPDKo7drGVURQv6fvU3DO50GSZDaILpfIGvo8g3VC2vJIf/rnyHQkshYQYjt/QfEzBZxNeP0zniIwCsDug9OJXeg2Wh8zVLdmbz5Ffb/NoItjK69LkVXr8zvrzdy+Qgx/X70kOeyStl2IsrMJsj0Gshtyz35Ylr2tM4ZSK/L51A+ugLGD9BkoJj3pqDTkhXVuWbj6znp3++JjYuXKGHrYy8qSKofSWhGs5qJHjVHlSrsyBIIkRwBDvG7rTRIqENHVPM3HeP1P7DN3bg4bfLhU3jlMdQLwIXPQcdm7fnqqulTLarr+nCuw9L6nNCQqQSz5iVVcRtz0kfwUPXT+Lt717HF76xyL6cBFZnAZPnPsLoaeVCcca42dypsi/53tvilwUKffhUKxPAskaorqqxd8PhoMffe8mjfokM1YUvj+7iVzTc+GR5xESRZQ7Nmz7Crj2vSH01G4mLDvfh3dVgMmiDOkpufHElh06XEGbQ8v4DvUmulZ4Hh28hRpBIl2QM7P+6lzIgr2KcLqfXBHI+w88zX6Yxpg1ooyQb9I2bx9s7T2I0iXy94D6envwdv2/7npv7j/Yq4OmrlGyfOpTOzy5Tfhf0aYE5XE9a/1b8vDHDS+he2e8aruh2HTq9SMMkfzpYo9HAqr+neK0wzGF65k4ayuB7LyMhMUoZQ8KFvbxMg8lx4fz16iUcOl1MowYmYspoCfRlq9vOHadwR/qFAZ+PR+Pgp3++psRi5ejJV5Xtt77oZvfzFT9bX9QkGqjWTA2B7JwLp2gChqGAlJAhlxbR6kXsVukD8X3ZDRtKZYDm/XGQh1XnazQCmZn5NE5+lE6NIvnln+cY8Vy61zXCDdIHpC4FpJ55AwldX8izpAydQWTCzAf86DG1hPHTNL1S8WLxKxos+YJibrlxssj8SVJFicrKuahR8MNo9m44wqan/ovJoGV9Xjp2p40hKo2zyDJHqk78nvSEvJZUqudZGbGNGmoeXYvFzs2T74HJeEVp5OWW8P0rpkrrs6m1fHW5l6NZFrr3aEpuTgnPzNvCnOFtK2qmxlAL3eTkBKxWK3a7m6aNJgEw5tIHvCbM5OQEdFoNx3MOExcRT8PYJrViMwxp1YO/OawyBBK62R3TvL55mbpVXHESQSNgNOj4809JYG7cJZHAB6uwLLXrz2gGsHx7ptfvg6f2YOzt75S8buANbDy4hsysHL99O44W8OriPdz52shK7zXMoKVDs5ig+w8dKO+PHCJ6KvNtrr1sBsYwLUdPvl3pNSpCTUMwq0dTVQlaNntEogC0aPyoEGW4HAI2iwabRYOlQKpq2jPiv170kQClpTZOn85Go2LUemPS5yCK2Gx2nC43oiGwrdCoM3gFkVdkGgB4Kf3NkO/RanUQ7mOjlCcPgBuf9AS87yJrIWNnjqTzs0v5/eQNWB3uCgfY8S3HMRm0bC+5S3nJRn0Yr6W/yxtj3glYKDOYE7OqhQoDQT2IX77zLcUZ+vEEnTLJWix2PpnkxO60KX2W71Eu93LthWm4XB7WrzvEsWN5FNpcZzWBIjWlPRERZqKjI3E6XWgELT9tXMzVV8zk/XeX06blZM6cyeZkRiZfrfuUuX/O4PftP9b4uurnEey9q/dV5ZkEatt3ib93wxH2rD1Eq+ZjsRS5ueaq4IVW1Vg2cRDgE/aoQloT7wl9/7GDyt/qDNZuzXuTktwAu0syOU0Y8RAbnruYgh9Gs+t4IW63VPzUYrHTr8/LdEh9isIlqwkF6r4tX/0EOiEdnZBOdnYxhSUfkJgYRct2EQrDoS+a9mwe0nWgfHJT00NWBbWm8b6c/iaT50l5+Y9c80KVY+j6xs1D0Gtp17M54eGrKS11clGPFuw9WURcXCSoSpM/+votzPl6u1SfS4AHrk31c0iBFJ5m1IexcIqnrMRQYNPGS+lvEmWK8pvlp495J2CJ9cKSD7BY7HzzsgabVV3y298D7lvFVS385L/njF/gZ36oKJMsLEJk9IsVv7qbX7IEdPgVWQtD0noDVZ+VIaePm3Te7ciZa2Nnlvd31rgP/UrWpPVvhc3hwmZzkJ9fSIMGMZjPAieC2idxfZ9b+XTlB5wpOIler2Nwh8tZvf93LuvZm1Hp/Xng/nnKeW63C4vFwbr9y7mw/aXVqmGnRmX12dTH1KTtYGap9XnpxEfC/Zc+SVbRaUSPwMufP63sX7N3GQ3jmpASU05kHl7GRR2sTtqooS0Z60OKdDr/JA0iE4gyRfPxxHLb7Yb5j3vZfW957mLMZiOdW8Ry9OgZ5buVOSUaXP1hSJUocvecUtLSQdJw5Wt07fQcn8wfzcLP/X0TMoQLe8GGrSEnIdWkPLwghhgvM3fCFyE3GirUkQ/7Z35Do7uv8hMWHds2Yus+/xnq9Jd/sflQHq0bRtK2kX+Cgq/GIMeU2h027ptZbnPyXVYFSgoJhEAP2u60oXbs3jfDf4k/dqb/Mko2ZVTmhZahdmLK5hydXuS6yaVexwWLtKgOY1yozwW879H3+cr3OHfdKb7Zno211EF4uJGLO17JwCDcAXUBh8vOJ6vfRNA7ETQC+dk2rHbp+Wk0cPJklnJsbGyUQp7z5PUvK6WCKkJVKnaESpJT1bb7JX2K1eEir8TBFdMl0vJAZgQ/815KIghw6lT5M1g/ZTA9LqrYFLTlYC697/sagGZNGmJzOMjMzPGLHAHv6BHFifbXBvRllJG+qEjwBpqw1IkUFoudaT8+RVwDM5u2PO17unIMgKkKgjdQPzo980tIx9ZI41XfHFQtU0TWcOEWLBY7PSf/ysFb/AfeymmXKn/71mK6sldwXtmghTd9bM5F1iKmzJM+ukD8sr73ph4kXWI/oU8ZM9nsCbN5vEzjB3j+treUv9V24lnjPvQiE1Ivw0IZdJIALH9tLqdkytHpRS+NvjKzioxgmT7quF1Jww1dy6soZlu2Ubdo5qKn5XdO55+gZVJb+qf6F0+tSxTYstiwdaLyW7bzlpba8DXjhoVJyTqXd72+SkJX/ruy9xqqpuQ7MVfUts4getXum+OsmAdk+ph3+HnLt/y1aSmnTmcRFVW1KI7PVhxj5AsjcN17NRf0epGIaLNiO/aFbwRBdlYR0S0nBjy2MgQzyZRY7Gg1GvRaA0Z9GG2TO7HzxFYlGicsTEdenlU5Pjxcz5ns2dXqg4yqZL3VSPD6FjKUl6CVCWClGGWfyrlONYKgmBHU9iqLrfJ40GChNGqzyBSVsBz1upvFU8tLqqvvb88rnyvVfuV2Lfby/Q/MeMArhnX2A5aAfTLqw5SwunKNX9JgP5lSgstiVEwkvpA1k+e/igxo21WjVfNHiYszeX1c4G3HVq84wDvTpzKHWTCoIwckU02Y37VSEh9WyPMbNUrCLTro0rwnDSLqjgnMF9HmWK/fGo1Ai5bxHDqYjcmkx2azIYoipaVOTp+WyjelXdWZg2f28t3GRThdDvq2HRSwyKrfAKyFisOB2q6tWni+4ZQARUUW2rVsy/2XSxOSybAo6Pkej8hrX+1ipMTwyJqNT3H1FeXOK1EUFdZBKY5cUBSQMJNI65bljvmDh6fRukwIZ3x9B+YyE4fvGA9mlhFFkV+2fsffB1ehETRc1f1G7u+5j95Xify2tzHf7DGTa3Fw8OApr/bOZM+WtO6KHlQtotqCt7i0CPDO3ZYH1vxJ2oDC1+/j8XgQ/9qAWBavqhas2+YOp33zMqLdSlIMFZtTENrEtP6tsJQ62bvhCJ0jPmI7dykaqLwslqMUjCYPOoPGT/BoTUbadG1SnmO+6h/wODGZDAFjbY16ox87VCBYVAUsx7xc/gGqtW95ma8Js3tlV80YUx4Tq9bkP3jUQk5OScDrTZn3iMSVUZa2Pei+aTRvkYDFYldss5JwjlPO0enFCifTQGFa4G3Pfm/Ch8if2+msWcpS88kpVzB/3np+2bqYkQPu9WujujiUuY/dJ7cTFxFPnzYD/UrkmI1mZD7ent1ewO32cPBAFoIgKDSh6uUwwHebP+XQKWnAezwiy3f9RkJkEnd3LdfsAmk9NSkYWhEnbDDFwhfViVFNSIhk56HyWof7pgfX9EUgNs5bQ969+wyJifFkZeVQWuokOuIeLxOXUR8WUODH7zugfONHPvuDRv/5L1BuaqjMDn489wh/H1xFcbEFrVbLks1fcUenDvQa3Jb2/UU+ue8nSiyByeBnP/op919RN1WtfVFtwXukcDsWSzdFaKhjTX1RIaGwx4PZqPWqXBFMg5WPCUa2How20VLqpOEIFT/B41rlpc0a9yGjXncr9yGFg/lre23HD/O+1sAeRABFlr7Ksn7rK1/Q9UkphMaoN6IVKze9VLbMUtvf1Br1y3e+5XWcmpJRjxRfHcieDP5cGTohHZPJoEw+U+Y9wls/RShLr1tf8vDxhOABMNWNlujRvQ2j7xrA9m0n2bQmu1ptBMKRrIMsWDWHxo3j2LJzA7nFWVzrw7fgcghMvf0kH/31Njk5+QiCQIMGMYSHBx8SS1bcSfcuz5OfL1VHSUlJ4OsNn9LQ0JAr28dXyjhWE8Kbqrat/h7UUNvqReDHfxbRukVzDh45CkBiYjw2W6nfWE59bHjQahBajcDKtd7f1Ie3pvL74X5M//Llim5LwbKJg+g2sDVmXXnViTYjyyOcLDYnx7dI3NsVTVw2h2Snt9sd6HQ6PKYw7C5JDrjcIsWlLoqKipXj1eGR465sw9kqK11twTtjkSRwZK3g4OHAdV5CpVoLJX000DEH5t8S4EgVjAby2rT2Mu6rSWKM+jC+f9njFfhfVchCe0PO1Wx42MLIF3Xc+CwsnmqqUFN0OQRlWQXey6zKEGUKznUM/vb3YOjUYTLx8RFe9i2dkB5Qiw8Fk0dMxSW6SIltzMPvl9sVXQ68KkpPue155q94j3ZtnsblcnN51+urdb1AOHhmDw3iIli1diIvv/gziz7dgs4gUmQpVOLNp495B7MxEgCTKRxBkOx++w6WCwq1VxwkZ+UNw3qzYf1RoqOlcyMjjbyz9gx9mkUHjcsOpqWphaCv3T/KFE2RtZDOM6W42fVT3JgMWtL6t/LiN1g/ZTCmsuW4r0AK5INRa5mX972Sw9l7GHVnPxZ86iFMiCS3JJuoqJqn0Q555Q6ip37K9LLfL6e/6Vd3T+0LCDdoFcEaSFbs33iMA47gEQkyWiS2ISGqnFKqfeMuNDCLSvTIsAua8NWq41it0rNv3eIxGjdKZPnrl5AQcRazJ6sb1aD2rFssdi6+8C2u73Q3idFS/lFdcluqPzwvb6eqLMjJr5bx9YqjTJjtzU6v5l2VP3BfW6c68UOnF5W/+yQuIvWx4RX2Tb08VWuowcwvaq00UIKDWuOdcf87RJmk2bkyO/roGS4vZ6Q8s6trpkHgLEOdkM6M+9/hgdnS8lG2ywWDLEDW7FvOyj2/A9AkvinX9xjJk59MAAJ7008XZHAk8wCJ0cm0Tm5HbWHr0Y18t/Fzbrq5J8v/2k+8uSG/rhntZzqYM34BGw+t5efNi/GIHvQGLYePvurXnvq8li0bYrO5EEWRcQ8MJiEhkuef+5GRA8fSOrldwFRdgE0lUtZlmFnkpmc9fvy/vlDzmsi/L0yS7Kydny1PYlg/ZTDbS+7yOld+H+qVHFAW6ue/CnKJ87h1xFxO7vXQIrEtucXZrNwuXcNkMvD6ne/RK3YB7Xo1V87xHYOCQe9HXSou34jMR52S+CDZ2cWKuaHUYWXd/hXYnTa6t+wbsBjsHz/t5MqZa5T7D4U/BaSIlf2n96DX6mmTkoaAwOmCDLpE/0iTGAOLj1p45VOJvvVU5tsM7P8aT9yYptRhrAl0Q0Nz0FVb450/SYsoimTknSC/qJBbe44nIiyyTusUqTWKgGmoZbbgnCI71z27jFKXhwk+h6i9/XK0QbBlGXgLuA1ZI0j1MUOobbS+qGifDPWsb9QbAwZjl8cmflthW94YSWJiVKWkNYEgVYf+lt3Ph2aPNOrDcHlcrN63lFF39OPSyzow8tYPycg/VmHoWkpMI1JiKq54XJ3g9D6xInkll7D8t23EmBpxVbfgk2WvVv3Zm7GDQvdJr+0Lpgj8vvlX1u/35hOwWp2IogetVsvyv/Zx/HguWq2GlFgp5tU3Znl9XrrfxB4Kwsz++pCc8ajGxvzbMJbpHb6FLh98F7/3HyjipGfXF8nKLuLUqSzWss4r/Csl8UFcDkFxLMvwJbcRHU50QrpXer4aaru+KIp8tmYOeZYzRESEsX3FRu4dOoloU4xXVmfjuPCQQh997dsGnZGOTboq1/rm7wXsOL6F8HA9ZoOWYpu3jVcURb/qF3WNal9NEkgCyZHNSJZWXXWm5fot1SrhOli/J5vsQhtrNzzJ5Ce+4eVXh1WqYVQXMsNasH2V8VZEmaKVwfDgu3eHFC8ZCgIllAB+JgTx7x0wuKfXtgGXpil/CxslJ+bGfElTCqZpCwhoBAGHw6Vco6bptdX9nvasPcTkQZlAsiL4wE1hyQd8OVWDzVLer92n/+FUkZRoYLM5adb4cW7scztpjTqxcscyrKWlpKQkKKY/QQCNRlI69uw5jSDAkA5X+7FcVcWBJts31b6Lm571cNOzEvfAwikatGXhfOvz0pk1rpwWVNYC3YKNx+eNC0pjuW/6V/SNs7OedD/h2zahGxe1bsGMxf4p9KezZvHe/TYEvRZhqKTR+pVa10r2f5PJQHZ2MTohHcfvY/lh4ymuV1VgyfhyFLl75pFvdXIy5zgzZ42g/wWt6dX9RY7nHKFT027KPYYCPyWvTC6szhnJit2/czLnKHGRCew4voXnX7yO9DulKuVqWdAw6SG6dmrGpT0ahnTN2kKtiPm6NCsEitOrjOugUVkV4Ten/85PP25jzgfLsNu9qyHPnTjXawDK8KWzrGiJLUMWNOowNTWCmRlkqAdBuz4tKr1eSJAjQcqqTyibfVcKYrkmIxPEqyHHgqaVafrBVgZajZahna7hi0Xfs+jzjbRIakW7RhVzNZ3IPcruk9uINsXSq9UFaDWSrbKy7ykYtaTv8vf4luNKrKvUb6nvRpWrYPoXXZhOF0AiRO/a5AKaNmjBfbMk00BUlBmr1UajRvEYdWGUlJaQnV1ATIxk8rl7yATiIxOV5X1ly+EvpmpwO+DWlyT+X3HFRixFpYrQ/XnCBcSZDV6TtdGg9bLnq/e5HNI3O/p1HWPemuMlVDK+HKU4qtp2bVwe/VAesALA3O+G8t00Da6v5wHQsvmjXvsffPdu/n7uEuW3cGEvXOI8sn5YiUmnIeJKqWZhkWUAJT9K1Kqf/HGIqZ/t4N2lxzh2PI+Rg1vw4NVtSLswFeHCXhx/FW4e/j5LftyBIAjEV7HKxwWNPyf1MUkZkB3pspPxwKFprN6TjTlCz4qtY4EbmD9vbdC2kgwCxVYnkWeRprRGgvdsmBWCzX7B0i4BurWK4+lbOvH+L7vQIGIyheHxiF7VEURHuNcADAQ1TSV4e4plx4WaCD3SFMWc8QuwOgu8SINOZWeSXZxJkwbNiVIVUKzOMrrKKAvZq3B/EG91IAQL2tcZROYs6Q/0Z8aDWURoktEIwSMh9mTs5Iu1krARRdh0aB1vXx9HXFmV2Yq+J7VmqLbx+y5/q1O7LMYU6zURFhVZaNgwkX0HX/KymUdGeujdpj/xkYletthAS2P1d9M3bh4YYffzge/xyhlrcP5xD3te+Vx1fnmttIpir0ESyrI93/e9NkhrGJT/9rbnygfD4aNveNF+mkwGNHr/kLTEawf5fVvyu/hjyxmGDGnH4Ivb8fSU7/jgp338uP44y9ZPUWoHfvHVvQzq8izX9ryZlNjGiKJIUWkhOq2WI1kHKS4tol2jTsSay2cKOfEq9bHATvW0/q04siwDa6mdYxnlGvyo9P506zyVLdufxWw20rx5MjabG61WYMdpKxdO+oPnLmvGbTd1DdhubeO8q41R1Xz19XnpdI74SKGEk4sq3n15a+6+vDX5JXYmf7KVXccLGNihPZOGt+fgxmOYDDUrrFhR1eUoc7RiW3vi9u0sWLoAjQb0WgN3X/wQSdHly5q0/q3I+DL4gKgVVJYCWRb/bLE5wV1W461sAKlNFvumfxXS5SbMSqww/Mwjevhx8yISEyOJT4hkz+7TZBedIf3zbL6aPJCureKCnltVVBbCNWnkZl5f0B2AuIgEOjfr4XfMuEulJAJ1hENKcgP6tb2oSn3pHPGRQqsYjGxGhuzI8u2/zOhXEYLV+PP9xuLjIzh09I2AGY8dmndh427JpFCRnyD6mo8oskgrKtkEkZVfytdLdwGwcuU+JfX4zBnJ/KZu7/0b27A+rzce0cO3f3+m2GIBdDotq/b+zpiLHyUlKbYstr5y5rI+7eL5e3+u3/YRPR/g9bvyyMg7zkXtrmbdoT/YtX8qAKNu+5BFW09x202VNl8rqJHg9dU6oWaabyiMTE63kxJbEVHhMRjDpMEt6MsHuW/Z8tgII+892MerDcWGGkATcjkEr7CnYKioqJ7LIfDe/S4vTSgyMoyE+AZsz9jAJdE3eB0fjHikTqDRlCealAlk2RQRQbkHX9Ekna5q12gLBoutBKvNyutv3kq//q3o0fUFNBqBcLOBD345wHsP9KnwfDW1pBq+seChfE8tojvz8h2ZFNuLuaXvvYQbTH6JL5L5wNsEs3Lto5jNRj6ZVL6KUqd/qyGvbJp2awFIgtf3O1XfW1UweoaLhU9pmT9JW2UHXk5OCX16vsjOPS+QlVVEl45TFMdYjvUkkZFmLBZv/o+srCJat3gMoFxACunkfj+a8e9vZP3eHA4eOa0cf/y4N12kGtcNnsZ1XaSit4fO7GPH8S089/y1jL5rgHJMx7Rn2JOxnUfnDgjYhrh8o5disWftIS5LNLCj/WVc2X8+TRJa0K/tIAwGgZR4iWI2uUECP/39PRpt+Rie/9ndjLx8ul/7dYVa0XgrWvaHglAp8E4XZDB/xXuUOqy0b92cX1eMA8BiuQnKOBN8obb7ydqwjKB8DiFwTqg/8spsuAD5Re+rjq84E6xGCJK9J0Nt74WyDzcIqrL6CGXCcrjs/Lbte04VHMeo0/D8cz+SmBSFRiOUdV2DXhdcU5YRbKKStfSqUCr6Zk/NGb/Az05bUbWRO1/XIzqkicnutAVNWqlIoAYrehoIUuz8GK/Ig0Dp3QunaOgWcdQrGmHZxEFKeavCkg+Yevd+Fq38lOPH82jZ7BEvTfTI0XLhqU6OSkyMCkh4M+PbPSzbnklRUeBUeRmnMstTia22GOVvp1uawNLSUryOdzrdRIZ5a/BfTtVw07PSt7133UG/iItNhXdyUYfy3x4n3DrNe+LcfdNhvlzuzXzer108VrsLk7HuDQG1egVfp1dVz60Mv2/7gRJrCYVFRYrQBcmuJVcO8BUkas0okJYRKO0yNFS85DmcVc5H2r59syq0WwP4ONKqYrsFyPphlfL33g1HFOL1UFHZZLJ0xxJ2nfqHq67uzA/fnSE3p4SsrGIEQUrBFVwuxl9X/Xje2qBVVKc/zxr3IWazkVGvu7H4yJNQKqyoIX97aq28OghWWMAXUkLQLcpqRVEqxPLrt0xsS0xEDBdeUHFBgOzsYi/h2yHtSaXyCEiTysSPtuCwOykuthAbG0WftCR+XXvAr63ExCgvW/mw7ndi1IfROrkdjRo0ZviN79O4cTQ/LHlI0axnHXqTVg94x7CXm7Jur1Yq9qtfevMUZ2UVMX7mcsbPXM6pr0eREB0e5Mzg2LP20NmpuRYIdUlm7XQ5cHvcOMs87xaLnZTEBymyzMFsNkpxs+H6atG6VVVLV9s+e8UuYF3m7V7780qyaN68IXsPvMCHc1fRo+sL/LM1MCXd2YRfmJnKuZZg0nnxmdb2u7RZtzJwUBveeGs4WzYf4/DhHCwWK0VFFlJSErjnyja0SomsVtuVabm+bGvyJKF2jvqGWRVbizCbJW+7r8arFh5VCe6vrQKflWUWyv1dkelduFW9KjEZTdx72cPsydiOrZNbcai9fOdbXnweIAnfI5/+RvOUKHa+c72yXVyxEadH5O99OegNepKT49FoNNx4QZOAgvfzqU5uf65c6FltFnad3IbL7WJEv7t4dM79nDwtZcHKmrVOSGfCO/d7vR/1Mw/lO903/Ssl+SlQqKXafj940u+MvLgVjwxrjyGEFVh1FM3zzrlWEQamDSUj/wRJSfF0TH2Ov1b5h25ZSp0cO11AlzESL2jGl7djDquDMBEVcY/odPt5+5sltMK5w80Vl87kxPE8GsW0CBqKVRcQV2wMnOEXgHAIakdbDAZZIznaKIL//rGbHl1fIDfXgsfjwWQKJzxcGkBhATznlSFUs0IwtrUH3onggXek/vmaSibPe4SPJ37qVzIKJM1NTZCkaF1TBtOkSzmBeE2/PbdHJLPwNBFhkZiNERj1Ycwa9yEBCvqSEPcAjRrFs2b9k14x62rnrzzhlEdHhAN9+HiCjsHdB3Ldk9Yybd7MtG+8CaDajPpcWjH6RMIs+TuDUoebvLwCzGYTpnADnXzSleVY91ue1XP7c+Xb31ryIoJGivn+feviCp9FdTlB+sbNw231XgGKf21g9o/7+GjpYbbueM7r+EKrm/eWHOCnvzP485WhGIN8l4HGzFkpdnm2kdqwAw9c/jjZhZk0jGvMNz78G7L228UnNbSuy4gHshU3jmvGbQPGsu3YRro2aceg9pdU3Ah4pTyrSX5Chs+ACDVSoqb1oyqCOib32b4tafnXEV5etAObzU5YmBG73YHBoEcURZ5fuJ0OzaLp1TY+5D7XZr/tTruf1hss8UYnpCvOJalclbbWQyqLS508+M0BDufuQCNoGNZnJB2bdMWoDyuLbiifTKLMY4mJiUFwmHl/fGB7tNohLFXS9h7+0uRUsQklp8hOXIQBjUbgeJaFPScK8Xg8iIBWq0WjEYgy6jCbDUGjIUwmAwePTOeCvi9jt5d/4y4R2rdp5GXWsFjsihmxqglQFcaDezw8cFUbbrpAqnwiXyM7q4h+fV6hqKgURJEvVh5j1MUtsTvdGHQaJSmopmPmXyV4ARpEJCi8rXanDavVQZR5LKvXPnVO+xWofEvr5FRaJ6eG3EagTLPaQsMRC5Slm1wuuy4Frhrys9FoBO4Y2pKf/z7J+r1u3G4PubkFREWZMZtNuNwePvvrSKWCtzr9lour3vqSh1Gvu5XkGF9WvShTtBLVYHfaA1IXynhr3Fs4S8MUrtrqOJYrwlerjnE4t5Tc3ELM5nB+3rxYSYVVpxR3bP8kVqsDqzWLR+57CqNQTteqjrRQO4STEyYw5i2JV+CLqRrCzJ6AKe6///k4785aRu6JHPKKbPR48GfaNopkwvXtePC9Tbg9IqIoEm3WA5FEm/W8+2AfKAnuZJO/wwOHX6VJw4kIgsDbs28hPj6CW0fMZfHTl0gKhF6HWVZEVmxUCr9KadKVm3bUPqdg7yUxJozDX6+g5X+kqsQXXPsODoeD0lIbMdERZBfauOutdSzdeoaEaCMfTehHl5axSvvVRZ0UuzxbMOrD+HjipxRZ5tCqdRIHj0jhIGrP6f9nFPwwmowvb/fbLlzYC2FoP7QmY0BGK/lfdSAX8xw7c6QX+5Ya08f0oFmSGa1WQ1xcNCaT5MgQBA2/bDrF/oyigOfJRRzX56V79VtnEBk9w8XoGS7CIgL32+UQvBxTsunh8etfVYoiytlhMll9oHp7amgFqRS6uj8VFbEMCRoNwtB+CEP7oQuXru/xePB4RDyipB3anTbFqw+wc3e5o+ux9x5SiPbnT/mUCXPMjJ7h8nufVqtDCR28+dlydj65Ii9A2xbJ3Dd2AV9/O45lm55BMErmgn0ni3huwXZKbQ7OnMnG6XRhd8Ojwzuw9b1r6J+WELTIgW9WnIxVKw/w59I9AMSYy+woZWYxcek6cLowh+sxGbQh29MB5d1U9F5axBhw/raGP9/4luQIHWaziZSUBCLCpZXY0q1nKCws5kyuhUfmbgIkE1B2USZWe8VRHMHwr9N4fSFnBVldFh6YLXk9ZXKYPa98TmKsqZIWzh94ZQFVs+6TGpWZWFIfG86aCeW/K8uKCgWh2OGaJJhZ8fql9B7/C5miKEU0CFBcbMEVbmT0m+tY/cZlyvFVMSv4ZhtWhihTdJVq0J3KfFvRChdPDfOK7lWHVf6zfL+S/l1dU9cdU29i9hfb/q+9846Posz/+HuyLdlNJ5XeOwgKgqgIil3x7iynqIingCIqKuIJWFDRU0FFRH8UET1ERU/RU+EsoIAQxIL0LkUCKYS03SS7m53fH5OZnd1sz26ywX2/XrzI7k55ZuaZzzzzfb4FOcZ3RJ8rAf9BFFq95K7obtf2VcBURs61AFDw8Ri2H3Xmrt2y7UkSE8aRkpJEeZVd8UaxWMycKHLmh5bNZOJ3mzlaYqHt36TRZGFhOcVFzu316/Mk1dU1JCTE8/FHPyMCk/7SnR5t/RdjDRZ/aQa0mjguPCOHC8/IYf2OQv4otnBBn2yWrv4dARGLpRqtVktJuZXKKhu3LttFec0ORBGGdr+EC3pe4mm3Xgmr8AZarDESGLUpLJ7k+t3g9FqvJzoqCYPYKtTZixOB0lVaflu7n2TTOKWcDchvBuGLEgsGQRD48ukLmf2fXXy4/jA1VjsVFWa0Wg1HiszsPFJGz7YpYTWHBBocIyOPHNW+uV/ONjLmedfbxt0FLa9kTN06UrBEIBVyvTH/+m58fOB8khNSyEiSAgDKqorp2H4WBw/NBlxHqVK4cP2Hj1xFRPbokKuXLJvu9PYwmQxkZiZhs0H3tumkJxkY2tvVrcpms+NwiHRrlUShJYGiolPeG2+30yZZT9HH3/HVz/ms//EI/xp3LuX/XUvBqWqStALGhHiG9s5izl0DSDBoidcHP8EaKIHGG5zXK0v5+y9DWvPm//aTmyuZN2+/pBPT395CidnO7Xecy/9W7WDt7v+x5fBmxo/wPJr3RNiqDHurCQWNK8CeiGQSH3fkV2FPnCjN5/tdXyE6ajmv+wiu67KG7ud0pKLKTlKCNvRsXnFuFiOHQ8kkpcY9Fy/AG/cvRIN0c4WSIMgd92rEg9OX+D3vNzy3lrxdxcrxi6LIBZ1SeXREWzadut3nujK+Igkbiruwur/qeqqqrP5OTlYecP9TXc9d6/fVM6u41ALcmU+fXlKJHnU1hcWTtMo5kW3bMrde/A3ndB2mlKkfnL6E/cVVPPTZAWps0nLPjenHqOEdlPZs2FXE2Dl5VJqt6LQC7z1yPr1uu1jJzqcOqghmYrjWIaKJC/x6+bq/giVQXThSaOb7bQW0zTJxQZ9sbn5hPduOVfLrb4/z/HMrWTB/LbW10rk+fjzf57ZkGiy8/hLlRNJNKRgimdBHjbeOUWOrZu7/niUjOx69XsuRQ6W8cFVr5uQVcCC/gh5tU1jywDnkpAfvuO0usuLqTfUi1MCz8EJo5d4DJRDhLSqr5ryH/oelxo7NZsNgkF7l+7U/m95t+tEpu1uDU0xGEk/C6y7WchLzUKI61SXL3cOC50w8yUPznCMtddUMuS3u63XtNI2Wqe15/RrXKM7DBZVs3F1M55ZJDOjSol5bjhRKbyK926fSOsPosd8B4X1zcyOcwguh6cLabQWMnr2BtDQTJSWSW2RtbQ37f59FsimwAJkGTa6pnxjeGq3+rVGycXkhrBMgIVBSWUxlVSXPv3gtc+beSLW1mkV5xzE7BF6cfT3Fllpe+mRXWPYli25O5kR6dX+k3u/qMk1Go77BE2r+8HeuM1Pief3aLiToNGi1WsrLK4mLE9hy6EeWrlvAt9u/jEi7wsXcCYuUf/JoWLYdyyHI6kmecCLn6ZVx9zd2p7rKxvTHruTgiX1Y7Q6X+7NddiI3XtDeo+gCtM0ycdmAlrSuS7sqrt7k8g+HI6KiKxNOHXHXhUAY2iebZy7vQEWZPIgR2P/7rKCiGRvs1RDoUyJabKyhnOhwkJ6YQWJCIlMmf8S997xHgiGecnsOrVunceVVfcjKSabUHFqds3qJqeuwWKwcOVKizNpbLFb2H3yRTFX2qnLzAka/UKv8CzeBnOtdGw5gttaSaspBo9FgNMaj1Wr4devj3Dn2fDYfWB/2doUTpxdE4LPtgdJjSCcGpy/xKDbvTNFg1Erub0/c/Fz9leuwWwUev/kwbVtNYdL977N40XraZSfS9/wGVtSVhbaRBBcI+yBOfW6D0aiz2iTxyDUzOb/7CK/J533R7L0aQsXfLGe4MejiufX8u/h+59eIdge3nHcTFdXlLN+4hJ7dHkerEbj5svaBbcw9EY46Gk0VhLH/91n1RkCBFtMMJ+7lcNx9nr/YeZK5644BkuuUVqvFarWz4pMt/PrrUUzxJvdN/qmQA3QGpi0FpDy0y6a7Jmaa8e6jyt9nn92NogILdoddCYe4sds6Eu2t+HzTfnIyE3n6zkEezTfV1lo+2XAEc3UtIwe3Jis1/A+ThhJKnmVPNHTuR6vRclGfK7Db7Vx4wQts+inwlAANsvEGYr9TE277TLgIp/032GM8UXqM/FNHaZ3enpEdVvlvh1siHNn157c3b+CMO5YDzvDMbTtmkpGZTErieD6deA7XvOaMart00OVceebfMCYJyiz9sukazOUOjpUcwaCLJzM522cyczXeEqR7Wk5NXskYZv33ScrMp7Dbazl5spQWLVJpkZJOZXUlpngTj1+czRktG1751huN2SeDumdU19r8zSZyr3kTgC/uGUwLVUVci7WWwTPXKJ+373yOS0a8zLNXduDM1s7cF/72K4oio2dvYN32QnRaDZkpBlY+NZwUU+NV3w2Whry1NjSFrbrfVFktfPDDW/zw29qA1v/TjnjVNDStZUPISW1FTl3Bx4Da4ebBIIusLLqAywyznPhELboAvx3+iT7t+tNV31Nxw7PVWnlrzTzyTx0FoLbWQUFBMSCVNcpIycIdtZAGkiXK028GrQEQ0Om0JCWZ0Ot1dM3txePDzei1Ui23SF0TT2lBowad8/Y0jRikJBzXCmNcsuxJpZAk4R0ypDsPPbCcBIOWERd3Izst8MnawtJq1m4rZPZLN3DWgHYMG/oiP+ws4oqBvguSNiXRYsJM0BsZMzzwXBLNOnIt3AQS5dKk7YiLQxg2ELO5Rsk+VW5eUC8/qjfKKudTVjmfxEQDcXECOdpVLr/vyd9B/qmjnDxZSmWlRRFdwGMtOffJVbX9LRgb3NUDrideH48gCCQlJXJGSxNDWh3lkf8e4P7Pf+e/x6qx2iNjQ4yWyV9PCOefRWFhuWKj95YTWM7n+8uCG+iQoiNVtPHWA4NdRFcURaqtvm34yUYdxngtn674lTcXSXb1nCCEO0bgxEa8Hmhs+28g7RB0GrqfK1XOkJOFqJOQqN2I3PMPyL/Ls67Z2Rkk6eMY1DaZlIQlyr4EJJufIAg+3bd82cbc8xsHMopsl9GJ87pdxM+/byDbVEOnjAReW5+P3V6LVqthX/5eAKZc38vPlkInXHbDcONuo3/6rsXceElv3vhiL3dc2tklbWGfDmkseXBIvW0cKzbz16fXUlBaTYdsEx9MHUq2m+3W4RD5ce9JRl/Ygf9sOMovmw/x8HU9ObNz0wTYnO7EhNcLwZofIjVCzisZQy1VjJrpQHBzV1ELbJ+ezsmVoqIKCj6UKnLsW/J3stKMCCpPhhm39OWivtlkJBtc2t6tVW/aZXQCpM8JCfFkpWYzasg4TPGSC1GgExLBCNlHef9mxx9bEEWRMgvsK66mpsaq2Ht1Oi1vfnWAkYNb071N+MNJG5tA+pO5ygZfuHpz9Or6GA6k6LG12wv5o8jCzDH9vG5DFEX+88MRnly6lTKzlerqGg4cd/DA/J9Y9ohrKZ1H3vqV5WsPA9CtTQqfPD8UU3xMHjwRjns9dmb94G1GXk2kIvRqbNXU2Gp4bOkkrpk6W0n2LiPH1du+Hs+J92/BXCO9SpprbLS69m1lOdvX4yU/yzr78N+Htpd+cHMB0sZpuW3Y3eSXHOVw8UHidQlKGkI1wbwB9BjSib1b/uAfj7uWXpEj4xyigwPF2xFFO+XllSQlJSMIAnq9jpSURPR6HYIAxAk8tOgXvpgxPOB9B0tjRFoG0p/QaUmtK96qxu4QEQSRoqISkpMT+WbLcWbSz+u+3v/+EP98awtdumZTsbeAhIR4RFFkw84ijhaZaZMpeYucqqxh+drDTJ1+BYMHd2TkVa/x/baCqLbtNgXhDAaLCW+AeDI/ROpG1epFasVq7p0zVvmub6+pnCh6TSlzJAuwcfNWaYG4OBKvlCKJpPn/t8nMTFJGxOLqTQjDXNNOit9sxFxlw2KtpcZWjUEXT5wQR+sW7WjdInzliuTM/2rkZDal1SfYe8CZWLlNS8ndTRDAaEzAbq9Fo4mjtlZkzx/lzPvvHsZf0QWtJnzTE00R2u7LnOWeHvTRqdfw9My/0rP7Y1RW1JCamkR8vIGefpLJfLetkAED2/HxinsYd+c7rPxyKwUFJ8nNzeS7rQXcepGUQcyg06DXxrF92zEl9DUpwjmsmxvh7iMx4Q0CT1WVg3GhCvSiSTW+HIxVFT11D/WVY/JFD6WOZFEuKqrg0O9FtO+Q6XVfqSMX1/21hrLK+fxnhjG0XAc6LZYBfRX7c37Bq4jrfqbVdW9jF+vnjZDR6zxP3mg0GqqrrRQVlZCRkUpcXBw1NVZe+GgHRw8Wc9vAnODb6IOmsOn6qtKtttl/+MFm9u8vorJCuq4JCfGkJBlY8qUUKmz/bjMaux13urdOZt7ne5n84HK+W7MHh0MkOVka5crRZwBGg5aZt/Vj2ttb+OzT37isezrn9fLeZ0KhqedLQiX4+/zvAW03JrwhEOhNqraHBuq25C1sV50/Vc6W743Kr/OUvzt3fBi7uIT5K/cxyuog+TJJBL1Fu02cd4eLyOcXvMo3r6ZRdkq66S1eZsaFCwaCygyinhRKNo0j/8PRUhmcuDhwONi96SCD02sRdBrkoID+fWfQo1Vf+rUfSGHZcVbvWElWVjoajUax+aalJbPuUALdOo3xeQ6aE3klY9DqRQamLWX35kN012rJdDiwfXs3FdU2nln6Gx+s3Y8oigiCgMPhwFbr7CfaYQN544G3uevKri7bnXBVV0rNVvI27mNI9xbsP1ZOaaWB2y/pzLC+2S7L9tHaWT66JxtP3sjwnOXs3ngwbCLpIl6+TCxRRLBmhWA9YmLCGwE8BWQEM9svVwKQBfbNqSc5L/s7+p9dly1q0xaU204e7arK/hQXV7ps747b32LN6j28/tlu3p1SSu92qcpvx5aP9lkiqGX2fZRVzncpu2Ib1tXr8p6wWKxQ6xpa2n1ge0A6HzufWkqN3cH4oY+hrysm1imnG6t3rESjkdIE6vU60tKSiY830LqFtG5ReQH7T+wmKSGZbrm90HkqRNZMkMK1b1I+73ruPboP6kiSXsNzY/qz8qd8SiutlJaWYzIZcU/o9dzyHVzUP4cuLZ2TqAadhhm3nAHAj3uKeWTxr8TrNaQl6uuVsAHYUvEPEvQB2qEDwNNoMVo8hrwRquAGexwx4Q0z/i5EIKNfi8WqmAv+OHqSRKEL8Wo/Vj9x8WeM/dDl89Gjp+jYKZNau4NXV+xmwf2D65zuwRSvZduzl7L51C0sm15Tz6QhB2iUVc6nU/uHXETdXGVTTBXHVtjIvmaoy2i8ctUGWl0nTfKljlzMseWjyXLzC1U/kIZmLVPOx6otKwDJtc1sthAfbyA+3kCv1v24qM/lHC89xsJvXqbWUVvn/hbHtYNupneb/j7PTXOhx6OSCO98aik9hnTi4v65LF97iKqqGgwGPQnaOLp1nsapU2U4HCJGo4mSciu0rL8tq93BHS9vpKSiGqvVzpPvbiXFbKZHtmR28CYwoYqkP/HyZWJpSkIxH0JobY8FUEQZdqvAmtdTyMpKJisrmd2fSIlMGhLYsXfPCe4cez4ajYCjLkI8deRi5d+B4xVs3LWRIwVHmTthEc+OeQmQRPd44VxSEseTkjheEV1P7egySkotaTIZMJkMGH/aSlZKPKWfOdPk+RpZqzuvKIpsP/ozySmSN0V5uZnKSguCIHD1gOvQafRsO/wztQ4HgiBQVlaBxVLFih/fo9bhagqx2q1KyZxo5q0pNpfAGHf+cUknEgxacnMzSUiIZ+LIbvRqnUR8vBGj0US3Vkn065SmLF94qgrdxfPRXTyfEyUWyqvsVFRYKC+XruGJcmu9EkqeCGSZUNdrqoRVvgjmWH1lZfRHbMQbZvyNEgJ5qlaeimPxpPrPRHnbO3/Yz1s/nmDlnlNkpsTz6l0D6NMhzcOWJBL0GqZM/ogko44XJ9d3sL9vxSHstfsBuPSMazi/91AlOMOTEPxUeZuSySwz80OKiiqwWKz1ysabq2yYq21e2+ULURRp07YF27f+QXZ2CwRBQBRFtBppBJ4Yn4wc41FTY0UQBOwOO7WOWjRxGhyigxWb32Pr4Z9J0Mfz17NvoWtuz5DaEmlqbJIHy9i6bJ1llfMxmQx8MCOOPnXH2KtdKl/NvIiNu4ro0iaVAV1acNOFHfli41HsDgdXDmzlUoZc/ZBLT9QzsGs6P+2VHrpGfRx24x2Ndnz+iHbzQySICW8E8PQq5f5bQ7a969hWlm9ZQmWlhdLKasbOyeOdyecC0KVVksvyvy28jiSTgQP5lfTpkEbh9j/YVXCKNQ8PZfiLUkIPo0nL7t1S5vw803eIWiujkfxl3XOMqqvWAhwvnMuLN77CH6dq+HFPMWd3kyoEq80QgMvI1x+CIDCs5+V8tfUzlyi6rOQcdJq6kuqdz+Vg4T72Hd9JVpaUP3ZApyGKjXjH0d/YevhnHnv8Klav3sOnP73H5KueQhAEyqvK+PyXDzhZWUjn7F5c0nckf5w8zA971mCrtWG1V5NqTOOCnpeSlRJe7wl31AnT1SybFke1Oc6lMlP77ETaZycqCcgTgGt1qmoP7pVI6tjz4yGmnpfL52l69pb3pl/7gSQlJHtctqmIVvNDpDhthVdtg2mq8E91Zwq0HYG0u9Qs1bmqqJCy3x/XaLh4mhSpdnHXVJdlzxj7kXN7dSVo8krG4BAdTLimP3n71vLLzl+dy/w6uZ7YvnH/QgDsNqEumMLV82LuunwQHazYvo73pl3AkAlXkohzNAyBF3y019o5XHyANhntGT/iIX7cv57jZUfJSMzmyjOvU5bTaXTccv5YLFYzB07sJUFvpFO2c9KvymohLk7g6pFnUFpqIW/DAUREBAQ+/2U5p6zHuOpvffj3O+sxitv47kApcp4+URT54+Rhdh3bzv1XTCPFmEok8Ca6gEtFZBe8iCvgkrWu9HNbnffI78o1b9MW2jSoxZHH16AlEJqLWJ92wutu9I6G7FOhzI768n7omtuTb7d/SW5OJtRVej1xohCAVbXe7ZmbT92sRKF9u+1LftizmpQUz360HdtNRqczsPTmHpybLh1D3WDTpWjknM9nkp8v7Ts7qwXLV+5hyASpGu7xwrlohTEcWz7a7/GDNAm0eM1cJTvawE5DuGagb79Io95En7b1J9R6tO7D+r1fc/aAmQAM6nK+kuLSXPU7l17VjxlPj2T1t7vYdLQcUQSz2YLFUk1mZjqiKOIQazlSfJA+bc8MqP3B4kl0X7lnHsuma9CIDSt19MeufBwWK1sro8ekEAyh3KtNkV0wVE4r4fXkURBK0pbGxNvsqK9cBy2SMhk/4kG2H/2VGls1G/Z8r/xWUFDMIzc+Qet0aWxTY6tRbvAaW40ivDvzf+XW0ecw4+mRDOj/ND/kSbkenKPdOOIctXTu35rURINLO8otZUyeU180RGDx6t28gmQbVrugBcIvf1Qq2dF0Oi2bD2xgWK/LMBmCz8WbFJ/MuAsfYt+JXSQakuic010519vaJPLu0jy+W72bP46VkpFioNrmIC4uTnFfk2mRVD8VZjgot5S5fJ41dh7JxrpIND8ZsgsLyxU/aXUFY3HdzwjnnwVA98k3sHiSVrIfv34nIPlkr5qVFvZioNFCuNzgGoPTQngD8aWLxuxTgbbb00MjMzmb4b0u48CJPfyw+zuXdYz6BEVg1WaD51f8Uwkh/vSilqz+djepaUa2bHvSZf0RQ5/nyBFpFJv51yXYvh7v0o6+c77x2NbCwpMAJBnHctngK5XvW93wjkv+WG/otZIgaLWaOgEUiBNCL/edGJ9E//ZnA67n+sXBHem/5ncOHK/kolG9OHbSIvm4xhuUfAYA53a/kJZprUPevydqBakK8+PvPoDRqMdisbqKrj8cDq911Xav30uPOuEFsNhKmfT6ROVzy+z7WPzwv4Nuc7Sly/RHKJN1je1V0ejuZMHmag2U5lT7TT4Hgbqj+FomO7UlBp2erMx0srJa0L51G9KTnOGe6jpqRUUV7Nwhldj59NvbaGHK4b1//+SyPfGbjax4uH6Ir3vHzMxMwi4uoaxyPm/cv9Bl0q2qysYna1b4XF/N3i1/IIw4h1sW3M2Znc8iJSUJkymBS88YSYI+fPlg5fOoiRO49aKOPHlLX87vncVfzmmDTiMw8Oz2XH/9WQiCwA3n3MbFfa4K275lxr6sZezLWpc8ygad5yKJNbZq+j7xDbqL51N4qsrvtrsP6ojZXKPk71WLbqg0tDxOUxGMq1ooeRgamre7UUe80f7aH2kiUWI+MT6J24ZNYP2ub4mLi2NYr0vrKjo42bp9Jn17TwOgb+9piqvY52tu562HXd29dm044BIWfGz5aJeOKb0if6OMnE0mAw8t9Fw2XqZvj97KtsH12HdtOEDPx53l0f969k2c2eY8nnp3Gm/lL+TMDoP8FpGMTxQZ9YzU5nemaIJ+lY7Xa5g5ph/T3v6NnzYf5sIuafRo3Teobfjdh8mz7V1dmdgX6rcGr9GGDoeLeUceUcu8MuG1gM9NJPpqU+DL/NDQxDcNcYNrElNDNL72R5pIjhzatGjPTefdoeR5qLFWcXddZrOrpr5KRmaS13VveNKhTJQB2K1SZ9o6YwQAJ3fVuZnVXSNvs/DeyM3NpHNWd/JK/gLUn63OKxlDT5wJXgRB4Kl3p/ncpiiKHD15CHNNBR2yuvKPZ5zduNxSzqR5UhuDeYX/+9D2XDmwFVXWWop3HCOvJHwvg7VUcc1UWXidD8Ulj9iDqkwsjDgHcfUmstIS/JpujEY95eYFih/2axMrMepS/e7jdBFcd9xFUv19Q7cLzn7dZ0Rg6zWpjTdavA6CIVQzSaQ7sVYvKmYFs9nB3XOk71tm38f+gy8qy8l/52ROxGKxcrxwbr1RkLozyX/Loi6PorIz7uHkSTMACW6uYlNueIzDxQc4UrqXdT9Lr7tLp9ViNWs8bttV+F3bMjDtXYx6jUu7Vm9fybrdkp05IzmDCUxRlp/61gPK35MX3sOC+5d6O2X1SEzQkZigo9j/oj5R9xG5EKV8PeziEqePrp/bz6CLJ2/acHo8emPA+y797B8ubmWyjd9QM5/B6YFVkzidBFeNp77nC0+FWf1tu0+AbWnyybXmZH5orvYuOUPZsukaVs8RqKWKA4dmA/Dpc0av66lFVxb10S8sQCuMUUQX4OlbXsGgM2DQxbN6+0qWrpfyNZhU1WlvmSkqRTXV24b6Yjt3wiIGpr0LwFnqhDwbllDrEHlq7w7Gjjufq64+g5FXvcYDN/3Iy++dHfD5iBSeRos/f7e3Qds06jX1/Kq9otOSOMJzCs7OZ7Smx1m5DWrL6YI/jfF0HcM9QGxy4ZWJZvNDc3n9Kiwsp2O7B0lL9+x+dc2jlrrRpcAH00wh7+edqe8w+lmnb64sulZ7Det2fcO48UP5Yf1+2rR1HWFp9aJfG6PzXGvqneseQzqx44f9JOgE9u0tYOBZjwMw9/3X6ZMthUI/P+b1kI+rIXh7KHcf1AG5AvB3U4eFZIMWv9/smhxdp1U+i6udkWvuCdTVXHJmTHQDwdt1DPcAMeqS5IRa8TXQ2cVgZiHVHhgNSYgRLnydE7tVoGX2fVRX2zmeX+ry2/6DLyp+tfe+fif3vn4nNTbJrUkqL1StfA6EUTMd5Be8Wu97QRAQ4gTKy6vIbZnC+nX7At4m1K9a7Ile53bm+TvOZP1azyNJgy7e5Z+aSLkM+XoTkisA274eT7pBy4DEt+st4xebHfGbjVIuDIfDp8B6QxfGih2B0Nxc0ICAPI3CVZE66oQ3VNcOeV1vN5f6t2AjyZpacOV2QHDueHZxCXZxCRsWZbNsmudLLQuxWozrbccqsHiSlsWTnC9IWVnJ2MUlzBo7TxE4nUbPJX1H8sH7P/G/VTvYu/eoz7Lk7gR6HTvX1vDOqO7Kd+75Ixqy7V0bDgQ9mgnEbSlS5YVSrn4T3cXzOXS8jMov1lP5TR65WfeGdR/BEkpfbU6EQw+ixtQQDtcO8JxkI1TBjTb8ve7sP/ginTs+rPwNkvlh9LOeHe5D4T/PxXHto9KrbW7WvRQVVbhMYA3uMpRerfvx0IIJynfvTNFg0AXW1dyvY4seLRXXKXWuCYAF948Lqu3eKkeHo4ihN7elcBZIlBFXbwIk0ZXdxbqMfh+A9HQjJSUWpVpJfsGrZG7dEZb9BkNzmrtpCppceMPdMRtaFw3CL7rhjh93t4fLtO9wi+KjK9O5w2QlmflHYwdy27Ktig/usukis8bOc3ER8+cTW1YQxyvjKny6lYUj85V8zcbd4PTxVeeaaOi2Pbm1hYNIblvB4ZCKlHrwnU5PN1FSYlE+Z2Ul+4tAdqGx+mognM5i3WTCG9GOGeQ2IzXKVR9jJFLduW+r3iQMKNFRAJVfruf4K87KxVKl3xSXEeuoZ+oXTXQXY4PNOcvu7TV/7oRFyt/hEEs16vwDs8bOo6j8BHtP7KR1enu65HRX0kj62m8kb+qwVaLVi1JNuro6df74beF1ZI4c6hJSXPlVHqYADIqN3VcDIgon2sNFkwhvU5TT9kQkzQqejjHiuUbrJmGIi3Px5ZQxxYdWslsWXRmDLt6vf2y4xNafgE9eeA8tW2bhcDiIi1unZEqT1w236Dcm6jpsau8FT8gBFUJWsjLxOeDMJ8BmB4PvfBdN0lcDoDn6+QdKowpvpEe5gRJpswIEVmsqYh3axw2abHLaRVdOOo++iSJJqUa6Tb4egDn3FpIanyNVdPDj9qSejJOzoMkRUwDLpmuorhQ8Lh+oIAaynNVqxWKxKPuVbc+nM6YEncfk8uLqTYjl1XS5+V3JFOFwAJ6FNyr6qh9OV1uxIMqpmPywcNIH9b6T3S8CJZQZ43DTGGaFQI8xkiNuyzlnKo73BSu+x6QRMFfbKC6rrlcMUy41A9Ct8zQ6Z/bhb2ffrLyyq0vOq8V43JxbcEctvIDiCaE2DwBBRZR5QhbxN1fPZcvu3+rtVyuMiZoRr7fz5w+1icffiDcYGquSbriJ5JtysMforS1jX/GdP1qmySfXGovGNisEQiRrTRlVJeBNGoHUkYsVcbLfeaXXUWF5eSXbqn7hnK7DlJSIDcnfKotzIC5f7vgSLFlQrx5wPVt2/1Zv3Vfumo9elSxIXe2hsQVZnSEumACK6kpBqTIcLpqjh08k35RDPcaGBnyd9sLbVGaFQInYK52f0ZFcHcIdi8VKSkpgguXuEeFOdobztxqb05c3UBEORLDatGjPJQMv46vNq0g2jcNojCcpKRGrtZYEQwJX9LuW3m36B53c53QjWjx8gqExBBcadozudmiIjXijyqzgD3c/0GAJ5Rjl8u2ymWH40BfJyUmnU0ZvclNbAd6zkdVSpfz2wp2vMTT7P4Dk8iWbF9T5HLR6eGPSIuxWabQab3Iwaqb0cHC3BQfLV5tXAdJDw2KxUlxcrvz26sHZPHPbbJfl7339zoiOetW5LZZN17BsuqbeBGVjETMruBKJh4onn21/nJbCG41mhUCJRK0pZSLGLWzUaNSTkjhe8f1ds1YKvnj74bi60un1zf9Ou6OOhxZKmcqmLJpI6arxJF56DgOA/3uglImvuCbhvuslEyaTFq0whjfuX8iomU4PC8mtrX5XDJdgTX/7IeZOWORiYw6UUCYE1cjH5un4IklMcOsT6WOM+ny8kSLazQqRIhBbsSlBp5QFlzlwaDY5mRP5Ydo7nDtztBLaa7XFMfYVSRivfWI+y6bFKRWGPfn5AgjnOQtC3vVyIlMWSKL8/LiX6kRXGlUbjXpl295QjxjlSLnRL9TWMzfIy1019VVaZt9XL/G3Gn+iWeuo5cf96ymuKKRby150ze0J4CLW7qPkhopypIiZFVyJlmNUc1oIb2MILkSn6Mr4Cpn2hlyt4IJnV5Ox4EeKiyuV30bNlDwdTCYDY1+RvntniusI+HjhXGUb6pGzmhlL/8lD851uXu6smCVQXujdw18OT/aFnDeie+ep7D+QX+/3WWPnuRSXnDnmpXpC+dXWz9h8YD1t2rRg89oN/H3IGDrndHNZpri8kJW//YcSczE9W/Xjs3WfuuxDTrqursLcmATTV6NJjJqTWSFchJwkJ1qSX0QymY26Q0Sz6KrxVWtK/H6z1/XUoguwfIb/ruGeJ9aTsFosVqUGmCcvir9M9p8qMlDuHD/U5fP0m59mwf1LSTamuNiqpy15kPhE14fIsYp9HDr6POs2TKG2tpo5H79YzzQxfnYiG7bey513DeGnAxt9tsVuFZR/DSWQmmHB9NVoSwAFTR+92tgEPeKNFlvQn9WsECgek7bY7FT+dy2pIxfXWz4hQYcgCIiiSFWVjbJSK2/cI3D3PGcXkTwTvHeZoqIKj54SwaIeMWp1InaboHzvvtys8UUsWj2HC4Z14/eDRcpvT93+LDnJbb3uw92u3MLkLOMue3wkJOioqnLWpGuZfR9llfO57/6L+PeSPPLrD67Djj8zUnM0KzQmkXTZbAgBC2+0XLSYWSE43DueupAlSAUQJ85zJk6XhVMeIZpMznLgd78yhuc+acHBQ65eAu5IqSLrV00w6OLrRpp1M/51tmNPyCLrb8SYnpDLpb2vY+PGNRiN8Uy/7QlapbVBI7qaEtSub55yCV/e71qXz7LHh7p4pMy5g/5FRUU1U2+aQW5aK+XYIoUnM5L7b76Ilnu3qYiWKDw1QY14m7rBzck9TEbd6Ztq2+qO586k1ydy+wvzvZaXcRe+YjdzgWzXVQdkyBUpZJyBEKKLl4LdFp5X8TPaDaB3+96MfdnZnZc8Uk1VnfXEoIsnMSHJxQbdv+8Mrus/nty6IBGLpYa7rvmJ4pojfLTqZiWDm8f9tR5C+749lQATT4RqigvmOjYnb4VIEux94KnicDgIpthlwCHD9m8m+l/ID6GGDDdX9zB1u8Mp7u4jmGC3rQ6KUFNWOR+zucYlu9U70/6tiOVrE80888EjnCh6DYAPn7Nz/aNOsZNf3dURZ+AaCKEm2DI4am+HD2bE8fcnnH7AZnONi/CCc/Q+d8Iiah21zP36Kf71wnUMH96N3j2fYOSAG+jTtj8Wq5kF387GQS37Ds502YY6ibvJZPDb5ob01Uj2kWgmXLrQVGYX9XXr8/jKgNaJauFtrmYFXzdfQ/cbyLYbIr7uqEeJst3Vm5AunqR1EUd5HfVntW9uQ4TXnYUP2H0Kr15rYNGalym3niQt1Ujepl3Kcrdecjvf717Fr1sfJyUlwWUbE/6ygQ5ZnUlPyFVyV3giEjdyQ/pHONrRWIRbFxorLNrTvRx1uRqCrXfVHM0K4L/doWZbCuR8BBM/nmyU8vCqE93MHPMSycZktDqRUTMdHu2b7gTjNiVHqHkKJvDlEyuPoLU672MEs6Wa/n1n8+vWJwDo3eMxl98FQWDUueNYv/tbqq1VgFN4kxOSsdtreeP179izu4C33h6j/DagvaunhDuRioQKJR3in8ms4O8+CPT+CtX80NA35UYR3lAb2Vy9FQJpt7uJIFzbDWTbzkKXNbx070vc8ZxUcTg3617+b5Kc/7YKcKaRfO2eN7FbBUxpTr/a5TPifI5Yl03XKPXa/OEpUEEWXPdR7rJpcdz1inP5Gbf8i4cXPAhIpgGTyYDN5mDqqBm0z5TOmVYvkqI3ceXAkQAM73W5MuLv1rI3g7sMZdH8H8hMd62M7ItICp37Axr891v1ROrpKr6BHGMoRU0D9X4I18AtosIbLW5Zp6O3QkNQi5zalGA06hk100HHdg8yauZLlFXO59MX4ygrck6CyXZVgGpzfdH1JbSiKLJ+z2p+OZhHqimdvw25gTSTZ6HzZVYAyT9YzramdmGTbbIZydlkJuco37tvSyvc4xL0MLzXZQzvdZnLqHrZdM+j+cZ8nQ/2DSla3afCia9jbIjm+PJ+CLeGRER4o0XooqUdzQV50mzbzucAaTJp1JOELc/A7vxtfLvtCyyWaiz2Mu6fl8Kh308oBToDRaMTPUbJAS4Tg5t+He8iru5MXniPkhfY5WFk85xApyntp8GYkaLRfSrceHOxC2fdRveEVeHUkIDvqGCH700tdKHOcAa6TnNG7dOakzlREVyZ3Kx7XZKKq2lI4pqi8gIEREpLy8nJTQKoJ7pbZ4xAY/xEqYgBsGfWhzhsdjafkuzR0qjUOTLNL3iVzh0mu2xHztkweaE0ss3N+qfiIhZK+fNosZ8GY/+NpPuUux401XlRC3C471t5ZK3ejzcilhayuYhRQ11KTtcaT2rUE2vuSWU6tnvQ5bu9cz5mcLpUtTavZIzXybFAuKbLPtZsF2iZm8H2nTM9LvP27nKeX+YsDS+u3kTXfq0xV9kwb5Ii7nZaXUvefPqcsd6DQm1+kB8y7lF16npu3nILR6OXQFOaHzyNLqPBtNGU2QJDeSifFklyIHxp8E7XGk/ekHMpyOV/LBYrv711o/J7lz6twOFo0APJea77kNs9l0/zjmI219Tzmji/fzuWrTnI827rm6tsSpizZNe9TfltySN27n7lTsa+vCSoNoFkSrHXPWPkh5F7m6V2R4fgutPY5gdvg5o/g2nDEw3pI1EtvIFexGAN6oHUiot0hdNQZl7DzdwJizCmOLhumqhErh3/4FaPFYoDSfbsySXM/QE3qHsGg7pn0KHHoy7rllXOJyVxPEajPqhjkKPTcrPu9RptJocwywU5QTJPrJrleZvRYlYIlEi7TwU6qPkzeFXINLSPRK3wBuM2EqlRaaguPb46dWNN+PUY0snvSMigi6fWAh9Mc3169/QgvP4eFN6KWeaVjOHc1u8puYDF7zeDzc6af11Ol5vf9XscZnMN5mpnopqVk85z+V3epzpBj11cwv6DLyr2YzmE2aCLd4nE80VzEo5Q7oNAzA/NNZl6Y9BQ803UCi94fzo3trdCuGxqje1eF8pEzOD0JeyZ9aEyubV700FEW63f9X2hnigTLhiI+M1G2mclcmz5rSRecZ6PNaHljZKAl35xJ3s3H8Zhs7PwATsGnYGJ8+7wuE5O5kQlzaXRqEerdwZfNMRGHW00tD/5stHGsp75pyEmlgaVdw8HgdpRw+l5EIipwRuhjgKCWcfbdsI9KeJrX2oCaXPfxDcZPHMNAAN7D6DEXESnrK6MHHATd73mmtt351OSmFqstVz48g/K9+XmBXTrPI3S0nJEEaqra7xOmvkq5aP2cnBfPxDRbei5BkIeCQWzbQi8DwbbVxtTcEPN1RAqkZi7kc9F2HM1hFt4PWVvaqyTH84bCxqn3eFoM4R/1O1+HZ/+6jB7KhyMuvls/u+N7zmn84UM7T2MhxZIngrP3v4yRq3kVyubJzIyEjlwaLZiZ+7a6Z8UF1eQkJDAsROuhli18AJKeDNA5w6TMZvri7WaxhDeSLpaRYubZDjNCo0lvI2hOVGXq0GNp4vW3Ny4mqv3QzgnDT1dx8IV+xk0uDMPTr6YVSt3UFxeyN114b2ZmUlMfM1EYWEJHz8bR01dLt7i4kpSEscrnhXrN06lZfZ9lJeblRBggA7tHlT2U2OrIdmYglYvYjJJppDjhXPp1mkqgIvXRH7Bq2RlJXuNRAsXXh/GYfCjDcurfwDeD4Fuu7mZFKJNcxpVeH29mjRnIQPC0qkbi4b6LPu6+W4Y3pGZ72/lh3V7KSuv5tpBl/D1j18BkjC6p530hPp3tSCfdCtP1DfxTQRdHHCrs209s+jY/iHyfnyi3vbU7mLhxN/bT0MmYsI5wdWQh25zteP6Ox/QNJrT6CPeQNy4gIgJWagJqv0RjEtPsES6zaG0xdt1HHtZZ1pnGNl1tIzzemahPfEzr4JXNzG190FO5kSXUjvulJsXKFFnkxaYgNvIzbqXfQM6YEqQKhcvuX8QlnPuDiizWrgJpx9tKKasYDJ3BUNzH+X6I5L3rjeidno33H60jdF5QunUvojWfMS+2iIIAlcMbMUVA6WSOHTPIA8Y8MxtHpfPrKsQDPUjyzzh7qt7vHAuP01/G6Ne47Ndz455ye+2QyXcYbyh2uGDcRH7M7iHBfKwa6pEXlErvBCeMN7T8RWpoTR2ZztrWFflb5PJgNGox2KxKiYET3hLguOJzadu5oLs9z3eXE/9YwY5SZG/7uFwOQzHhK03F7E/s3tYpM51Q4hq4ZXxJMChrN8caIxRblN0NPUkmTuDBjzDqVMWsrMzaNUqlVMlFm665L9c3u8vSpVh9f9aPdxQl55yySN2DLp4l5tL2HyIxQ//G/BfLDPcNCSM19/ywRDqtpv7KNcbkTzXodAshFfmdOsMaqLVrBAuTCYDWmEM+QWv1kvMU1paRXW1HYNOj8aWTO/WPRna9QrsVtdimBZbGVPmSUl8rpw8n9yse7FYrC5RctFCSOaHCBBO+/DpQLT0kWYlvKcrp5NZwRvi95uVYppGox6jUa+Mgo2CSOucnvz17FEYDcZ66zqToidy18sLArIFRwPNwVPndDMrNBdiwtuE/BkEV8Fmx7jxF4xA2ae3Q1wcbN+FCPzyxtV17V0edHtnjZ0XgcaGl2h1OfyzjHKjkYAj12LEiBEjRniI879IjBgxYsQIJzHhjREjRoxGJia8MWLEiNHIxIQ3RowYMRqZmPDGiBEjRiMTE94YMWLEaGRiwhsjRowYjUxMeGPEiBGjkYkJb4wYMWI0Mv8PsahPbMt5LfUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boundaries_on_embedding(reducer, logr, embedding=embedding, \n",
    "                        title=\"Logistic Regression on PCA\", \n",
    "                        cmap=\"inferno\",\n",
    "                       n_pts=30)\n",
    "plt.savefig(\"images/LogRegUMAP.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:19:49.478898Z",
     "start_time": "2023-05-30T13:19:49.263397Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cfm(y_test, y_pred_test, title=\"Logistic regression confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:19:41,254] A new study created in memory with name: no-name-8257fda8-3a57-45b1-aa49-741eb6d5295c\n",
      "[W 2023-07-08 15:19:41,272] Trial 0 failed with parameters: {'penalty': 'l1', 'C': 98.9866154914385, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "[W 2023-07-08 15:19:41,292] Trial 0 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:19:41,981] Trial 4 finished with value: 0.9586776859504132 and parameters: {'penalty': 'l2', 'C': 36.78380751016376, 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.9586776859504132.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:19:42,017] Trial 3 finished with value: 0.9476584022038568 and parameters: {'penalty': 'l2', 'C': 61.75997181212335, 'loss': 'hinge'}. Best is trial 4 with value: 0.9586776859504132.\n",
      "[W 2023-07-08 15:19:42,019] Trial 5 failed with parameters: {'penalty': 'l1', 'C': 51.27160016737008, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "[I 2023-07-08 15:19:42,022] Trial 2 finished with value: 0.953168044077135 and parameters: {'penalty': 'l2', 'C': 99.32006852166549, 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:19:42,024] Trial 1 finished with value: 0.9504132231404959 and parameters: {'penalty': 'l2', 'C': 7.60925594976306, 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.9586776859504132.\n",
      "[W 2023-07-08 15:19:42,035] Trial 5 failed with value None.\n",
      "[W 2023-07-08 15:19:42,076] Trial 9 failed with parameters: {'penalty': 'l1', 'C': 53.467665503920344, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:42,081] Trial 9 failed with value None.\n",
      "[W 2023-07-08 15:19:42,079] Trial 7 failed with parameters: {'penalty': 'l1', 'C': 77.26287785122729, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:42,098] Trial 7 failed with value None.\n",
      "[W 2023-07-08 15:19:42,114] Trial 11 failed with parameters: {'penalty': 'l1', 'C': 66.43038057005023, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:42,118] Trial 11 failed with value None.\n",
      "[W 2023-07-08 15:19:42,116] Trial 10 failed with parameters: {'penalty': 'l1', 'C': 4.504443161478379, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:42,128] Trial 10 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:19:42,955] Trial 6 finished with value: 0.953168044077135 and parameters: {'penalty': 'l2', 'C': 43.93961364092259, 'loss': 'hinge'}. Best is trial 4 with value: 0.9586776859504132.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:19:42,971] Trial 13 finished with value: 0.9559228650137741 and parameters: {'penalty': 'l2', 'C': 93.09528728258456, 'loss': 'hinge'}. Best is trial 4 with value: 0.9586776859504132.\n",
      "[W 2023-07-08 15:19:42,994] Trial 15 failed with parameters: {'penalty': 'l1', 'C': 72.79409842806935, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[W 2023-07-08 15:19:43,008] Trial 15 failed with value None.\n",
      "[I 2023-07-08 15:19:43,026] Trial 8 finished with value: 0.953168044077135 and parameters: {'penalty': 'l2', 'C': 97.16934151947096, 'loss': 'hinge'}. Best is trial 4 with value: 0.9586776859504132.\n",
      "[W 2023-07-08 15:19:43,047] Trial 16 failed with parameters: {'penalty': 'l1', 'C': 31.598192710535166, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "[W 2023-07-08 15:19:43,055] Trial 16 failed with value None.\n",
      "[W 2023-07-08 15:19:43,075] Trial 18 failed with parameters: {'penalty': 'l1', 'C': 0.6007037978158242, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:43,118] Trial 18 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:19:43,250] Trial 12 finished with value: 0.9559228650137741 and parameters: {'penalty': 'l2', 'C': 74.75949823792232, 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.9586776859504132.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:19:43,668] Trial 17 finished with value: 0.9614325068870524 and parameters: {'penalty': 'l2', 'C': 3.0975403647375006, 'loss': 'hinge'}. Best is trial 17 with value: 0.9614325068870524.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:19:43,962] Trial 14 finished with value: 0.953168044077135 and parameters: {'penalty': 'l2', 'C': 61.341141061901716, 'loss': 'hinge'}. Best is trial 17 with value: 0.9614325068870524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:44,007] Trial 22 failed with parameters: {'penalty': 'l1', 'C': 0.6052817847240419, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[W 2023-07-08 15:19:44,021] Trial 22 failed with value None.\n",
      "[I 2023-07-08 15:19:44,039] Trial 19 finished with value: 0.9504132231404959 and parameters: {'penalty': 'l2', 'C': 81.2977172746096, 'loss': 'squared_hinge'}. Best is trial 17 with value: 0.9614325068870524.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:19:44,102] Trial 20 finished with value: 0.953168044077135 and parameters: {'penalty': 'l2', 'C': 11.87398347125887, 'loss': 'squared_hinge'}. Best is trial 17 with value: 0.9614325068870524.\n",
      "[W 2023-07-08 15:19:44,106] Trial 23 failed with parameters: {'penalty': 'l1', 'C': 1.4220064488114772, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,116] Trial 23 failed with value None.\n",
      "[W 2023-07-08 15:19:44,139] Trial 24 failed with parameters: {'penalty': 'l1', 'C': 7.14748582691497, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,169] Trial 24 failed with value None.\n",
      "[W 2023-07-08 15:19:44,218] Trial 25 failed with parameters: {'penalty': 'l1', 'C': 26.57499550185442, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,224] Trial 25 failed with value None.\n",
      "[W 2023-07-08 15:19:44,228] Trial 26 failed with parameters: {'penalty': 'l1', 'C': 24.31848826772639, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,229] Trial 27 failed with parameters: {'penalty': 'l1', 'C': 26.476157637147004, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:44,258] Trial 28 failed with parameters: {'penalty': 'l1', 'C': 28.320022970343917, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,265] Trial 28 failed with value None.\n",
      "[W 2023-07-08 15:19:44,259] Trial 27 failed with value None.\n",
      "[W 2023-07-08 15:19:44,258] Trial 26 failed with value None.\n",
      "[W 2023-07-08 15:19:44,331] Trial 29 failed with parameters: {'penalty': 'l1', 'C': 26.91638114661474, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,335] Trial 29 failed with value None.\n",
      "[W 2023-07-08 15:19:44,339] Trial 30 failed with parameters: {'penalty': 'l1', 'C': 27.54850614004094, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,361] Trial 30 failed with value None.\n",
      "[W 2023-07-08 15:19:44,342] Trial 31 failed with parameters: {'penalty': 'l1', 'C': 26.40634797185417, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,368] Trial 32 failed with parameters: {'penalty': 'l1', 'C': 26.320379733801047, 'loss': 'squared_hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,386] Trial 31 failed with value None.\n",
      "[W 2023-07-08 15:19:44,389] Trial 32 failed with value None.\n",
      "[W 2023-07-08 15:19:44,390] Trial 33 failed with parameters: {'penalty': 'l1', 'C': 27.95094778057979, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:44,413] Trial 33 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:19:44,456] Trial 21 finished with value: 0.9586776859504132 and parameters: {'penalty': 'l2', 'C': 55.22990523728413, 'loss': 'squared_hinge'}. Best is trial 17 with value: 0.9614325068870524.\n",
      "[W 2023-07-08 15:19:44,474] Trial 34 failed with parameters: {'penalty': 'l1', 'C': 26.2884575062636, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,482] Trial 34 failed with value None.\n",
      "[W 2023-07-08 15:19:44,476] Trial 36 failed with parameters: {'penalty': 'l1', 'C': 26.578102729513418, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,486] Trial 35 failed with parameters: {'penalty': 'l1', 'C': 27.92432383257479, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,510] Trial 36 failed with value None.\n",
      "[W 2023-07-08 15:19:44,528] Trial 35 failed with value None.\n",
      "[W 2023-07-08 15:19:44,554] Trial 37 failed with parameters: {'penalty': 'l1', 'C': 28.48042840534413, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,595] Trial 37 failed with value None.\n",
      "[W 2023-07-08 15:19:44,626] Trial 40 failed with parameters: {'penalty': 'l1', 'C': 28.690406747045813, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,629] Trial 38 failed with parameters: {'penalty': 'l1', 'C': 30.22814657200902, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:44,637] Trial 38 failed with value None.\n",
      "[W 2023-07-08 15:19:44,634] Trial 41 failed with parameters: {'penalty': 'l1', 'C': 25.046378061142768, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,643] Trial 41 failed with value None.\n",
      "[W 2023-07-08 15:19:44,630] Trial 39 failed with parameters: {'penalty': 'l1', 'C': 25.385994831187453, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,635] Trial 40 failed with value None.\n",
      "[W 2023-07-08 15:19:44,678] Trial 39 failed with value None.\n",
      "[W 2023-07-08 15:19:44,679] Trial 42 failed with parameters: {'penalty': 'l1', 'C': 30.501059661923083, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,680] Trial 43 failed with parameters: {'penalty': 'l1', 'C': 23.776459234284083, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,719] Trial 42 failed with value None.\n",
      "[W 2023-07-08 15:19:44,722] Trial 44 failed with parameters: {'penalty': 'l1', 'C': 24.53170828673678, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,744] Trial 44 failed with value None.\n",
      "[W 2023-07-08 15:19:44,723] Trial 45 failed with parameters: {'penalty': 'l1', 'C': 25.429417236550652, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:44,722] Trial 43 failed with value None.\n",
      "[W 2023-07-08 15:19:44,754] Trial 46 failed with parameters: {'penalty': 'l1', 'C': 28.791645556754272, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,786] Trial 46 failed with value None.\n",
      "[W 2023-07-08 15:19:44,767] Trial 47 failed with parameters: {'penalty': 'l1', 'C': 24.122147026119613, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,786] Trial 48 failed with parameters: {'penalty': 'l1', 'C': 24.342720717412618, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,765] Trial 45 failed with value None.\n",
      "[W 2023-07-08 15:19:44,806] Trial 47 failed with value None.\n",
      "[W 2023-07-08 15:19:44,810] Trial 49 failed with parameters: {'penalty': 'l1', 'C': 0.2847841770149082, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,811] Trial 48 failed with value None.\n",
      "[W 2023-07-08 15:19:44,850] Trial 49 failed with value None.\n",
      "[W 2023-07-08 15:19:44,851] Trial 50 failed with parameters: {'penalty': 'l1', 'C': 28.261155439971198, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,852] Trial 51 failed with parameters: {'penalty': 'l1', 'C': 23.305707589501715, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:44,880] Trial 50 failed with value None.\n",
      "[W 2023-07-08 15:19:44,896] Trial 52 failed with parameters: {'penalty': 'l1', 'C': 21.28509704067123, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,896] Trial 51 failed with value None.\n",
      "[W 2023-07-08 15:19:44,898] Trial 53 failed with parameters: {'penalty': 'l1', 'C': 22.450197946043758, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,914] Trial 52 failed with value None.\n",
      "[W 2023-07-08 15:19:44,919] Trial 54 failed with parameters: {'penalty': 'l1', 'C': 26.288437933964033, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,935] Trial 53 failed with value None.\n",
      "[W 2023-07-08 15:19:44,956] Trial 55 failed with parameters: {'penalty': 'l1', 'C': 29.46079534071876, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,958] Trial 54 failed with value None.\n",
      "[W 2023-07-08 15:19:44,966] Trial 55 failed with value None.\n",
      "[W 2023-07-08 15:19:44,977] Trial 56 failed with parameters: {'penalty': 'l1', 'C': 26.85406979847092, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:44,993] Trial 56 failed with value None.\n",
      "[W 2023-07-08 15:19:44,996] Trial 57 failed with parameters: {'penalty': 'l1', 'C': 26.787723159439185, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:45,044] Trial 57 failed with value None.\n",
      "[W 2023-07-08 15:19:45,068] Trial 60 failed with parameters: {'penalty': 'l1', 'C': 29.482657612996544, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,070] Trial 59 failed with parameters: {'penalty': 'l1', 'C': 27.625681881039768, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,071] Trial 58 failed with parameters: {'penalty': 'l1', 'C': 27.068656015499005, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,072] Trial 61 failed with parameters: {'penalty': 'l1', 'C': 25.768540107383572, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,073] Trial 60 failed with value None.\n",
      "[W 2023-07-08 15:19:45,075] Trial 59 failed with value None.\n",
      "[W 2023-07-08 15:19:45,077] Trial 58 failed with value None.\n",
      "[W 2023-07-08 15:19:45,078] Trial 61 failed with value None.\n",
      "[W 2023-07-08 15:19:45,142] Trial 62 failed with parameters: {'penalty': 'l1', 'C': 23.9954865493876, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,158] Trial 64 failed with parameters: {'penalty': 'l1', 'C': 26.377233345645443, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:45,159] Trial 63 failed with parameters: {'penalty': 'l1', 'C': 27.582509510334162, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,161] Trial 65 failed with parameters: {'penalty': 'l1', 'C': 25.320767440719887, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,168] Trial 65 failed with value None.\n",
      "[W 2023-07-08 15:19:45,165] Trial 64 failed with value None.\n",
      "[W 2023-07-08 15:19:45,166] Trial 63 failed with value None.\n",
      "[W 2023-07-08 15:19:45,162] Trial 62 failed with value None.\n",
      "[W 2023-07-08 15:19:45,226] Trial 67 failed with parameters: {'penalty': 'l1', 'C': 28.711152263128017, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,233] Trial 66 failed with parameters: {'penalty': 'l1', 'C': 27.73142784404115, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,248] Trial 68 failed with parameters: {'penalty': 'l1', 'C': 24.562479590139052, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,250] Trial 67 failed with value None.\n",
      "[W 2023-07-08 15:19:45,253] Trial 66 failed with value None.\n",
      "[W 2023-07-08 15:19:45,254] Trial 69 failed with parameters: {'penalty': 'l1', 'C': 25.444238572533166, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:45,256] Trial 68 failed with value None.\n",
      "[W 2023-07-08 15:19:45,281] Trial 69 failed with value None.\n",
      "[W 2023-07-08 15:19:45,318] Trial 71 failed with parameters: {'penalty': 'l1', 'C': 28.68441162210577, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,324] Trial 70 failed with parameters: {'penalty': 'l1', 'C': 24.57190297060473, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,338] Trial 71 failed with value None.\n",
      "[W 2023-07-08 15:19:45,342] Trial 72 failed with parameters: {'penalty': 'l1', 'C': 25.542873210338033, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,344] Trial 70 failed with value None.\n",
      "[W 2023-07-08 15:19:45,346] Trial 73 failed with parameters: {'penalty': 'l1', 'C': 28.083784768082786, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,360] Trial 72 failed with value None.\n",
      "[W 2023-07-08 15:19:45,384] Trial 73 failed with value None.\n",
      "[W 2023-07-08 15:19:45,388] Trial 74 failed with parameters: {'penalty': 'l1', 'C': 23.363782522563195, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,389] Trial 75 failed with parameters: {'penalty': 'l1', 'C': 25.969409996493802, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:45,427] Trial 76 failed with parameters: {'penalty': 'l1', 'C': 25.040174553827775, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,429] Trial 74 failed with value None.\n",
      "[W 2023-07-08 15:19:45,432] Trial 77 failed with parameters: {'penalty': 'l1', 'C': 24.828455099362092, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,433] Trial 75 failed with value None.\n",
      "[W 2023-07-08 15:19:45,435] Trial 76 failed with value None.\n",
      "[W 2023-07-08 15:19:45,457] Trial 77 failed with value None.\n",
      "[W 2023-07-08 15:19:45,480] Trial 78 failed with parameters: {'penalty': 'l1', 'C': 25.716552854791036, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,512] Trial 79 failed with parameters: {'penalty': 'l1', 'C': 26.11808048499459, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,513] Trial 78 failed with value None.\n",
      "[W 2023-07-08 15:19:45,517] Trial 79 failed with value None.\n",
      "[W 2023-07-08 15:19:45,520] Trial 80 failed with parameters: {'penalty': 'l1', 'C': 25.66521381081437, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,524] Trial 81 failed with parameters: {'penalty': 'l1', 'C': 24.436332578330866, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:45,543] Trial 80 failed with value None.\n",
      "[W 2023-07-08 15:19:45,545] Trial 81 failed with value None.\n",
      "[W 2023-07-08 15:19:45,553] Trial 82 failed with parameters: {'penalty': 'l1', 'C': 22.953669142670417, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,571] Trial 82 failed with value None.\n",
      "[W 2023-07-08 15:19:45,607] Trial 83 failed with parameters: {'penalty': 'l1', 'C': 23.593073747113024, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,614] Trial 85 failed with parameters: {'penalty': 'l1', 'C': 24.161516148114526, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,615] Trial 83 failed with value None.\n",
      "[W 2023-07-08 15:19:45,616] Trial 84 failed with parameters: {'penalty': 'l1', 'C': 27.07787045077926, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,631] Trial 85 failed with value None.\n",
      "[W 2023-07-08 15:19:45,641] Trial 84 failed with value None.\n",
      "[W 2023-07-08 15:19:45,654] Trial 86 failed with parameters: {'penalty': 'l1', 'C': 28.237138966179334, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,669] Trial 87 failed with parameters: {'penalty': 'l1', 'C': 26.007146624349943, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:45,700] Trial 87 failed with value None.\n",
      "[W 2023-07-08 15:19:45,699] Trial 89 failed with parameters: {'penalty': 'l1', 'C': 25.428074891763526, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,695] Trial 86 failed with value None.\n",
      "[W 2023-07-08 15:19:45,703] Trial 88 failed with parameters: {'penalty': 'l1', 'C': 26.403303832637057, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,709] Trial 89 failed with value None.\n",
      "[W 2023-07-08 15:19:45,728] Trial 90 failed with parameters: {'penalty': 'l1', 'C': 22.614816478353752, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,757] Trial 90 failed with value None.\n",
      "[W 2023-07-08 15:19:45,748] Trial 91 failed with parameters: {'penalty': 'l1', 'C': 25.82737757794012, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,743] Trial 88 failed with value None.\n",
      "[W 2023-07-08 15:19:45,772] Trial 91 failed with value None.\n",
      "[W 2023-07-08 15:19:45,789] Trial 92 failed with parameters: {'penalty': 'l1', 'C': 24.485880490997264, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,834] Trial 92 failed with value None.\n",
      "[W 2023-07-08 15:19:45,837] Trial 93 failed with parameters: {'penalty': 'l1', 'C': 25.80311223718092, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:45,839] Trial 95 failed with parameters: {'penalty': 'l1', 'C': 25.70097693421398, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,843] Trial 94 failed with parameters: {'penalty': 'l1', 'C': 24.919748881113133, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,844] Trial 93 failed with value None.\n",
      "[W 2023-07-08 15:19:45,863] Trial 96 failed with parameters: {'penalty': 'l1', 'C': 23.82717893653425, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,864] Trial 95 failed with value None.\n",
      "[W 2023-07-08 15:19:45,865] Trial 94 failed with value None.\n",
      "[W 2023-07-08 15:19:45,873] Trial 96 failed with value None.\n",
      "[W 2023-07-08 15:19:45,905] Trial 97 failed with parameters: {'penalty': 'l1', 'C': 29.54221519273461, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,940] Trial 97 failed with value None.\n",
      "[W 2023-07-08 15:19:45,954] Trial 98 failed with parameters: {'penalty': 'l1', 'C': 26.617267652587245, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,955] Trial 98 failed with value None.\n",
      "[W 2023-07-08 15:19:45,959] Trial 99 failed with parameters: {'penalty': 'l1', 'C': 25.882991075622396, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:45,980] Trial 100 failed with parameters: {'penalty': 'l1', 'C': 24.97065738426015, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,995] Trial 99 failed with value None.\n",
      "[W 2023-07-08 15:19:45,998] Trial 101 failed with parameters: {'penalty': 'l1', 'C': 25.887454285190163, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:45,999] Trial 100 failed with value None.\n",
      "[W 2023-07-08 15:19:46,000] Trial 102 failed with parameters: {'penalty': 'l1', 'C': 26.22493228176715, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,009] Trial 101 failed with value None.\n",
      "[W 2023-07-08 15:19:46,039] Trial 102 failed with value None.\n",
      "[W 2023-07-08 15:19:46,041] Trial 103 failed with parameters: {'penalty': 'l1', 'C': 23.801204317078547, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,045] Trial 104 failed with parameters: {'penalty': 'l1', 'C': 28.443533351074752, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,086] Trial 104 failed with value None.\n",
      "[W 2023-07-08 15:19:46,083] Trial 105 failed with parameters: {'penalty': 'l1', 'C': 20.71200560791679, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:46,085] Trial 106 failed with parameters: {'penalty': 'l1', 'C': 27.756314717125306, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,082] Trial 103 failed with value None.\n",
      "[W 2023-07-08 15:19:46,092] Trial 105 failed with value None.\n",
      "[W 2023-07-08 15:19:46,110] Trial 107 failed with parameters: {'penalty': 'l1', 'C': 26.847108288447703, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,111] Trial 106 failed with value None.\n",
      "[W 2023-07-08 15:19:46,148] Trial 107 failed with value None.\n",
      "[W 2023-07-08 15:19:46,156] Trial 109 failed with parameters: {'penalty': 'l1', 'C': 28.64169977869059, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,158] Trial 108 failed with parameters: {'penalty': 'l1', 'C': 25.80578495107358, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,192] Trial 109 failed with value None.\n",
      "[W 2023-07-08 15:19:46,198] Trial 108 failed with value None.\n",
      "[W 2023-07-08 15:19:46,201] Trial 110 failed with parameters: {'penalty': 'l1', 'C': 22.876347299532775, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,202] Trial 111 failed with parameters: {'penalty': 'l1', 'C': 28.421736823047063, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:46,242] Trial 110 failed with value None.\n",
      "[W 2023-07-08 15:19:46,246] Trial 112 failed with parameters: {'penalty': 'l1', 'C': 25.449792821953086, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,247] Trial 111 failed with value None.\n",
      "[W 2023-07-08 15:19:46,250] Trial 113 failed with parameters: {'penalty': 'l1', 'C': 29.696029732958802, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,256] Trial 113 failed with value None.\n",
      "[W 2023-07-08 15:19:46,253] Trial 112 failed with value None.\n",
      "[W 2023-07-08 15:19:46,328] Trial 115 failed with parameters: {'penalty': 'l1', 'C': 27.73697384148584, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,329] Trial 114 failed with parameters: {'penalty': 'l1', 'C': 26.21393164598981, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,330] Trial 116 failed with parameters: {'penalty': 'l1', 'C': 26.668581279701158, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,337] Trial 116 failed with value None.\n",
      "[W 2023-07-08 15:19:46,333] Trial 117 failed with parameters: {'penalty': 'l1', 'C': 24.928819061544345, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:46,335] Trial 114 failed with value None.\n",
      "[W 2023-07-08 15:19:46,332] Trial 115 failed with value None.\n",
      "[W 2023-07-08 15:19:46,345] Trial 117 failed with value None.\n",
      "[W 2023-07-08 15:19:46,393] Trial 119 failed with parameters: {'penalty': 'l1', 'C': 25.61964397190405, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,407] Trial 118 failed with parameters: {'penalty': 'l1', 'C': 26.624298711308562, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,414] Trial 119 failed with value None.\n",
      "[W 2023-07-08 15:19:46,415] Trial 120 failed with parameters: {'penalty': 'l1', 'C': 26.848348904927835, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,418] Trial 121 failed with parameters: {'penalty': 'l1', 'C': 27.82405206671617, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,418] Trial 118 failed with value None.\n",
      "[W 2023-07-08 15:19:46,425] Trial 120 failed with value None.\n",
      "[W 2023-07-08 15:19:46,439] Trial 121 failed with value None.\n",
      "[W 2023-07-08 15:19:46,442] Trial 122 failed with parameters: {'penalty': 'l1', 'C': 26.634314100468508, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,497] Trial 122 failed with value None.\n",
      "[W 2023-07-08 15:19:46,499] Trial 123 failed with parameters: {'penalty': 'l1', 'C': 22.43161996285417, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:46,521] Trial 123 failed with value None.\n",
      "[W 2023-07-08 15:19:46,519] Trial 125 failed with parameters: {'penalty': 'l1', 'C': 23.70189388310608, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,506] Trial 124 failed with parameters: {'penalty': 'l1', 'C': 23.32860489137588, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,523] Trial 126 failed with parameters: {'penalty': 'l1', 'C': 24.943467144145817, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,528] Trial 125 failed with value None.\n",
      "[W 2023-07-08 15:19:46,548] Trial 127 failed with parameters: {'penalty': 'l1', 'C': 26.706996068194858, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,549] Trial 124 failed with value None.\n",
      "[W 2023-07-08 15:19:46,551] Trial 126 failed with value None.\n",
      "[W 2023-07-08 15:19:46,559] Trial 127 failed with value None.\n",
      "[W 2023-07-08 15:19:46,580] Trial 128 failed with parameters: {'penalty': 'l1', 'C': 26.30768870374541, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,621] Trial 129 failed with parameters: {'penalty': 'l1', 'C': 25.338824361738098, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:46,637] Trial 128 failed with value None.\n",
      "[W 2023-07-08 15:19:46,638] Trial 130 failed with parameters: {'penalty': 'l1', 'C': 26.543773474844087, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,640] Trial 129 failed with value None.\n",
      "[W 2023-07-08 15:19:46,643] Trial 131 failed with parameters: {'penalty': 'l1', 'C': 30.336620091567312, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,663] Trial 130 failed with value None.\n",
      "[W 2023-07-08 15:19:46,673] Trial 132 failed with parameters: {'penalty': 'l1', 'C': 27.342228822707764, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,690] Trial 131 failed with value None.\n",
      "[W 2023-07-08 15:19:46,699] Trial 133 failed with parameters: {'penalty': 'l1', 'C': 28.225679750507926, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,712] Trial 132 failed with value None.\n",
      "[W 2023-07-08 15:19:46,733] Trial 134 failed with parameters: {'penalty': 'l1', 'C': 25.950030583187147, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,735] Trial 133 failed with value None.\n",
      "[W 2023-07-08 15:19:46,737] Trial 135 failed with parameters: {'penalty': 'l1', 'C': 25.806783299013016, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:46,757] Trial 134 failed with value None.\n",
      "[W 2023-07-08 15:19:46,764] Trial 135 failed with value None.\n",
      "[W 2023-07-08 15:19:46,766] Trial 136 failed with parameters: {'penalty': 'l1', 'C': 23.062027208286214, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,801] Trial 137 failed with parameters: {'penalty': 'l1', 'C': 21.959933048811227, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,819] Trial 136 failed with value None.\n",
      "[W 2023-07-08 15:19:46,821] Trial 138 failed with parameters: {'penalty': 'l1', 'C': 22.509904675890667, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,822] Trial 137 failed with value None.\n",
      "[W 2023-07-08 15:19:46,823] Trial 139 failed with parameters: {'penalty': 'l1', 'C': 28.200535370465253, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,843] Trial 138 failed with value None.\n",
      "[W 2023-07-08 15:19:46,851] Trial 140 failed with parameters: {'penalty': 'l1', 'C': 25.71035907238932, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,864] Trial 139 failed with value None.\n",
      "[W 2023-07-08 15:19:46,886] Trial 141 failed with parameters: {'penalty': 'l1', 'C': 27.239959475973578, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:46,886] Trial 140 failed with value None.\n",
      "[W 2023-07-08 15:19:46,897] Trial 142 failed with parameters: {'penalty': 'l1', 'C': 29.41680553209393, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,898] Trial 141 failed with value None.\n",
      "[W 2023-07-08 15:19:46,932] Trial 142 failed with value None.\n",
      "[W 2023-07-08 15:19:46,933] Trial 143 failed with parameters: {'penalty': 'l1', 'C': 24.46463139991136, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,936] Trial 144 failed with parameters: {'penalty': 'l1', 'C': 27.200325123469472, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,975] Trial 143 failed with value None.\n",
      "[W 2023-07-08 15:19:46,978] Trial 146 failed with parameters: {'penalty': 'l1', 'C': 21.585118606969235, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,979] Trial 144 failed with value None.\n",
      "[W 2023-07-08 15:19:46,980] Trial 145 failed with parameters: {'penalty': 'l1', 'C': 26.501128988927558, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:46,996] Trial 146 failed with value None.\n",
      "[W 2023-07-08 15:19:47,009] Trial 147 failed with parameters: {'penalty': 'l1', 'C': 25.926824739919063, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:19:47,010] Trial 145 failed with value None.\n",
      "[W 2023-07-08 15:19:47,038] Trial 148 failed with parameters: {'penalty': 'l1', 'C': 26.42856825078867, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:47,047] Trial 148 failed with value None.\n",
      "[W 2023-07-08 15:19:47,046] Trial 149 failed with parameters: {'penalty': 'l1', 'C': 26.197284552429075, 'loss': 'hinge'} because of the following error: ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/266359131.py\", line 10, in objective_fun\n",
      "    lin_svc.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "[W 2023-07-08 15:19:47,053] Trial 149 failed with value None.\n",
      "[W 2023-07-08 15:19:47,041] Trial 147 failed with value None.\n"
     ]
    }
   ],
   "source": [
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    C = trial.suggest_float('C', 0.01,100)\n",
    "    loss = trial.suggest_categorical('loss', ['hinge', 'squared_hinge'])\n",
    "    \n",
    "    lin_svc = LinearSVC(loss=loss, penalty=penalty, C=C)\n",
    "\n",
    "    lin_svc.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lin_svc.predict(X_val)\n",
    "    error = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective_fun, n_trials = 150, n_jobs = -1, catch=(ValueError,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 3.0975403647375006, 'loss': 'hinge'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       309\n",
      "           1       0.95      0.90      0.92       308\n",
      "\n",
      "    accuracy                           0.93       617\n",
      "   macro avg       0.93      0.93      0.93       617\n",
      "weighted avg       0.93      0.93      0.93       617\n",
      "\n",
      "Accuracy 0.9270664505672609\n",
      "F1-score [0.92913386 0.92487479]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "lin_svc = LinearSVC(**best_params)\n",
    "lin_svc.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "\n",
    "y_pred_test = lin_svc.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(best_params)\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred_test))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred_test, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=default_style.SHORT_HALFSIZE_FIGURE)\n",
    "cf = confusion_matrix(y_test, y_pred_test)\n",
    "sns.heatmap(cf, annot=True, cmap='Greens', fmt=\".4g\", cbar=False, ax=ax)\n",
    "ax.set_xlabel('True')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('LinearSVC confusion matrix')\n",
    "\n",
    "ticks = np.unique(y)\n",
    "ax.set_xticks(ticks + 0.5, labels=label_enc.inverse_transform(ticks))\n",
    "ax.set_yticks(ticks + 0.5, labels=label_enc.inverse_transform(ticks))\n",
    "\n",
    "plt.savefig(\"images/LinearSVC_conf_matrix.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAADoCAYAAACnz4zGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADAVklEQVR4nOydd3gUVdvGf7M12U3vIfQWepEOIkXE3l8LiogIqFhAKb6IBVRsoIKAqFgQERUFKxYs9CYivUnvpNfdbJ/vj8lsZluymwa+X+7r4iI75cyZmTPPec5T7kcQRVGkDnWoQx3qUGtQXegO1KEOdajD/zfUCd461KEOdahl1AneOtShDnWoZdQJ3jrUoQ51qGXUCd461KEOdahl1AneOtShDnWoZdQJ3jrUoQ51qGXUCd461KEOdahl1AneOtShDnWoZdQJ3v9BpKenk56ejtVq9dh++vRp0tPTGThw4AXqmS/Wrl3LLbfcQqdOnejcuTNXX301H3/8MQD33HMP6enp/Pjjjx7njBgxgvT0dL7++muWL1/uvt833njDfcymTZvc2x9//PEavw/52cr/2rdvz3XXXce3337rPsbhcPD+++9z3XXX0b59e7p3784999zD3r173ceYTCY6d+5Meno6gwcPrvF+1+HCoE7w/j9CXFwcb7zxBk8//XStX9vhcPhsy8/P59FHHyUzM5OJEycyefJk+vTpQ25uLgA333wzAN999537nIyMDDZt2oTBYODKK6/0aG/p0qXuyWbx4sU1dSvlIjIykjfeeIPx48dz5swZnnzySXbu3AnA448/zowZM7Db7YwfP56xY8cSExPDoUOH3Of/8ssvmM1m1Go1J06c4K+//rog91GHmoXmQnegDrWH3NxcnnjiCdLS0hg4cCDLly9n8uTJXHrppahUKrZt20bjxo158803adSoES6Xi/fff5+vvvqKjIwM0tLSGDlyJLfccgsAkydPZs2aNRQWFhIdHU3fvn15+umniYiIYM6cOcydO5err76a8+fPs2fPHvbs2ePRn1OnTmGxWGjSpAkDBw4kNTXVY/+VV17JCy+8wLp168jNzSUuLo4ffvgBl8vFVVddhcFgcB/buHFjjh8/zooVK+jZsyerVq1ybwsEs9nM7NmzWblyJXl5eTRq1IgHH3yQq6++GpBWDgCPPvooX3zxBQ6HgyeeeILbbrstYJt6vZ5rr70WgL///ptffvmFbdu2YbfbWblyJZGRkXz22WfExcUBcPfdd+Nyudznf/311wCMGTOGOXPmsHz5crp27Vrue63Dvw91Gm8d2Lx5M127dqV79+7s3buX+fPnA/DBBx/w+uuv07x5cx5++GFiY2OZPHky69atA6Bly5Y89thjTJ48mZ49e/L111+zYMECj7Z///13+vfvz6RJk3yu26xZM5KSkti/fz/9+/enb9++TJ482S0sjUYjV155JQ6Hgx9++AHAvXSXhb+MNm3a0LlzZxYvXsySJUtQq9XlCkiAV155hYULF5Kens7kyZPJz8/n8ccfZ8uWLR7H7d27l2HDhpGbm8sLL7yAxWIJ2KYoiuTm5nLw4EF27doFQFpaGjt27ACga9eubqErQ6WSPsNTp06xdetW0tPTGT16NDExMfz888+UlJSUex91+PehTvDWgT59+vDAAw9wzz33AHDixAkAVq5cCUjC8/XXX3cve9esWYPL5eLkyZO8+uqrPP/8827BqLRXAlx//fU8+OCDDBs2zOe6BoOBr776ipEjR9KmTRuys7NZvnw599xzD3a7HSgzN3zzzTccOHCAgwcP0rBhQ79a4N13383evXtZtGgR11xzjY+A88avv/4KwLRp07jjjju49957EUXRvV3G9OnTGTVqFElJSVitVjIyMgK2mZOTQ69evbjhhhs4f/48N954I1dccUW5/ZDxzTffIIoiffv2JTMzk169emEymfjll1+COr8O/x7UmRrq4BZQGo00HJxOp8f+Z555hqZNm7p/x8fHs3HjRpYsWULDhg158sknOX/+PC+88IKPQ8/bfKCE3W4nMTGRiRMnApL99uqrryYzM5OcnBxSUlLo3r079evXZ+/evcyaNQuAm266CUEQfNq76qqrePXVV8nKymLo0KEettNg4K9NKHs+Wq0W8G+vlhEdHc2sWbPQ6XQ0bNiQpKQkADp16gTAtm3byMvLIzY21n2Oy+VCEAS++eYbAN5//33ef/999/7ly5dz0003hXQvdbi4USd4/4cxd+5c9zK2fv369OrVK6TzBw8ezK5du1i+fDlDhgzBZDKxYcMGrr32WhISEgCwWq3k5OTw888/h9y/Y8eO8dBDD3H11VfTuHFjzp8/T0lJCQkJCW6BJQgCN910E3PnzmXVqlWoVCq3FuwNrVbL9OnTOX36NO3bt69Q8F5xxRV88cUXTJ06lf79+/Pxxx8jCEKVogm0Wi29e/f22d61a1cGDx7MypUrGTJkCEOGDEGn07F582YGDBhAamoqp0+fpkOHDjzwwAPu81588UX+/PNPTp8+Tf369SvdrzpcXKgTvP/DeO+999x/d+/ePWTBe//99yOKIsuWLeOFF14gMjKSNm3akJ6eTqtWrbjjjjv4/vvveeedd7jjjjvYunVrSO3Hx8fToUMHfvzxR7Kzs9HpdHTt2pUJEya4JwyQNNx58+YhiiI9evSgXr16Advs169f0Nf/73//S3h4OL/88gubNm2iUaNGTJo0ie7du4d0H8HizTff5KOPPuKbb75hxowZ6PV60tPTad68uTsK47rrrmPQoEHuczZt2sTixYv55ptveOSRR2qkX3WofQh1FSjqUIc61KF2Uedcq0Md6lCHWkad4K1DHepQh1pGneCtQx3qUIdaRp3grUMd6lCHWkad4K1DHepQh1pGneCtQx3qUIdaRp3grUMd6lCHWkbQCRSO3y7O4O39G48AsDl3+IXtyEWGnnELAWjdu1m5xwV6fqNnDyUxMZJzmXMA+OxFK/ZCAw6b/7TaqvajprF/45FqHSNbj2xkxd9fIYfBO51O1Go1AI2TjaydcaXPORfbWA3m3ch9huD73TNu4QV/36GgMvcI/p+fZtDcoM4NOoHiYhO8lX1Y/58gDwzw/bgqEgKjZw/FIZadbzJZMRr1fDgu9GTH8vpRW6huwXv4/H4+WStlBtpsdqxWG5GRRjffgyCATqtmxv2daemyuc+72MZqecK3shPFv0nwVnUy9H5+/9OC92LTHC52KAdHsBPWmZzTPPFOLNERD3hsnz92AXpdWMiar7Ifcl9qE9UpeJ0uJ/mmXOb8/DKiKCKKolvgtu+QxsCBrXlr9u8AqFTw+T1t2GceWS3Xrin4GyNVEUYXu+CtbhkiP7/2z/4U1PH/Kq6Gi0XgKgXIxYLynol738aFFR4r49YWv7H6FV8XwI1PlZCUpGXRJHXIwle+bs+4hR4TQLC4kB+z3Wnj910/su3YJuxOOyqV4Ba4GRnZhIXpiYmJ4pZbLiEuPgIAjUaFw+FibcYNJEQGbls5nqp7bMttV9Tu5tzhHu/lQn9jcj+q+52HulIO5fkBtA+yH/8KwXuxmBUuhiWzP+zfeISecQuDHhzlQXmPXTtLlI5KW2+UcTSFpvf8nRo0KvMOZaFwoZ774rXvcjzrKIIgEB0TBiLk55cgiiLR0VGo1dIk9fw0iZdYo1HhdLqoF5dGXESC3za9x1NF79Eluii2FGLUR6JWqcvtr89YDWLSvdDCFjyVK+VEUB3vPZRJxXsFEKwADhbVInidaHCoDIiEvvysCEe3nwRjAjsKJCpAfVS1XyIodIr+GpEEmnZuCEDgGgTVDwERlWhDI1r8PmH3oAxBo/UHf/a+/B9GEnHtpe7f4eHaSrVdVXhr7bUpgM1WEyeyjiEIkpabnydVhCgpsRIericsTIder+GzL0bzyss/smP7KXSCga4te9MnfQAqwXfl4O9Zl/ceC8x5LF7/DlkFWcRExHB3nwdIjEr2299AbdeEAKku+FOuvFdIlX3nlRG4UPb85P+r8/lV2cZrUidyxtgHUa2HahS8dqtUgcDqiqi2NisDvaoYAK3+wggcCSKILgy2c6SU/I1WNAc8srJeaAgszIRBZXSSUcbRmM025ox5H702LKj2qxuVWXlUxcb70eo5nMg6hoiI0+FCEMBud5CbW0B8fAw6nRatVkW7dvXZs+cMDoeLNvU70id9AGlxDSvVd/k9qgw6Wk24HYDUpEfJyiqiY8dmxGkbMqTP/X7brmwkS3UhFBtvKOM11AiZypoVqvL8Rs26I6i+VUnjdaLhjLEPWmMCkWHVI5hs5lIPsA5Mrlj01dJq5WFUadAZdBe4F+BwiRSZDRzXxNKscAUqXOUeX5mPKpBWIa7eirlbB5o1Hu8uzPjo2yOZPvwNEqOTQr5OdaG2tN6zeafdYWMlJSWIIkRGGklMjEOrlT4hh0Nkz54zCCoBQYB9p3ey/8wubu0xlHYNOoc8WcjHHNxxCoDMzEKysooA2LnzCAXFk1g2TfSxswtaNQe2HqdVj6bgKn+M1BQ25w4PamVSWU00WHg7k4NFedp1ZdrzhyppvFZVFMejryY+Jg6dpmq5GJbispIxxU7/NrELgQh1NmERF1r8S7A6XOTm59K44Ef0riKPfdVhBw8kHA5sPU7Dx27BaNSjETzbfm9s7ZVRr4qNvSoa7yfr5nPk/CG3M03+ZDQaNaIokhKTRk5xBnEJBlSCgMGoZ8WPjzF82EecPezinZsjKtXn0osg9O/m89zPZrzFzzNjfQTviFllZYlOfP47DRPKKjHXtuMs0PuqjJbr3UYoqC7NN5jnVysar2TTrbp5QRa6F5PAvRhRGiGK6JVwWF0fVHlRB1+9pOLe6VVqvtK40E7NW7sPY94vr1FgyqOgoJiYmCi0Gi1qQU1yXD1u7TaUt399lTC9lmPHsomMDGPZsm0cP5ZFEyNAhG+/VSqEgT0AENdsBbvDvd2NcjTWesmPMX/sAtSE+91vMlm5/oU1XNsyhns6l61KatO2W9542pw7nMKSAkzWMyRFpfh1FlZX8k2oNlpvx55ye3XhgkY1hKrlRqizKzx+ydKP+c9NUj2ryqCq59cmakqDkQeesm2NTgSc7Nk3nbh4KTaqWePxQO2EQ13IKBKD3kh8ZCL5RXk4HE4EoF2DTtzS4273MY3im3Ho2AGeee5aFry7jslPLictRs8rT/SjYZKxrDGtBqFfN4/2hX7dEH/b5CGMAWmbw4H42ybyfxyNcFkXn7hqb7w46ihPL2jqPm7fvpP0b3YZZxyjK7zPqoRJBhMtIUdsnMk7xUd/TMIpOlCpBJxOkY4Nu3Jzj7t8+lGd791bAAfbZ+Xv6sIFEbyVFbjykt9SbHVv8z7/sy8XccO1t1ZacFb1/NrA0e0nEUzS/deUBhOo3XZtpnj89hGMVYys8G7Xo+0LiMtaD+J0znGSk+PRqrX0bHmZx/4eLS7j0PkDxMZGcMed3Zg963eWTx1ASqynRuotdIOGIDnXDAYd5lI/SJfYpVzynCT8lzytxlIsUFzooGHaJI9TdxZej8Li4IOqPutgwxnXZw9l3f6fWbNvpXub0ykloOw8+RftE08ytGtKpfsRLEKJ8Kip76vWBa8sdAvtcbhcLjTl9ECp4SrtrN4CWBa+8957E4D/PjMOlUrF00++wBfLFnPs+BHsdhvpLdrwwP2PotVq+WLZYlav+x2tRnIKPv3kC3z59RKP859/5lUi4qrv3qsKm9mG3WpHRe2HAzlsAkue9l0Oen8gVQ1butgErozmKa145KrJZBaeo15sfaLCYzz2D2m1iX9ORvHEuC8ID9fy0A2tSIk3BuXgElf7FgkV13huE/p24VxmF0ASwAAtezZx77/rRScfjtPQLDmdZiktOHs2071v+It6kpIcfpNeqmNFEeyk+82fn7H39A5ACkssKjIBoNHoEEWRv04VMf2xPpXuRyioiRCxUFAl55pFFc2J6KuJj4kNyrkmC93vfv+b1+e8jNVq4Y5bhzJy+Bh3yqUMby23ojZB0n6vv+1yPlv4LRHGCOa+8wZtWrdjYL/BiKLInHdep369Bgy+/BpGPnw3H7/3JXq9HovVgkpQodPpPM6X+3ExONcsxVYcLpFzBQ4OrjyFtdBe633Q6ERSB+3k6itnArDq9eu5tEPgir+hmkKCEgKlNtDM/BKaD/2UkpKy53Bm6TCSYv3bPKubq0GGcqJI79mUfWeKaH9fGUGO+NsmzxNkG65Wg9BXEqTiH1t8BbSXDVjbf557V3y8kYzseXhj3/OL2Zw7HJfo4njmEXQaHePfScBolMavUvBW9KztDhfv/HiIXcfy6NkqgfuuaIZKVbE/J9A7t9hLmPnDs6SlxRBu0LDyt/HufenNp2A22xh5ZTOevbtjhdeoCVSX2a5WnGuVQVaxgVfffJ4BA1rSuGkC785fRM9ufWjfrpPPscEIPH/mBxmbt27gwD/7+Ob7rwCw2ayoVCrCww2kptbn9Tkv07ljF7pd0pOE+MSq31wNIixCT3GhBb2qmE7RX7Ol8LoL0o8rBrdzk+fsez5wRENVg9YDQRjYg8zMQtKSH6Og+F0Pm2fa7Yuw/+ppA61JT74/4dWuUYz/g72dZlabWyhn5pWQdvsiAPK/G4HRK0mlIvOE+McWz0sJKlo2aA6A0eh0bz9wZjeN4lpTYM7DZHTSdUDLgG3O+uYA874/iNVmZ+Xf5xAEGDG4ebn9KO9Z5xRl4XA4eX76DVwx8FU0wnAKit/FaNRjtzsQBIHRVwfuT02juk1lFaHWBW9JSQk2m50Bl7fikksa8u78NeQX5Fe5XaWQjlDnABGIosjkCc+RVq+Bz/Ezp8/hwD972b13JxOeeoSJ46bQtnWHKvejJqEz6NDatDghKJtaTWLJ02o66XxjHmtE4Ho5nZKSonCICzGZrAFPqck082CX56lJj3Jo4R0YDXqE/mXC063hljrakoHExK/dcbr+8PrDlzF+3loAfp1xfVlb67b5HKvRiQx7rUzgtmv9HHa7g5ISO+G6cEpsJXwapWdWUiz92yf7NYds2JeJucRCXl4hiQmxbD6QHVDwVvSspVTnInQaLVcMfNVnv1arYVDHBFLi/K9WahO1leFX64I3NjaOS3tfxn8nLQOgflp9LunUtdraNxjCKTaZSTFm07dHF5Z98zkPP/AEarWa4uIiCosKiYmJpaTETNvWHWjbugMnTx3nyLHDtG3dgfBwA2azyW1quBjRtHNDjq3PrnXblMMmMP9hOU7UwRruxGjUI2yVNF/R7gy6P1W1LZpMVlqn/9f9+9BnQ0k06mpF4EI5/Xa53DG3BoOOiGsu9T2mVPtVarIyFwaUhZeJf2yhyGLn1hfXceR0AfXqJaFSCdw5fS0fme10b53kMSGx/pDfLhUWlvDFVw+wa+dppr+wgnfeG8o115YpGT7mEKBLi3h2HMkDBHQ6LZ2axvptW37eXx7qz7oDvyHwAf3aXEm92Pqcyz/Dyp3fcD7/DCZLCefPZ3mc2/+y1xCtep7ok8qIuzr7bf9CIJToh8qi1m28xc4EHA4Ha9f/QYmlhMv6DCAy0peAobK21Q8++Zxf/lhLmF7HC09O5PNvvmPHnr0gaFGp1dw3dDT10xryyuvTsFgsCAKkptZn7EMTMBoj+OzLRaxe9xt6XRjPP/Mq9eOcF4WNF8DmcJGTn0ejgp8IcxUANaPZeYcVKdsdPXuo+2+DQedBmBMMV29lBK5ZpcE4sJubE/j4sSyaN53o3i+bF2rbrBAIsunA+/mEAvG3TTicLmZ9vZ853//D9yse5fDhTB4f+wWtW6cQ4bTz1TP9PQTvgvvmsfBvkUijgZ83jgCgU/up5OaaEUWRNm3rcWD/OeLiDGzfNdXjWt6w2JzMWLaP7YdzubRtEo/dmI5GXfaNK5+1yVrMnJ+n07hpHA6Hi7Oni3ho0CRm//QiDqcDURRxuUQyMspMgQXF7zL6lt/on34dfRI+uagcqd4IZVwFa+O9III3GFSnU6sqCRoXi3MN/AteGdUldPwJGLntv4rvZcSMe9zbQxG8lYlWMJXYqXfnYgpN72EyWYmOeIDExEifJfmuaYPcf18sccTHzxXSYthn7t9KUnklUpPGYjZbKCh+12O769eN3D9rM7/vOA9AUlIkbdulsWH9Ydq3r4eroJhvnhvgFrzHvlzNwCd+okfPZuTkFHPmZDFmixmb3U5RUTFRUZGo1SrUahU6nZqDh6VsGOfqragcDoKFv4n+eNYRFq6ex4qfH8NstnPbLfPp1+ZK1uz7xc1XDIJb401OTuD23sNo3/AS4N/F3wsXQebavwVuwVnsP/b3fwFVdQ6UJ2Bku1e32MDONH+hZsG0XRFkNjTZnhvIDnpBzAoBYCqxewhdkOy9SnMCwJP3vYdWqycmWs+gy17jt7Vl8bdHzxfz+47zvP7G7SQmRTJs6AfkrDmI0ymyZ9dp3n20B7hcbm31wJEcnC6RGW/8h717zjJ65CL0mjAsVgtWqw2Xy4VarSIhIYL/PnW1R18jtcFlnwaa3JOiUjDow3n4wSU4nS4iwiOw2iX+vsSkSLKziiksLCYqKoKICAMalZbGieU76i42VLf5odYErzLsK5RzqlPbDIvQl5t84Q3vKIl/A4LhdfVGMIKxde9moFL5aGYVmReqassND9eRkvgIR46/7rHdYNDx07hL2We+i8251cuSVmGfFdlnPqFgWg0Rg3oBH3qckpVVRMaXv5MUa/CIYvjo6cGYrS76tUt024bDw7VseusmAP7adpzoaCn7Ye6DXVm/L4sGCUZ6t/GMwonIK8QYpuG2W94lN1di1LM6LGi1WlJSEmnWPJFVayaSmVlIveTHAInvIenq3pz/ahXJMeU/w/JWVAa9kXv6PsT6g38gIHB93ys4k3sSgMGD27Dk0z9xOJyo1dLi+j89hxIZ7mlevJBcy6FAqeBURfjWuKmhqst8GdW93K+oX8HGEdcmyjM1eCOUuNVQlnoHd5xy0xRCaHZdCF0AZ5pspN30ESAJ21WT+qLSauj81JCQ+hAKAj4PlQpUKszdOrg1cMPWXZjMVoyl7HwR10sZbfv2nqFDO88svzNL78EYpiXmhjKhLIdUyaYUJeaPv5yXvtiDSxQZPqgZK/46S4HZjs3mYEDHFD4c15MDm466j//m6BVsPLiKQ1m73aaETu2nkp1dzOlzUuy1N9mOQ1zI+Dvn0qt1Iq3rR9EmUDgcoZmzLHYLC/54nZzCHI/SSGHacJ688UWfuP2LITU8FAT6vi64qaE62Mbk8yLU2TWi/UoX8dR+L0aBezHBZbaxaFL51Q+8URVC66TIMLeWLScCXBAoQtqMSKYDOXVXCYcoCd5GjX3HfNrtn/hsk4Xt4aMzfPaNvKo5dw1ojNMl8seO83z06xE2bpnM2jX/MGnCV+gGS/b1maPmEWWIJiUGBnW4noO/7nK3sWP3VJ8UYiUu7fUKWVlF/PDXOdRqgf5tEpk7ppuPYITQzFlh2jBGDnic/Wd2czbvFKeyjhMXGc+N3e7023ZNVJy4mBG04PXHQykaE3D1smMz23D5yWqpLluqu53i6heK3uaH6m4fyiah/xVhXplClxCY9alCrD/kQQiuRHm25dqGwSCZRQDMZhtJSQnMfXsIt/9nTgVn4hGlAXBo0RBMJXZ3MkVqaYzru/PXcOifDIz6shXmhAUPu+k59Rq9R/QAgE5f9pnLk1h0xAO0bduIc2fzOXLiFff+9OZT2H4kj0uaB86VDzbWNVxn4JImPbikSQ+/+73hj82sJgTwxWDWCFrw+nu4eoeWdFcEJlcsarHmzcXFzgS39gvVJ8hqSiB627WrW2u/UAiLELnrRSlmN9Sil5W1iwkmC60qdWbtQRnhsfzFpYyb/1e5VA07F9xGx1Ffun/bf30AU4mdmBs+dDvn5FC57ukJ3NM1mU8/Xs/JM8H7Hpo2Hs9RhX1cuWpIjdRxqKjE4/iDh6ezaf6KCtutyVjX6ir54w3lhH+hNet/XVRDTZofqhP+bMg1MWlcCMhCtzYx6rWRjJ0rMcbNfuRt7ntV4+5Lddt4/cLlQvxjCyaLxA1xbvl9GK8sK4nUvesLHodf070+S9ec4IlxX5CSksjjN7di6IDGHuaGRsmR5H83wv1bFrr+sH/jEe7uksyr3+322TdzlCdvg9ls80ji8IeUlET2nSzg7NlMH+HcpRxt1xs1mWpbXeaHQKFgF9K08a8TvDICmR/eX/QZ99x5K/oQaR2zcnJ5ZvoM3nnj5Sr1qzynnfekAb4CuNfgm1i5fDGRERdv5tyFgmxTNdsKgPja74DLhVEnmTaUdegAVq2Z5BEypteo+XRiHw6eLqTD/Z/z5Pwsnpy/zqdJJS+DqcST+OjM0mF+HFq/uffPHDUPvVbPo2+PdP+OMkS7zQ5WuwVNgM9gUNsE/tifA0C2V4ieVquBEGJ7oeZSbatqfijPIVhTmnUw+NcKXhne5ocPFn/BHbdc7yN4HU4nGnVge2BifFylhO4LM2Zz7eCBtGlWRvBRkW27JrX2ytaECmbgyW0rnWuVtfdWBsqEja9eErCZBBz26ru+HHtqtjlD+siVIVqypmn/9QFUKoHWDaM9jpUjGwAfMhxvJMWGk4On0Jg+/A2mLHwCAL1WGjeyVvvsp48za1SZxqzXSmXoF03y5G4AWPjbkzRp+CStW/vymCjtI8rJwGjU+6+aUYqapFr0JiYPBsFG9oRawbo66q796wUvlAmy9xZIgvPBJ55CrVKREB9HXFwsZ86cIze/gC8+nMdzL7/BydNnsDscJCcm8NQTjxAfF8u58xkMe+hxfi3l5O01+CYeuO9u1m78k/z8AkYMvYPrrrzc59pOhwtb6eCU+2GxWhjx4J3Me+NDYmOlZduSpR9jMpsYNXwMHyx6hz37duF0ODAYDEwaM4KGafWqLIArm71W0cCrSf6DyuLqsZKQXDJFFbD8TSAUmguYsOBhAI9qybLmKG/vl/y5/wlJXzapi+u3U6/vbI/dZ5YO8/ktx+0aw7QBBa4xXOthevCHxOgkjzp3VrvFw7a8aJJvAUyAZS8J3PqUZ+RoVlYep05Jq4go42if9GZv04f994fcf7urZvhBbXAd1AQqMm1U53dwQQSvIDhp2n49AMf39sLprJ5qD6NHTeb7lb8x+4WpRBiNzJj/DgcPHeGdN17GaJA+znEP3U9sjKSFLPp8Ge9/8jlPjn3Ib3s6rZYP58zg+MnT3P/oBK4a1N9Da5a17BJXtIeWG6YPo3ePy1i17jduueF2RFHk99UreeZJyQ74nxvv5P5hDwKwdsMfzH5/Ca8/N6FSSSZQvTXXvAdebRdIDIQ5Y9730NqUMa+hlpqXhW5FCDQhyTy6AMKlnuQuZ5be48MJnBQb7kNXGQiyDRkq1oihVKvFU/OUNXeQtFRvbRekcDiLpSwcTmkX9kdNWRnUFtNXdcKf+aEmFI+gBa8/FV80JuBSjcCo0qAJgiTZDaFsKdO47SYy9rat1jTeYmc8EVhwOlxc1qM7apfKLdRW/PwHv65Zh81mw2a3Ex0ZiaXYitVsQxQ9IxH69+iFpdhKSlwiKpWac6cySEyI571PlvDn9h0AZGTlsmvfIcLCpI/toVFjaZ3elkEDruStd17nlhtuZ/feHURFRtG4UVMAtu/axg8/fU2JpQTR5aKouMjj/q0mG1p8hbDDJWK32j1K/8gIhREs2FpTwQrdytbqCmUQG416fpgpcsdzoZcs1+hErGIBD82UQr3Cw7UeBOoyZo6a5yGUy+gVh3Jw5pfu59FGYd/NzCz0aOOfrSf4BxgwQ6JwLI+c3RumEruH860i7VfGkqfVboen1F8NUcbRmM02dr90JTDE43h5XyAIA3vA33vA6xlpL59P/g/2kITyha70UFl4T7oXrOaaP7uHRRXNCb0WnUEXWnl3wXcGDjaNN1gUOxOwu/So9AnuNvfu382yFSuZMX0OMdGxbNm6kU+/WEixMwGT0wEIHte3qVModkpOLkGlptAeTbgzgbvueoy7pLp8vDn3VQYNuJL2bTt5XL9VeltEUeSfQwf4ffUvDBogVSXIzMrg3Q/m8MYrb5OaUo9jJ44w+dnHvfoeD05f55pTdGB1OThYcHNIFSiUWUHVXWuqShlHQQ5qb37ZBY/7On5EUSTPlINLY+apd58iISGC81lzAXzYzF4eMQu1KJl1lJqy0jFV2qr7r/QJt7mjJ/a/7OLWydIEINt2ZcgCV0ba7YvYNW2Qz/OpiPwcICvfTE6xzeP+5dpqSliKBT4cp/Eo7Z6QGOkRqQAgbt4JZgtHFt1J6n8W+VxPCaFvF4y/bSL/uxGekRYuV1DljLzxbzY/1AQujI1XVFNwsqzER1iEtHz3rqFWGZTHp2syFREeZiAyIgq73c7Pv/5Q6esEg0EDruT7n75m244/GTVc0qTMZhMajZrY2DhEUWTFT9/W2PX9pepW1wdQHbXRqmspqtPo+W7b52w/ttWj1hhI5DreyQl6jQ5H6bxltVtCMlNodCKmPCHk+GWl+UbSbMsXfAAthn0OwPyx9wCSYA42fM5b6AIIPTtS8uN6EqLD+WXGDUxdvJMSu5OJt7ajf/skv31Smj6qA7Vd6eFixYVzrom+EQbVwSJ28/W38cwLE9HrwoiL8ww5uqRTd1at/Z2Hxg4nMjKKju0vISe35ohwBlx2BSMeGkLvHn2JiJBKojdu1JS+vQfw8OP3ExUZRc/uNVPcryJNtCofQHXm1Vd1Ipg5ah5n806x/dhWpjxzLQ8/9FG5x899bC5qwnno7TJe4UA2YodN8Ijg8Na8Pxyn4aXhb/BUaZSBjKl3v8zUTye7+7c5V/IpyOabDs/9hj8Yw7UeSRQyCs2FBAqf0+jKtPL9L0tJF616NPUkSFfg5unr+HzypdSLN+AQBTLzbXy14SRXda2HffXDbvKfY9+s47/zt7Bs5R73uYcW3Vkttl+oHJnT/xJqlY83FITC3fv/BU7RQWFRVlDFLoMRjpV1GtQEoUlF9mSlgPHWNE9mH+PDVXN4Y9YdnD6Vw4TxUmRKQkIEu/a+5DYHTB/+BonRSYAnoXuwzjl/glfZjhKeJgtPeJ/j7Xjzl0jx4cQy26/y/pXmhQMzlyLanYh2J637pZdbq+2Gvi/x4/p/PLblrxjpU6ZISapTXU43GTVVl6+y16gOXHCSnDpcWAQbIlaZAVmdhCbB9qO8ZX39+Eak12vDE+O+AOCa3tdya+87EASBn2f6F4LejrRQUV0cET+O81zx7N94BLPN1wcSjFlD5rLY9/xi9q85SGu7wyfRw31dL6EbsExRDSDUCb8qE/3FGllRp/H+ixCKxquEv6iDmigTVBlNpLr64hJdnM45gUpQkRbX0C8DljdEUeTQ+f1kF2XSLDmd5OjUkK+rjAmWIWeQKaEM8SoyF7rNE5unDMCg8xTiazLu9IgphrLJQ75eeWWFFk1S+w0hk1H8yyZirvLkVQ4P11JkXuCxLTXpUbKyimhQP4lfpl9Oi3q+JbpCQW0K3PKuX5PCt07jrUFcKIJ0h0vEWlreXdAEH07mnfUT6tIu1PCzYFGdH4BKUHF7yzUhnfPF9kyW/HkeEFEJGu4f+ChpcQ1DasM3EsJ/zbpH3x7pwZsgn7OruOwc+XmER1h8StfLqEhL96eJ73/5M3JNDpwJkQx8/BsAjn92N42HfOo+5vBnZeYPcc1Wjp7MdVf7+HRin2oTujVpVqgI3n6NmkEtCF4BEWXIzf86LjRXr9XhQmvT0LhzffSuMo2qOkPEvLWM6g4/qylURjta+dUhzOYS8vOLqJeaQFbGYtLinir3HKvd4sONUF4/lM+vvAwz5fMb/qoGk6lMY/UmwfEHZaSD0h4OsCnjHnrGLaRDqdAFGDl7s8cxBrXKIxOtaWpU0Ekf5SEULbemBK43LjQlJFRR8GpcZgSnlSKLnciw6jO6g6TdOcXQiDpqCkZVHgAOF+gMOmyO0OMYqwqHS6TIXILKaUbrMnnsq44g9UCD/mKPv6zKcjQ5JozTWXpiGodz+NhrAKyf8j79X1oNVOx0U/Lg9oxbiNqgJ32CpDnKJYHkfq2aGDhhQYaSbtNo1LsLZCqFqmybNpttRBlHM/fhD8ptU9aApfdWFk2x43CeRxmn7O/XExFWfQvgC21WuNhRpSetxkGaaQNn6EOORQ9UD2GJ3SrZL62uCy949apirIBWXzqx2EzlHl8zEEF0YbCdI6Xkb1T4F/yVFZJB11yDKteaqi5Uh3b0yn2d+c9L69hzaLp726XTh2OYtbHczK5AfUmfcFvAYy4d3JqDM790HyPbYJXxwN50m0umqHxIgPRavYfJwmJxolH5fsZyGFwgp1x2di4tmj6JSqXCaAxn9Uu+PCSVxcVgVrjYUeUpzujMolnhDzhUBsRqELxHt59EBewouBnIq3J71YFO0V/jBJp2Ds3+V10QEFGLVtSitcInXJlB/28a8P4+1O1Hcvl64ymSYsK4f3AzwvUVD+tTWSaGztxIobl8J6V3GJteG8acMe97HCNHeZQHJbNbeY4vJXILijBoykwZGp3IPzl7PUwWt/b7lms73+pxnrJ9WbBb7CX0bNuTzXvLTAyaUs7IMVc3JyUuNKKh8hBMjO7/V4Ero1rWFmocqF2FFR9YDuSBKSALjerNmKkKthReB4BgWghcnAPl/4OW4W+iOHCqgP+8uBanywUI/H04hw8f711hWzOW7cNsdxEZGYbd7kSrLXNKrZ7Ujy2Zd/gQzMhLfn/mh825wxFelmJtzTYH6Zc0AuDk9pMex3jbX602Cw/NHgWATZjLg2+WZVw+MtcIOFjytBqHTRaoHT3OP5F9qMJ7Bfhjz08cyyo7Njk5gWYpEbw3rifNUyODaiMUlJeg82+c8KsbFzyqobYpBx1OBw6XnTBt6DP8xViQ7/+DLa2FfgFOlwjoiG+divYKyTbZqVV96icZcbhcnD2bhdFoYNVOPKraBkKh2U69tBiOHs2mV/eXMJms3NSrPi/d25kwQSwVrqE5jjdl3AN4JkismngZe0zD0OhArxPRaD3bVJoSHpn1CA++uZCmjcdjNlndXBN3vej0W2D00l6vkhzluwpTkuaA9M6/NR8hIzPHvc3pdHL0fDHfbz7N4ze3Duk+Q4F3HK287f87qlTssrpQ0wI335TLX0c2cfDsHrKLMhERaZHamiF97kclqPyG/1TU1wvBWq/E/weB2zNuIYv/ymDqtgwAbu/bkFmKdNsdB06TWZiEKEJcXDRarYbGycagYnjvvbwpI2dvxuEUyc4qYkj/xkwd0j4gAUxlEyYGzFiLwbC51DxQZtctg68fwx/PghIP376WHQd3kRDRlMEdb/LZL5Pm9IxbSNdSBfrK3g1Z8dcx9zEulwsRkeyCEvdEVt2ZaTIupjHnLccu+pprF4NDpTI4nnWYhavfdv+2WKxYrTYOsZ8/90xnXD+Jgb/S4VNBstZXJ/6/mBWyTXYWb8uguNiMy+Vi6bqTPsdlZOQQGxtFeHgYKgEWjPWfqaVEUYmdPw/mMLBjCs3rRXBz74a0TPONU3XYhJDruWl0Imcz3nKnKYeHa0lI8CRsCuTwOpvxlt/tsp1W7kuXegPpUm9gwD74e+cdriiLYEhMjEOjUQMCr326tcJ7+l+Av2/mQipPF9zUUNP45s/PEAQQRVCrVRgMYRQXmwFYfTifdyf39zg+1MiA2jQ/XIwxkdUNZb8bdWwAi/fjdDpxOiVN1Gg0YDJJ7y8xMY7CwmJUKgGNRkXDRAPN61Vsrxw9ezObDmTjcrr4TaPi+h5+yt9UAUlJUTjEhWRmFnpU9QX4YppnhqdeG8Z7Yxej0Yn8NEPk3hm+GncoLGjeK5uzOWbe/Hq/xzGi6OLcuVzi4z1jkNFq3CnG/kr7/BtR3jdzIZWn/2nBu/PEX+SbpciIm2/pzCVdGvHs09+QkBCLy+UiJtIQ8NxQ2LsqUw8qVPyvRyuAb7/n/3AQURSJjpaEqSiK2O12oqKMREUZUalUaLUxAKhEkVfv6+yvWQkqlZux658nVpKfX4TJVEK9ekls2p9FG6/aaFWFyWT14OqVY3KtJv9C1GETOJd3hvTmc5j6/A0gisye/Tu3dX6A2PCUoK7p/fzyi21c99wqMvI8S7hnZ+cTHh5GmF7HyBs6MnOkVFEj4qoyp2R5pX3+DQhFSVEqT7X1zfxPC951+1e6//56+Xa+Xr7d7XgJ16t5dcQlFbYRDMlGbQi6UPpRE32pjTx379XD2z8e5j+3XcKct34BJE98QkIsAIbSkLFih4sGSUaW/leiOgwGf+96job1JqArLYjaqoEkdKvjHmWTgLUS2qIgCJSU2CkstGC3Ozl7pgBHO4FgS8rJz++nH/ay62wxzmgjOUU2MhVONRklJRY6dGnE1KEd3XZdZdHOguJ3Ce5pXnyozHsMJiSwOnFRC16L3YLDaScirHLhLg7RgV6vxmp1UlhYTEmJleTkeMbf0oqRV7Vwf7wVIZD5obaX84Hs0LUhcOVr1TTka2iK52CxOTh1qiyWOyMjm/9c3pYog4apQzsSEa7hXG4JjZKM6LWhOb/6tU8hI9/CsEFNicsvZP/GQo/rVxVWu2/pporsxcnR9ejZuhdvzJQUhq5Ne5ESn4ggSJEQwZgcvjh4GYvWvg0COJ2uch2N3z3X3+O3UkN3rfqTA1kmXCK0bhAVlMPyQuNiLMoaCFWquVYeqnrjW49s5MftyxBFkaZJLckpzkIlFjGsWzJXt/ZPCu2N61vp+eSvfERRRKcr89Y2S40MWugq4Y9k40Is5/0J4JroR6jmjaq+c4fLwbr9v3Ei8ygbd20BoMTiqTk+e5nEIJZ/4Cz5pduOnsiqsG1Bq6Z1qanh4MwvmdxHXr5LNtXqvke59LqMuY+YPJIh/EGrh6W/3QzcDMAHY9XcO8M3GQLA7rTz5+F1FJUU0r7hJW5yn23HNhMWriU2zsDDjw5g8qTlxMREodVqEAQBp9OJKLponBLlLt3uL5LhuUU7+GLtCTIyJH6SvG/vI8LgWZT2Ygmr/DcJXBlVqrkWCFXlv7TYLaz4+yssFitOp5MjGQex2+w4XS7eWuvguitb0bJ+xWxJL/RqSt+/z/H8kt2cyoKwMD2XNI/j6q5pIfdJiQs90GTUVD8qGzVR3jtX8hD4qxsG8MfuH/nz6Dpapie5t2VkZJOYGM/QfqNomtSczbnBl+kBL1KbYzeUktoMKf8kLwR7j4Ewc9S8CoWuP5SnZS7fspj9Z3YjuuDPw+t54IonSI6uh0FnxGq1ExUZRmyMZCwwm0sQBIH4+Bg0GjVqAf7ed9pNti6T4cjFNY9mFHPdc6vdQhdg2+Fc+nUoszUrhd3FEFb5bxG4MmrE1FAV0haX6GL3iW2IokhYmKQ1iKJIsakEh8NBeHgYp7LNQQleQRC4sks9Bl+SysksExq1inrVmBr5v4bqiA0O9M6VAf2B6oadzD3KNde2579PXUXjBmXldLKycmiS1Cyk2mj+oCS1CQaBTDjBjGs5WqGykOOGvZMhQPoeDpzdQ2FhMcXFZurVS+Lw+QMkR9fjstaDOJp5kAMHzvPg6MWIokh8fAwCAo1j9UwY0IDOfZrQREEJKUPWfP2tBgeN/5b870a4M/F87ruWIwP+rQJXRo3aeEMJzRJFkXN5p/ll13ecyDqCIAhkZ+eh1+uIjDQSFxeNAMRH6enaIi6kfgiCQKOkCJasOsa0JbsQRZhyZ3vuHdS0Cnf3v4PqTMaQiznG3PAhBsPagGTd/tAgsQFz377R777KZBpWBRXdI1Q/Y5u/uGE5GUIJQRCIMybgdDhL43EhPlJaJRj0RsYMnsSvu75nw8FV5OTkExFhJDw8jCH9niNbHUbGnjJGszNLh/n0o2lKBHcPaMwnv4ucP19mxjmw5RgGndrv/dZWWOW/0azgD7XiXCvPI19sKWLF31+x/8xuQIq1VamkBCKNRo1arUIAxt3cClGEOy5rRLRR53uRCnAmx8xTC3dgMlsAkec+2cmADsk0TDJW/Qb/B1Cdg3jl9rMARMcY3DW7CorfZdm08v3k/doMdv+tpCz0ly4bDMIiRO6Y7OTR0vyZYHhtQ8GFLNh4Z58RfLv1cwpLCujarDfpqW099suCWKNRIwgQrg13rxh2Fd/P5inQc/oq0m5fxJmlw0iKLZvYBEFg+r2dGH5FM7ZtOMKwBX8CsMd+N8Nf1NAGh98qy7UZGVBTz7u2zCa1FtUQyPywbMsijmUeQRBAr9dgsTj48eexPDnxK3bvljThOy5rxLibqpZPnltoRUQKoxFFEYMhnKxCS53grQTKi3s8kVHMuHe2AXDubL57u8lkxWEr/1lr1Vr3sXL1hbMZb6HXhrbCkSEt0SVe21DLsVcU23mhl7qJUcmMvHxswP0dGnZh36mdHOYAGrWWm7p72rW35t0NrAIg7fZFPqTngiDgPJFF5yax7hjk8lDrJOY1UB6+NpOhaj2czFsAP5911B1bm5QcxckTubw1+3eSkiNhtzQApgxpX+XrtmoQTbtG0cjFqtPrR9G+cWyV260KlNVkvbWOix3+sn72bzzCXyeLcPnhlnlwyAoGtLwZo74sfVZZtVdyuIXx4ThwKpjp6iU/xntjF3M27xRHMv4hOTqVlqltauiuPBHoHn32X4TQqDXc3XcUZpsJnUbvntRAcjh6h7sphY3yHrfmDaU1gWksL1SGZE0VsawtLpYqFbusKs5km+k9XgqOd5XS+un1KkRRRK1WU1BgxhCuZ88712OsBnZ8k8XBt5tOIQI39qxPRA0QggQNlQpzj04edbXOLB1Gzv6zlWquqpV+qzJwy6ovSCTfLZs9hclkQ69XcfJkJgDJyYk0S2nB8P5jAN9S6VAW56qMRAB46q6pfLL2HTRaNVarncEdb6B3y/4V9qu8kvByv6F6a9D9G6BkT5s5ah56rR69NszvPfp7TwAfTbLTM/YrAFp1a1yT3a0QNbn6CNV00v7Zn4I67oImUMz57iAgmRNA8DDkAzRpksrl7ZODFroHThVwLKOYri3iSYwu84BbbE4yCyzUiwvnrgFNqq3/1Y202xcB/mt5lYcLzZS2Kede7n+27ONs0TKZ3bvOEBlpIDU1kXPnsjCbzZzJ9SW58QdvsvFfdn5HWv1YVq+bwLjHPufPdVuDEryBTAs+WloIaeH/a5CFLlR8j588befhNx/m8LGZjJohJVvs2jMdzgX3XmsKNW1+CAXBrs2rtyZ7iCixOQkP1yIIAmFhvg4Uq9XOj3+d5de/z/nssztcvLBkF1c89RuTPvibD345zJVP/8GDc/5kwJO/cvS8VCF174l8eoz7kb4TVnLZxJWcyy3xaetCwWjU+2WkmrDgYQrNBUG3szl3OJtzh7N/45Eape9UQqMTGTHLwYhZDo4W7PTYd/ZMPjfd3Bm7w8mpszNwiAs5fe4NTpw6zejZQ/3em7cDTa8Nc/+LCo/m/PkC3pm/hr+2niRSX3leBWW0gvzByv/3jFtYq2mjIDkA5efoTZJeUwjFyShHWnw4TkNrliCKokeGW4d2U9x/bzucw89/na2wqkdN4UK+x1BxQU0Nfx/O5dbpa3C5YP8/L/iUsw4P1xIXG8MjN7Riwq2edr23vj3A/J8OYy6xEB4eRonZBoKA2VyCwRDGqKuaExmu5Y2v9yPfoUol0Kp+FMumXAYqFSaLHWOYFlyuauchFUWRpetO8OfBHDo1jeXuAU1QqTw1sANbj5NTbHUXV5Qh19R6ffTbqMXQYlcrY3OrjKnBewkqRy88/sQ1LP9qO3aHk+YNmvLH5gcBT4cZ4GbkstosgEQIHihO1+aw8vXWTzl07gDJMSnc2v1e4iKCy16UEWyGX207zUbMKsvMC9UBWBMQRZE/D69n98m/iY9MZHDHGzDqI+gQ8QE9p0vOOGXNN7PZxpmlw9yrtZSURMJ0ar6c0pdOTSvnFK0OXCjn56hZtVDePVQonUlnM96iy6AoHt6dwZxvDnhUVQVomDYJu92OiEDPVgk+bR3JNLFt57Pujzk5OQFBkKIVAE5nl/DTX0coKbGWkqGICIKavScK3H1Q4szSeyQhjP8UyoqQV2xl74kCmqVGkhoXzid/HOOZRTtxOZ18tf4kxRYHD13bEvCMRfQWulB+GfCKEIpzoCa04zff+BGQJo3Y6Eg3haPJ5MtdYDJZefTtUe7fgRIOdBo9d/QaUS39u5AmmX8D9p3ZxU87vsZisXJaf4JiSxH3XFY2YRoMOo/xqRGGu4UuSMkuSUnxjHhzM1tnX41adWEmEm8n4cWGWrfxyrNl8yYTKDS9xxWX1GP+D/9w/30L+eCj4QBc0fdV7h3UlIx8Czf0rM+lbZN82unTJtHjd0ZGNsnJkhYUF6Fl+5FcXC4XeXmFREYaMRolgay0IxcUv4vRqCfSMIq02z9xb/cOrakIh84WcssLayk029GoBT58vBdrdmVgs9rIzsknLi6aVTvP89C1LTmw9TiCVs3WvKE4bAKJiVs4lzkHgOSEh8nJqZ4qxhVxjVanRpCa9KjPNp1Gh8Mm+KxiQFrqanQid0x38vyXke77X/C4JWQNP1hUNCFdKA1JaWK50NpuWITI61+15XVeI8o4Grvd4bbLK8PPyoNWK5kOc4usjH5rMwse6+mz0qtDDQtemYQDyrRI70ym1NIU3u1/n6R7l+ncM6wnx88UMLhdAs/f41nYT4nbLm2Er7VWQBAgz2TH4bCgVqsVbPuyE6/68cHPRyg0WcnMyiM2JorXl+3j0nZJ/L5DR0xMJHq9jnjBxfYNR7nkubsBaI2UNisLHZBC5wqK38VksvoQaAcDbxuhwyb4xCbKCFbAWO0W999KU4Ayy+rZ294EoMhcyFMLn6A8lDkOpb4q77824D0h+d1XQyg0FzBhwcMAzBnzPnptGA6b4Hd7daKi6A6Q3vMdk52YTJLvIb1VA7ZuewaQVl0g9UlpZpAn3EOL7mTp+lO89e1B1GoV4eFa2rZLY8OeM+w+nk/Hphc2bPNiRLULXuUH3kFRH2vzlAEYdGraXO95fO6Bs1zbKpYVB/IYfGVbxjwygOXL/vbvBFOV+QIFwLDpb36ZcQMj3tyM0yUSFRXGpX2b8/NPe8nNLUCn0xIdHekWuIIgkJyc4EH+AbD6ycvoMfV3AJaP6emuQaXsd3koyipCFEGlUoEA+08WMLFPCifaxLHzbDFHswp45/fJPud5C8ojx193C9xPp9m5d6q0DH911OvEGpLL7QPgE/Yja1PeNJahhE8p32EgoSBv00f78hPMHDXPLVRAchx+/lAvSqwCRuNoj2PHvzeG5+9+M6SIjspCmWVVW1qu8jkEs7064G2LD0RN+ejbI90ZfgXF77qFrhKzHp5XWvlYwveju9Jz+ipaDPscgCn39uTz9ac4eHi6+5h9H/5cHbdxQRBKLcZQUW2CVylwlx0axLTF//XYvzXvbvTaMHY87c1SdQ+dW0NU2Kt8smI3bdOfwWJ18PytviW65QoCMjK+/IMrJ37n/h0T04Bfft6LWoDYWEmrEkURrVaNXhtOWkwjerccQKPEpmj1sGyadJ7Ddh/vjb0PgFsUMY4AhiGDaNQ4gWXTDAG1hWaNchD2TSchIZawMC02q4Mle9vQve1o2re0MOw1p48Wm5r0KIePzSTK+Ch7979Eg4YJGI1693F5mWU20ScXjK8U4Yr8wckfW+V4GMoEb5hRRLR5Hh9IIy7bpvcRvpNWHMPhcPHlvlf5bs2TmExWUpMexWy2hUxkUxX8r4aIhQpvAXNw9jIueeoun+OiDFGgSKZYsL0lSvPDR78eZWCXeh7ntGpQMZnVxQjv76C6U8OrLHj9ZfJMWzw0wNH+ST8AmjV5kmkJb3Esx0KntAi/dl1vKI36AAcOnOKF2zrhCLuDb7Z+RmbBOdRqFe3b1ycxMYJff91PvzaD2XpkAy7RRYeGXTDoy09jlcNlEhIiyM4u9qv1xRjjCNeF0alrGrfcegkTx3+JRi3do7cmYTTq3REAIHmFmzSa4P794VMLwF45bgJ/TFbBIlA0xJmv7iXtPx8DcPtzLr6Y4nmeMtHB37NR7k9NSeTSvs05d66Ao0ezOXC6LKzMbPaS6OXAZC3G5rASY4j7VxB0y1DGJiuf0/yxC9x/q6kZGzf4r5Qsv3dlgc6WHRsi/rGFA1uOAtA1wukjcJ5/eA9vLL2ED0oTEc9mvEVSUhS9ur/kPkZcs/Vf9X4gcPRLdWfKVUnwKh0SkrNEcgyNnu17bDB2KzHyMRpHQqsADhBxzVaEft3cf/tDcj1JiGn0Dq6+pj2r/tjP/aN606xZMitX7uOrzZ+QZ5JKoWw5tI5rL7kVnUZP/fhG2Bw2jwGo/FsJJbcsSEv6azrfxrdblrBp4xGaJDenfcMuPuelJD7iHojx8f4FvilfQK8VPIi0Xx9TfrlvGfKk5s19WxHKC7VKijV4RJtUZdYXgWHDe/PAqE8oKbFgtapom/40G16/ki1TL0e0u0qdOIHx15GNrPh7GSIiLVJac2efEahVlZuoahv+voEwo4u7ppdF0Xw4rnqvGahSsvc7F0oLdAKIf2wBl8udkabU9j4cp0EURZ6d105q34vHYdOfT/HYI5+xef0/bJk5mH8TKgo5rE7tt8pxvLLw3ZB7Bw/NHuWz/7mhr5AQlRCyw6Bn3MLyw35UKrLatXYLxlUTLyNcp3bT1snxkUrtsnHDNGwOOzk5+bhcLhITy+IMY43x5JlyiIoMp1/rq/lkpRRyZjZLwrh5kwmYzTbmjHmfh+Z5DmQ5/rLEZqbEZibWGO8WsErHiTfmjHkfq93qsb8mnCsVIdCzdjtHVSq3c3T/+kMeA64ix5Byf6e2DSm2OjGb7WRm5qBWq4mPj2HBHS1pEFNx9pTD6eClr/9LscmMzWYjJiaK23sNp039DpW99QsOSfCWVRYOtZx8VeCxyrksHaG/pNSYftlE9FXvehyrzKYURZH7Z1e8srrQxTJDjU8PJga+ouiXWovjjW+XRot7PgPWYjDo3EvGmrbT/XUoh24Dy2bpuWMXck2HeliOZpQ+QF9zh8VmQ61SYTSG43Q6cblECguLkVdD94+8lLNnC/jpl+9488F3uP91yZn3yRQ7rw6X7AWSYPFfyDBcZyBc50l9GGWI5r2xi922UKvd6tZm9dowj/jlJU+rKcizVmg3rS0o453zvxvhN75Zvr9AkPf3jFtInktFp4m3AtC5/XNYrU4axeqpF6UP6gNxiS5cogun04nDIX34Dlf5WVIeFShCSMWu6UiDiwFKp+uBTYdpXSp4jVf2AjwFr/ezeOCGtWw7tZq/tj9biz2uWXiHHIKnlut9XFVQNcEbYSB5UC8KbxlQ1qAwnDXPXc7B/Cr2rBys2nmeMe/8xYEHrnFvm7viEPN/PMSKqf05sv0kIy55ns1/P+thLmjcOJ6cDBsul8i585kUFBS7zzeZSujatRGnTufx04+7sZQ4+HCcLEQ16BUyR2lLNZmsWG2qgJlXFX34haYCNIK0migoftcn7vXDiZ9c8PjOqsJqt7Am406Gveb0uL8rOzfkl+0n6bz3FHPGDPF4fk6Xk61HNpBVmEGL1Na0qtcOnUZHn/SBbDj4B5GRRpKiUkmv187jOjL8vYtQHHfVHWmgFOTzxy5Ar5NCyRz2sncbjFmoJrA5dzi9kj+p+EBAowONVqRPqwHkFRaR3lwy+ofrwxk+YDTj5kq+mUCmwH8D/Alg5fbqQKUEr6nETov7v/Qbg+kQF7L/5c9qjBw6v9jGc4t3IQgC78xfxew3f+eRRweydfszdG4/jZXbzwFazmUUe5gZADZvPgBAdHSEb8PAA6MXo1IJdG7czUdzVULpIBw9u+waPTt0JykqlUEdrnNXTOgWW1Zixd+HP+5tSeiGB8iWG/aa/zI5ULPhLoBHKmhloZx4ZCejjF+2ByZX+W33Cjb9sxrR5WTfub94bakUohT29LW0qd+BEptZik5R6wiLELlxstknJbk8eD+71Rl3olVra8xerBTkd013YTRK7zWQDbY8BJrMq7JSUtI/vjvexPThb7j3TVHEZo96U4M7smHSDTRKaMqby16V9v2pUCoqUd5ehnfM+YXKNKycmaIGTQ0mi92v0E1NepRzmXNo1aMpqFW06Sc9/OrMQX/yo+3klTjp1z+dl178Ca1WzQ/f76KwyILN7qRBciQulwu1JvD1lJquEr3b9CE9rS3NkltSwQrWLxq30bLtr7+xOkqYcbVkt2vYuQnKkJtAE1JJid1H2/VHoCO3Af7rgFWn8E2KDQ85i88byqiG8HAtL973CuPfHu9znLer4di5DZhMJRQUFNGsSVmIklSvTaqoa7VbsLosjHhRgymIhD+ZHEb5/Cw2J0Om/cHfp58iQqfitt5jaJTYNGAEQijwpresCSgn84oiTPz1rwxhfDhOU9pnT21fpo70B1noVgf8aZcXmnkvGFSm0nfoglelosXwLyi87XIAdwwmSI4o2aCujLmV40mrQwDvOVnArbd3Yeq0G+jZ7SWsxSUUZRew6IP1PHBdOldPlEpj3/jf78ttJykpnsxMKbrBaAwnKSmWpb/fVLpXLNe7rEx8mPXwPMbNkwbqu+8P49WXf+KXr7cB6e4XIVdvhdIMPgV9nfyBKz8aOewMPJef5Rn/gwl3US53Q6WerAy8E0TOZ83FaNQzdt5CGqZNIj+/ELNZ+vhlZ6Tc/1/iw8koKg0x80o5lR2nqUmPk5VVxEPzFnrsV7JvKYtO+vtAPltznL9PF5OfX4jDGM43W+bzeP8GqMPHoFFrsDlsfL7hIw6fP0BSdCp39L6XMG04Gp3cvj7oMT1/7IJSbVdfJbNCWIS0sjx+LIvmTScyevZQpt79csjtBCuolcJ9ydNihSGLB2d+SctO9YPuR3nL+YpS3y8kKiNwZVRK4xVFkSjjaAwGHaIoBh2D2S12MZsy7gn6Ov5muj6tEljyyWb+/usE584VcF33NBKi9dx5WWNah1BRQha6ABHGCLo29U3YCATPDDEjR89N4KvNi7h36Ifs2nmK67rV8+i3h1NKq6HNs5LjT3j5E/fzmDt2Lo/MLosc8V5+BvOSKwp38c4gUy7Ha0KrGPaak6sm+A/Ja9/wEnbzN8mJSdzRa7gHEXfr3s2Y164+//1oOwdOFXBll3o4ft+MWhA8JvRzmXPQCMOJKs2AK88eHuj5FZrsCIDFYsVoNJBX4uTZn46TFjuX+wY+woaDf3Dg7G4KC4uxO+ys+HsZq7etVoRROYNWKNSE+8RBVwZ6jQ5w0bzpRPe2qZ96ZkYWmQvRRwevqUtO34qPl81sVruF57981P0cFjzu4Isp0vmdk5wIg3oB8OvcFVzxyLVAqd03gAmiopVaRaWYAqGmTJ5VEbpQmXAylYoTTZp6vHQo0+rcQqY0vVf5oYSq8frT8Cw2J2//8A9HzhWy+3gBJ7NMIIrodWp+f3UwDW4fCMCfm4/Qu9cLHu0FisuVIWuaS6epsJikfvrrr5LKDyQh+fexLRw8u4cOiZm88HBPwv2UyAbcAxLgn9nLaTn2FgCWTFGVG1ZUYXidDJXK/cylzECp/8rU0dSkR8nKKvIQvBWF0lSGRMb7OcmQ+2V32lGr1Ngd0sTdTPsR18zeAMCPr17PloM5tGoQxa19Gro1YuXzg7JwwWA0eH/3eDLTxDXP/kFRidTXgoIiHA4n8fExDO37AHtObWfbkc1kZGQTGxtFw6RG7Dy42yN+tbxxXRMRKnIImrcPwxsVmRuyCzI9uDXk8eAdAunv2VrtFo+wSuUzCPTeIXCIWXnjqyrlhWqyVJO/fmkGzQ3q3ErF8ZqsTmKuK7OB+asXJt+wzMQFlWdf8je7FJhsdBizAqvVhsvlIjw8jNdHXULTlEiGvLoes8XhwUR2U/cm7MyycOyYRKqekpKA6IKMzDLeBnmgVsSR6p2g4E+4+czuWo07+cMflIL3o0l2Rs2QYqLlQV8ZwQtlAtw7Z3/+ww6/H6W/VEkZoQ5c5XMqTzgpS9EoaQcHD3ydAwczePymVoy7ubTYqeI5Hpz5JRtOD/FpryL0jFvI2QIrOUYj6fWjKDqSwfqj+cxbfxaz2YzT6SI6OpIRAx7F7rTxydr3QBRxiWXlzuPjjWRkz6vw3moKYUYXVpuVzMJMprznX42uSPB626BDCQENJHi9t3ujvNjeQDZeqLqJoTYEcOvezYIWvJUyNRj1al+7pQLVTbHnj2HLbHOi0ahISU0kPEzLiRM57Nl5hte/zEcjQN9m0dx6czMax4UzY0Mim/5ZjVqtYvh9/Rl8ZRvuulNysU+4bQozv5Q85t1iP2VX8f0V9idQ2rMMk8lKVsPG7lXBmaX3kFxqE5ch/rHFQ0A67IKi5liZwK4qd4HNYeWfc/tLWaVaVni8P/auyr5HS7HgDr0b9lrwS3IZK/8Yz7jHPuenrUfKBK/d4f54nWZfjt9gsPzI5SxcMw+bXdK0n+hfn+S0iZw/XzYBXNZhAA3iGyMIAiMGPMLRzH+IMyYw9xuJiS0nx4RGGB7w3dQkAY+7bdNwjp05RVq9JD7/cjRLv/iLOW9VjpQmlKoUIGnvCx4v0+bVYlmKvLfNXUZFIWb+KpFXl/nLX9uhIKiyUBsX0n5QcO1VOo7XXzB9TXKaereZWXCe6Ojj/PmXNNv36vES074ezzRg6rPf8eEH62ne8G4yqM/mQ0/zwEP9WLxoE5GR4W6hC9AosQm7ppU9rZ5xC1ny9L2V5jwAPKITdDoVabd/QkHxpR4kOTabg88e/oDh8yRBr9EGJjy32i2YbUH2x+Vy59lvzL6D939/i8xCScvf3rsD63auBSRHaHkCvbreYTDPUUmic+gTTw123ZqDXNKoep2A245uIjHJyM+/TmHcY5/z+d8FjPacF7mm8y1u80bDhCY0TGjiFQUQGMoPuzptjN4Co2fcQrap0kEQyMsrwWSy0bRRA8Zd8yyCIMWVHzq/n7+ObCBMa2Bgu6uJNpT5QfTaMD6cqIzfDY10PxB3cqRhFCWlWY+y+W7DvB/onR5c1ZBaKQ8fAoKNGNqcOzzommuVE7wKekZcrhpR4x1OBwfP7UUAWqa2dZPOyIgxxrJ913Pu35u2POX+e+rzNzD1+RsAiR8hMjIKURS56ur2LPtqm0c73WI/pXVvL01w48fsez7wveSZcvh99wpKbCX0bHEZLVIlbcxhE9gwxTPu1WaTzAfREQ+Q/8NIjOFaRFFkxJsbWbcni+GlisZd010seNyGyWT1iDyYsOBh93Iwv0eT4KpjuFyIdieHTx8hs/Ac2dl5aDRqdrp2hkRGU1uIMkQz9+EP+PWv6fR/8jf2lybkXH7pK7RJjeCFYYF5mSuDMK2B/PNmfv5pD8eO5qDXSgxa3ixq3tBrw7wiJjxDrAJqadVQhDFQCOH9Hfdz7JyRB0d/glql5saudxKmk8x+GQXn+HzDB7Rtl8bZc6f4bONpHrh8ogdxTaBKzzJCtVF7P0OZba9360RwuTyOzcwrcceJB8qMvBhQE8U0KxVOZu7Ryf3zxOtfVltnZJitZsa9I3mqk5MTaJLcnOH9x6ASVJTYSli561uyi87zIBXXgTufVWZz6dR+KjqNnpSURCL1AmMHNMKUFMeyP8+QV2ClxObkqs7J5YZmuUQXH6+eT15xDg6Hk6MZ//DQ4IkkRacAoArXEB6udc/4HnC5wOXiZEYx6/ZkkZfnWfRx/HtjPARjoNjJimAqsWO2OVGVJgPo9TrUahUCZR9cRUvLYO2zFSHYCgu/7VrB5uOFOJ1OGtSbCKJIhEHLopcGkRxTvem6fVoN4GTOESaO/5KYiBiG9L4JkCaAt8a8z7dbP2P2j9NpWb8F362T6BFlW74/B15Fzp+qMFuVt+SWt72mEThTYCVKr2F/SRk505nckzhdLr74ajQrftjFhCe+xOqwuJN7/GHELIeHvdbbBlxRKnUgB6cwsIePfbeqyTm1jepkKKuUxqtcSgcTqK107CidUYFwPv+M+++MjGzUahUHzuyhdVp7ftz+Fcdy99N/QEvSm0/hqk4306WpZCsttpgY81bgvuzYPZUGqRMpLjYhigYe/MhXu2nd7ClWTBsQMDTLYish35xLfkERFouV1NREzuadcgveZqOvQ3h5NYePzvCJ/JARadAiCKDX691JJ4FQkRYmQ1nPrgyruKXfbWw+tAaVoOLqzrfQrVlwYXNVMbUoUZ6wlceFyWRldMRy93aDIYySEunZrtmdwZD+TaqlL+72dUZG9H8Mi92CXqtHJZSt4Fbt+Yn9Z3ZTXGxGVJVNglLiRvmfS0WhfjVVA6xtn+ao5LYV9QPS4hqgUqkYcvsCzp7JJykmGb3G8/vwRyUq2+OtfnSHUFOpK1NJ5WJGdb3HkAWvzNEpY9hrToxGR1ACFaQBPP/hMueRLLRzirNYuvFjcoqzSIjw5OIVRZGlmxYSY4jFiZ3rb+7Aq6/9h/59Z3Iy4yQd6/cEQHBqPASZvxI6doeD4mIzer0Of7A5XPy+4zwjr2qOKIqsznPy87ZzxKqe58Fe9dgrjiAuQoqIcEQ4EAQVaXEN3ecbjXrMZptb6Ob/MBKjvkzrk1/a9V1uZ8Xfy7DbHR4hUTGxeoa/Kr2W/S9/hmh3smvaoErbvaYOzMN0aVu25d+DTuP/ni82GAzh6HTSsnPb4dxqF7wgJWyE63w1v5yiLKxWG4WFxURHB04bV8Lb+Ruonpt8bCgItm1/7SZH1+PO3iPYemQDKeGJDOx+jQ8/ruwo9hcCptGWBTyF4nzbPGUArXo0kVjtSr8/f4616khJr01Up0k1pHAy+cJ/ZNzk5hhQZlkF0ggClQKHMsKQ936ey/Gso5hMZiIjjDhdLgRBwOVyodGosdsdaLVS+2q1irZt09i16xT/6XkP7Rp09ntNvcHFHVPLbq9zh2lkZ0vpwgkJER42YoAxDyzmhx920bFpLOF6DW0aRPLhyqNce10HNq4/RHqMlqlXNiar2MbM9RGU2Ero0aIvzZLLbMQRsS7umjrM/XvzlAF0GdjKHcGgDIFyupyIiGhUZc9N+QEcmLmU9E4N/D5Tb/jTeOUwv8o4PYOp0xUK/LWn1HiV1aJVKoGIyDDi4420iNXx4eO9/LZZmbL0FWHb0U18v+1LRBcIKril9x1c0qS7R7/LQ6BwvOrop7LtamfL8vpGF01S+/yGMpvwwicduKz+V5dBhz7+SxDKs652Wsj9G4+wJuNOnlw4hkLTUB4JEDISKFRj/8tqzDbfWVUmDBn22kOkN5/M+fMmjIZwqWhlXj5RUZE4nU630AUQXQJF58NomdoWl8uFKIo+M3nXiI8RtGqgzEuenVVEXn4R0dG+QrdZ4/9i1KuJjtCR7xTQRxr5aOVRUlKiePudu3lh2g+sWL5NGlAbj/DqVTY25/qGnhXnqXy2HdhylNalgjd9wm1sGCdtr4iQpdWE292k1BXBGK4NGOLn7RwIBVVm2teJaLSi3+QQh00o/aANfDjxE1ppP+TTgwV8s/k07drW488/j3FPr3YBWq5+OJwOdp2QnK+CCjo06kKHtB44QvBHeofjVefEUJm2D5zZw087vkYUXQzqcB0d/BD0g/JdlP1W4tVvn6FVvXYM4z8ADH9VU+2k7YBHnHZ5mW61hVAmTkn2VbPglS7sG06zZIokaBx2oVxHgH8bpCcOHn6ZhvUmgQDRMeGcPjcTgPTmT1FS4sBud2C32zEYwjmWeRhEkX/O7SWnOIsBba9ytyP3o1W3xoh/bOFEZjFvr/gHQaUiMtKARu0r8JwOkZdGd2LMvK288MqVXNavJZ3aT+P8+UKuuXI2hw9lcH33NM/7C/ABKAlWdhWHobGJbuanQJD7vP9lNa0n+0kK8JOA4S2UK/IKV0oLqaIA8faae0P5gUdEqJk5qgst60ex40geU+5sx/2Dm1fquhVBFEVM1mJ0Gh06jbRiO3huLyeyj5KbW4Ber2X3ib+5vsttaNWhm2hqsp5bsG2brMUs3fQxJZYSRFHk6y1LiItIxGIzkxiVQrQhxuN4b2GrtP/mFxSwx7kdSgWvP5zMPsapnGMYGxXTOpQbUkDo143MzEJ3humFinYIRcutTFxw0IJXoxNxCp7lnQG3JqMRhof0kOy/PiAJEy8b7D3dksly9Oa9FWXLy7i4CDb9KYWLNao/EQEVDqeT8+eziI6OZOeJvxjQ9iq/gv/w6QJufH4NFrs0gNIbxHJdjzR+nf09V4yVSh7LKbQPvLWFegkGpj37LXHxEeh1ap66vS3bDucy6OoWjLlOEXamUtFo/G2lS+TfWDXxMg7ZpEgMb2ejtzbhDe9+K0scgTRpCb0ugUqWfa8KqrvWVEXkMBq1ijHXpVfpGhXB6XLy1ZZF7D+9G61GwyWNe7H/zC5sTkm1FUURUQQR6f9/KwpLCnCJTlylk7OIyEer5uJ0OVCr1Nxz2QM0Tgw8sVmKBdo0e5GMnAwKCopQqbS0afEsTtFJamx9bu8+0h0hse/0LpZuWgjAr7sgrH48N/QMnigH4LvNp7lxEJ5p/SpVWfhqECu/qiJUE05lEz1818UBMOw1J6PelOotaYThvPFAbkgXUuLM0lIbqN0haW0KvDj2UsZ0OeSxTRa6AGFhOlqndUClEoiMNGIID6NpjC3gA1iy6hioVezaO5X77u9DvtnO+FvacHmbeGY/+hGtm00mK6sIkCIokmLCuKpjEq3jdHw6sQ/Dr2jGnIe68cQtrQlTlnnXes5ZA2asdffhXN5plm1ZzDdbPyOnWEoxddgE9z8ZPeMWuu1hHv0uzc4Sf9uEyWQl5oYPiY54wIc2Mlicyy3hn9OFuFyVkyLK/oUyu1vtFj6aZMdkkjLMFk0KzgFb09h3ehf7T+/mtZn/YcCgdPae30JCqpaUegZAJD4+hogIA6Iokllw7kJ31wOiKOISgxNAscY4BAT0eh06nRZRBJvNRmZmDharlbX7f/M5R6MTGTHLwYhZDlR6S2mVlHBSUxMBkbyCYs6ezebo2WNsObTO3adfd32PzWbn7NlMbFYbX6w5LjWoUiEM6iVxbMjfjCxMVZ7iZ8HPh2jb6mmPbUL/bggDe/hUGK8JKM0KwWi5tcpOJgiCT4E7mRayPBjDtR7crqYSu/RS+l+CsuzjgS1H0WlUfPLQu8zbXCRVItj5pHv/wcNSeu+1/awcOnGcxKhkxvULc9/8+dwS5nx/EJPFwX8ubcgXa09gsjpY9PEmNm08gl6rct/HYze2IqfQwktHyz6uenEGXhru66zzeQ59u4DJN2W12FLEh6vmYrVZEASBQ+cOMO7aKR7L1aqQfoirS73DpTHBFWHBz4d48bM9AFzWPokPx/VCqwl6vvVATrGNATPWAr9VSEqjjAEdNSM4HoDNucODov+rqsPK5rAQHq7lziHduXOI5Dj7e9sJAG66YR6XdGnI39skkvatRzZQP75Rpa5T3TiTe4rPN3xAkaWQNvU7ckuPuz0cs94oMOchIpKXV4DT6SIpKR5BJaBSqcjKyiUra72bGc4fhr+q4eVleVgsFsL0YWjUWiyWImw2B4hlyRWHzx8gz5SDVqvBaAxHo9WQHOcbMSL06+aTKu/6daPbPxNj1FF4JJewMD2xMZGMuLplrazwQrfjSqiKA7FyX6ACs0ab3Brj9nWHMZXY0V7xLtor3iUzr8TvObK9N+a69320uNaTh9Dm2aG8uTaXs5mZ5OYV8eKIU3Rs8zw3XFtGDL5izX3c0PUO7h/4GEmRklBzukTufGUdn/5xlGXrjnPvzI0UWxxYLDZeeeknDv2TybmcEhb+WraceOKWNlzVpyWpKYnUr5/E+j0ZzP3ugA8xtz8YjXoKit9l2xvXU1D8Lm2eHUqRKwO700Z2Th65efmYrEXkFpdRUCpnyVBf3Jmlw8DhkP4FIXQtNievLN3LkLu789bcIazdnclvO0LX4A5sPc6Brce5dt5m97YJCx72SaFVakthRs/nF2y6rTz492884hMvqdxWFZNH6/odSEtK8dg2buznjH30M1QqwS10gUrZd2sKy7csJq84j8LCYvad3sn2Y38GPNZqtxCmNaAWNERHRRETE4WAgFatxWYLnuX/4OHp5OYWYrHa0Gn1hIXpSU6OB0FiMSssKaDIUghAp84NiYmJRBAExt6Yjs3hYuFvnuGnS1YfRSMMRyMMJzOzkAU/H3bve/bu9qTGG4iLi6Z1oxgeubGVe19NlBIKdTxV5dv1RpWLXSqzqwbMWMtmxXI87fZFla5gUFxSTF5eIVFRESzb8Dl5xcWMuqqPxzE/bf/ao8JsdoGFYxkmcnMLsdnspKQkAOByidhsNiIiwnG54LPVxxl+hfTgoo06sotsJCRFkJNtIr/Yyoxl+9Hr1Iy6qkXA/u1/+TMAzDYHrSbc7l5Oj3szlXd+EElIiEV0gV4TRowxrtLLEu+VQoVQOOFcP2/AJYLRoCc6WtJAnM7gzQ3yoJT5gwsnDyHKONqdXWdxFROu1eKy+9ptb3/OxagZwXdbCX/VB6ozLMugMzK074Me244fK5scTSYzLpdIZKSRRolNq3y96kKxRUraMZlKiIqMoLhU4ClhtVt8Kld3b9eNfHMexZZC7I7yha6/kLnU1CQEAUSVFXDicLjQaHScyN/P4vVnGXrpA0QaItm75yyiCANaxNIoKYJJH/zNF2tP8MoXuxFUAp9OupQ1uzPc7dZLfoz2rRpw9Fwxj9/Smhb1otj0xlUUldiJMmgRBKHGKhVfCC1XiZAFrzKldeGTvqEePaev8vjtL8vDm/BFjutVxgSDSGxsFIJKIKc4C5UKZr62kg8WrMdsthGXYKTIUsCRjIP0LK3SHhepx6hX44gyuu2ZEaXOPq1WzcDLW/HzT3upn1AWGO9yieSb7aS3SsFqsXH6dD5hYeH8tv18QMGrfGmjZw+Fqb977I+IMGAwhBOuNzDzhvq0SJSEdG3ENiqdcgadhsduSGfWgnW8v2AdXVrEM6hzalDtKO+xTYCqyndPU5GUJDJrTBZRukSPfUajnldHv8GT70l8r0qibeVADpb1qbqjBDRiGHLtsM4dplFYWERUVCSiKGI0lo2PerHBxVFXBcE+j+7NL2Xdgd+IiDCgVWv9xq97lxpKTIxk425JCDdMm8D5jGwSEmLJzs4LeB1lNMPU+w/SO70fyXFJvLyog0e89fD7+zBn9u+AwKiBj3M4aw/hOgP3tt8LwI9bz1BUZOLsWRNp9RL5bdsZGijoYw0GHdv3S5zZd1z7Jp+N64FKJRBtLGeVoQw3CzLUUokLLXBlBC14Za/8S8PfcAtKOV1YDp/ynmlnjprH5lz/dsCZo/7jN/1QzjazWJ0YDDo6dqpPZkYRR49modGoWL/pv3ywYD2z3vwVnU7NmVzFslCjYujlTXjvp8M0bZaIwaAj+0wecx/qyiPz/+LXlftpnGzkjdFSLKOpxA5qFQcOTfd8KMJwlv9RgGlcT48ojWA9nsXFZlQqFbFGLS0SDdJL8yIWkq8vh9j54zT2gZ82KsLjN7fm2m5pFJhttKgXSeS175d7PX8DU/khvjb6DR6ZJSXPKL3Pc8a8j0bnaY8b/24c499dSJRxNBMWPOxmgcuIiGDp2hOoSywM7fI++8zl1yWridAsOdLE4XQSpUukcWNpona5RPbvP0lkpJHoyEjiIxMraKny8P6wK4oeGdjuatLiG5JvyqVlahviIhIqvIYyHT08TE90dCQ6nZahg4dzWWv/HIZK2tOGkW1p2LEteoMTZThpRkY233+7k2hjNEZ9BDq9wNx3e5bu7cC0ke9LvN0xEWg0GkQEmqdGck23NAptTtbty6LEVrb6+mLF4xR8t5YoQ/lRUUrF4nxeCUmROlSqih22tRWtECyCFrzyEsSgjfFxlAQyzsfFRAUMPrfa/XOpGo165ozPxBCu5cChF93b05tPoaTEzpuv/8qaNf+g1aopKbFTL7YBf508gCkxhy7N43jk+lZs2JfNnsNZ6DQqZj3YlQEdU9j7znVuQZdw0zF3uqJEvH1pufde3kvzx6WQmpKAoFJx1+VltiClQ8HfTB2MWaaiNtzbZZTub1lfYt8yKYh7vK9X3j0qP0TRHpgLQ1kxN1AVAkdqHMOnrcZhd6DRqDlrFXlx4EK/161JKEmARjAGwG0uatZ4IqAmMrxmatIF0qQqKt0kCAKt6pWfUKIcj8p4coBWae04qjpOy9TW9E7vH1KfvROUAMx5Ggx6HT/sXMK3azxjz5esPsYjjw5kzeqD7N93jtFXNefm3g0QBIEZi8f4vUZkuKc4qkgx6f/kr7RIjWDxhN7lasmVtePWJKps41VCrw2joPhd92+5hDX40svZvATvrj3T3WaGR19P4tHXX/TYr1JLL/7D9zcgImKz2VGr1Xz311IWl+TDT8fo0iKO+wc355tnLuPoeROJ0XriIv17RQPliHtHaFT00vRavcdg/2Bkdw7nWmnXNoXbBjZH6B+46kQoMDvxiP4IiErEOlaH/bTQXEiUQTYp6Fn4JG7OCSj7cD745TCiCBmZuRiN4Ww7JNDyqcv4Z/PRGquP5Q/exDDKtGWAtLQUrusSOFmgsgildl5lkleiDNEeitGiSWVa5Y2XBF/v0BsOu6/gPZ93jkFXtOaff4777FOrVYwc3RetVs2e3WcYf0trv8Ib4LE75jLhljbEGcrGi3c+gPy9nllm5cF5W1FHGZnx+m1MGv8lH648wuM3+6ZshDqua0voQhUFrz+uzkDhH0rb03NDX2GaV3G+Du2mMH/sAkbNKnvgL0//kclTrgHA5RRRCQIOp5OiIhNFRSZSUhIoLMknOzsPnU7LtkOw7dCfjLyqOc8MqZiSWNZ6NcJwWjVP5cBhyeN/2+WtGd8zhZPbT1b40rxtave/X+ppXr6Tu1/4hbMZb5GUFBVUX9zwY1IwXumfrwDA4XTxz5kiEqL0JPmjUCwtBxQB5P+kcadhVkbgypy0z376uHub2WzjxS+e9KHCdFkX0zNuIQXf3ufe1r5xDADx8THodVpaNYhCrRJqlL2rMhBFF1//uYQRAx6tdnNDsB92dTyT6ipJ5LAJLJvmSRqk1ar44KPhfPjBeve2Be+u5eWXfkSjEuja+QVsNifJMXqeWriD/97elpgInUeCkLhmK7NHdSEzz+yR2Rpo9dfiniUM7J1OdHQ4t9w0C4DMPIXfwis2ONSJvLY4JqokeJVCR47rVNoDA2UpTVv8X7/bHXbB4/xFH2/i04+3U2gq4N7hvbHbnXy6eDMREQbCw/XuGVSj0aDRqFGpBIaP6MPnizf7Cl6ViojrL6OguAfium1gd3hEDJzPLeH7P09jPpvPwBaxaNRCtWhf9ZIfc8c9e3toA0UsKE0KUcbRHFp4J8mK/VHG0W5hVlRiZ8irG9h9LA+NWmDmyC7c3DuwQyjiqt7se75MIwrlHsuW50bGvfeee7tGGM75rLmkJD7iIXxlYhyliaN7egJvju7Cp6uOkRQTFtQEWRP4dIqKu0uzLtObT+Hvnc+694WHa8nKykWMF1l/8A9u7Bpc/v3/OryFuN3u4qorZnHyZA4vPv8DCVFJ5JvyaJnSjv5trmLjP6vYcXwrJzOK+HyNhXO5Zj6e0MejfJOMtNs/8fgtj5n8H0Zi7tbB7U+Q6/EBfPnlJsxmGzM/+4unh3SQvvFrFQrKes9ErIsJ1WZqkGuDBapHFiyvrHy+3WkjLjyFU9lSYHv/AelYrQ6WfCrZMNVqNYIg0KJ+c06Hn0AURXr3ac7GDYexOFw8NXsD93RL8ZnBjEY9XNXb58WnxIVzaZQKouKCFkYancisMXPdTG3lQdywPag2/aHF8M85GxVG86FLMJttHFp4p3vfN1vOcDzbzCef3s/iRZt58fM95QpeGVUpXClDmVPvjbMZb/HzTCmCxVuTuaVPQ27p09DvebWF5Wu/5slUSVOz2y0YjXr3BBllHI3dbsclikHFc/9/gmw3dricvPfr6xw8eB6A6PAYRg18Ap1G55E8I6/4WjR9kj8PZHtMwsZwrUcVCiXkMZO/YiRJSVEeJkx/kI93iGX+mov53VWrjdejYS/yc4hmzpj33S+koPhdoiMe8KgqK3H6SucfOLOXU9kneP/De3nqv8u5796PAGjYKI6TJ3Kx2x1ERxv4fcto9zUb1Z9EdLSB667vwKdf76B3kyg6XCG9sNVP9edShSbpvYQry8qCOWPuDKrMiXR/Edz32rsB03nlASP06cy+5xcHtZTx5mqQn8/5rN5lTrXSsJphg3oxrNQc/v13O7DZHD73JmjVbnY06RkPr7AP3vBHjO4tdP1lNXrD+8O7ELDYSvh2/deAZ1Vj8KQszcjIRtvi4kmgCBXe6d3ek63VYSW7MINYYzwGfVAeBPd30S9uId3vqMfP+8NwiZCQMsYv37O84jt09FVu7j7NYxIuWjGyYj7eUtOBPxOmVqshPj6cnJwCn32dO0xjYONIWjWzuCu7KLMtrQ4rDqcdoz4iqPuuCPI3V+PFLsFTi501Zm5AT7bM3q/XhrkN/0ajw2cWU7L8y2YEu91JvwHpfPnFXxgNWrIyi9BoBc6ezSM6ytPLKYrw8qu3IIoiv/y8lw3nBwIbAbhtwTbOTR8OwBfTVJjypL+9y5tI2yTHX3nCV6MT3V5wf5DvzXvAyAkB5aJ0KWYqsfutkbZt9T90ffFen+0/fL+bga1vYnOub5WJTePKv2SoiDKO9tn20n1vutnqoHRpqvgWzywd5vHhZX49nMx8KymxYeXHblYzAjl5/OHb9csZ0P5KDLrgBNPFAn+8wMpQtdzibD5eO48CUwFhOj1Deo/ymyzi7cfpEPEBAGYbdB+QTvcBstD5ihV7spj85U6fNgKtjAZPXePx+8zSezxMDnJcvzc95PncEm55cQ1GYwRaNeSU5r68/nBf6qdOZOVv4xg+og9jx0lScNSb76ERhrtX5X8f28wP274iNi7cTQ9bEXlTeVD6Smq22GUplB5Usz0/QCJEYAQ6xmq30CSxBe1SjTz0gNT+47e25fG3yoRN/dQJKBcSn0+Fdo3bcO11Uibbddd35O3HJfU5MTHSHc+YmVnI3VOlQfDYTZN465vXfK7vHYvszUlgtufz1IInGDGjTCjOGjOX+14r0+C8723ZSwIFXnyqFQlgWSNUVtXwrgCixINXjPdJZKgsvHl0l72s4tbJZREThab3aNzwCfbuf1nqq1FPXHS4F++uCoNOHdBRcuuLazlyrpgwnZp3HulOit+jqg/KemEywsLKBH7f3q95KAPyKsbusHtMIBczfDzzpRpj60tbuAvT9oxbyFt7TqM3iHy1+CGeeeobVu78ljt6j0Cv1bsVDm+lZNe0QXR4rixBSi6+2rp3M37cesZD6F7T63qu7nwjGq1IveRRPv3U63Ws+3OKxwrDGKZlwaRBDHjwShKTotzfkNCvm4dpMCUunD9euYIj54pIizcQEyG9HG3p6rZDuyncO7y/3+fjUtn4YdtXFJvMHD/9inv7XS862fd8uY/WB1WJBqo2U4M/O+eSKSq/YSggJWTIpUXUWhGrWRog3i+7Xj2pDNDCXw/zuOJ8lUogIyOP+injaZ8WyU/bpnLn1OEe1wjXSQNIWQpIOfP6E7rekGdJGRqdyLjZj/jQY6oJ44cZWnfFi2UvqzDlCW5zy61PiSyaJJXPrqicixL5343gwJZj/PX0xxh0ajbnDsdqtzBQoXEWmt6TqhPPl56Qx5JK8TwrIrZRQsmjazJZueOpB+ApPKI0cnOK+fZlQ4X12ZRavrLcy/FME5d0aUhOdjHPLtzOe7e1LK+ZKkMpdFNSEjGbzVitThqmTQJg1OBHPCbMlJRENGoVJ7OPEheRQL3YBiFpy4EQ1KoH/1mf5cGf0M1q19pjzMvUreKa0wgqAb1Ow++/SwJz616JBD5QHUWpXV9GM4DVuzI8fh8+ux99d1+n5I19b2br4Q1kZGb77Nt9PJ9Xlu3nvleHVnivYTo1bRvFBNx/5NB5999yiOjZjLe44cpZ6MPUHD/9VqBTg0JVQzCrTJLjD00bPSFRAJpUPlSIMhw2AYtJhcWkwpQvVTXtGvEx3WI/9TiupMTCuXNZqBSMWq9P+gxEEYvFit3hRNT5txXqNTqPIPLyTAMA04e/EfQ9ms02wr1slPLkAXDrZJff+y40FzB69lA6PPcbK0/fjNnmLPcDO7n9JAadml3F97tfsl4bxqvD3+b1UfP8FsoM5MQMtVChPyg/4pfue9PtDP1wnMY9yZpMVj6aZMdqt3iQ3gAkxYZj//UBbujXGofDxeZNRzhxIpcCi6NWEyjSU9sQEWEkOjoSu92BSlDzw9ZlXHf1bN55ezUtmj7F+fNZnD6TwZebPmHB77NYuev7Kl+3PBIgGZUlA/LXtvcS/8CWY+zfeIRmjUdjKnRy/bWBC60qsWriZYBX2KMCrRt4Tuj/nCgjv1HWa+vcuDupKfFYHZLJadydj7Fl6uXkfzeCvScLcDqlUlAmk5VePV6ibfrTFKxYTzBQ9m31+v+6yXiysoooKH6XpKQomraKcDMceqNh18ZBXQfKJjclPWQoqDaN96Xhb/DUQikv/4nrXwg5frBn3EIErZpWXRsTHr6ekhI7/bs04cDpQuLiIkFRmnz8a0N476tdUn0uAR65Id3HIQVSeJpeG8aSKa7SEkP+TRvTh79BlCHKZ5afOWqe3xLrBcXvYjJZWf6SCotZWfLb14vqXcVVKfzkv98bu9jH/FBeJllYhMiIF8t/dXdMN/l1+BWaC4LSev1Vn5Uhp48bNJ7tyJlro2eX9XfOmPd9Sta07t0Mi01ijcvLKyA+PgZjLXAiKH0SN/W4i0/Wvsv5/NNotRoGtL2K9f+s5Mqu3Rk2vDePPLzQfZ7T6cBksrHpn9X0azOYsCAcr+XBHwkQVE8xRWXbgcxSm3OHkxAJDw+eTGbhOUSXwEufPePev+HAKurFNSA1pozIPLyU/EqeOL0xbFBTRnuRIp3LO018ZCJRhmg+nFhmu92y6EkPu++QqZdjNOrp0CSW48fPu8etzCkRf937QRVZyNl/1p2WDpKGK1+jU/upfLRoBEs+8/VNyBD6dYMtO4JOQqoo07A8BF3scsG4L4JuNFgoIx/+mb2ctJHX+giLdi3T2HHQd4Y6t/QP/j6SS/N6kbRM801Q8NYY5JhSq83CQ7PLbE7eyyp/SSH+4O9BW+0WlI7dh2b5LvFHz/ZdRsmmjIq80DKUTkzZnKPRitz4lCcNZ6BIi2C4cb0R7HMBz3v0fr7yPS7YdJblu7Iwl9gID9dzebtr6BuAO6AmYHNY+Wj9GwhaO4JKIC/LgtkqPT+VCk6fznQfGxsb5SbPmXzTS+5SQeUhlIodwZLkhNp2r+RPMNsc5BbbuHqmRFruz4zgY95LTQIBzp4tewabpwygS//yTUHbD+fQ/aGvAGjUoB4Wm42MjGyfyBHwjB5xO9H+2IL28vl+2y5P8PqbsJTFVU0mKzO+f5q4eCN/bX/G+3T3MQCGEASvv360f/anoI6tksarvDkILUtG1nBhCCaTla5P/czhIb4f3toZg91/e9diuqZbWsD2A5GOeNucC82FTFkoDTrvQemvMq7yI+kY+xE9SpnJ5o6by5OlGj/A83e/6f5baSeeM+Z9DzIh5TIsmI9OEoBlr81hl0w5Gq3oodFXZFaREaiasDJuV9Jwg9fyyovZlm3UTRo56Gpaybm8UzRNbknv9AFBt18dyLdksmXHRPdv2c5bUmLB24wbFiYl61zV6aaQhK78d0XvNdSU1mDa1uhEj9p979nL5wGZOWoeP27/mj/++o2z5zKJigotiuPTNScY+sKdOB68jj7dXiQi2ui2HXvDO4IgK7OQ6KYT/R5bEQKZZIpNVtQqFVq1Dr02jJYp7dlzaoc7GicsTENurtl9fHi4lvNZcyvVBxmhZL1VSfB6FzKUl6AVCWB3McoeFXOdqgTBbUZQ2qtMlorjQQOF0ijNIlMUwnLYa06WTRPd/Vfe3/6XP0Msrdsmt2uylu1/ZNYjHjGscx8x+e2TXhvmDqsr0/glDfajKcU4THq3icQbsmby/JeRfm27SjRrPJ64OIPH4AJPO7Z3SW9l4ktFDrNAUEYOSKaaMJ9rpSY97ibPT0tLxina6Ni4K/ERNccE5o1oY6zHb5VKoEnTBI4czsJg0GKxWBBFkZISO+fOSeWbWl/bgcPnD/DN1s+xO2z0bHmZ3yKrPh9gNVQc9td2ddXC8w6nBCgsNNGqaUsevkqakAy6zwOe73KJvPrlXoZKDI9s2Po0111d5rwSRdHNOijFkQtuBSTMINK8aZlj/vDRGTQvFcJnvroXY6mJw/sbD2SWEUWRn3Z8w5+H16ESVFx7ya083PUg3a8V+eVAfZbvN5JjsnH48FmP9s5nzZW07vIeVDWi0oK3qKQQ8Mzdlj+sRZPUfoWvz+BxuRD/2IJYGq+qFKw7F9xGm8alRLsVpBi6bU4BaBNb926GqcTOgS3H6BDxAbu4362BystiOUpBb3Ch0al8BI/aoKdFpwZlOebrtoHLjsGg8xtrq9fqfdih/MGkKGA56qWyAajUvuVlvirM6pFdNWtUWUysUpN/d7yJ7Oxiv9ebsvAJiSujNG37sodm0LhJIiaT1W2blYRznPscjVYsdzL1F6YFnvbs+ePeRx5u5zLnuJeak6dczaKFm/lpxzKGXvqgTxuVxZGMg+w7vYu4iAR6tOjrUyLHqDci8/F27fwCTqeLw4cyEQTBTROqXA4DfPP3Jxw5K33wLpfI6r2/kBiZzMhOZZqdP62nKgVDy+OEDaRYeKMyMaqJiZHsOVJW6/DgzMCavgjExnlqyPv2nScpKYHMzGxKSuxERzzgYeLSa8P8CvyEg4fcY/zYp7+S9p+PgTJTQ0V28JM5x/jz8DqKikyo1WpW/P0l97ZvS7cBLWnTW+Sjh36g2OSfDH7u+E94+OqaqWrtjUoL3mMFuzCZOruFhjLW1BvlEgq7XBj1avK/G+HeFEiDlY8JVCY+EG2iqcROvTsV/ARPqt0vbc6Y9xn2mtN9H1I4mK+213LsLZ7X6tuFCKDQ1NO9rN/x8hd0miyF0Oi1etRixaaXipZZSvubUqN+6b43PY5TUjJqkeKr/dmTwZcrQyMMx2DQuSefKQuf4M0fItxLr7umu/hwXOAAmMpGS3S5pAUj7r+UXTtP89eGrEq14Q/HMg+zeN171K8fx/Y9W8gpyuQGL74Fh01g2j2n+eCPt8jOzkMQBOLjYwgPD/xJrFhzH5d0fJ68PKk6SmpqIl9t+YR6unpc0yahQsaxqhDehNq2cjwoobTVi8D32z6neZPGHD52HICkpAQslhKfbzl9wm0Bq0GoVQJrN3qOqffvSmfl0V7MXPpSebflxqqJl9G5b3OMmrKqEy2GlkU4mSx2Tm6XuLfLm7gsNslOb7Xa0Gg0uAxhWB2SHHA4RYpKHBQWFrmPV4ZHjrmmBbVVVrrSgnfW55LAkbWCw0f913kJlmotmPRRf8ccWjTEz5EK6HXktmjuYdxXksTotWF8+5LLI/A/VMhCe0v2dWx53MTQFzXc+hwsm2YoV1N02AT3sgo8l1kVIcoQmOsYfO3vgdC+7VMkJER42Lc0wnC/WnwweOrOaThEB6mx9Xn8nTK7osOGR4n7KXc/z6I182nV4hkcDidXdbqpUtfzh8Pn9xMfF8G6jRN56cUf+fyT7Wh0IoWmAne8+cxR8zDqIwEwGMIRBMnud/BwmaBQesVBclbefEt3tmw+TnS0dG5kpJ55G8/To1F0wLjsQFqaUgh62/2jDNEUmgvoMFuKm908xYlBp6Z172Ye/AabpwzAULoc9xZI/nwwSi3zqp7XcDRrP8Pu68XiT1yECZHkFGcRFVX1NNqBL99L9LRPmFn6+6Xhb2C1WzxMaEpfQLhO7Ras/mTFP1tPcMgWOCJBRpOkFiRGlVFKtanfkXij6I4euaVPA75cdxKzWXr2zZtMoH5aEqtfu4LEiFrMnqxsVIPSs24yWbm835vc1H4kSdFS/lFNclsqB56Ht1NRFuT0l6v4as1xxs29z+NcJe+qPMC9bZ3KxA+NVnT/3SPpc9In3FZu35TLU6WGGsj8otRK/SU4KDXeWQ/PI8ogzc4V2dFHzHJ4OCPlmV1ZMw38ZxlqhOHMengej8yVlo+yXS4QZAGy4eBq1u5fCUCDhIbc1GUokz8aB/j3pp/LP8OxjEMkRafQPKUV1YUdx7fyzdbPuP2Orqz+4x8SjPX4ecMIH9PBe2MXs/XIRn78exku0YVWp+bo8Vd82lOe17RpPSwWB6IoMuaRASQmRvL81O8Z2nc0zVNa+U3VBfirWMq6DDOK3P6cy4f/1xtKXhP5d79kyc7a4bmyJIbNUwawq/h+j3Pl96FcyQGloX6+qyCHuJC77lzA6QMumiS1JKcoi7W7pGsYDDpeu28+3WIX06pbY/c53t+goNP6UJeKq7ci81GnJj1KVlaR29xQYjOz6Z81WO0WLmnak+RoidpR+fx+/WEP18ze4L7/YPhTQIpY+efcfrRqLS1SWyMgcC7/DB2jv6dBjI5lx028/IlE33o24y369n6V/97a2l2HsSrQDArOQVdpjXfRJDWiKHIm9xR5hQXc1XUsEWGRNVqnSKlR+E1DLbUFZxdaufG5VZQ4XIzzOkTp7ZejDQIty8BTwG3JvJN0LzOE0kbrjfL2yVDO+nqt3m8wdlls4tfltuWJoSQlRVVIWuMPqyZeRnzE1+x7Pjh7pF4bhsPlYP3B3xh2by8GX9mWoXe9z5m8E+WGrqXGpJEaEzgyBXw9+cGgR6xIbvEVrP5lJzGGNK7tHHiy7NasNwfO7KbAedpj++IpAiv//pnN/3jyCZjNdkTRhVqtZvUfBzl5Mge1WkVqrBTz6h2zvDl3uM/EHgy8qzTLbXk/j615d6Mv1Tu8C10++jY+799fxEnXTi+SmVXI2bOZbGSTR/hXatKjOGyC27Esw5vcRrTZ0QjDPdLzlVDa9UVR5NMN75FrOk9ERBi71mzlwUGTiDbEeGR11o8LDyr00du+rdPoadegk/tay/9czO6T2wkP12LUqSmyeNp4RVH0qX5R06j01SSBJJAS2YgUadVVY1quz1KtAq6DzfuzyCqwsHHLZJ7673JeeuWWCjWMykJmWAu0ryLeiihDtPtjePTtkUHFSwYDfwklgI8JQfxzNwzo6rHt0sFlbP7CVsmJuTVP0pQCadoCAipBwGZzuK9R1fTayo6n/RuP8NRlGUCKW/CBk4Lid1k6TYXFVNavfee2cbZQSjSwWOw0qv8kt/a4h9Zp7Vm7exXmkhJSUxPdpj9BAJVKUjr27z+HIMDAttf5sFyF4kCT7ZtK38Xtz7m4/TmJe2DJFBXq0nC+zbnDmTOmjBZU1gKdgoUnF44JSIUoO9iU401Gy8TO9G/ehFnLfFPoz2XOYf7DFgStGmGQpNH6lFpXS/Z/g0FHVlYRGmE4tpWj+W7rWW5SVGA5s3QYOfsXkme2czr7JLPn3EnvPs3pdsmLnMw+RvuGnd33GAx8lLxSubA+eyhr9q3kdPZx4iIT2X1yO8+/eCPD75OqlCtlQb3kx+jUvhGDu9QL6prVhWoR8zVpVvAXp1cR10FaaRXhN2au5Ifvd/Leu6uwWi0exyyYuMDjA5ThTWdZ3hJbhixolGFqSgQyM8hQfgStejSp8HpBQY4EKa0+4d7svVIQyzQZmSBeCTkWtHWpph9oZaBWqRnU/nq++PxbPv9sK02Sm9EqrXyuplM5x9l3eifRhli6NeuDWiUJh4rGUyBqSe/l78ntJ92xrlK/pb7rFa6CmV90ZCYdAYkQvVODPjSMb8JDcyTTQFSUEbPZQlpaAnpNGMUlxWRl5RMTI5l8Rg4cR0Jkknt5X9Fy+ItpKpw2uGu6xP8rrtmKqbDELXR/HNeHOKPOY7LW69Qe9nzlPodNGrMjXtMw6s33fExp/t6XtzlrwTeD+GaGCsdXCwFo2ni8x/5H3x7Jn1OvcP8W+nXDIS4k87u1GDQqIq6ROHALTZdS/L1ErfrRr0eY9ulu3v7tBCdO5jJ0QBMeva4FrfulI/TrxslX4I7b3mHF97sRBIGEEKt89Kn/GekTJGVAdqTLTsZDR2awfn8Wxggta3aMBm5m0cKNAdtK1gkUme1E1iJNaZUEb22YFQLNfoHSLgE6N4vjmSHteeenvagQMRjCcLlEj+oIoi3c4wP0ByVNJXh6imXHhZIIPdIQxXtjF2O253uQBp3NyiCrKIMG8Y2JUhRQrMwyOmSUhuyVuz+At9ofAgXta3Qi763oDfRm1qOZRKhSUAmBIyH2n9nDFxslYSOK8NeRTbx1UxxxpVVmyxtPSs1QaeP3Xv5WpnZZjCHWYyIsLDRRr14SBw9P97CZR0a66N6iNwmRSR62WH9LY+W46Rm3EPSw73n/93jNrA3Yf32A/S9/pji/rFZaebHXIAll2Z7vvS9Q2B/A3VPLPoajx1/3oP00GHSotL4haUk3XOYztuR38ev28wwc2IoBl7fimSnf8O4PB/l+80lWbZ7irh34xZcPclnH57ih6x2kxtZHFEUKSwrQqNUcyzxMUUkhrdLaE2ssC22UE6/SJ/h3qrfu3Yxjq85gLrFy4kyZBj9seG86d5jG9l3PYTTqadw4BYvFiVotsPucmX6TfmXqlY24+/ZOftutbtSuYSMIhJqvvjl3OB0iPnBTwslFFUde1ZyRVzUnr9jKUx/tYO/JfPq2bcOk29pweOsJDLqqFVYsr+pylDHabVv77z27WPzbYlQq0Kp1jLz8MZKjy5Y1rXs348zSehUTQlcFFaVAlsY/myx2cJbWeCv9gJQmi4MzvwzqcuPmJJUbfuYSXXz/9+ckJUWSkBjJ/n3nyCo8z/DPsvjyqb50ahYX8NxQUVEI16Shf/Pa4ksAiItIpEOjLj7HjBksJREoIxxSU+Lp1bJ/SH3pEPGBm1YxENmMDNmR5d1/mdGvPASq8ectdBMSIjhy/HW/GY9tG3dk6z7JpFCenyD6+g8oNEkrKtkEkZlXwle/7QVg7dqD7tTj8+cl85uyvXdubcHm3O64RBdf//mp2xYLoNGoWXdgJaMuH8916b+UOrYrZi7r0SqBrf/k+Gy/s+sjvHZ/LmdyT9K/1XVsOvIre/+ZBsCwu9/n8x1nufv2CpuvFlRJ8HprnVA1zTcYRia7006xpZCo8Bj0YdLHLWjLPnLvsuWxEXrmP9rDow23DdWPJuSwCR5hT4EQKNVW/j3/YYeHJhQZGUZiQjy7zmzhiuibPY4PRDxSI1CpyhJNSgWybIqIoMyD79Yk7Y5K12gLBJOlGLPFzGtv3EWv3s3o0ukFVCqBcKOOd386xPxHepR7vpJaUgnvWPBgxlOT6A68dG8GRdYihvR8kHCdwSfxRTIfeJpg1m4cj9Go56NJZasoZfq3EvLKpmHnJoAkeL3HqfLeQsGIWQ6WPK1m0SR1yA687OxienR9kT37XyAzs5CO7aa4HWPZ5tNERhoxmTz5PzIzC2neZAJAmYAUhpPz7QjGvrOVzQeyOXzsnPv4kyc96SKVuHHADG7sKBW9PXL+ILtPbmfq8zcw4v6y8j3tWj+LOe8D0ic87rcNcfVWH8Vi7I2t0KgERt44m27p8fSJVqPRq7mhhZOteUNJiU/khz+/RaUu+4YXfTqSoVfN9G6+xlAtGm95y/5gECwF3rn8MyxaM58Sm5k2zRvz85oxAJhMt0MpZ4I3lHY/WRuWEZDPIQjOCeUgr8iGC5BX+I7i+PIzwaqEANl7MpT2XigduAEQyuojmAnL5rDyy85vOZt/Er1GxfNTvycpOQqVSijtugqtJrCmLCPQRCVr6aFQKnpnT703drGPnba8aiP3vaZFtEkTk9VuCZi0Up5ADVT01B+k2PlRHpEH/tK7l0xRodF5jjOlU62g+F2mjfyHz9d+wsmTuTRt9ISHJnrseJnwVCZHJSVF+SW8mfX1flbtyqCw0H+qvIyzGWWpxGZLjPtvu1OawFq3TvU43m530r6jZ+SLuG4bQt/SlYmfMa7VqBjnVe5ddgzKvop9tx9l6WpP5vNerRIwWx0Y9DVvCKjWK3g7vUI9tyKs3PkdxeZiCgoL3UIXJLuWXDnAW5AoNSN/Woa/tMvgUP6S52hmGR9pmzaNQmi3CvBypIViuwXI/G6d++8DW465ideDRUWTyW+7V7D37Dauva4D331znpzsYjIzixAEKQVXcDgYe2Pl43mrg1ZRaQedM+Z9jEY9w15zYvKSJ8FUWFFCHntKrbwyCFRYwBtyQpDSzhtliPYQrk2TWhITEUO/PuUXBMjKKvIQvm1bT3ZXHgFpUpn4wXZsVjtFRSZiY6Po0TqZnzf6VvlNSorysJXfcsl96LVhNE9pRVp8fW679R3q14/muxWPuTXr/zz7I2faJpEUU6o0heiX8IdXlnryFGdmFjJ29mrGzl7N2a+GkRgdHuDMwNi/8Ujt1Fzzh5oks7Y7bDhdTuylnneTyUpq0qMUmt7DaNRLcbPh2krRuoWqpSttn91iF7Mp4x6P/bnFmTRuXI8Dh17g/QXr6NLpBbbt8E9JV5vwCTNTDOJEg8aDz7S636XFvIO+l7Xg9TdvY/vfJzh6NBuTyUxhoYnU1EQeuKYFzVIjK9V2RVquN9uaPEkonaPeYVZF5kKMRsnb7q3xKoVHKMH91VXgs6LMQrm/VrvDo2/KVYlBb+DBKx9n/5ldWNo73Q61l+5704PPAyThe+yTX2icGsWeeTe5t4trtmJ3ifx5MButTktKSgIqlYpb+zTwK3g/m2bnnqllQs9sMbH39E4cTgd39rqf8e89zOlzUhasrFlrhOGk3brQw8QUDD+vEspx7y/UUmm/HzBpJUMvb8YTt7RBF8QKrDKK5kXnXCsPfVsP4kzeKZKTE2iXPpU/1vmGbplK7Jw4l0/HURIv6Jml92AMq4EwEQVxj2h3+nj7GyU2w77bydWDZ3PqZC5pMU0ChmLVBMQ1W/1n+PkhHILq0RYDQV5JHE+L4ONf99Gl0wvk5JhwuVwYDOGEh0uCIcyP57wiBGtWCMS29si8CB6ZJ/XP21Ty1MIn+HDiJz4lo0DS3JQESW5z1ZQBNOhYRiBe1bHndIlkFJwjIiwSoz4CvTaMOWPex09BXxLjHiEtLYENmyd7xKwrnb/yhFMWHREO9ODDcRoGXNKXGyebS7V5IzOWexJAtRj2mbRi9NI4V/x5hhKbk9zcfIxGA4ZwHe290pXlWPchz2m5Z2rZ9jdXvIigkmK+V+5YVu6zqJID2mvci39sYe73B/ngt6Ps2D3V49ACs5P5Kw7xw59n+P3lQegDjEt/30ytFLusbaTXa8sjVz1JVkEG9eLqs9yLf0PWfjt6pYbWdBlxf7bi+nGNuPvS0ew8sZVODVpxWZsrym8EPFKelSQ/QcPrgwh2oFa1flR5UMbkPtezKU3/OMZLn+/GYrESFqbHarWh02kRRZHnl+yibaNourVMCLrP1dlvq93qo/UGSrzRCMPdziWpXJW62kMqi0rsPLr8EEdzdqMSVNzSYyjtGnRCrw0rjW4om0yijKOJiYlBsBl5Z6x/e7TSISxV0vb8/KXJqXwTSnahlbgIHSqVwMlME/tPFeByuRABtVqNSiUQpddgNOoCRkMYDDoOH5tJn54vYbWWjXGHCG1apHmYNUwmq9uMWK0JUC4Xj1zbgtv7SJVP5GtkZRbSq8fLFBaWgCjyxdoTDLu8KVa7E51G5U4Kquo3868SvADxEYlu3lar3YLZbCPKOJr1G5++oP3yV76leUo6zVPSg27DX6ZZdaHenYvdSze5XHZNClwl5GejUgncO6gpP/55ms0HnDidLnJy8omKMmI0GnA4XXz6x7EKBW9l+i0XV71ruothrzndyTHerHpRhmh3VIPVbvVLXSjjzTFvYi8Jc3PVVsaxXB6+XHeCozkl5OQUYDSG8+Pfy9ypsMqU4nZtJmM22zCbM3nioafRC2V0rcpIC6VDOCVxHKPelHgFvpimIszo8pvivvL3J3l7zipyTmWTW2ihy6M/0jItknE3teLR+X/hdImIoki0UQtEEm3U8vajPaA4sJNNHoeHjr5Cg3oTEQSBt+YOISEhgrvuXMCyZ66QFAitBqPCPBAMg2GoSIoJ4+hXa2j6n34A9LlhHjabjZISCzHREWQVWLj/zU38tuM8idF6PhjXi45NJS7nqnw3NVLssrag14bx4cRPKDS9R7PmyRw+JoWDKD2n/5+R/90Iziy9x2e70K8bwqBeqA16v4xW8r/KQC7mOXr2UA/2LSVmjupCo2QjarWKuLhoDAbJkSEIKn766yz/nCn0e55cxHFz7nCPfmt0IiNmORgxy0FYhP9+O2yCh2NKNj08edMr7qKIcnaYTFbvr96eEmpBKoWu7E95RSyDgkqFMKgXwqBeaMKl67tcLlwuEZcoaYdWu4XbnyvTFPfsK3N0TZj/mJtof9GUTxj3npERsxw+79NstrlDB+94roydT67IC9CySQoPjV7MV1+PYdVfzyLoJXPBwdOFTF28ixKLjfPns7DbHVidMP62tuyYfz29WycGLHLgnRUnY93aQ/z+234AYoyldpRS84D42yawOzCGa93/qhNNYnTYf9nA769/TUqEBqPRQGpqIhHh0krstx3nKSgo4nyOiScW/AVIJqCswgzM1vKjOALhX6fxekPOCjI7TDwyVwocl8lh9r/8GUmxhgpauHjgkQVUybpPSlQ0QNMn3MaGcWW/K8qKCgbBcPM2SDSy5rXBdB/7ExmiKEU0CFBUZMIRrmfEG5tY//qV7uNDMSt4ZxtWhChDdEg16M5mvOXWCpdNC/OI7lWGVW5b/Y87/buyguLeabcz94udyKT0g9pfC1ScRCGHkXnbtcsrYCpD5loAyFg+nD2nyrhrd+yeSkT4aKKjIykscbijUcxmE+ezyvihZTOZuHorp3LNNLxF0iYzMwvJziprr1P7qVgsVsLDw1j+1TZEYNxNrWjdsOJirNUNjVrFwI4pDOyYwvq9mZzONtOvfTKL/ziGgIjZbEGj0ZBbaKO4xM49S/ZTaN2LKMJlrQbTr83gii+ivF51dj7YYo01AYMmmg/HeW7rGeeslsSOWkM1CFs3Su3FEUD+zxp2rj1MlHG0u5wNyCuD6ssSCwWCIPDjCwN5fdl+vlx/AqvNQVGRCY1GzcksE/tOFtCmYXS1mkOCTY6RIWuOytjcH183MPzVwKm4clVl6RwpWSJUD7wS796WzvIjfYkKjyYhMgmAgpJsmjaeydHjrwOeWqqULuw7+chVROSIDrl6yZKny6I9jEY9iYmR2O3QqmEccZF6LmvnGVZltztwuUTS0yLJNIeTlZUXuPMOBw2idGQtX83KbWdZ/+dJXhndh8Lv15KRZyFSI2AID+OydknMfrAr4XoNYbrQHayhQDmJB5IJl7ZNcv99U+/6fPDLYVJTJfPmfYOb8fTHO8g1Objv/j788vNe1h74hR0ntvLAIP/avD9UW5XhQDWhoHYFsD/UJImPN+SlsD+czz/Lmv0rEV1OLm01iP+0WEWrXk0pKnEQGa6pPJuXysti5HK5A8aV8ObiBZg/dgFqpI+rMgRB3vCuRtwzbmGFz/32l9eyeX+2+/5FUaRfsxgmD2rIlrz7yj1XRnmZhFWFt2D1Dh3zV1VZuU0mKw96/Cne5/71h3zMKh61APedpX1bqUSPsprCh+M07mci27Zl3HPFb/Rq2d9dpr5n3EIOZ5cw/rsjWO3ScS8P78RdA5q4+7NxfxajZm+m2GRDqxH47Mm+tL33Cjc7nzKpIhTHsNMlolbVUDKRAv5kUbBy4WSmiTW7M2iYZKRf+2Tufm09u88Us33ns7z68k+89+5anE7pWZ87d7bctmRUWfBWRJRTk2FKoaAmCX2UCCR4rXYLc355iYTkMHQ6DSeP5/PadfWZvTmDI2eLaN0wmoWP9yIlLvTAbW8hK/6xxSdDDfwLXqhcufdgEYzgzSqwcOn4XzBbHdjtdvR6aSnfqXF32jXoRLPk9CpTTNYk/Aleb2Etk5hXJqtTWbLcOy149iM5jJ9Xpmkpq2bIffE+r2WzKdSLaczbN3pmcZ7IKGbTgWya14uka4t4n76czJRWIu0ax1A/weB33AHVu3KrIiqSP5WRC2t3ZzDs9Y3ExhrJzZXCIp1OK4ePzSTKGFyCTLWwk1VUDwrKMsMulPCtbl6JUJFbnE1xSTEfzLibqKhwrr5yFu9vPofJpWbG67fx2ss/8cbX+3nt/kuqfK3/a+/Mw5yosvf/qeyd9EbTK4uA7KugoIiK4L4Nznx1XBCxHQUUUVERR8AFtXUUVATRYREbB1FxFpwZB38uoIKAooLIvokiSy9Ab0l3J+nk90d1VaqydJZO0mnM+zz9dJKqunWr6tZbp8495z0S6ebnTKJtWwvbdz2vWq4sMWQ2G2JqLULw2f6cDBOvXdedu9/fIypUVdWQmZnGloPfsOXgN5zf62LZv5mIUGo7SNawt+9YKZAezXEn6fRK8I439kZdrYMZj13NjOkrsTv7ccbw7vKyTnmpdMoLXPbntFwLp+V6ilr6qN4lEOFCaG/ckcgdDO+fxzNXduHJ/yeJ5wvs+2l2WNmMzY5qCHUQJYqP1XsGOl7ISs0mNSWVqVP+zr33vEOK0USVM58OHdpw9TX9yc1Pp8IaWZ0zH2HqRthsdn755YQ8a2+z2dl3YBY5CvWqKutCxr7QIP9FG6Gc653r92O1N5BpyUer1WI2m9DptGze+jh3jruATfvXRb1f0YQnCiK07LVw0HtYV4ZmFftNZ39rqhazTgx/e+KW53w3boTTLvD4LT9zWvupTL7/XZYsXkenvFQGXNDMiroul/ovwSBxTqDz570sHI46q2Maj1xbxAW9LgkoPt8UWn1UQ6QIJqYebRj1Jm694C6+2PEJbqeLMeffTHVdFSs2FNOn5+PotAK3XNE5tMa8hXCUWTmKJIx9P832sYBCLaYZTXiXw/GOef5wx3HmrT0MiKFTOp0Ou93Jyn9tYfPmQ1hMFu8mf1OQEnSGtFkGiDq0y2eohZlmvv2o/Pnss3tSVmLD6XLK6RA39VxLqrM9//16H/k5qTx95zl+3Td19gb+tf4XrHUNjBragdzM6D9M4gl/WixKK1e5TrjQaXVc3P8qnE4nF134Al9/G7okQLN8vKH475RoauKpJRFN/2+4x3is4jBHTh6iQ1ZnRnX5KHg/vIRwpNCfH964gTPuWAF40jN/3F5Edk46GakT+GDSuVz7qier7fJzruTqM/8Pc5ogz9Ivn6HFWuXi8IlfMOpN5KTnNSlmrkSobiR/kS+z//MkldaTOJ0NHD9eQdu2mbTNyKKmrgaLycLjl+ZxRrvmV74NhHiOybDuGcW1tn76NQXXvgHAh/cMpa2iIq7N3sDQojXy9207nuOyS17m2au7cGYHj/ZFsP263W7GvrietdtK0eu05GQYWfXUSDIs8au+G2uEEtUQajvKcVNrt/HeV2/y1Q9fhrT9b9biVaK5spbNQX5me/IbCz6G1A+vCAaJZCXSBVQzzJLwiZJ0AX74+Vv6dxpED0MfOQzP0WDnzTXzOXLyEAANDS5KSsoBsaxRdkYu3lASqbdF4Q/+lhl1RkBAr9eRlmbBYNDTo6Avj4+0YtCJtdxidU38WUIJA73n9rRcco4sOK4TClUqe2IpJJF4hw3rxUMPrCDFqOOSS3uS1yb0ydrSijq+/LGUF1+6gbMGd2LE8Fl8taOMq4Y0XZC0NSFW4yjFYKZwZPAYdgmtOnMt2pD8v83OPopVPzQahBFDsFrrZfWpKutCH33UQKisWUBlzQJSU41oNAL5uo9Uy3cf2c6Rk4c4fryCmhqbTLqA31pyylc16U/6PRyJzd8N/iMmgwlBEEhLS+WMdhaGtT/EI//Zz/3//Yn/HK7D7oyND9G734kE4YKzKC2tkn30gTSBJT3f7xfeQJcMPZluB28+MFRFum63mzp70z78dLMes0nHBys388Zi0a+eHwZxJxE6khavH8Tb/xtKPwS9ll7niZUzJLEQpQiJMozIW39AWi7NuublZZNm0HDOaelkpBTL+xIQfX6CIDQZvtWUbyySKJZO2V05v+fFfPfTevIs9XTNTuHVdUdwOhvQ6bTsPbIHgKl/7Bu0rUgRSX22eMDbR//0XUu46bJ+vP7hHu64vJtKtrB/lzYUPzjMp43D5Vb+8PSXlFTU0SXPwnvThpPn5bt1udx8s+c4Yy/qwj/WH+L7TQd5+Po+nNmtZRJsTnUkiTcAwnU/xMpC3niikAZqGV3kQvAKV1ESbP8+nsmVsrJqSt4XK3LsLb6R3DZmBEUkw8wxA7h4QB7Z6UZV33u270en7K6A+D0lxURuZh6jh43HYhJTr0OdkAiHyP6+8W9s/3ULbrebShvsLa+jvt4u+3v1eh1vfLyfUUM70KtjbNNJpYmsWCKU8WStdcCH6miOvj0ew4WYPfbltlJ+LbNRVDgwYBtut5t/fPULTy7bSqXVTl1dPfuPunhgwbcsf+R81bqPvLmZFV/+DEDPjhn86/nhWExJevCHaIyP5JkNgkAz8krEKkOv3lFHvaOex5ZN5tppL8pi7xKkvHrHJxM49u4YrPXiq6S13kH765bK6zk+mSDGXDb6h28c3llc4BUCpNPouG3E3Rw5cYifyw9g0qfIMoRKhPMG0HtYV/Zs+ZU/Pa6uWSZlxrncLvaXb8PtdlJVVUNaWjqCIGAw6MnISMVg0CMIgEbgocXf8+HMkSHvOxERynhCryOzsXirEk6XG0FwU1Z2gvT0VD7dcpQiBgbc17tfHOTPb26he488qveUkJJiwu12s35HGYfKrHTMEaNFTtbUs+LLn5k24yqGDj2dUde8yhc/lpxSvt1oIJrJYEniDRH+3A+xIlydwU2Du457Xxkn/zag7zSOlb0qlzmSCNi8aau4gkZD6tViJpE4/7+UnJw02SJ2r/4aYYRadtL96QastQ5s9gbqHXUY9SY0goYObTvRoW30yhWJ1WHVkMRsKuqOsWe/R1i5Yzsx3E0QwGxOwelsQKvV0NDgZvevVcz/z24mXNUdnbZ1T0805c7ylgd9dNq1PF30B/r0eoya6noyM9MwmYz0CSIm8/mPpQwe0ol/rryH8Xe+xar/baWk5DgFBTl8vrWEWy8WFcSMei0GnYZtPx6WU1/TYqxh3doQ7Xs9SbxhwF/2WzghVKFeNLHGl4txiqKn3qm+Uk6+20+pI4mUy8qqOfhTGZ275ATcV+aoJY2f1lBZs4B/zDRHlr2m12EbPED2Px8pmYt77Xe0v34pTrevboQEg97/5I1Wq6Wuzk5Z2QmyszPRaDTU19t54e/bOXSgnNuG5DfZnURJ2GkKTWVTKn3277+3iX37yqipFq9rSoqJjDQjxf8TU4Wdn29C63TijV4d0pn/3z1MeXAFn6/ZjcvlJj1dtHI7ZHtU+8xGHUW3DWT60i38+4MfuKJXFuf3DTxmIkFLz5dEivDv8xtDajdJvBEgVAJV+kNDDVsKpIOr1E+V1PIDoeaTjfLnbqc/jNNdzIJVexltd5F+hUiCgbLdJs2/Q0XyR0rm8uncNlSeFG96W4CZceHCIaBwgygnhdIt4zny/lixDI5GAy4Xu74+wNCsBgS9FikpYNCAmfRuP4CBnYdQWnmU1dtXkZubhVarlX2+bdqks/ZgCj27FgY8/kSYGA0HG08UojO4GdJmGbs2HaSXTkeOy4Xjs7uprnPwzLIfeO/LfbjdbgRBwOVy4WjwjBPdiCG8/sBS7rq6h6rdidf0oMJqZ+OGvQzr1ZZ9h6uoqDFy+2XdGDEgT7Vuf52TFWP7sOH4TYzMX8GuDQeidu5U5NWUiyWBEK5bIdyImCTxxgD+EjLCme2XKgFIBPvGtOOcn/c5g85uVIv6egvybSdZu4qyP+XlNar27rj9Tdas3s1r/97F21Mr6NcpU16mLCDoD+3y7qOyZoGq7IpjRI+A6/uDzWaHBnVqaa8hnQHxfOx4ahn1ThcThj+GobGYWNf8nqzevgqtVpQJNBj0tGmTjslkpENbcduyqhL2HdtFWko6PQv6om/ctiXjsiOFmK59s/x953Pv0Ouc00kzaHmucBCrvj1CRY2diooqLBYz3oJez63YzsWD8unezjOJatRrmTnmDAC+2V3OI0s2YzJoaZNq8ClhA7Cl+k+kGEL0Q4cAf9ZiokQMBUKkhBvucSSJN8oIdiFCsX5tNrvsLvj10HFShe6YlHGsQfLizxj3vur7oUMnOb1rDg1OF3NX7mLh/UMbg+7BYtLx47OXs+nkGJbPqPdxaUgJGpU1C+ja+SEVqVtrHbKr4vBKB3nXDldZ4zUfraf99eIkX+aoJRxeMZZcr7hQ5QNpeO5y+Xx8tGUlIIa2Wa02TCYjJpORvh0GcnH/KzlacZhFn75Mg6uhMfxNw3Xn3EK/joPktqNFIC2B3o+KJLzjqWX0HtaVSwcVsOLLg9TW1mM0GkjRaejZbTonT1bicrkxmy2cqLJDO9+27E4Xd7y8gRPVddjtTp58eysZViu980S3QyCCiZQkg5FXSwtWBUIk7kOIrO+te4YiQRFKqFWgZAOnXWDNaxnk5qaTm5vOrn+JQibNSezYs/sYd467AK1WwNWYIZ45aon8t/9oNRt2buCXkkPMm7iYZwtfAkTSPVo6j4zUCWSkTpBJ118/uo8WlbgsFiMWixHzt1vJzTCp6mQ1ZVkrz5nb7Wbboe9IzxCjKaqqrNTU2BAEgd8Nvh691sCPP39Hg8uFIAhUVlZjs9Wy8pt3aHCpXSF2p531x8eGfc7ijTenOlSJMd7402VdSTHqKCjIISXFxKRRPenbIQ2TyYzZbKFn+zQGdm0jr196shb9pQvQX7qAYydsVNU6qa62UVUlXsNjVXafEkr+EMo6kW4XaduxRDj9Ud7H4SJp8bYgArkfak5qWDLZ95koWSA7vtrHm98cY9Xuk+RkmJh712D6d2njs76EFIOWqVP+TppZz6wpvgH29608iLNhHwCXn3EtF/QbLidn+COCb2tuk5XMcnLep6ysGpvN7lM23lrrwFrnCH4i/MDtdtPxtLZs2/oreXltEQQBt9uNTita4KmmdKQcj/p6O4Ig4HQ5aXA1oNVocbldrNz0Dlt//o4Ug4lHL86nt++hJwTqHWIEy7hZ4vfKmgVYLEbem6mhf+Mx9u2UycdFF7NhZxndO2YyuHtbbr7odD7ccAiny8XVQ9qrypArH3JZqQaG9Mji2z3iQ9ds0OA03xG340vCF0niTQCEM/m28UQhOw9vZcWWYmpqbFTU1DHulY28NeU8ALq3T1Ot/8Oi60mzGNl/pIb+XdpQuu1XdpacZM3Dwxk5SxT0MFt07NolKudvtHyOW2dnLGK8rLfGqLJqLcDR0nnMumkOv56s55vd5ZzdU6wQrHRDACrLNxgEQWBEnyv5eOu/VVl0uen56LWNJdW7nceB0r3sPbqD3FxRtHtw12Gyj3j7oR/Y+vN3PPb4NaxevZsXv/iJsTcORBAESk7WMnXJZvYfq+HSgflMv6kfm/ed4K//24vd6aK0tAqtYSkX9rmc3IymoyeaC6VguhLLp2uos2pUlZk656XSOS9VFiBPAa7TK6o9eFciacTubw4y7fwC/tvGwJ6qfgzsPIS0lHS/6yYRH5yyxKt8fU+01xl/aEq+zhsVVrHOVXW1qH5/VKvl0uliptqlPTJV654x7u/yZ6kEzcYThbjcLiZeO4iNe7/k+x2bPetsnuJDtq/fvwgAp0NoTKZQR17MW3sE3C5WblvLO9MvZNjEq0nFYw1D6AUfnQ1Ofi7fT8fszky45CG+2beOo5WHyE7N4+ozr5fX02v1jLlgHDa7lf3H9pBiMNM1zzPpV2u3odEI/G7UGVRU2Ni4fh8uN2gF+HPxFnYcs3HlVWdQ/NYGjlfX8++NvyLp9ImCfVvYeXgb9181nQyz+pxGC4FIF1BVRFYhALkCKtW6iv86GqNHfpKvecfToGOzepyYiJbiWDxxyhGvt9M7odWn/CCU6IceBX34bNv/KMjPgcZKr8eOlQLwUUPgibdNJ2+Rs9A++/F/fLV7NRkZ/uNoT+80Bb3eyLJbenNelnjuGo1NVdHIV/5bxJEj4r7zctuyYtVuhk0Uq0UcLZ2HTijk8IrQfKx2p4sla+bJ6mhDug7j2iFNx0WaDRb6nzbI5/feHfqzbs8nnD24CIDf98uWa3sdOFbDZZf3Y+bTo1j92U4+3XIMtxusVhs2Wx05OVm43W5c7gZ+KT9A/9OaXxXEH/yR7px75rN8hhatu3mVQH7deQSXzc7WmlPXpeA9GdaaolhOKeL1F1GQKKWHwkVTWgdt03KYcMmDbDu0mXpHHet3fyEvKykp55GbnqBDlmjb1Dvq5Ru83lEvE++OI5u5dey5zHx6FIMHPc1XG0WtB4+1q0HjaqDboA5kphpV/aiyVTLlFV/ScANLVu9iDqJvWBmCFgq+/7VGVkfT63Vs2r+eEX2vwGIMX4s3zZTO+IseYu+xnaQa0xjTxxPbfNmgfBYt28jnq3fx6+EKsjOM1NY3oNFo5PA1CW3TfKUwo4EqW6Xq++xx80k3N2aiBVHILi2tkuOklRWM3Wu/Q7jgLAB6TbmBJZN1ov/4tTsBMSb7o9ltYlLeKZ4IFDXRmqJYTgniDaf2WyzVp2IhK6i02pV9zknPY2TfK9h/bDdf7fpctY3ZkCITrNJt8PzKP8spxB9c3I7Vn+0is42ZLT8+qdr+kuHP88svohWb84diHJ9MUPVjwCuf+u1raelxANLM47hiqKdGWvsb3lLpxwaCQScSgk6nbSRAAY0QebnvVFMagzqfDYAgeOqD/fmGfpyWY2H/0RouHt2Xw8dtYoyrySjrGQCc1+si2rXpEPH+/aFBEKswP/72A5jNBmw2u5p0g8HlClhXbde6PfRuJF4Am6OCya9Nkr+3y7uPJQ//Lew+J5JcZqh11MINVYu3DOwpE07WkrXfIq3bFCqaajMvsx1GvYHcnCxyc9vSuUNHstI86Z7KOmplZdXs2C6W2Pngs9toa8nnnb99q2rP/ekGVj7sm+LrPTBzctJwuouprFnA6/cvUk261dY6+NealU1ur8SeLb8iXHIuYxbezZndziIjIw2LJYXLzxhFiiH6erBajcCtF5/Ok2MGcEG/XH5/bkf0WoEhZ3fmj388C0EQmH7paTx2YXnwxsLEuJd1jHtZp9JRNur9F0msd9Qx4IlP0V+6gHUf7wzYphTet+nkGKzWelm/V0m6kSKW41qJYKGS0vJQQ9DCqa0YiQ5Dc3W7TwmLtyURr4EZCKmmNG4bMZF1Oz9Do9Ewou/ljRUdPNi6rYgB/aYDMKDfdDlU7L9rbufNh9XhXjvX71elBR9eMVY1MMVX5E9ly9liMfLQIv9l4yUM6N1PbhvU52rn+v30edxTHv0PZ9/MmR3P56m3p/PmkUWc2eWcoEUkTaluRj8j9vmtqdqwX6VNBi1FhQOZvvQHvt30M38Y1pFxt5yFRiNE7Q3JZPHve5dKsAfDyFlfsjXVQO9hXVXZhsrJM0Dl3pEsaglzJr4a8rmJZjmsYGjKR9tcRbCm3A/NFb5pThZekngjRDwHZjB0bNuZm8+/Q9Z5qLfXcnejstk10+aSnZMWcNsbnnTJE2UATrs4mLbOvASA4zsbw8waB2egWfhAKCjIoVtuLzae+D2gzlaS2u2DR+BFEASeent6k2263W4OHT+Itb6aLrk9+NMznmFcZati8nyxj+G8wt84vDNXD2lPrb2BnAwPEUZjgraBWq6dJhGv56FY/IgzrMrEfR4fw87n3sHtaJCvT6D+mM0GqqwL5TjsVyfVYNZnBt1HS45rb5L0+b2ZbXuPvWi07f3Q6H9JaNsliTdMJBLhKqEzuGW3gtXq4u5XxN/b5d3HvgOz5PWkz/k5k7DZ7BwtnedjBSkHk/RZInXJisrLvofjx60ApHiFik294TF+Lt/PLxV7WPud+Lq7bHoDdqvWb9tq4lf3ZUibtzEbtKp+rd62irW7RD9zdno2E5kqrz/tzQfkz1MW3cPC+5cFOmU+SE3Rk+on7M1fqF+okApRStfD6S72xOgGuf2MehPzJi5WuYs2nRzD4NSlAQnDe33Jx2+sX8DQrNCqSbT0uJZIMtrzMP7GXlPwV5g1WNv9Q+xLknjDQEu7FSKFpFC2fIaW1a8INFDL/oMvAvDBc+aA2ylJV7qZx76wEJ1QKJMuwNNj5mDUGzHqTazetopl60S9BouiOu2YIrdcVFPZNviS7byJixnS5m0AzlIK8qwvpsHl5qk92xk3/gKu+d0ZjLrmVR64+RtefufskM9HpIjkun/3+Z5m7dOoN2GxqCUfAxGAKdXdaP373tbdzuhA77MKmtWXeCKW0UfB2vZnXEU7LDVJvCEgUa1cb5SWVnF6pwdpk+U//OraR22N1qXAe9MtEe/nrWlvMfZZT2yuRLp2Zz1rd37K+AnD+WrdPjqeprawdAZ3UB+j51xrfc5172Fd2f7VPlL0Anv3lDDkrMcBmPfua/TPE/OBny98LeLjigV6ndMFqQLw59NGROSDXj5DK/uwIbBPW7mONy47s/WQbksikHEV7bDUUyaqIdTZxXBmIb2jFVqadJt6zXXaBdrl3UddnZOjRypUy/YdmCXH1d772p3c+9qd1DvEsCaxvFCd/D0UjC5ycaRkrs/vgiAgaASqqmopaJfBurV7Q24TfKsW+0Pf87rx/B1nsu5L/5akUW9S/SnREpWjpQrAjk8mkGXUMTh1afCNvFBXI7Bkso4lk3U47YJfgg3mAtHHuWJHIoWghYqhWcVB7/NoVaQ+JYhXGTYS6OZSLgtXZ7OlCVfqB4RXOt3pLsbpLmb94jyWT/d/qSUiVpKxTzt2z40vITc3Hae7mNnj5ssEp9cauGzAKN5791v+30fb2bPnUJNlyb0R6nXs1lDPW6N7yb9560dE2nYsEasyUZPm38H4V8bw64laaj5cR82nGynIvTeq+wgXkYzV1oRo8IHglqLFg2DR5Pd8fpOeEKFCisOLJQL5ZyC2wsbxRKDjuej+o3Q7XaxZtu/ALDp3yVFlOSkhhTGNf2WMz29NISPPxXWPijP0Bbn3UlZW7TOBVV1bxUMLJ4bVrjek69C2dzs5dEqpNdEcxPMaR7NAogRpotO7WghAVpaZEyds8vcjJXPJ2bo9KvuNBLF64MQC4fBZIC4bN+c3WvqnuXXRIPo3ZLTzx72z8CR07jJGjtGV0K3LFFnM/O/jhnDb8q1yDO7yGW5mj5uvChELFhNbWaJhzvjqJsPKoqF8JV2z8Td4HgxKrYnmtu0vtChWiDbpDE5dis3e4Dd2OivLoiLe3Nz0YBnIKsRrrIaC1kDWkeKUI14J4Vy0WFlAyhs7Fkr73m25v9jkU6FWyo4CqPnfOo7O8VQuFiv9Zqgs1tHP+BZN9CZjo8MTixroNX/exMXy52iQpRJK/YHZ4+ZTVnWMPcd20CGrM93ze8kykk3ttzXc1Mr6e067oDIOlJN2En5YdD05o4ar3nBqPt6IJQSHYrzHakiIYXp/S+OUJd5QEMtXTn/WdsxLnTicohi5RqOSCJRgMUVWstt7MseoNwWNj40W2QYj8CmL7qFdu1xcLhcazVpZKU3aNtqkH08o43HFxAnPuJFKN0mQtDCE3HR54nPwmU+AwwnGpvUuWmSshoDWqC4YKn6TxBtrtwKEVmsqZgO6iZps6Zbx8udVk89nQKqbtEwzPaf8EYBX7i0l05QvVnQIEvaknIyTVNCkjCkQw6DqagS/64dKiKGsZ7fbsdls8n4l3/OpBuV4saTo/YrLu1d/jbuqju63vC26IlwuwD/xJsRYDYLWqi4YDM2eXIPg5BWLCYZIEQ+3QiTl36MN27lnyllLJSu/wKIVsNY5KK+s8ymGKZWaAejZbTrdcvrzf2ffIr+ye7/ySlBOzElQEi8gR0Io3QNAWBll/iCR+Bur57Fl1w8++9UJhQlj8QY6f8GgdPG4V38dtMhpqIh0rLb0hHMsJ+rCvRcD9SUuk2uh6F8myqxmvN0KoSCWpa7NihLwFq1A5qglMjk577w6oFVYVVXDj7Xfc26PEbIkYnP0WyVyDiXkyxtNEZZEqL8b/Ee27PrBZ9s5dy3AoBALUlZ7iDchK10G4SRQ1NUIcpXhaCFR7sdwEEvDLVJeaK7MbFRcDf4IJFEucEu5FUJFzF7pglhHUnUIb9hsdjIyQiMs74gIb+Rle5bVOzyxvKGScCiE1bFtZy4bcgUfb/qIdMt4zGYTaWmp2O0NpBhTuGrgdfTrOChscZ9TDYlyP4aDeBAuNI8XvP3QEOdwskjDuGKJRHIrBEMgZaZQEckxSuXbJTfDyOGzyM/Pomt2Pwoy2wOB1cgaqJWXvXDnqwzP+wcghnxJ7gWlnoPOAK9PXozTLlqrJouL0UXiw8HbFxwuPt70ESA+NGw2O+XlVfKyuQde5JnbXlStf+9rd8bU6lVqWyyfofVJ+Y0nEsnNFw5ixSGxMMS88wVCQdQn1xLh4iaiWyFURNJuMGtZnojxShs1mw1kpE6QY3/XfCkmXyx9WNNYOt3X/e/xO+p5aJGoVDZ18SQqPppA6uXnMhj46wMVTJqjFuG+6yULFosOnVDI6/cvYnSRJ8JCDGvzHYrRIqwZSx9i3sTFKh9zqIhkQlAJ6dj8HV8skSRcX8Q6ceY3q8eb6G6FWCEUX7ElRS+XBZew/+CL5OdM4qvpb3Fe0Vg5tdfu0DBujkiM1z2xgOXTNXKFYX9xvgDC+Z6CkHe9nMrUhSIpPz/+pUbSFa1qs9kgtx0ISovxH89puO5RF2NfaPBxN0jrXTNtLu3y7vMR/lYiGGk2uBr4Zt86yqtL6dmuLz0K+gCoyNrbSm4uKccKiTxWA6E1uBWiiVOCeONBuJDYA9mfqyfYuZCqFVz47GqyF35DeXmNvGx0kRjpYLEYGTdH/O2tqWoL+GjpPLkNpeWsxMxlf+ahBZ4wL2+snC1QVRo4wl9KT24Kkm5Er27T2Lf/iM/y2ePmq4pLFhW+5EOUH2/9N5v2r6Njx7Zs+nI9Nw4rpFt+T9U65VWlrPrhH5ywltOn/UD+vfYD1T4k0XVlFeZ4orWMVW+0JrdCtNDqRXLiIWYTap2nREBTtabcX2wKuJ2SdAFWzAw+NJSFNME/sdpsdrkGmL8oit9PCS4VGSrunDBc9X3GLU+z8P5lpJszVL7q6cUPYkpVP0QOV+/l4KHnWbt+Kg0Ndbzyz1k+rokJL6ayfuu93HnXML7dv6HJvjjtgvzXXIRSM0xJXq1lrCoRiz4n8nlotRZvIj/NEgF+Q/0cTmr+8yWZo5b4rJ+SokcQBNxuN7W1Dior7Lx+j8Dd8z1DRIxMCDxkysqq/UZKhAulxajTu3E6BPl37/VmTyhj8epXuHBET346UCYve+r2Z8lPPy3gPrz9ym0tnjLuUsRHSoqeWkWGWLu8+6isWcB991/M34o3csTXuI46grmRWqNbIZ6IZchmc9DqiDdJuOHBe+ApC1mCWABx0nyPcLpEnJKFaLF4yoHfPaeQ5/7VlgMH1VEC3hClIn0r5xr1pkZLs3HGv9F37A8SyQazGLNSCri83/Vs2LAGs9nEjNueoH2bjmjdaleCMvTNn5bwlQOvU32XIj6UxSMlnHfOX6iurmPazTMpaNNePrZYwZ8byXtZEoGRKFl4SoRMvJHoaiZKsHNLQnneYunDCqUelL9rOPm1Sdz+wgIft4EEb+Ir93IXSH5dZUKGVJFCgicRwq2KUnA6ovMqfkanwfTr3I9xL3uGc/EjddQ2ek+MehOpKWkqH/SgATO5ftAEChqTRGy2eu669lvK63/h7x/dIiu4+d1fh2F0HtBHTjDxh0h1aMO5jknSFRHufdBUwldzEJNil+F2MpriFq2RcEHd71icj3DblpbNHne9yucpWXWVNQs4UjJXpW6lTFu1OefzzHuPyMvef87JHx8Vh9DR0nnyq7tItB4fqjIRojlQRju8N1PDjU944oCtVvW6hc/rZOt93sTFNLga6NntKf7ywvWMHNmTsrIaDp84RFZqNja7lUWrX8JFA3sPFAEe/3VlzQK5TYvFyFtTtQzrelnAPjZnrIZ7HX/r8D7Xoeo5RNv9EIm8aMhaDc5PJwVfyQ+a44NKBLdCJOLtTd18zZ15DqXtUNpVZqQ1BaWVKPldAxHpksk6FTlK2yi/K2Nzw60/5t22EosecKosXkBFvAadkcVrXqbKfpw2mWY2fr1TXu/Wy27ni10fsXnr42RkpKjamPj79XTJ7UZWSoGsXeEP0Ryriei3jaVWQ7j3WLBzHa/CB/7u5YQRQo/U2jsVrFx/iFRtKZTzEU7+eLpZ1OFVCt0UFb5Eujkdnd7N6CKXX/+mN8IJm5Iy1PwlEzQVEyu5KnT6wDaC1VbHoAEvsnnrEwD06/2YarkgCIw+bzzrdn1Gnb0W8BBveko6TmcDr7/2Obt3lfDm0kJ52eDO6kgJb8QqE+pUlUNsLkK9D8KxfoGw3Q/NfTjGdXIt3E62NtKVEEq/Q725IrmxlVoZ/uApdFnPS/e+xB3PiRWHC3Lv5a+TJf3bWsAjI/nqPW/gtAtY2njialfM1DRpsS6foZXrtQWDv0QFiXC9rdzl0zXcNcez/swxf+HhhQ8CYLXWY7EYcThcTBs9k8454jnTGdxkGCxcPWQUACP7Xilb/D3b9WNo9+EsXvAVOVnqyshNIZbGQazKijcHiRAZoHQTBOpHJK/+obofohUrHVPiTcRXpkRCsJsrVje2kuSUrgSz2cDoIhend3qQ0UUvUVmzgA9maags80yCSX5VgDqrL+k2RbRut5t1u1fz/YGNZFqy+L9hN9DG4p/omnIrgBgfLKmtKUPYpOy77PQ8ctLz5d+929IJ96iSHkb2vYKRfa9QWdXLZ/i35uPpAksUPdpEigxoiiSbwzlNHWO0k1NiQrytNYOmpeCPgJW/xwvHyl4F4McdzwHiZNLoJ4mazsCuIz/y2Y8fYrPVYXNWcv/8DA7+dEwu0BkqtHq33yw5QDUx+PXmCSpy9caURffIusCqh5HDv4BOS16b5soQRguxjgwItx/eIXbROC+BBKuiec5DvqPCNd9bmnCV/W0tLgslAceyz8qY1vycSTLhSijIvVclKq5Ec4RryqpKEHBTUVFFfkEagA/pbp15CVrzv+SKGAC7Z7+Py+Fk00nRHy1apR7L9EjJXLp1maJqR9JsmLJItGwLcv8sh4hFUv48UeYcEsX/myiJCUoCjva5kI5RuZ9AiJksZEsTaajw+6rRwk/ncBHrfion1rxFZU7v9KDqtz2v/JOhWWLV2o0nCgNOjoWCa7vvZc02gXYF2WzbUeR3naW7qnh+uac0vHv11/QY2AFrrQPr12LG3Q67uuTNB8+ZfR4USveD9JDxzqpT1nMLpC2cCJE13khU94Oyby3Vl5ZoN5KHcqvLXAuEpl43EuXpnIiQtBSk8j82m50f3rxJXt69f3twuZplZXkGZn8KehXwwcZDWK31PlETFwzqxPI1B3jea3trrUNOcxb9urfJy4ofcXL3nDsZ93JxWH0C0ZXibHzGSA8j7z6L/U7M8ZJo7odE8P/GE80ZIwktkhOqeyMUgZCmxGOCIdIspETHvImLeePRhaqaa0ffu5W+hVf4rBuKCFG9o07+k+BtDZzTK5tnCwfRt/ejqm0raxawdvPPVFZVEQ6k7LSm3Aezx81n3sTFqsoX/tKG/fW5NZCI1MeWHqeR3l+tEc0dIwlLvKFcREmVKRxFpkhD2oZmFYc0sDeeKFSpRbUUeg/rGrTPRr2JBpuZ96Zb2PHUMnY8tYyd6/b6XTfYMUnFLKU/CRtPFKI1GxEuOVfUA9aLL1lr/nJlSMdhtdZjrfMI1ayafL5qubQvSaBHcifsOzBLcZxiCnO6OYO3pv8Np7uY3Nz0JvfbGghXQqJEDyWKHzweUPJTJPd6QrsaAs2gxjtqoqVTEiNFJOnEQ7OK2T37fXlya9fXB3A7GoJu3xSUE2XChUNwf7qBzrmpHF5xK6lXnd/EltDuJvH1v+LDO9mz6WdcDieLHnBi1BuZNP8Ov9vk50ySZS7NZgM6gyf5ojk+6kRDohEu/DZIV0JzXCzNKu8eDYQ6OeBtuTVnsDUn/TFc0o/09a8lBd0jOdcDUt9gaNEaAIb0G8wJaxldc3swavDN3PWq+sVqx1MimdrsDVz08lfy71XWhfTsNp2Kiircbqirqw84adZUKR9llIP39qGQbjTSY2P50I1kDMaylA407zgjSctvDmJxPqRz0f/xVSGt32LE64+Q4nXyo3ljQetSYYu2leR9HZ/++Gd2V7sYfcvZ/PX1Lzi320UM7zeChxaKkQrP3v4yZp0YVyu5J7KzU9l/8EXZz9yj658pL68mJSWFw8dmq9pXEi8gpzcDdOsyBavVl6yViAfxer96tlR59mgaK4HajsaxxYt448E5CaPV4A/+LloixCaGg1iG9MQySD2acaD+rmPpyn2cM7QbD065lI9Wbae8qpS7G9N7c3LSmPSqhdLSE/zzWQ31jVq85eU1ZKROkCf51m2YRru8+6iqssopwABdOj0o76feUU+6OQOdwY3FIrpCjpbOo2fXaQCqqIkjJXPJzU0PmIkWLQR8GEfhOkZKuKp9RiH6obX6cRONc+JKvE29miRKbGK4iGVIT6x8xc3VAWjq5rth5OkUvbuVr9buobKqjuvOuYxPvvkYEInRaq1XZZf5g3K5kpCPe5UnGpD6BoJeA9zq6VufXE7v/BAbv3nCpz1luFg0EeztpznXMVLXlr99NOeh21r9uMHOB7QM58Td4g120WIdmxirkJtwFJHCgTJ7JtoIJqYTCcZd0Y0O2WZ2Hqqko8tB1+zvmIs4yeUP+w7MkrPX8nMmqUrteKPKulAOG5u80ALcRkHuvewd3AVLili5uPj+c7Cde3dIymrRRqiTl6FMxETiygpHuSsctHYrNxhide82hbj6eMP1nUXTjxqvwRNNf1UsrYx46gLXO+rk2m3eiRPKGOJA9dqU6/jDtzOWYjZo5b7Yzj3Th3ifLXyJ7Ixcf5v7IBIfbzQt01hqWMdLqzYcxNrHG6tz7Q8J7eMNFdGQxjsVX5Gai2gMNn9+6EDkIwrOOAExW8xsNmCz2Zsk1EAiOP6w6eQtXJj3rl9L8qk/zSQ/LfbXPRohh9EwNAKl8UbFR9xKEatz3RwktMXrjUhfi+M5eJr79I6HlRtL902gtm8sssokm24ZryLecwY/w8mTNqxWO+3bZ3LyhI3B3c/lyoG/l6sMK//rDHBDozxl8SNOXPUmVT8EvVYW1Imkpls0o17CJbqWuDb+1m+N90xLn2s4RSxeb5wKT99ASGS3QjCE0qbFYkQnFHKkZK6PME9FRS11dU6MegNaRzr9OvRheI+rcNrVxTBtjkqmzhdFfK6esoCC3Hux2ezypFkiTchGkrwSC0TTP5xo8PbhtvS5DgetinhPVSS6WyEa2D37fSprFmC11mM2GzCbDXKomFlw0yG/D384ezRmo9lnW48oeip3vbwwoC840dAaInVaq1sh0D3TWsJSk8TbgvgtEK50jD0GdoUN32MGKj+4HTQa2LYTN/D9679r7O+KsPurFL5JVCSKipg3WruVm2ghYuEgZB9vEkkkkUQS0UHCqpMlkUQSSZyqSBJvEkkkkUSckSTeJJJIIok4I0m8SSSRRBJxRpJ4k0giiSTijCTxJpFEEknEGUniTSKJJJKIM5LEm0QSSSQRZySJN4kkkkgizvj/Daw19lS2zpAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boundaries_on_embedding(reducer, lin_svc, embedding=embedding, \n",
    "                        title=\"Linear SVM on PCA\", \n",
    "                        cmap=\"inferno\",\n",
    "                       n_pts=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision_function = lin_svc.decision_function(X_train)\n",
    "# support_vector_indices = np.where((2 * y_train - 1) * decision_function <= 1)[0]\n",
    "# support_vectors = X_train[support_vector_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Plots the decision function for diferent values of C\n",
    "# for i, C in enumerate([0.02, 300]):\n",
    "#     plt.figure(figsize=default_style.SHORT_HALFSIZE_FIGURE)\n",
    "\n",
    "#     cmap=\"viridis\"\n",
    "#     clf = LinearSVC(C=C, loss=\"hinge\", penalty='l2', random_state=42).fit(X_test, y_test)\n",
    "\n",
    "#     # Genearate a grid in embedding\n",
    "#     xx = np.linspace(np.min(embedding[:,0]), np.max(embedding[:,0]), 30)\n",
    "#     yy = np.linspace(np.min(embedding[:,1]), np.max(embedding[:,1]), 30)\n",
    "\n",
    "#     XX, YY = np.meshgrid(xx, yy)\n",
    "#     points_in_embedding = np.array(np.meshgrid(xx, yy)).T\n",
    "#     old_shape = points_in_embedding.shape[:-1]\n",
    "    \n",
    "#     # Maps them back in the big space\n",
    "#     points_in_embedding = points_in_embedding.reshape(-1,2)\n",
    "#     points_in_gigaspace = reducer.inverse_transform(points_in_embedding)\n",
    "\n",
    "#     # Gets results\n",
    "#     results = clf.decision_function(points_in_gigaspace)\n",
    "#     mappable=plt.contourf(XX, YY, results.reshape(old_shape).T, cmap=\"viridis\", alpha=0.6, levels=15)\n",
    "#     plt.scatter(*embedding[test_mask].T, c=y_test, marker=\"o\", edgecolor=\"k\", s=5,cmap=cmap, label=\"test\")\n",
    "#     plt.scatter(*embedding[~test_mask].T, c=y[~test_mask], marker=\"+\",  s=5, cmap=cmap, label=\"train+val\")\n",
    "    \n",
    "#     # Plot support\n",
    "#     results = clf.decision_function(X_train)\n",
    "#     support_vector_indices = np.where((2 * y_train - 1) * results <= 1)[0]\n",
    "#     plt.scatter(*(embedding[~test_mask][support_vector_indices]).T, s=10, color=\"r\")\n",
    "#     plt.axis(\"off\")\n",
    "# #     decision_function = clf.decision_function(X_res_t)\n",
    "# # #     we can also calculate the decision function manually\n",
    "# # #     decision_function = np.dot(X_pca, clf.coef_[0]) + clf.intercept_[0]\n",
    "# #     support_vector_indices = np.where((2 * y_res_t - 1) * decision_function <= 1)[0]\n",
    "# #     support_vectors = X_res_t[support_vector_indices]\n",
    "# #     support_vectors_pca = pca.transform(support_vectors)\n",
    "\n",
    "# #     plt.subplot(1, 2, i + 1)\n",
    "# #     plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_res_t, s=30, cmap=plt.cm.Paired)\n",
    "# #     ax = plt.gca()\n",
    "# #     xlim = ax.get_xlim()\n",
    "# #     ylim = ax.get_ylim()\n",
    "# #     xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 50),\n",
    "# #                          np.linspace(ylim[0], ylim[1], 50))\n",
    "# #     clf = LinearSVC(C=C, loss=\"hinge\", random_state=42).fit(X_pca, y_res_t)\n",
    "# #     Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "# #     Z = Z.reshape(xx.shape)\n",
    "# #     plt.contour(xx, yy, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "# #                 linestyles=['--', '-', '--'])\n",
    "# #     plt.scatter(support_vectors_pca[:, 0], support_vectors_pca[:, 1], s=100,\n",
    "# #                 linewidth=1, facecolors='none', edgecolors='k')\n",
    "# #     plt.title(\"C=\" + str(C))\n",
    "# #     #plt.scatter(clf.coef_[:, 0] + clf.intercept_, clf.coef_[:, 1] + clf.intercept_)\n",
    "# # plt.tight_layout()\n",
    "# # plt.show()\n",
    "#     plt.savefig(f\"images/linear_svm_UMAP_decision_function_C_{C}.pdf\")\n",
    "#     plt.colorbar(mappable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for SVM is find hyperplane that maximizes the margin, furthermore C is the inverse of regularization strength therefore smaller value of C correspond a stronger regularization namely greater margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:20:50,505] A new study created in memory with name: no-name-7575583a-d439-424f-a08d-40eac4d4f648\n",
      "[I 2023-07-08 15:20:50,750] Trial 3 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 31.009873512017172, 'gamma': 0.7506084665277776}. Best is trial 3 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:20:50,983] Trial 4 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 71.0818997182604, 'gamma': 0.7548534330191142}. Best is trial 3 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:20:51,284] Trial 5 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 73.48830166188019, 'gamma': 0.8219833601934208}. Best is trial 3 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:20:51,313] Trial 2 finished with value: 0.4820936639118457 and parameters: {'kernel': 'sigmoid', 'C': 3.7294243432104377, 'gamma': 0.6464274955883247}. Best is trial 3 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:20:51,334] Trial 1 finished with value: 0.4820936639118457 and parameters: {'kernel': 'sigmoid', 'C': 19.736247080691218, 'gamma': 0.6127309506618068}. Best is trial 3 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:20:51,594] Trial 7 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 31.815631670438396, 'gamma': 0.9255410572246763}. Best is trial 3 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:20:51,709] Trial 0 finished with value: 0.90633608815427 and parameters: {'kernel': 'rbf', 'C': 49.75978532548985, 'gamma': 0.9175215348628527}. Best is trial 3 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:20:51,878] Trial 9 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 13.889972317044991, 'gamma': 0.06292787804914445}. Best is trial 3 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:20:51,979] Trial 8 finished with value: 0.9559228650137741 and parameters: {'kernel': 'rbf', 'C': 55.9946198640896, 'gamma': 0.23990274551977872}. Best is trial 3 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:20:52,125] Trial 6 finished with value: 0.4820936639118457 and parameters: {'kernel': 'sigmoid', 'C': 40.62259272606092, 'gamma': 0.9886794971658797}. Best is trial 3 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:20:52,181] Trial 11 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 23.69441784133246, 'gamma': 0.08423145818271568}. Best is trial 3 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:20:52,189] Trial 10 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 74.11196559474534, 'gamma': 0.1767092335726213}. Best is trial 10 with value: 0.9696969696969697.\n",
      "[I 2023-07-08 15:20:52,410] Trial 13 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 29.103769029842766, 'gamma': 0.47435449276912883}. Best is trial 10 with value: 0.9696969696969697.\n",
      "[I 2023-07-08 15:20:53,160] Trial 12 finished with value: 0.931129476584022 and parameters: {'kernel': 'rbf', 'C': 7.679595499541669, 'gamma': 0.6118955565283845}. Best is trial 10 with value: 0.9696969696969697.\n",
      "[I 2023-07-08 15:20:53,228] Trial 14 finished with value: 0.9449035812672176 and parameters: {'kernel': 'rbf', 'C': 78.63147238817972, 'gamma': 0.4062748425942007}. Best is trial 10 with value: 0.9696969696969697.\n",
      "[I 2023-07-08 15:20:53,246] Trial 15 finished with value: 0.9449035812672176 and parameters: {'kernel': 'rbf', 'C': 79.71774253345941, 'gamma': 0.40103243483051587}. Best is trial 10 with value: 0.9696969696969697.\n",
      "[I 2023-07-08 15:20:53,460] Trial 16 finished with value: 0.9366391184573003 and parameters: {'kernel': 'rbf', 'C': 57.947229257441, 'gamma': 0.43356423028567465}. Best is trial 10 with value: 0.9696969696969697.\n",
      "[I 2023-07-08 15:20:53,722] Trial 20 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 39.54420175641618, 'gamma': 0.25936791659636715}. Best is trial 10 with value: 0.9696969696969697.\n",
      "[I 2023-07-08 15:20:53,806] Trial 17 finished with value: 0.953168044077135 and parameters: {'kernel': 'rbf', 'C': 62.29056444553515, 'gamma': 0.2738239786962613}. Best is trial 10 with value: 0.9696969696969697.\n",
      "[I 2023-07-08 15:20:53,915] Trial 18 finished with value: 0.953168044077135 and parameters: {'kernel': 'rbf', 'C': 62.40253673503866, 'gamma': 0.2637206542760814}. Best is trial 10 with value: 0.9696969696969697.\n",
      "[I 2023-07-08 15:20:53,916] Trial 19 finished with value: 0.953168044077135 and parameters: {'kernel': 'rbf', 'C': 63.392607006567246, 'gamma': 0.2642757559658545}. Best is trial 10 with value: 0.9696969696969697.\n",
      "[I 2023-07-08 15:20:54,074] Trial 21 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 64.42846937543305, 'gamma': 0.017011933506123567}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:54,235] Trial 23 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 69.5281246036381, 'gamma': 0.7547830958158618}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:54,240] Trial 24 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 69.5558269897885, 'gamma': 0.7152338679158476}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:54,397] Trial 25 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 71.69975797249428, 'gamma': 0.012391132273231525}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:54,615] Trial 27 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 49.13790058327194, 'gamma': 0.04112941228387956}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:54,637] Trial 26 finished with value: 0.9724517906336089 and parameters: {'kernel': 'rbf', 'C': 48.11970454916407, 'gamma': 0.014959082309536702}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:54,643] Trial 22 finished with value: 0.4820936639118457 and parameters: {'kernel': 'sigmoid', 'C': 45.32714003801521, 'gamma': 0.7350643364001082}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:54,743] Trial 28 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 77.54840000694404, 'gamma': 0.004934709947430725}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:55,100] Trial 29 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 75.22376411258783, 'gamma': 0.11619514565296729}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:55,137] Trial 31 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 54.435490489226765, 'gamma': 0.12876884007077197}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:55,140] Trial 30 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 53.53491283353988, 'gamma': 0.1224736344826332}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:55,180] Trial 32 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 54.97019602222645, 'gamma': 0.12746138595645418}. Best is trial 21 with value: 0.9752066115702479.\n",
      "[I 2023-07-08 15:20:55,473] Trial 34 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 65.82867332256988, 'gamma': 0.020405532222576565}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:55,535] Trial 35 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 67.04846825560679, 'gamma': 0.0458098675302657}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:55,556] Trial 36 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 65.71282026094305, 'gamma': 0.004223039833914593}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:55,655] Trial 33 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 66.20322307816306, 'gamma': 0.14792646326853373}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:55,928] Trial 37 finished with value: 0.9504132231404959 and parameters: {'kernel': 'sigmoid', 'C': 65.82063624926225, 'gamma': 0.0018799496293887275}. Best is trial 34 with value: 0.9834710743801653.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:20:56,544] Trial 38 finished with value: 0.4820936639118457 and parameters: {'kernel': 'sigmoid', 'C': 64.22934434790488, 'gamma': 0.18733035646400992}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:56,609] Trial 39 finished with value: 0.4820936639118457 and parameters: {'kernel': 'sigmoid', 'C': 59.56627177869247, 'gamma': 0.16675841813134212}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:56,630] Trial 40 finished with value: 0.5234159779614325 and parameters: {'kernel': 'sigmoid', 'C': 59.08957149370967, 'gamma': 0.07711555035026654}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:56,942] Trial 42 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 74.5187715222135, 'gamma': 0.07986562203695109}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:56,950] Trial 41 finished with value: 0.4820936639118457 and parameters: {'kernel': 'sigmoid', 'C': 73.64075695520337, 'gamma': 0.19800016539572157}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:57,029] Trial 44 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 73.25922330177653, 'gamma': 0.04936554342320148}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:57,075] Trial 43 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 72.8834463413067, 'gamma': 0.08037633734255384}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:57,329] Trial 46 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 70.71320379912866, 'gamma': 0.04718333636696487}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:57,371] Trial 45 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 71.56458060267781, 'gamma': 0.04423091828364016}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:57,406] Trial 48 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 69.84711021668686, 'gamma': 0.040263565696517}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:57,478] Trial 47 finished with value: 0.9559228650137741 and parameters: {'kernel': 'rbf', 'C': 70.21373455496062, 'gamma': 0.002053503761176804}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:57,698] Trial 49 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 69.93836361506493, 'gamma': 0.006023744041861585}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:57,903] Trial 52 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 77.08886698158169, 'gamma': 0.10314379433351191}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:57,967] Trial 50 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 68.37166978446801, 'gamma': 0.18217716209112347}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:58,018] Trial 51 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 60.96337287336862, 'gamma': 0.20992660896709942}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:58,166] Trial 53 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 77.28345295088195, 'gamma': 0.09806599912189766}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:58,360] Trial 54 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 76.20394397503028, 'gamma': 0.1119339368559466}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:58,580] Trial 56 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 79.62022917889225, 'gamma': 0.16086768267481874}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:58,582] Trial 55 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 59.3351616393972, 'gamma': 0.20563174415475088}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:58,857] Trial 58 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 62.94950966489877, 'gamma': 0.15858000417712123}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:59,104] Trial 57 finished with value: 0.953168044077135 and parameters: {'kernel': 'rbf', 'C': 62.36757765304144, 'gamma': 0.31992377815082274}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:59,460] Trial 62 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 66.99150137964607, 'gamma': 0.07729103954182537}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:59,548] Trial 60 finished with value: 0.9504132231404959 and parameters: {'kernel': 'rbf', 'C': 67.35331134528718, 'gamma': 0.32427102086879145}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:59,559] Trial 59 finished with value: 0.953168044077135 and parameters: {'kernel': 'rbf', 'C': 62.54385155806603, 'gamma': 0.2986870561348741}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:20:59,857] Trial 61 finished with value: 0.9504132231404959 and parameters: {'kernel': 'rbf', 'C': 67.65307478584036, 'gamma': 0.30552619880358245}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:00,065] Trial 63 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 57.15383564446805, 'gamma': 0.22631576354461985}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:00,110] Trial 65 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 79.91204135443832, 'gamma': 0.15096289023176557}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:00,154] Trial 64 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 79.91802084465414, 'gamma': 0.1746128695172273}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:00,382] Trial 66 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 77.91017065513554, 'gamma': 0.14842873027465853}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:00,626] Trial 67 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 78.69868156356648, 'gamma': 0.15939423272099165}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:00,655] Trial 68 finished with value: 0.9724517906336089 and parameters: {'kernel': 'rbf', 'C': 75.50334526423337, 'gamma': 0.16283357802739284}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:00,662] Trial 69 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 76.01920220430726, 'gamma': 0.136423885053474}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:00,811] Trial 70 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 75.28234743374466, 'gamma': 0.10252094868213621}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:00,975] Trial 72 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 74.10435195880878, 'gamma': 0.10694210829772635}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:00,979] Trial 73 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 74.51478722407604, 'gamma': 0.1030618039238854}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:00,989] Trial 71 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 74.72321142250489, 'gamma': 0.1088447645081301}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:01,363] Trial 74 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 72.35523123349427, 'gamma': 0.23367099748834774}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:01,451] Trial 76 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 71.95327074004112, 'gamma': 0.061384296741799245}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:01,615] Trial 77 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 65.01346150505628, 'gamma': 0.2311236533873224}. Best is trial 34 with value: 0.9834710743801653.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:21:01,668] Trial 75 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 72.19057813432454, 'gamma': 0.23351079392627996}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:01,689] Trial 78 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 64.7106005757501, 'gamma': 0.026184287663825117}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:01,966] Trial 79 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 64.09091665396505, 'gamma': 0.18336282821075992}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:02,034] Trial 82 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 67.69095407960538, 'gamma': 0.03027870399658164}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:02,066] Trial 81 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 64.60905996125996, 'gamma': 0.036741213490639586}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:02,133] Trial 80 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 68.27182506704062, 'gamma': 0.18337389236224907}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:02,382] Trial 84 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 69.74830168001729, 'gamma': 0.03087530169370914}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:02,476] Trial 85 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 69.6598106754165, 'gamma': 0.06830237130730377}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:02,512] Trial 86 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 60.80936029930655, 'gamma': 0.06876596152499735}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:02,665] Trial 83 finished with value: 0.7107438016528925 and parameters: {'kernel': 'sigmoid', 'C': 51.95694734185987, 'gamma': 0.028018284331103066}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:02,888] Trial 89 finished with value: 0.8484848484848485 and parameters: {'kernel': 'sigmoid', 'C': 71.81905930095547, 'gamma': 0.019186018886990147}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:03,016] Trial 87 finished with value: 0.6666666666666666 and parameters: {'kernel': 'sigmoid', 'C': 52.150690924447744, 'gamma': 0.06796300463165857}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:03,055] Trial 90 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 57.34068135554967, 'gamma': 0.08286444807698996}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:03,124] Trial 88 finished with value: 0.6556473829201102 and parameters: {'kernel': 'sigmoid', 'C': 60.54971071656938, 'gamma': 0.06987889257904771}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:03,392] Trial 91 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 68.19801730138371, 'gamma': 0.13773154866902454}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:03,618] Trial 92 finished with value: 0.9559228650137741 and parameters: {'kernel': 'rbf', 'C': 56.905832513996394, 'gamma': 0.0020158075373497616}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:03,622] Trial 93 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 65.70615713846026, 'gamma': 0.12526388614127548}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:03,642] Trial 94 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 78.07353271371618, 'gamma': 0.1363819540696291}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:03,687] Trial 95 finished with value: 0.9807162534435262 and parameters: {'kernel': 'rbf', 'C': 79.36036204819938, 'gamma': 0.016449921480138574}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,014] Trial 97 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 79.88957024797024, 'gamma': 0.023977393152121468}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,050] Trial 99 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 76.22081291776142, 'gamma': 0.0394147092571204}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,129] Trial 96 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 79.78579017404819, 'gamma': 0.18101228127049185}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,204] Trial 98 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 79.3924089022053, 'gamma': 0.17039584640182187}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,389] Trial 100 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 75.89635567489721, 'gamma': 0.02189751031172792}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,427] Trial 101 finished with value: 0.9807162534435262 and parameters: {'kernel': 'rbf', 'C': 72.86647620062864, 'gamma': 0.020725099671641253}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,461] Trial 102 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 73.54171924651548, 'gamma': 0.016338311320000742}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,495] Trial 103 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 77.02787680148582, 'gamma': 0.01567144440542656}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,738] Trial 104 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 76.67159811123149, 'gamma': 0.02204637146651712}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,810] Trial 105 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 73.42777654362268, 'gamma': 0.01761150834530703}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,815] Trial 106 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 76.70400052018229, 'gamma': 0.019125825441528264}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:04,837] Trial 107 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 76.85948132497262, 'gamma': 0.02400507371145953}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:05,017] Trial 108 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 77.25915507312467, 'gamma': 0.021241170237450997}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:05,229] Trial 109 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 73.29964513743465, 'gamma': 0.05542086446313327}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:05,242] Trial 111 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 73.2520102390906, 'gamma': 0.05584219951676237}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:05,251] Trial 110 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 77.78173845276795, 'gamma': 0.05084029945686652}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:05,359] Trial 112 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 73.58589708449226, 'gamma': 0.057481869577075594}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:05,658] Trial 113 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 70.97502695811718, 'gamma': 0.046531735411633024}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:05,714] Trial 115 finished with value: 0.953168044077135 and parameters: {'kernel': 'rbf', 'C': 75.40888878535853, 'gamma': 0.0021259132518541245}. Best is trial 34 with value: 0.9834710743801653.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:21:05,762] Trial 114 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 74.59111961091966, 'gamma': 0.0013792371688843529}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:05,836] Trial 116 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 70.84838893782546, 'gamma': 0.0011452488792927616}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,036] Trial 118 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 77.5399036533778, 'gamma': 0.019122726088211594}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,121] Trial 117 finished with value: 0.953168044077135 and parameters: {'kernel': 'rbf', 'C': 75.50851495226027, 'gamma': 0.0016193518038298133}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,172] Trial 120 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 77.96388502071754, 'gamma': 0.025539836004990303}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,205] Trial 119 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 78.27700546502025, 'gamma': 0.08887407070839971}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,448] Trial 121 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 77.67746318120275, 'gamma': 0.09540225107872588}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,548] Trial 124 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 76.38087765427946, 'gamma': 0.027499342800611976}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,573] Trial 122 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 78.11799258831316, 'gamma': 0.0909378847200245}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,644] Trial 123 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 76.91608000314325, 'gamma': 0.08989157075759793}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,772] Trial 125 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 76.44333614950634, 'gamma': 0.03711834353056477}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,898] Trial 126 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 73.47862222241055, 'gamma': 0.026076246089541788}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,945] Trial 127 finished with value: 0.9724517906336089 and parameters: {'kernel': 'rbf', 'C': 72.51640106171348, 'gamma': 0.02634542923187009}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:06,982] Trial 128 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 73.81083718408009, 'gamma': 0.027675087104974152}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:07,048] Trial 129 finished with value: 0.9752066115702479 and parameters: {'kernel': 'poly', 'C': 73.0437696824505, 'gamma': 0.021465111314401694}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:07,176] Trial 130 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 71.54577666760275, 'gamma': 0.05098837514429014}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:07,271] Trial 131 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 69.19934559223063, 'gamma': 0.052945282985960254}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:07,307] Trial 132 finished with value: 0.9586776859504132 and parameters: {'kernel': 'poly', 'C': 79.8872226131609, 'gamma': 0.05922285625404723}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:07,456] Trial 133 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 79.72850210262288, 'gamma': 0.06259127517765715}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:07,544] Trial 134 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 79.87492260793036, 'gamma': 0.06976209617787482}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:07,688] Trial 135 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 79.69915421222012, 'gamma': 0.06952165089810673}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:07,754] Trial 136 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 75.34425155776714, 'gamma': 0.07154973471339174}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:07,762] Trial 137 finished with value: 0.9807162534435262 and parameters: {'kernel': 'rbf', 'C': 75.32036674045312, 'gamma': 0.01632651082173294}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:07,848] Trial 138 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 75.78955955422867, 'gamma': 0.01748778457337713}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:08,003] Trial 139 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 75.20119280508442, 'gamma': 0.018768581419748458}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:08,139] Trial 140 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 66.65270161430104, 'gamma': 0.01759399072158972}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:08,140] Trial 141 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 66.31529935029609, 'gamma': 0.016772521906179973}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:08,209] Trial 142 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 70.4219686482549, 'gamma': 0.041127771128569274}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:08,346] Trial 143 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 70.48515828576377, 'gamma': 0.040828149554387086}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:08,525] Trial 144 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 74.79220147202331, 'gamma': 0.0385234687128362}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:08,529] Trial 145 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 74.49230597224725, 'gamma': 0.038497957416078435}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:08,582] Trial 146 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 74.70865734329412, 'gamma': 0.040098281425358664}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:08,774] Trial 147 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 74.84583308742347, 'gamma': 0.11444170215484183}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:08,992] Trial 148 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 76.3050222262647, 'gamma': 0.0027641792631405496}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:08,995] Trial 149 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 76.11908641372524, 'gamma': 0.0023006268662271352}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:09,046] Trial 150 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 72.05092919287775, 'gamma': 0.11756937871754945}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:09,120] Trial 151 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 71.82819749874287, 'gamma': 0.003306650828876625}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:09,446] Trial 152 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 71.76986937625466, 'gamma': 0.08645010638983361}. Best is trial 34 with value: 0.9834710743801653.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:21:09,481] Trial 153 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 68.1064788616774, 'gamma': 0.08832116219644745}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:09,510] Trial 154 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 78.02620828436902, 'gamma': 0.07896902052712208}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:09,512] Trial 155 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 77.98341142424891, 'gamma': 0.08427651390833363}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:09,747] Trial 156 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 77.98646355269969, 'gamma': 0.02114736545540879}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:09,886] Trial 159 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 76.71829939489636, 'gamma': 0.022871051858138345}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:09,890] Trial 158 finished with value: 0.9724517906336089 and parameters: {'kernel': 'rbf', 'C': 63.6248592603094, 'gamma': 0.02768464669404949}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:09,897] Trial 157 finished with value: 0.9807162534435262 and parameters: {'kernel': 'rbf', 'C': 78.11548199340777, 'gamma': 0.01649027047053659}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:10,097] Trial 160 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 76.56255905440479, 'gamma': 0.05390142367425301}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:10,314] Trial 162 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 78.3157096772146, 'gamma': 0.053010168054412526}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:10,324] Trial 161 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 69.32088220435912, 'gamma': 0.05687235355636887}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:10,334] Trial 163 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 77.99554773478613, 'gamma': 0.0537291165784113}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:10,408] Trial 164 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 73.4631661334681, 'gamma': 0.016375887570224124}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:10,697] Trial 165 finished with value: 0.9807162534435262 and parameters: {'kernel': 'rbf', 'C': 72.9904705471706, 'gamma': 0.017505592976477878}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:10,707] Trial 166 finished with value: 0.9807162534435262 and parameters: {'kernel': 'rbf', 'C': 73.31683982497233, 'gamma': 0.017176883419104772}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:10,742] Trial 167 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 73.85126574073243, 'gamma': 0.01596937778127315}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:10,848] Trial 168 finished with value: 0.9008264462809917 and parameters: {'kernel': 'sigmoid', 'C': 72.76518614647092, 'gamma': 0.016000576254617833}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:11,101] Trial 169 finished with value: 0.8347107438016529 and parameters: {'kernel': 'sigmoid', 'C': 75.33819552134776, 'gamma': 0.01945459671554991}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:11,175] Trial 171 finished with value: 0.696969696969697 and parameters: {'kernel': 'sigmoid', 'C': 75.87596512325973, 'gamma': 0.04038312992284071}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:11,233] Trial 170 finished with value: 0.9559228650137741 and parameters: {'kernel': 'rbf', 'C': 75.03782080851609, 'gamma': 0.0012600198274362526}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:11,262] Trial 172 finished with value: 0.953168044077135 and parameters: {'kernel': 'rbf', 'C': 75.82715500314492, 'gamma': 0.002187075565083057}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:11,611] Trial 176 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 72.8004214095676, 'gamma': 0.035472350195678674}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:11,614] Trial 175 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 73.3997010013295, 'gamma': 0.03434906610193333}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:11,666] Trial 174 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 73.71175445031642, 'gamma': 0.0013401982495984434}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:12,042] Trial 177 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 77.27488591092708, 'gamma': 0.0667587909101453}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:12,075] Trial 179 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 78.30662856858578, 'gamma': 0.07485572886398452}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:12,093] Trial 173 finished with value: 0.9393939393939394 and parameters: {'kernel': 'rbf', 'C': 76.1183368748612, 'gamma': 0.5592738520803274}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:12,732] Trial 178 finished with value: 0.9393939393939394 and parameters: {'kernel': 'rbf', 'C': 78.24787772298845, 'gamma': 0.5554854421019084}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:13,041] Trial 182 finished with value: 0.9476584022038568 and parameters: {'kernel': 'rbf', 'C': 71.51122109437586, 'gamma': 0.34569245734418896}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:13,072] Trial 183 finished with value: 0.9807162534435262 and parameters: {'kernel': 'rbf', 'C': 70.71200893560811, 'gamma': 0.02061598893862259}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:13,110] Trial 180 finished with value: 0.9366391184573003 and parameters: {'kernel': 'rbf', 'C': 78.65033596093858, 'gamma': 0.5772919153084916}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:13,150] Trial 181 finished with value: 0.9393939393939394 and parameters: {'kernel': 'rbf', 'C': 70.88034940653979, 'gamma': 0.5507710826216535}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:13,432] Trial 184 finished with value: 0.9696969696969697 and parameters: {'kernel': 'rbf', 'C': 69.59421800168626, 'gamma': 0.02889634821479256}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:13,482] Trial 187 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 74.32546586721581, 'gamma': 0.02203892222871799}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:13,496] Trial 186 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 74.26994661546348, 'gamma': 0.021317233765192158}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:13,499] Trial 185 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 70.47579687431934, 'gamma': 0.018594378536560152}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:13,793] Trial 188 finished with value: 0.9807162534435262 and parameters: {'kernel': 'rbf', 'C': 73.58498846160619, 'gamma': 0.02032276757071873}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:13,878] Trial 191 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 76.97406050216588, 'gamma': 0.04744064910801778}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:13,904] Trial 190 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 68.9468111891159, 'gamma': 0.05055819558098931}. Best is trial 34 with value: 0.9834710743801653.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:21:13,906] Trial 189 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 73.38780621188077, 'gamma': 0.04682023987816558}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:14,123] Trial 192 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 68.38325949309245, 'gamma': 0.04864022988344041}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:14,311] Trial 193 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 69.11574668950114, 'gamma': 0.04606588465779945}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:14,324] Trial 195 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 44.4992773859216, 'gamma': 0.03579769657130323}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:14,424] Trial 196 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 71.16784499687992, 'gamma': 0.021804692705876344}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:14,447] Trial 194 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 71.00110675809479, 'gamma': 0.001414165068020383}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:14,667] Trial 198 finished with value: 0.9807162534435262 and parameters: {'kernel': 'rbf', 'C': 71.0289728549655, 'gamma': 0.017441213440364447}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:14,746] Trial 197 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 71.5930618294695, 'gamma': 0.0029779647482481714}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:14,889] Trial 200 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 75.3834438839746, 'gamma': 0.0688389136641705}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:14,928] Trial 199 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 75.99902170754027, 'gamma': 0.0025967860925328757}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:15,050] Trial 201 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 71.99265404647294, 'gamma': 0.06582483204019964}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:15,290] Trial 204 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 72.57278149992487, 'gamma': 0.02528042639535987}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:15,306] Trial 203 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 72.3336107431849, 'gamma': 0.07184292100416094}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:15,356] Trial 205 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 77.23102092158469, 'gamma': 0.022119533803230014}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:15,711] Trial 202 finished with value: 0.9393939393939394 and parameters: {'kernel': 'rbf', 'C': 75.79492894799841, 'gamma': 0.4660925768661045}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:15,736] Trial 207 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 33.41063663804367, 'gamma': 0.03260738279047667}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:15,738] Trial 206 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 74.6358515539332, 'gamma': 0.031484475763847344}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:16,096] Trial 211 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 78.55208444786511, 'gamma': 0.01756092247508065}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:16,118] Trial 209 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 74.3381970850617, 'gamma': 0.034457830913451525}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:16,301] Trial 208 finished with value: 0.9449035812672176 and parameters: {'kernel': 'rbf', 'C': 75.73146898851356, 'gamma': 0.4109672269341953}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:16,342] Trial 210 finished with value: 0.9614325068870524 and parameters: {'kernel': 'rbf', 'C': 77.0656731053486, 'gamma': 0.21537652276363747}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:16,530] Trial 213 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 79.99660944967212, 'gamma': 0.05630469042924793}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:16,533] Trial 212 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 79.25852130071807, 'gamma': 0.0443600350966389}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:16,683] Trial 214 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 79.01772661100892, 'gamma': 0.015385079986211792}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:16,688] Trial 215 finished with value: 0.9807162534435262 and parameters: {'kernel': 'rbf', 'C': 79.20886291483241, 'gamma': 0.016559091960152306}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:16,887] Trial 216 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 78.11695689693079, 'gamma': 0.01816835245195739}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:16,904] Trial 217 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 78.1969681937449, 'gamma': 0.019267095250445142}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:17,048] Trial 219 finished with value: 0.9724517906336089 and parameters: {'kernel': 'rbf', 'C': 77.16270352510718, 'gamma': 0.013286130362752356}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:17,069] Trial 218 finished with value: 0.9724517906336089 and parameters: {'kernel': 'rbf', 'C': 70.03783772456576, 'gamma': 0.016047261487246643}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:17,299] Trial 221 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 66.76653463950413, 'gamma': 0.005165589156941397}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:17,346] Trial 220 finished with value: 0.9586776859504132 and parameters: {'kernel': 'rbf', 'C': 77.08752808415238, 'gamma': 0.002312592061973196}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:17,648] Trial 224 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 78.69207665376558, 'gamma': 0.0398882882564651}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:17,688] Trial 225 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 78.58222008170101, 'gamma': 0.03922654980396752}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:18,248] Trial 223 finished with value: 0.9201101928374655 and parameters: {'kernel': 'rbf', 'C': 66.62412708816571, 'gamma': 0.7844601993571436}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:18,285] Trial 222 finished with value: 0.9201101928374655 and parameters: {'kernel': 'rbf', 'C': 66.71884435401826, 'gamma': 0.8435444947464741}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:18,342] Trial 226 finished with value: 0.953168044077135 and parameters: {'kernel': 'rbf', 'C': 73.72464712443272, 'gamma': 0.2629852168933005}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:18,668] Trial 229 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 74.18537277857975, 'gamma': 0.053634194138510304}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:18,674] Trial 228 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 74.67598118497726, 'gamma': 0.06038739328656609}. Best is trial 34 with value: 0.9834710743801653.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:21:18,719] Trial 230 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 74.69416539341866, 'gamma': 0.05800429448505815}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:18,778] Trial 227 finished with value: 0.928374655647383 and parameters: {'kernel': 'rbf', 'C': 74.1705406632496, 'gamma': 0.6485695325580833}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:19,041] Trial 233 finished with value: 0.9807162534435262 and parameters: {'kernel': 'poly', 'C': 53.28701428671427, 'gamma': 0.020321237356688886}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:19,098] Trial 232 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 76.40051646136182, 'gamma': 0.020773485898699352}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:19,110] Trial 234 finished with value: 0.9752066115702479 and parameters: {'kernel': 'rbf', 'C': 55.83064507412496, 'gamma': 0.02022885238698863}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:19,349] Trial 231 finished with value: 0.9559228650137741 and parameters: {'kernel': 'rbf', 'C': 55.35563156319198, 'gamma': 0.2470870822208926}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:19,358] Trial 235 finished with value: 0.9641873278236914 and parameters: {'kernel': 'poly', 'C': 76.43610848774243, 'gamma': 0.022629834708718283}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:19,417] Trial 236 finished with value: 0.9614325068870524 and parameters: {'kernel': 'poly', 'C': 49.696043919989854, 'gamma': 0.03125081830332127}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:19,426] Trial 237 finished with value: 0.9614325068870524 and parameters: {'kernel': 'poly', 'C': 54.03928835500247, 'gamma': 0.037502588155955266}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:19,750] Trial 239 finished with value: 0.9614325068870524 and parameters: {'kernel': 'poly', 'C': 50.728220867074306, 'gamma': 0.036021054055529876}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:20,024] Trial 241 finished with value: 0.9504132231404959 and parameters: {'kernel': 'poly', 'C': 72.59766886878052, 'gamma': 0.004007660476532901}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:20,143] Trial 240 finished with value: 0.9366391184573003 and parameters: {'kernel': 'poly', 'C': 72.60622669832506, 'gamma': 0.0031150285228016324}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:20,271] Trial 238 finished with value: 0.8705234159779615 and parameters: {'kernel': 'poly', 'C': 58.50747625964996, 'gamma': 0.002108033997909823}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:20,395] Trial 243 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 79.90618050335294, 'gamma': 0.017605414235476742}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:20,501] Trial 244 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 77.69828532312886, 'gamma': 0.018630555255286844}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:20,609] Trial 245 finished with value: 0.977961432506887 and parameters: {'kernel': 'rbf', 'C': 77.65068517708816, 'gamma': 0.02220957112520305}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:20,672] Trial 242 finished with value: 0.7961432506887053 and parameters: {'kernel': 'poly', 'C': 61.41255496728261, 'gamma': 0.0017558950543834634}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:20,764] Trial 246 finished with value: 0.9834710743801653 and parameters: {'kernel': 'rbf', 'C': 60.42687725634089, 'gamma': 0.021718693664435573}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:20,833] Trial 247 finished with value: 0.9641873278236914 and parameters: {'kernel': 'rbf', 'C': 60.606940406477015, 'gamma': 0.03559712127309647}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:20,915] Trial 248 finished with value: 0.9669421487603306 and parameters: {'kernel': 'rbf', 'C': 60.0663726879984, 'gamma': 0.04171465325280687}. Best is trial 34 with value: 0.9834710743801653.\n",
      "[I 2023-07-08 15:21:21,249] Trial 249 finished with value: 0.9449035812672176 and parameters: {'kernel': 'rbf', 'C': 79.4656196000737, 'gamma': 0.35874586914458956}. Best is trial 34 with value: 0.9834710743801653.\n"
     ]
    }
   ],
   "source": [
    "# objective function to be minimized\n",
    "def objective_fun(trial):\n",
    "\n",
    "    kernel = trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid'])\n",
    "    C = trial.suggest_float('C', 0.1,80)\n",
    "    gamma = trial.suggest_float('gamma', 0.001, 1)\n",
    "    \n",
    "\n",
    "    lin_svc = SVC(kernel=kernel, gamma=gamma, C=C)\n",
    "\n",
    "    lin_svc.fit(X_train, y_train)\n",
    "    y_pred = lin_svc.predict(X_val)\n",
    "\n",
    "    error = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective_fun, n_trials = 250, n_jobs = -1, catch=(ValueError,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 65.82867332256988, 'gamma': 0.020405532222576565}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       309\n",
      "           1       0.95      0.92      0.94       308\n",
      "\n",
      "    accuracy                           0.94       617\n",
      "   macro avg       0.94      0.94      0.94       617\n",
      "weighted avg       0.94      0.94      0.94       617\n",
      "\n",
      "Accuracy 0.9384116693679092\n",
      "F1-score [0.93949045 0.93729373]\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "svc = SVC(**best_params)\n",
    "svc.fit(np.concatenate((X_train, X_val)),np.concatenate((y_train, y_val)))\n",
    "\n",
    "y_pred_test = svc.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(best_params)\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred_test))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred_test, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 231)\n",
      "(2429, 231)\n"
     ]
    }
   ],
   "source": [
    "print(svc.support_vectors_.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:155: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:155: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=default_style.SHORT_HALFSIZE_FIGURE)\n",
    "cf = confusion_matrix(y_test, y_pred_test)\n",
    "sns.heatmap(cf, annot=True, cmap='Greens', cbar=False, fmt=\".4g\", ax=ax)\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Non-linear SVM confusion matrix')\n",
    "\n",
    "ax.set_xticks([0.5,1.5], labels=label_enc.inverse_transform([[0],[1]]))\n",
    "ax.set_yticks([0.5,1.5], labels=label_enc.inverse_transform([[0],[1]]))\n",
    "\n",
    "plt.savefig(\"images/nonlinear_svm_conf_matrix.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support_vectors_pca = pca.transform(svc.support_vectors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_res_t, \n",
    "#             cmap=plt.cm.prism, edgecolor='none', alpha=0.7, s=10)\n",
    "# plt.scatter(support_vectors_pca[:100, 0], support_vectors_pca[:100, 1], s=10,\n",
    "#                 linewidth=1, facecolors='none', edgecolors='k')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision_function = svc.decision_function(X_res_t)\n",
    "# support_vector_indices = np.where((2 * y_res_t - 1) * decision_function <= 1)[0]\n",
    "# support_vectors = X_res_t[support_vector_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support_vectors_pca = pca.transform(support_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for kernel in ('linear', 'rbf', 'poly'):\n",
    "#     clf = SVC(kernel=kernel, gamma=0.1, C=26)\n",
    "#     clf.fit(X_res_t, y_res_t)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.clf()\n",
    "#     plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_res_t, zorder=10, cmap=plt.cm.Paired,\n",
    "#                 edgecolor='k', s=20)\n",
    "\n",
    "#     # Circle out the test data\n",
    "# #     plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], s=80, facecolors='none',\n",
    "# #                 zorder=10, edgecolor='k')\n",
    "\n",
    "#     plt.axis('tight')\n",
    "#     x_min = X_pca[:, 0].min()\n",
    "#     x_max = X_pca[:, 0].max()\n",
    "#     y_min = X_pca[:, 1].min()\n",
    "#     y_max = X_pca[:, 1].max()\n",
    "\n",
    "#     XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "#     clf.fit(X_pca, y_res_t)\n",
    "#     Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "#     # Put the result into a color plot\n",
    "#     Z = Z.reshape(XX.shape)\n",
    "#     plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "#     plt.contour(XX, YY, Z, colors=['k', 'k', 'k'],\n",
    "#                 linestyles=['--', '-', '--'], levels=[-.5, 0, .5])\n",
    "\n",
    "#     plt.title(kernel)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boundaries_on_embedding(reducer, svc, embedding=embedding, \n",
    "                        title=\"non-linear SVM on PCA\", \n",
    "                        cmap=\"inferno\",\n",
    "                        n_pts=30)\n",
    "# plt.scatter(*(reducer.transform(svc.support_vectors_).T), color=\"r\", s=10 , marker=\"+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the different boundary for different kernel:\n",
    "-Linear: just see previuos section\n",
    "-Radial: Basis Function:The gamma parameters can be seen as the inverse of the radius of influence of   samples selected\n",
    "-poly : the polynomial kernel looks not only at the given features of input samples to determine their similarity, but also combinations of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  build the model for neural networks\n",
    "def build_model(meta, hidden_layer_sizes, activation, optimizer):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, activation=activation))\n",
    "    model.add(keras.layers.Dense(n_classes_, activation=\"softmax\"))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Sklearn wrapper\n",
    "clf = KerasClassifier(\n",
    "    model = build_model,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:22:23,133] A new study created in memory with name: no-name-2a2b1a6b-ec20-42b0-885e-6028458092b0\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 3s 11ms/step - loss: 0.6966 - accuracy: 0.5404\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.7000 - accuracy: 0.5049Epoch 2/50\n",
      "46/46 [==============================] - 4s 10ms/step - loss: 0.7018 - accuracy: 0.5072\n",
      "46/46 [==============================] - 4s 12ms/step - loss: 0.6999 - accuracy: 0.5052\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6605 - accuracy: 0.6315\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6713 - accuracy: 0.5873\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5052Epoch 3/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5052\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6145 - accuracy: 0.6825\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6373 - accuracy: 0.6563\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.5764 - accuracy: 0.7232Epoch 4/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6927 - accuracy: 0.5059\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6508 - accuracy: 0.5312Epoch 4/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5793 - accuracy: 0.7177\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.6925 - accuracy: 0.5058Epoch 5/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6926 - accuracy: 0.5045\n",
      " 1/46 [..............................] - ETA: 3:41 - loss: 0.6661 - accuracy: 0.6562Epoch 5/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6114 - accuracy: 0.7074\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.6926 - accuracy: 0.5134Epoch 5/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5622 - accuracy: 0.7205\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.5849 - accuracy: 0.7231Epoch 6/50\n",
      "46/46 [==============================] - 5s 11ms/step - loss: 0.6777 - accuracy: 0.5942\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.5043 - accuracy: 0.8221Epoch 2/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.6926 - accuracy: 0.5169\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5735 - accuracy: 0.7384Epoch 6/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5735 - accuracy: 0.7384\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.4945 - accuracy: 0.8333Epoch 6/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5079 - accuracy: 0.7854\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.5360 - accuracy: 0.7567Epoch 7/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.6018 - accuracy: 0.6680\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.4883 - accuracy: 0.7837Epoch 3/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6926 - accuracy: 0.5100\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.5307 - accuracy: 0.7626\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.4864 - accuracy: 0.8348Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4654 - accuracy: 0.8150\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6924 - accuracy: 0.5397\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.4995 - accuracy: 0.7723Epoch 8/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4593 - accuracy: 0.8226\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5060 - accuracy: 0.7550\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4228 - accuracy: 0.7812Epoch 8/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5084 - accuracy: 0.7502\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4795 - accuracy: 0.7805\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6926 - accuracy: 0.5052\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3225 - accuracy: 0.8861\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6969 - accuracy: 0.4062Epoch 5/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4550 - accuracy: 0.7937\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.6922 - accuracy: 0.5151Epoch 10/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4991 - accuracy: 0.7536\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.2536 - accuracy: 0.9030Epoch 10/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2507 - accuracy: 0.9034\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6924 - accuracy: 0.5072\n",
      "Epoch 6/50\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4501 - accuracy: 0.7805\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.6925 - accuracy: 0.5455Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4260 - accuracy: 0.8378\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5410Epoch 11/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6925 - accuracy: 0.5424\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2190 - accuracy: 0.9172\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4340 - accuracy: 0.7937\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.1741 - accuracy: 0.9408Epoch 12/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4446 - accuracy: 0.7909\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6924 - accuracy: 0.5197\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1699 - accuracy: 0.9413\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.6925 - accuracy: 0.4961Epoch 8/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4055 - accuracy: 0.8192\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.2001 - accuracy: 0.9201Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4294 - accuracy: 0.8081\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.3967 - accuracy: 0.8188Epoch 13/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6925 - accuracy: 0.5052\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1747 - accuracy: 0.9337\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.6923 - accuracy: 0.5469Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3601 - accuracy: 0.8454\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6925 - accuracy: 0.5155\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2533 - accuracy: 0.9375Epoch 14/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.4339 - accuracy: 0.7992\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.2870 - accuracy: 0.9152Epoch 14/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1774 - accuracy: 0.9337\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.6924 - accuracy: 0.5296Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3986 - accuracy: 0.8150\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6923 - accuracy: 0.5335\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3958 - accuracy: 0.8254\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.2254 - accuracy: 0.9100Epoch 15/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2068 - accuracy: 0.9186\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.4370 - accuracy: 0.7837Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3287 - accuracy: 0.8661\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6925 - accuracy: 0.5176\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.1625 - accuracy: 0.9375Epoch 16/50\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4345 - accuracy: 0.7867\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1706 - accuracy: 0.9296\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4174 - accuracy: 0.8012\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1529 - accuracy: 0.9494Epoch 17/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.5100\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3065 - accuracy: 0.8868Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3065 - accuracy: 0.8868\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1422 - accuracy: 0.9517\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.3346 - accuracy: 0.8565\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3594 - accuracy: 0.8295\n",
      "Epoch 18/50\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6925 - accuracy: 0.5176\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1189 - accuracy: 0.9572\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3535 - accuracy: 0.8468\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2794 - accuracy: 0.8896\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6924 - accuracy: 0.5121\n",
      "Epoch 19/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3255 - accuracy: 0.8438Epoch 19/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1316 - accuracy: 0.9462\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.6921 - accuracy: 0.5125Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3520 - accuracy: 0.8316\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3301 - accuracy: 0.8585\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1814 - accuracy: 0.9688Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.5052\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1145 - accuracy: 0.9600\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2614 - accuracy: 0.9020\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3053 - accuracy: 0.8654\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.6923 - accuracy: 0.5221Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6923 - accuracy: 0.5252\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1127 - accuracy: 0.9628Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1098 - accuracy: 0.9648\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2673 - accuracy: 0.9006\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3567 - accuracy: 0.8565\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.2738 - accuracy: 0.8973Epoch 22/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6924 - accuracy: 0.5183\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1075 - accuracy: 0.9662\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.2994 - accuracy: 0.8867Epoch 18/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2635 - accuracy: 0.8979\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.1122 - accuracy: 0.9663Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2369 - accuracy: 0.9193\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1079 - accuracy: 0.9666Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6924 - accuracy: 0.5176\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.2485 - accuracy: 0.8973Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1033 - accuracy: 0.9669\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2991 - accuracy: 0.8847\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2946 - accuracy: 0.8668\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6922 - accuracy: 0.5197\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.1340 - accuracy: 0.9463Epoch 24/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1374 - accuracy: 0.9413\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2514 - accuracy: 0.9034\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3221 - accuracy: 0.8682\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.0876 - accuracy: 0.9688Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6925 - accuracy: 0.5066\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1702 - accuracy: 0.9420Epoch 25/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2972 - accuracy: 0.8820\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.2696 - accuracy: 0.8914Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1123 - accuracy: 0.9572\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.2874 - accuracy: 0.8846Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2671 - accuracy: 0.8882\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6923 - accuracy: 0.5224\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1618 - accuracy: 0.9375Epoch 26/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2924 - accuracy: 0.8778\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1203 - accuracy: 0.9572\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2508 - accuracy: 0.9006\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.1717 - accuracy: 0.9531Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.5204\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.1685 - accuracy: 0.9625Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1966 - accuracy: 0.9337\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1536 - accuracy: 0.9406\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.2512 - accuracy: 0.8966Epoch 23/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6923 - accuracy: 0.5404\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2489 - accuracy: 0.8979\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6934 - accuracy: 0.4375Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2758 - accuracy: 0.8820\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.2452 - accuracy: 0.8976Epoch 29/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1187 - accuracy: 0.9476\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1489 - accuracy: 0.9688Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.5107\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2200 - accuracy: 0.9165\n",
      "Epoch 29/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6910 - accuracy: 0.5938Epoch 29/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2570 - accuracy: 0.8958\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0993 - accuracy: 0.9648\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.2207 - accuracy: 0.9117Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.5349\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.1931 - accuracy: 0.9293Epoch 30/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2546 - accuracy: 0.8882\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2137 - accuracy: 0.9186\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0989 - accuracy: 0.9600\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.5183\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.1647 - accuracy: 0.9418Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2823 - accuracy: 0.8854\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1712 - accuracy: 0.9363Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1923 - accuracy: 0.9255\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.6920 - accuracy: 0.5516Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0852 - accuracy: 0.9703\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.6922 - accuracy: 0.5324Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.5266\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.2699 - accuracy: 0.8912Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1819 - accuracy: 0.9441\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2567 - accuracy: 0.8930\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0655 - accuracy: 0.9786\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6922 - accuracy: 0.5328\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.2482 - accuracy: 0.8906Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2333 - accuracy: 0.8999\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.2311 - accuracy: 0.9157Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2140 - accuracy: 0.9206\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9696\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1961 - accuracy: 0.9018Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6922 - accuracy: 0.5162\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.1347 - accuracy: 0.9516Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2704 - accuracy: 0.8847\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2409 - accuracy: 0.9068\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.6919 - accuracy: 0.5347Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1197 - accuracy: 0.9531\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.2450 - accuracy: 0.9002Epoch 30/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2029 - accuracy: 0.9199\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.6923 - accuracy: 0.5210\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.1235 - accuracy: 0.9484Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2112 - accuracy: 0.9172\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1799 - accuracy: 0.9362Epoch 36/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1017 - accuracy: 0.9586\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1749 - accuracy: 0.9286Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1849 - accuracy: 0.9303\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6922 - accuracy: 0.5273\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5937 - accuracy: 0.7188Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2271 - accuracy: 0.9068\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.0681 - accuracy: 0.9746Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0689 - accuracy: 0.9738\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.6923 - accuracy: 0.5214Epoch 32/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6922 - accuracy: 0.5190\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1485 - accuracy: 0.9467Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2574 - accuracy: 0.8992\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6933 - accuracy: 0.5000Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1540 - accuracy: 0.9455\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0655 - accuracy: 0.9752\n",
      "Epoch 38/50\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.6924 - accuracy: 0.5097Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1710 - accuracy: 0.9386\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.0684 - accuracy: 0.9743Epoch 38/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.5259\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2319 - accuracy: 0.9068\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.6926 - accuracy: 0.5116Epoch 39/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1467 - accuracy: 0.9413\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.6925 - accuracy: 0.5137Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1762 - accuracy: 0.9386\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6923 - accuracy: 0.5155\n",
      "Epoch 39/50\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1754 - accuracy: 0.9331\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.6919 - accuracy: 0.5139Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1032 - accuracy: 0.9600\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6921 - accuracy: 0.5190\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.2075 - accuracy: 0.9219Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1626 - accuracy: 0.9365\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1853 - accuracy: 0.9268\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.6918 - accuracy: 0.5271Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1098 - accuracy: 0.9510\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.1613 - accuracy: 0.9443Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1633 - accuracy: 0.9434\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.2283 - accuracy: 0.8914Epoch 41/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.5141\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.0613 - accuracy: 0.9844Epoch 41/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2091 - accuracy: 0.9068\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0898 - accuracy: 0.9696\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.6922 - accuracy: 0.5081Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2174 - accuracy: 0.9137\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.5128\n",
      "Epoch 42/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6930 - accuracy: 0.5000Epoch 42/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1558 - accuracy: 0.9413\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0944 - accuracy: 0.9607\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.1587 - accuracy: 0.9460Epoch 38/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2667 - accuracy: 0.8986\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6920 - accuracy: 0.5383\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1651 - accuracy: 0.9358\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.6918 - accuracy: 0.5063Epoch 44/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0777 - accuracy: 0.9696\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2262 - accuracy: 0.9020\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.0881 - accuracy: 0.9688Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.5086\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.0694 - accuracy: 0.9766Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1380 - accuracy: 0.9510\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.6912 - accuracy: 0.5404Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0580 - accuracy: 0.9800\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.5238\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1591 - accuracy: 0.9372\n",
      "Epoch 45/50\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1723 - accuracy: 0.9289\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.6919 - accuracy: 0.5391Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0746 - accuracy: 0.9731\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.1443 - accuracy: 0.9449Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1288 - accuracy: 0.9634\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.1437 - accuracy: 0.9482Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.5238\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1539 - accuracy: 0.9400\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.6925 - accuracy: 0.5134Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0635 - accuracy: 0.9786\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1666 - accuracy: 0.9372\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.6920 - accuracy: 0.5595Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6920 - accuracy: 0.5604\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.0394 - accuracy: 0.9875Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1983 - accuracy: 0.9255\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.1454 - accuracy: 0.9361Epoch 48/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0519 - accuracy: 0.9848\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1883 - accuracy: 0.9227\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6920 - accuracy: 0.5611\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.0413 - accuracy: 0.9818Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1391 - accuracy: 0.9496\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0936 - accuracy: 0.9593\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1308 - accuracy: 0.9575Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1348 - accuracy: 0.9476\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1193 - accuracy: 0.9375Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6919 - accuracy: 0.5121\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1362 - accuracy: 0.9545\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1315 - accuracy: 0.9593\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.0652 - accuracy: 0.9759Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9752\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6919 - accuracy: 0.5266\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1845 - accuracy: 0.9248Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1974 - accuracy: 0.9227\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2213 - accuracy: 0.9061\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0581 - accuracy: 0.9786\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6920 - accuracy: 0.5514\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0719 - accuracy: 0.9779\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 6ms/steposs: 0.0499 - accuracy: \n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.0490 - accuracy: 0.9878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:22:50,652] Trial 2 finished with value: 0.4820936639118457 and parameters: {'activation': 'sigmoid', 'hidden_layer_sizes': (100, 50, 10), 'optimizer': 'sgd'}. Best is trial 2 with value: 0.4820936639118457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "27/46 [================>.............] - ETA: 0s - loss: 0.0470 - accuracy: 0.9873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2023-07-08 15:22:50,667] Trial 3 finished with value: 0.90633608815427 and parameters: {'activation': 'tanh', 'hidden_layer_sizes': (100, 50, 10), 'optimizer': 'sgd'}. Best is trial 3 with value: 0.90633608815427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0510 - accuracy: 0.9841\n",
      "Epoch 48/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3399 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/46 [===========================>..] - ETA: 0s - loss: 0.0476 - accuracy: 0.9847Epoch 1/50\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0493 - accuracy: 0.9841\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0686 - accuracy: 0.9779\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0583 - accuracy: 0.9758\n",
      "12/12 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:22:52,399] Trial 0 finished with value: 0.9366391184573003 and parameters: {'activation': 'tanh', 'hidden_layer_sizes': (100, 50, 10), 'optimizer': 'adam'}. Best is trial 0 with value: 0.9366391184573003.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 3s 8ms/step - loss: 0.6883 - accuracy: 0.5238\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.6755 - accuracy: 0.5983\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.6654 - accuracy: 0.6190\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.6516 - accuracy: 0.6756\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.6329 - accuracy: 0.7095\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 4s 8ms/step - loss: 0.6661 - accuracy: 0.5956\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6165 - accuracy: 0.7274\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.5583 - accuracy: 0.7681\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.5956 - accuracy: 0.7598\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4726 - accuracy: 0.8438Epoch 8/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8854\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.5716 - accuracy: 0.7819\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.8758\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.5434 - accuracy: 0.7909\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.2481 - accuracy: 0.9176Epoch 10/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2472 - accuracy: 0.9082\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.8213\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.7412 - accuracy: 0.5074Epoch 11/50\n",
      "46/46 [==============================] - 4s 6ms/step - loss: 0.7136 - accuracy: 0.5010\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2641 - accuracy: 0.8854\n",
      "10/46 [=====>........................] - ETA: 0s - loss: 0.6748 - accuracy: 0.6156Epoch 7/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.8344\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.6628 - accuracy: 0.6121\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1746 - accuracy: 0.9400\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.8496\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.6186 - accuracy: 0.7361Epoch 13/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.5877 - accuracy: 0.7591\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.4348 - accuracy: 0.8245Epoch 4/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8454\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1623 - accuracy: 0.9448\n",
      "Epoch 14/50\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.8123\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1647 - accuracy: 0.9379\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8157\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3365 - accuracy: 0.8923\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8344\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1483 - accuracy: 0.9476\n",
      "Epoch 16/50\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2619 - accuracy: 0.8986\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8330\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1414 - accuracy: 0.9517\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2226 - accuracy: 0.9172\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.3710 - accuracy: 0.8319Epoch 8/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8378\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1510 - accuracy: 0.9455\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2200 - accuracy: 0.9151\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8254\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1267 - accuracy: 0.9545\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1883 - accuracy: 0.9303\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1013 - accuracy: 0.9688Epoch 10/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8192\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1513 - accuracy: 0.9393\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.2364 - accuracy: 0.9531Epoch 15/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1749 - accuracy: 0.9372\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2991 - accuracy: 0.8854\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1191 - accuracy: 0.9565\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.1797 - accuracy: 0.9299Epoch 16/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1639 - accuracy: 0.9386\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3229 - accuracy: 0.8516\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1245 - accuracy: 0.9565\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.2972 - accuracy: 0.8715Epoch 17/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1498 - accuracy: 0.9489\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.1196 - accuracy: 0.9514Epoch 13/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2687 - accuracy: 0.8910\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1083 - accuracy: 0.9600\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1738 - accuracy: 0.9351\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1118 - accuracy: 0.9441Epoch 14/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8620\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1019 - accuracy: 0.9586\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.2405 - accuracy: 0.8924Epoch 19/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1403 - accuracy: 0.9469\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1497 - accuracy: 0.9408Epoch 15/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3483 - accuracy: 0.8433\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.1513 - accuracy: 0.9368Epoch 25/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1540 - accuracy: 0.9351\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1497 - accuracy: 0.9427\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0971 - accuracy: 0.9600\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.1371 - accuracy: 0.9475Epoch 21/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3301 - accuracy: 0.8544\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1373 - accuracy: 0.9476\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0942 - accuracy: 0.9641\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3388 - accuracy: 0.8578\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.9565\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.2417 - accuracy: 0.8971Epoch 18/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1181 - accuracy: 0.9524\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2482 - accuracy: 0.8999\n",
      "Epoch 23/50\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.9558\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2761 - accuracy: 0.8930\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.1223 - accuracy: 0.9540Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0929 - accuracy: 0.9689\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1214 - accuracy: 0.9545\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2738 - accuracy: 0.8792\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1010 - accuracy: 0.9641\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1157 - accuracy: 0.9579\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2259 - accuracy: 0.9137\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0801 - accuracy: 0.9696\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1241 - accuracy: 0.9531\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2821 - accuracy: 0.8847\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0911 - accuracy: 0.9614\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1147 - accuracy: 0.9600\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2498 - accuracy: 0.9006\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1285 - accuracy: 0.9441\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.4498 - accuracy: 0.7882Epoch 28/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.9531\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.3279 - accuracy: 0.8574Epoch 24/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2285 - accuracy: 0.9096\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0901 - accuracy: 0.9648\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1191 - accuracy: 0.9565\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1830 - accuracy: 0.9379\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9745\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.9620\n",
      "Epoch 26/50\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1896 - accuracy: 0.9296\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1265 - accuracy: 0.9503\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1019 - accuracy: 0.9614\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.1986 - accuracy: 0.9236Epoch 27/50\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2429 - accuracy: 0.8999\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0990 - accuracy: 0.9676\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0768 - accuracy: 0.9717\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1724 - accuracy: 0.9372\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0976 - accuracy: 0.9627\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0963 - accuracy: 0.9607\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1998 - accuracy: 0.9241\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0986 - accuracy: 0.9620\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0678 - accuracy: 0.9772\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2941 - accuracy: 0.8758\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0977 - accuracy: 0.9614\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.2075 - accuracy: 0.9219Epoch 31/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0774 - accuracy: 0.9724\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0530 - accuracy: 0.9688Epoch 35/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1699 - accuracy: 0.9406\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0882 - accuracy: 0.9662\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9703Epoch 36/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.9703\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2378 - accuracy: 0.9027\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0713 - accuracy: 0.9717\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0955 - accuracy: 0.9662\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1895 - accuracy: 0.9241\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0742 - accuracy: 0.9724\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0875 - accuracy: 0.9662\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1410 - accuracy: 0.9558\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 0.9731\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0966 - accuracy: 0.9614\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1614 - accuracy: 0.9427\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0773 - accuracy: 0.9669\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0919 - accuracy: 0.9689\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0579 - accuracy: 0.9688Epoch 36/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2549 - accuracy: 0.8965\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.0949 - accuracy: 0.9660Epoch 46/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1418 - accuracy: 0.9413\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0961 - accuracy: 0.9669\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1696 - accuracy: 0.9344\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1160 - accuracy: 0.9558\n",
      "10/12 [========================>.....] - ETA: 0sEpoch 38/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0789 - accuracy: 0.9731\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0459 - accuracy: 0.9688Epoch 42/50\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.0589 - accuracy: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:23:08,653] Trial 1 finished with value: 0.9035812672176309 and parameters: {'activation': 'tanh', 'hidden_layer_sizes': (100, 50, 10), 'optimizer': 'sgd'}. Best is trial 0 with value: 0.9366391184573003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/46 [====================>.........] - ETA: 0s - loss: 0.0614 - accuracy: 0.9763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1421 - accuracy: 0.9510\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.0859 - accuracy: 0.9679Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0943 - accuracy: 0.9655\n",
      "10/46 [=====>........................] - ETA: 0s - loss: 0.1314 - accuracy: 0.9563Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0656 - accuracy: 0.9752\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0907 - accuracy: 0.9688Epoch 43/50\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.1544 - accuracy: 0.9403Epoch 1/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1453 - accuracy: 0.9489\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1381 - accuracy: 0.9462\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0593 - accuracy: 0.9800\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.2279 - accuracy: 0.8973Epoch 40/50\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2993 - accuracy: 0.8772\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0800 - accuracy: 0.9738\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2424 - accuracy: 0.9062Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0861 - accuracy: 0.9676\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1651 - accuracy: 0.9351\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0976 - accuracy: 0.9634\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0590 - accuracy: 0.9800\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1278 - accuracy: 0.9469\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0752 - accuracy: 0.9683\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.1140 - accuracy: 0.9336Epoch 47/50\n",
      "12/12 [==============================] - 0s 9ms/steposs: 0.0316 - accuracy: 1.00\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.0442 - accuracy: 0.9856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:23:11,033] Trial 4 finished with value: 0.8980716253443526 and parameters: {'activation': 'tanh', 'hidden_layer_sizes': (50, 50, 50), 'optimizer': 'sgd'}. Best is trial 0 with value: 0.9366391184573003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/46 [=================>............] - ETA: 0s - loss: 0.0530 - accuracy: 0.9833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.9641\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.0604 - accuracy: 0.9808Epoch 44/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0653 - accuracy: 0.9772\n",
      "Epoch 48/50\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1018 - accuracy: 0.9514Epoch 1/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1097 - accuracy: 0.9524\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0893 - accuracy: 0.9620\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0839 - accuracy: 0.9710\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0795 - accuracy: 0.9696\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1262 - accuracy: 0.9524\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9855\n",
      "46/46 [==============================] - 4s 10ms/step - loss: 0.6943 - accuracy: 0.5273\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0745 - accuracy: 0.9758\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6814 - accuracy: 0.5990\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/steposs: 0.0732 - accuracy: 0.97\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.6737 - accuracy: 0.6062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:23:13,606] Trial 5 finished with value: 0.9641873278236914 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'optimizer': 'adam'}. Best is trial 5 with value: 0.9641873278236914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0745 - accuracy: 0.9717\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.6737 - accuracy: 0.6104Epoch 49/50\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.0384 - accuracy: 0.9955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6722 - accuracy: 0.6011\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.0431 - accuracy: 0.9917Epoch 4/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0694 - accuracy: 0.9758\n",
      "Epoch 50/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000Epoch 1/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.6636 - accuracy: 0.6549\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0746 - accuracy: 0.9745\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6552 - accuracy: 0.6536\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/steposs: 0.6426 - accuracy: 0.68\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6415 - accuracy: 0.6936\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:23:15,439] Trial 6 finished with value: 0.9614325068870524 and parameters: {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 5 with value: 0.9641873278236914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/46 [=====>........................] - ETA: 0s - loss: 0.6376 - accuracy: 0.6344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 12ms/step - loss: 0.6322 - accuracy: 0.6957\n",
      "Epoch 8/50\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.6222 - accuracy: 0.7054Epoch 1/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6131 - accuracy: 0.7350\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 5s 8ms/step - loss: 0.7619 - accuracy: 0.5052\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5950 - accuracy: 0.7516\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.6946 - accuracy: 0.5091Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6947 - accuracy: 0.5052\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.5780 - accuracy: 0.7891Epoch 3/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5701 - accuracy: 0.7798\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5052\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5100\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.5428 - accuracy: 0.7930\n",
      "Epoch 5/50\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.5129 - accuracy: 0.8213\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.6931 - accuracy: 0.5093\n",
      "Epoch 13/50\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6935 - accuracy: 0.4934\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.4756 - accuracy: 0.8261\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5052\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.8440\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5238\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4487 - accuracy: 0.8081\n",
      "Epoch 9/50\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 4s 9ms/step - loss: 0.8193 - accuracy: 0.5052\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 6s 10ms/step - loss: 0.7132 - accuracy: 0.5638\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6863 - accuracy: 0.5597\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4247 - accuracy: 0.8178\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7147 - accuracy: 0.5052\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.5883 - accuracy: 0.6925Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5302 - accuracy: 0.7447\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6807 - accuracy: 0.6197\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4173 - accuracy: 0.8006\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.7016 - accuracy: 0.4792Epoch 18/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6967 - accuracy: 0.5052\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4200 - accuracy: 0.7916\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6749 - accuracy: 0.6101\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3751 - accuracy: 0.8475\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.6929 - accuracy: 0.5188Epoch 19/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6939 - accuracy: 0.5052\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2493 - accuracy: 0.9006\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6634 - accuracy: 0.6411\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.6941 - accuracy: 0.4884Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4402 - accuracy: 0.7895\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.2441 - accuracy: 0.9010Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6937 - accuracy: 0.5045\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.4376 - accuracy: 0.7984Epoch 6/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1920 - accuracy: 0.9220\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6514 - accuracy: 0.7157\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.6931 - accuracy: 0.5136Epoch 14/50\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3697 - accuracy: 0.8440\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1494 - accuracy: 0.9375Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6935 - accuracy: 0.5052\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.3212 - accuracy: 0.8691Epoch 7/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6361 - accuracy: 0.7467\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.3622 - accuracy: 0.8445Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3566 - accuracy: 0.8468\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.6932 - accuracy: 0.5156Epoch 22/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1906 - accuracy: 0.9179\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6180 - accuracy: 0.7736\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3969 - accuracy: 0.8288\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1505 - accuracy: 0.9427\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.4948\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5899 - accuracy: 0.8385\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.6931 - accuracy: 0.5122Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1285 - accuracy: 0.9531\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.6933 - accuracy: 0.5082Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3118 - accuracy: 0.8765\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1370 - accuracy: 0.9062Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6934 - accuracy: 0.5031\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.5735 - accuracy: 0.8500Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5639 - accuracy: 0.8565\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1484 - accuracy: 0.9433Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1489 - accuracy: 0.9441\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3050 - accuracy: 0.8723\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.4886\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5359 - accuracy: 0.8185\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.6928 - accuracy: 0.5221Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1415 - accuracy: 0.9469\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3187 - accuracy: 0.8627\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6933 - accuracy: 0.5010\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.2594 - accuracy: 0.8951Epoch 12/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4963 - accuracy: 0.8854\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.6935 - accuracy: 0.5016Epoch 20/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1093 - accuracy: 0.9634\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2780 - accuracy: 0.8847\n",
      "Epoch 12/50\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6935 - accuracy: 0.5024\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.3310 - accuracy: 0.8582Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4562 - accuracy: 0.9075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/46 [===========>..................] - ETA: 0s - loss: 0.6934 - accuracy: 0.5082Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1402 - accuracy: 0.9448\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2860 - accuracy: 0.8778\n",
      "Epoch 13/50\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.6934 - accuracy: 0.5072Epoch 28/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.5052\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.2844 - accuracy: 0.8906Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4169 - accuracy: 0.9213\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.6938 - accuracy: 0.4801Epoch 22/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2466 - accuracy: 0.9089\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.5059\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1276 - accuracy: 0.9517\n",
      "Epoch 29/50\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.3826 - accuracy: 0.9130\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.4997\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3718 - accuracy: 0.8351\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6903 - accuracy: 0.5625Epoch 30/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0973 - accuracy: 0.9593\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1992 - accuracy: 0.9688Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3470 - accuracy: 0.9227\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.6928 - accuracy: 0.5156Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5052\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.2787 - accuracy: 0.8826Epoch 17/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1875 - accuracy: 0.9206\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.3161 - accuracy: 0.9339Epoch 16/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2670 - accuracy: 0.8889\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3206 - accuracy: 0.9268\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.6938 - accuracy: 0.4762Epoch 25/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6935 - accuracy: 0.4886\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2500 - accuracy: 0.9117\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 0.9510\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6472 - accuracy: 0.6875Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2952 - accuracy: 0.9255\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.5052\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0877 - accuracy: 0.9703\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2454 - accuracy: 0.9041\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2704 - accuracy: 0.9303\n",
      "Epoch 33/50\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6934 - accuracy: 0.4997\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2559 - accuracy: 0.9324\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1205 - accuracy: 0.9551\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2434 - accuracy: 0.8958\n",
      "Epoch 19/50\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5100\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2374 - accuracy: 0.9379\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2078 - accuracy: 0.9193\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1769 - accuracy: 1.0000Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1098 - accuracy: 0.9545\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.1969 - accuracy: 0.9766Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6934 - accuracy: 0.5045\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1193 - accuracy: 0.9507Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2235 - accuracy: 0.9427\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.6935 - accuracy: 0.4943Epoch 30/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3392 - accuracy: 0.8682\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1051 - accuracy: 0.9571Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1017 - accuracy: 0.9593\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6933 - accuracy: 0.5052\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.0594 - accuracy: 0.9792Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2177 - accuracy: 0.9427\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.8923\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1147 - accuracy: 0.9551\n",
      "Epoch 37/50\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.1995 - accuracy: 0.9489Epoch 22/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.4914\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.2116 - accuracy: 0.9330Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2040 - accuracy: 0.9434\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2244 - accuracy: 0.9130\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.2021 - accuracy: 0.9464Epoch 38/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1068 - accuracy: 0.9531\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5052\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1969 - accuracy: 0.9386\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2535 - accuracy: 0.9006\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.2123 - accuracy: 0.9375Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1221 - accuracy: 0.9510\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 24/50\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1884 - accuracy: 0.9489\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2271 - accuracy: 0.9068\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6933 - accuracy: 0.5052\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.2129 - accuracy: 0.9091Epoch 27/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2114 - accuracy: 0.9096\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6880 - accuracy: 0.5938Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1890 - accuracy: 0.9434\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1613 - accuracy: 0.9413\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1821 - accuracy: 0.9413Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.5052\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1015 - accuracy: 0.9688Epoch 28/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0831 - accuracy: 0.9655\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.1769 - accuracy: 0.9446Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1739 - accuracy: 0.9476\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.1616 - accuracy: 0.9416Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6935 - accuracy: 0.4983\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9351Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1781 - accuracy: 0.9351\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0710 - accuracy: 0.9745\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.6933 - accuracy: 0.4663Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1707 - accuracy: 0.9551\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6935 - accuracy: 0.4803\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.1764 - accuracy: 0.9361Epoch 30/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1781 - accuracy: 0.9358\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.1115 - accuracy: 0.9540Epoch 43/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1049 - accuracy: 0.9579\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.1940 - accuracy: 0.9203Epoch 28/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1633 - accuracy: 0.9551\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0878 - accuracy: 0.9375Epoch 38/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5038\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.0984 - accuracy: 0.9635Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1626 - accuracy: 0.9413\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1015 - accuracy: 0.9635Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0937 - accuracy: 0.9676\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1654 - accuracy: 0.9558\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.6935 - accuracy: 0.4955Epoch 39/50\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1992 - accuracy: 0.9186\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1177 - accuracy: 0.9524\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1558 - accuracy: 0.9551\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.6935 - accuracy: 0.4818Epoch 40/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.4914\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.0858 - accuracy: 0.9589Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2203 - accuracy: 0.9193\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.6929 - accuracy: 0.5148Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0752 - accuracy: 0.9696\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1535 - accuracy: 0.9545\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.6934 - accuracy: 0.5017Epoch 41/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6933 - accuracy: 0.5052\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1466 - accuracy: 0.9469\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.0616 - accuracy: 0.9774Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0676 - accuracy: 0.9745\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1486 - accuracy: 0.9545\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5059\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1484 - accuracy: 0.9469Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1448 - accuracy: 0.9455\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.6932 - accuracy: 0.5167Epoch 48/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1466 - accuracy: 0.9572\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0792 - accuracy: 0.9696\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.6934 - accuracy: 0.5052\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1761 - accuracy: 0.9274Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1741 - accuracy: 0.9289\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1418 - accuracy: 0.9593\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.6930 - accuracy: 0.5177Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0818 - accuracy: 0.9683\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.3141 - accuracy: 0.8715Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6933 - accuracy: 0.5072\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2162 - accuracy: 0.9117\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1448 - accuracy: 0.9551\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9689Epoch 45/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0769 - accuracy: 0.9689\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.5059\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.1274 - accuracy: 0.9545Epoch 38/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1410 - accuracy: 0.9455\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1393 - accuracy: 0.9607\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.6931 - accuracy: 0.5020Epoch 46/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0634 - accuracy: 0.9772\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5052\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.0953 - accuracy: 0.9583Epoch 39/50\n",
      "12/12 [==============================] - 0s 9ms/steposs: 0.1346 - accuracy: 0.95\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1372 - accuracy: 0.9579\n",
      "Epoch 47/50\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.0605 - accuracy: 0.9759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:23:36,906] Trial 7 finished with value: 0.9504132231404959 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (100, 100, 100), 'optimizer': 'sgd'}. Best is trial 5 with value: 0.9641873278236914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0610 - accuracy: 0.9752\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1531 - accuracy: 0.9464Epoch 37/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.6933 - accuracy: 0.5045\n",
      "Epoch 40/50\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.0985 - accuracy: 0.9609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1340 - accuracy: 0.9593\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0778 - accuracy: 0.9696\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.5079\n",
      "Epoch 41/50\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.1507 - accuracy: 0.9543Epoch 38/50\n",
      " 1/46 [..............................] - ETA: 1s - loss: 0.6928 - accuracy: 0.5938Epoch 1/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1383 - accuracy: 0.9579\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6933 - accuracy: 0.5045\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1331 - accuracy: 0.9448\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6930 - accuracy: 0.5312Epoch 39/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1376 - accuracy: 0.9600\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.6932 - accuracy: 0.5194Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5176\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.1265 - accuracy: 0.9663Epoch 43/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0709 - accuracy: 0.9703\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.6947 - accuracy: 0.4241Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1302 - accuracy: 0.9586\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.4907\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.0989 - accuracy: 0.9614Epoch 44/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0924 - accuracy: 0.9627\n",
      "10/46 [=====>........................] - ETA: 0s - loss: 0.6934 - accuracy: 0.5125Epoch 41/50\n",
      "12/12 [==============================] - 0s 8ms/steposs: 0.0542 - accuracy: 0.\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.5052\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.0597 - accuracy: 0.9744Epoch 45/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0617 - accuracy: 0.9758\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.6931 - accuracy: 0.5035Epoch 42/50\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.0464 - accuracy: 0.9766"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:23:39,673] Trial 8 finished with value: 0.9449035812672176 and parameters: {'activation': 'sigmoid', 'hidden_layer_sizes': (10, 10), 'optimizer': 'adam'}. Best is trial 5 with value: 0.9641873278236914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0767 - accuracy: 0.9689\n",
      "Epoch 43/50\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.6931 - accuracy: 0.4972Epoch 1/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.4962\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1198 - accuracy: 0.9490Epoch 47/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1043 - accuracy: 0.9565\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.5128\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.0693 - accuracy: 0.9698Epoch 48/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0786 - accuracy: 0.9662\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.6936 - accuracy: 0.5018Epoch 45/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.5052\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1347 - accuracy: 0.9455\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.6932 - accuracy: 0.5048Epoch 46/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.6931 - accuracy: 0.5114\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1034 - accuracy: 0.9551\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.4934\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0632 - accuracy: 0.9738\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0578 - accuracy: 0.9758\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 8ms/steposs: 0.0615 - accuracy: 0.9688\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.0449 - accuracy: 0.9824"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:23:43,146] Trial 10 finished with value: 0.4820936639118457 and parameters: {'activation': 'sigmoid', 'hidden_layer_sizes': (100, 50, 10), 'optimizer': 'sgd'}. Best is trial 5 with value: 0.9641873278236914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 3s 7ms/step - loss: 0.7220 - accuracy: 0.4948\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0752 - accuracy: 0.9724\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.7158 - accuracy: 0.4323Epoch 50/50\n",
      "46/46 [==============================] - 6s 8ms/step - loss: 0.6931 - accuracy: 0.5169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/46 [======>.......................] - ETA: 0s - loss: 0.7069 - accuracy: 0.4635Epoch 2/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6976 - accuracy: 0.4948\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.0769 - accuracy: 0.9727Epoch 3/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0742 - accuracy: 0.9738\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6547 - accuracy: 0.6253\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.6938 - accuracy: 0.4943Epoch 3/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6930 - accuracy: 0.4990\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.5813 - accuracy: 0.7578Epoch 4/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5699 - accuracy: 0.7619\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.6924 - accuracy: 0.5072Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/steposs: 0.4684 - accuracy: 0.84\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.4881 - accuracy: 0.8385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:23:44,467] Trial 9 finished with value: 0.9614325068870524 and parameters: {'activation': 'tanh', 'hidden_layer_sizes': (100, 100, 100), 'optimizer': 'adam'}. Best is trial 5 with value: 0.9641873278236914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/46 [=================>............] - ETA: 0s - loss: 0.4510 - accuracy: 0.8578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6924 - accuracy: 0.5114\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4364 - accuracy: 0.8468\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.5238Epoch 1/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6924 - accuracy: 0.5238\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3212 - accuracy: 0.8854\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6923 - accuracy: 0.5321\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2878 - accuracy: 0.8847\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6924 - accuracy: 0.5328\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2274 - accuracy: 0.9137\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.6915 - accuracy: 0.5227Epoch 8/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5052\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1972 - accuracy: 0.9289Epoch 9/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1921 - accuracy: 0.9289\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.6921 - accuracy: 0.5082Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.5238\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2187 - accuracy: 0.9144\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.6920 - accuracy: 0.5420Epoch 10/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5349\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2025 - accuracy: 0.9165\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.6922 - accuracy: 0.5236Epoch 11/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6923 - accuracy: 0.5224\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1781 - accuracy: 0.9337\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.6920 - accuracy: 0.5580Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6921 - accuracy: 0.5514\n",
      " 4/46 [=>............................] - ETA: 0s - loss: 0.2282 - accuracy: 0.9141Epoch 13/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1610 - accuracy: 0.9379\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.5335\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6919 - accuracy: 0.5162\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1668 - accuracy: 0.9393\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6922 - accuracy: 0.5000Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6919 - accuracy: 0.5804\n",
      " 1/46 [..............................] - ETA: 4:21 - loss: 0.6897 - accuracy: 0.5625Epoch 16/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1726 - accuracy: 0.9337\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6919 - accuracy: 0.5500\n",
      "46/46 [==============================] - 6s 10ms/step - loss: 0.6707 - accuracy: 0.5839\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1650 - accuracy: 0.9386\n",
      "Epoch 17/50\n",
      "Epoch 16/50\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1482 - accuracy: 0.9469\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.6920 - accuracy: 0.5229Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5633 - accuracy: 0.7536\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6920 - accuracy: 0.5217\n",
      "Epoch 3/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4417 - accuracy: 0.9375Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1543 - accuracy: 0.9462\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4431 - accuracy: 0.8068\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6918 - accuracy: 0.5300\n",
      "Epoch 4/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0349 - accuracy: 1.0000Epoch 19/50\n",
      "46/46 [==============================] - 6s 10ms/step - loss: 0.6929 - accuracy: 0.5162\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6916 - accuracy: 0.5493\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.1300 - accuracy: 0.9510Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3297 - accuracy: 0.8778\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1334 - accuracy: 0.9489\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.6718 - accuracy: 0.6078Epoch 5/50\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6678 - accuracy: 0.6349\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.6909 - accuracy: 0.5186Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6916 - accuracy: 0.5052\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1443 - accuracy: 0.9438Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1443 - accuracy: 0.9434\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2428 - accuracy: 0.9137\n",
      "Epoch 20/50\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6322 - accuracy: 0.7578\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6919 - accuracy: 0.5452\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1222 - accuracy: 0.9489\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2146 - accuracy: 0.9262\n",
      " 1/46 [..............................] - ETA: 1s - loss: 0.2677 - accuracy: 0.8438Epoch 7/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5790 - accuracy: 0.7792\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6916 - accuracy: 0.5397\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1262 - accuracy: 0.9579\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2276 - accuracy: 0.9006\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.5012 - accuracy: 0.8654Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4817 - accuracy: 0.8682\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6915 - accuracy: 0.5107\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1746 - accuracy: 0.9344\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1336 - accuracy: 0.9489\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3814 - accuracy: 0.8827\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1294 - accuracy: 0.9509Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6915 - accuracy: 0.5280\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.1199 - accuracy: 0.9589Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1750 - accuracy: 0.9234\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1239 - accuracy: 0.9564Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1208 - accuracy: 0.9572\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2963 - accuracy: 0.9186\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1172 - accuracy: 0.9557Epoch 8/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6916 - accuracy: 0.5597\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1641 - accuracy: 0.9379\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1141 - accuracy: 0.9593\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2772 - accuracy: 0.8979\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.6915 - accuracy: 0.5855Epoch 9/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6914 - accuracy: 0.5749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/46 [=========================>....] - ETA: 0s - loss: 0.1470 - accuracy: 0.9508Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1510 - accuracy: 0.9489\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.6913 - accuracy: 0.6473Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2266 - accuracy: 0.9220\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1053 - accuracy: 0.9572\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3286 - accuracy: 0.8438Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6915 - accuracy: 0.5714\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.2061 - accuracy: 0.9319Epoch 28/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2062 - accuracy: 0.9310\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1337 - accuracy: 0.9538\n",
      "Epoch 11/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1496 - accuracy: 0.9688Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1018 - accuracy: 0.9627\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6913 - accuracy: 0.5638\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.1055 - accuracy: 0.9567Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1287 - accuracy: 0.9572\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1865 - accuracy: 0.9406\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1096 - accuracy: 0.9558\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.6913 - accuracy: 0.5378Epoch 28/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6911 - accuracy: 0.5466\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.1389 - accuracy: 0.9513Epoch 30/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1958 - accuracy: 0.9248\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6898 - accuracy: 0.5625Epoch 13/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1275 - accuracy: 0.9579\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1056 - accuracy: 0.9614\n",
      "Epoch 15/50\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6912 - accuracy: 0.5079\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1750 - accuracy: 0.9420\n",
      "Epoch 31/50\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1038 - accuracy: 0.9627\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1264 - accuracy: 0.9489\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1622 - accuracy: 0.9517\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6913 - accuracy: 0.5459\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1217 - accuracy: 0.9552Epoch 32/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1333 - accuracy: 0.9510\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1244 - accuracy: 0.9496\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1483 - accuracy: 0.9462\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.6911 - accuracy: 0.5385Epoch 16/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1029 - accuracy: 0.9620\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1106 - accuracy: 0.9634\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1659 - accuracy: 0.9246Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1619 - accuracy: 0.9344\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1003 - accuracy: 0.9703Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6910 - accuracy: 0.5542\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0974 - accuracy: 0.9717\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0964 - accuracy: 0.9676\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.6909 - accuracy: 0.5172Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1517 - accuracy: 0.9503\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.6911 - accuracy: 0.5307\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0884 - accuracy: 0.9703\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1073 - accuracy: 0.9611Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1082 - accuracy: 0.9627\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.0828 - accuracy: 0.9732Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1482 - accuracy: 0.9489\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6910 - accuracy: 0.5155\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.1177 - accuracy: 0.9556Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0887 - accuracy: 0.9689\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1105 - accuracy: 0.9551\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1378 - accuracy: 0.9503\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6910 - accuracy: 0.5266\n",
      "Epoch 20/50\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1109 - accuracy: 0.9558\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1596 - accuracy: 0.9358\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.5894\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1264 - accuracy: 0.9593\n",
      "Epoch 38/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6936 - accuracy: 0.4375Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0948 - accuracy: 0.9689\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1208 - accuracy: 0.9517\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.6912 - accuracy: 0.5690Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6908 - accuracy: 0.5811\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1284 - accuracy: 0.9586\n",
      "Epoch 22/50\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0803 - accuracy: 0.9710\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0910 - accuracy: 0.9689\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.5052\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.0850 - accuracy: 0.9688Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1303 - accuracy: 0.9545\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6916 - accuracy: 0.5312Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0812 - accuracy: 0.9696\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.6905 - accuracy: 0.5461Epoch 39/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0809 - accuracy: 0.9717\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.6906 - accuracy: 0.5379Epoch 25/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.5507\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1306 - accuracy: 0.9572\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0905 - accuracy: 0.9662\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.0794 - accuracy: 0.9711Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9717\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.6907 - accuracy: 0.5393Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6906 - accuracy: 0.5707\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.0653 - accuracy: 0.9712Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1167 - accuracy: 0.9558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1061 - accuracy: 0.9579\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.0957 - accuracy: 0.9628Epoch 41/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0939 - accuracy: 0.9648\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.1192 - accuracy: 0.9605Epoch 27/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1234 - accuracy: 0.9607\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.5680\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.0724 - accuracy: 0.9766Epoch 43/50\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.1049 - accuracy: 0.9594Epoch 26/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0862 - accuracy: 0.9669\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.6907 - accuracy: 0.5813Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0980 - accuracy: 0.9627\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1178 - accuracy: 0.9578Epoch 28/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1144 - accuracy: 0.9600\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6906 - accuracy: 0.5521\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.0896 - accuracy: 0.9700Epoch 44/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0888 - accuracy: 0.9703\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1160 - accuracy: 0.9591Epoch 43/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1272 - accuracy: 0.9572\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 0.9793\n",
      "Epoch 28/50\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6903 - accuracy: 0.5252\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0948 - accuracy: 0.9627\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.1767 - accuracy: 0.9284Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1669 - accuracy: 0.9331\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.6480\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0698 - accuracy: 0.9786\n",
      "Epoch 46/50\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1211 - accuracy: 0.9538\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.6897 - accuracy: 0.5208Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1256 - accuracy: 0.9600\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.5121\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0642 - accuracy: 0.9765\n",
      "Epoch 47/50\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.0923 - accuracy: 0.9648Epoch 31/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0951 - accuracy: 0.9648\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.1187 - accuracy: 0.9586Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1120 - accuracy: 0.9600\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.6018Epoch 31/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.6018\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.0710 - accuracy: 0.9724Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0800 - accuracy: 0.9689\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.0617 - accuracy: 0.9783Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0712 - accuracy: 0.9738\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.0995 - accuracy: 0.9637Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1023 - accuracy: 0.9634\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.0626 - accuracy: 0.9789Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6901 - accuracy: 0.5335\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.0900 - accuracy: 0.9750Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0594 - accuracy: 0.9793\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0721 - accuracy: 0.9758\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.6901 - accuracy: 0.5829Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1034 - accuracy: 0.9641\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.6900 - accuracy: 0.5938Epoch 33/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6900 - accuracy: 0.5921\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.1048 - accuracy: 0.9531Epoch 50/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0739 - accuracy: 0.9689\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0804 - accuracy: 0.9717\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1113 - accuracy: 0.9593\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6901 - accuracy: 0.5873\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0915 - accuracy: 0.9648\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0837 - accuracy: 0.9655\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1078 - accuracy: 0.9627\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1013 - accuracy: 0.9625Epoch 35/50\n",
      "12/12 [==============================] - 0s 7ms/steposs: 0.0858 - accuracy: 0.96\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0719 - accuracy: 0.9710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:24:06,074] Trial 12 finished with value: 0.628099173553719 and parameters: {'activation': 'sigmoid', 'hidden_layer_sizes': (10, 10), 'optimizer': 'sgd'}. Best is trial 5 with value: 0.9641873278236914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/46 [==========>...................] - ETA: 0s - loss: 0.0778 - accuracy: 0.9705Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0875 - accuracy: 0.9689\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.0506 - accuracy: 0.9863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1066 - accuracy: 0.9614\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.0478 - accuracy: 0.9867Epoch 36/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0552 - accuracy: 0.9848\n",
      "Epoch 37/50\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.0833 - accuracy: 0.9609Epoch 1/50\n",
      "12/12 [==============================] - 0s 7ms/steposs: 0.0629 - accuracy: 0.97\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.0625 - accuracy: 0.9766"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:24:06,875] Trial 11 finished with value: 0.9421487603305785 and parameters: {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 5 with value: 0.9641873278236914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1117 - accuracy: 0.9607\n",
      "Epoch 37/50\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.0877 - accuracy: 0.9661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0601 - accuracy: 0.9779\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1020 - accuracy: 0.9627\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.0535 - accuracy: 0.9812Epoch 38/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1270 - accuracy: 0.9375Epoch 1/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0653 - accuracy: 0.9786\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1067 - accuracy: 0.9634\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.0718 - accuracy: 0.9715Epoch 39/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0748 - accuracy: 0.9676\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.1022 - accuracy: 0.9727Epoch 40/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0966 - accuracy: 0.9669\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.0841 - accuracy: 0.9677Epoch 40/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0763 - accuracy: 0.9703\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0932 - accuracy: 0.9731\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0955 - accuracy: 0.9593\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1045 - accuracy: 0.9648\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0665 - accuracy: 0.9731\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1167 - accuracy: 0.9538\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0627 - accuracy: 0.9738\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0935 - accuracy: 0.9703\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0762 - accuracy: 0.9669\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0951 - accuracy: 0.9696\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9876\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.0799 - accuracy: 0.9731Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0972 - accuracy: 0.9641\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0612 - accuracy: 0.9772\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0893 - accuracy: 0.9696\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0534 - accuracy: 0.9827\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0857 - accuracy: 0.9710\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0739 - accuracy: 0.9738\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.0895 - accuracy: 0.9701Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0854 - accuracy: 0.9703\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1163 - accuracy: 0.9537Epoch 49/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1141 - accuracy: 0.9517\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.0897 - accuracy: 0.9705Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0896 - accuracy: 0.9703\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.0537 - accuracy: 0.9803Epoch 50/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0890 - accuracy: 0.9607\n",
      "46/46 [==============================] - 6s 9ms/step - loss: 0.6801 - accuracy: 0.5776\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9703\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6371 - accuracy: 0.7039\n",
      "11/12 [==========================>...] - ETA: 0sEpoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/steposs: 0.6218 - accuracy: 0.81\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.6148 - accuracy: 0.7865"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:24:13,948] Trial 13 finished with value: 0.9669421487603306 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'optimizer': 'adam'}. Best is trial 13 with value: 0.9669421487603306.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 8ms/step loss: 0.7113 - accuracy: 0.\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.5897 - accuracy: 0.8087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.6855 - accuracy: 0.5547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:24:14,184] Trial 14 finished with value: 0.9504132231404959 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 13 with value: 0.9669421487603306.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/46 [=======================>......] - ETA: 0s - loss: 0.6797 - accuracy: 0.5667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 12ms/step - loss: 0.5798 - accuracy: 0.7937\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 8s 10ms/step - loss: 0.6751 - accuracy: 0.5797\n",
      "Epoch 2/50\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.6536 - accuracy: 0.5804Epoch 1/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5039 - accuracy: 0.8489\n",
      "Epoch 1/50\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.6342 - accuracy: 0.6943\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.4449 - accuracy: 0.8630Epoch 3/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.4249 - accuracy: 0.8640\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.5887 - accuracy: 0.7524Epoch 6/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.5648 - accuracy: 0.7867\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.3592 - accuracy: 0.8730\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.4614 - accuracy: 0.8288\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.3344 - accuracy: 0.8906Epoch 5/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.2981 - accuracy: 0.9124\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.3464 - accuracy: 0.8896\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2552 - accuracy: 0.9234\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2745 - accuracy: 0.9020\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2334 - accuracy: 0.9234\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2306 - accuracy: 0.9193\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.2010 - accuracy: 0.9427Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2150 - accuracy: 0.9310\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.2161 - accuracy: 0.9237Epoch 11/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2058 - accuracy: 0.9289\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1962 - accuracy: 0.9379\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1968 - accuracy: 0.9220\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1762 - accuracy: 0.9482\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1911 - accuracy: 0.9262\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1834 - accuracy: 0.9324\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1673 - accuracy: 0.9427\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1591 - accuracy: 0.9524\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1616 - accuracy: 0.9386\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1489 - accuracy: 0.9558\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1540 - accuracy: 0.9469\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1787 - accuracy: 0.9397Epoch 14/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1751 - accuracy: 0.9331\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.1359 - accuracy: 0.9583Epoch 17/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1432 - accuracy: 0.9503\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 6s 9ms/step - loss: 0.6760 - accuracy: 0.5804\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.6845 - accuracy: 0.5764Epoch 2/50\n",
      "46/46 [==============================] - 6s 9ms/step - loss: 0.6732 - accuracy: 0.5942\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.1408 - accuracy: 0.9554Epoch 2/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1706 - accuracy: 0.9427\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6097 - accuracy: 0.8438Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1341 - accuracy: 0.9586\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6253 - accuracy: 0.6839\n",
      "Epoch 3/50\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1461 - accuracy: 0.9517\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.5708 - accuracy: 0.7536\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4796 - accuracy: 0.8040\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.9344\n",
      "Epoch 17/50\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4291 - accuracy: 0.8309\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1550 - accuracy: 0.9476\n",
      "Epoch 20/50\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3370 - accuracy: 0.8716\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1351 - accuracy: 0.9524\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2763 - accuracy: 0.9082\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1500 - accuracy: 0.9448\n",
      "Epoch 5/50\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2416 - accuracy: 0.9110\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1222 - accuracy: 0.9551\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.2013 - accuracy: 0.9326Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1374 - accuracy: 0.9510\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2380 - accuracy: 0.9089\n",
      "Epoch 22/50\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1999 - accuracy: 0.9289\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1407 - accuracy: 0.9577Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1190 - accuracy: 0.9593\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1340 - accuracy: 0.9688Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1989 - accuracy: 0.9282\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1350 - accuracy: 0.9565\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1189 - accuracy: 0.9588Epoch 7/50\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1984 - accuracy: 0.9175Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1156 - accuracy: 0.9593\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1904 - accuracy: 0.9282\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.1657 - accuracy: 0.9330Epoch 21/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1875 - accuracy: 0.9062Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1838 - accuracy: 0.9275\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1366 - accuracy: 0.9559Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1668 - accuracy: 0.9337\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3036 - accuracy: 0.8438Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1112 - accuracy: 0.9641\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1722 - accuracy: 0.9331Epoch 22/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1708 - accuracy: 0.9331\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.2322 - accuracy: 0.9041Epoch 9/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1230 - accuracy: 0.9586\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1275 - accuracy: 0.9485Epoch 25/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2051 - accuracy: 0.9193\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1298 - accuracy: 0.9605Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1223 - accuracy: 0.9496\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1596 - accuracy: 0.9455\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1568 - accuracy: 0.9388Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1272 - accuracy: 0.9565\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1495 - accuracy: 0.9433Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1487 - accuracy: 0.9441\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1350 - accuracy: 0.9503\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.1312 - accuracy: 0.9557Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2286 - accuracy: 0.9096\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0442 - accuracy: 0.9688Epoch 11/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1163 - accuracy: 0.9662\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1130 - accuracy: 0.9609Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1524 - accuracy: 0.9406\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1222 - accuracy: 0.9607\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1473 - accuracy: 0.9482\n",
      "Epoch 12/50\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1165 - accuracy: 0.9586\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1251 - accuracy: 0.9554Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1464 - accuracy: 0.9462\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.1434 - accuracy: 0.9503Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1142 - accuracy: 0.9614\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1246 - accuracy: 0.9558\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1322 - accuracy: 0.9462\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1091 - accuracy: 0.9732Epoch 29/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1496 - accuracy: 0.9372\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1017 - accuracy: 0.9601Epoch 13/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1004 - accuracy: 0.9614\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1123 - accuracy: 0.9637Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1204 - accuracy: 0.9614\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.1067 - accuracy: 0.9666Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1058 - accuracy: 0.9669\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.0943 - accuracy: 0.9736Epoch 30/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1315 - accuracy: 0.9503\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0959 - accuracy: 0.9710\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.1084 - accuracy: 0.9607Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1110 - accuracy: 0.9614\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1057 - accuracy: 0.9615Epoch 15/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1084 - accuracy: 0.9620\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.0999 - accuracy: 0.9688Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1172 - accuracy: 0.9586\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0962 - accuracy: 0.9689\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1348 - accuracy: 0.9434\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1231 - accuracy: 0.9538\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.1151 - accuracy: 0.9592Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1121 - accuracy: 0.9607\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.0906 - accuracy: 0.9714Epoch 16/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0989 - accuracy: 0.9607\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1355 - accuracy: 0.9387Epoch 30/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1035 - accuracy: 0.9627\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1013 - accuracy: 0.9676\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1151 - accuracy: 0.9509Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1232 - accuracy: 0.9455\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.1793 - accuracy: 0.9236Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0944 - accuracy: 0.9662\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1069 - accuracy: 0.9620\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1339 - accuracy: 0.9496\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.0528 - accuracy: 0.9858Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0999 - accuracy: 0.9572\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.0786 - accuracy: 0.9740Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0897 - accuracy: 0.9676\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.0851 - accuracy: 0.9733Epoch 32/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1070 - accuracy: 0.9676\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0935 - accuracy: 0.9669\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0976 - accuracy: 0.9634\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0855 - accuracy: 0.9724\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1094 - accuracy: 0.9600\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1141 - accuracy: 0.9586\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0921 - accuracy: 0.9648\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1268 - accuracy: 0.9491Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1190 - accuracy: 0.9551\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1197 - accuracy: 0.9535Epoch 37/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0923 - accuracy: 0.9683\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0740 - accuracy: 1.0000Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1139 - accuracy: 0.9558\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.1250 - accuracy: 0.9479Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1042 - accuracy: 0.9607\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.0903 - accuracy: 0.9700Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1178 - accuracy: 0.9600\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0983 - accuracy: 0.9655\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.0998 - accuracy: 0.9596Epoch 35/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0969 - accuracy: 0.9669\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.1683 - accuracy: 0.9318Epoch 22/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1182 - accuracy: 0.9545\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1189 - accuracy: 0.9609Epoch 22/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1314 - accuracy: 0.9462\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.1065 - accuracy: 0.9552Epoch 39/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1133 - accuracy: 0.9565\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1022 - accuracy: 0.9558Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0914 - accuracy: 0.9669\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0910 - accuracy: 0.9620\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0984 - accuracy: 0.9655\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.0992 - accuracy: 0.9605Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1060 - accuracy: 0.9607\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0894 - accuracy: 0.9648\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2432 - accuracy: 0.9062Epoch 37/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0915 - accuracy: 0.9655\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.0741 - accuracy: 0.9760Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0892 - accuracy: 0.9717\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.0828 - accuracy: 0.9635Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9703\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.0860 - accuracy: 0.9688Epoch 25/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0849 - accuracy: 0.9696\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0654 - accuracy: 0.9688Epoch 38/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0854 - accuracy: 0.9689\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0954 - accuracy: 0.9614\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.0505 - accuracy: 0.9760Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0888 - accuracy: 0.9655\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0932 - accuracy: 0.9641\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.0692 - accuracy: 0.9720Epoch 26/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0735 - accuracy: 0.9688Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0855 - accuracy: 0.9662\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1011 - accuracy: 0.9634\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0873 - accuracy: 0.9662\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0940 - accuracy: 0.9614\n",
      "Epoch 40/50\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1431 - accuracy: 0.9393\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0981 - accuracy: 0.9676\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.0880 - accuracy: 0.9671Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0809 - accuracy: 0.9696\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.0848 - accuracy: 0.9625Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0934 - accuracy: 0.9641\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1162 - accuracy: 0.9583Epoch 41/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9683\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.0802 - accuracy: 0.9698Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0891 - accuracy: 0.9676\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.0780 - accuracy: 0.9688Epoch 45/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0794 - accuracy: 0.9689\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9710Epoch 29/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.9710\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.0675 - accuracy: 0.9754Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0672 - accuracy: 0.9779\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.0823 - accuracy: 0.9651Epoch 29/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0860 - accuracy: 0.9738\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.0873 - accuracy: 0.9634Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9648\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0660 - accuracy: 0.9786\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.0726 - accuracy: 0.9766Epoch 43/50\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1028 - accuracy: 0.9531\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.1010 - accuracy: 0.9647Epoch 30/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1025 - accuracy: 0.9620\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0885 - accuracy: 0.9703\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0801 - accuracy: 0.9655\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0705 - accuracy: 0.9765\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9765\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.0740 - accuracy: 0.9752Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0781 - accuracy: 0.9738\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0975 - accuracy: 0.9641\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0755 - accuracy: 0.9703\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1196 - accuracy: 0.9479Epoch 32/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0881 - accuracy: 0.9710\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1054 - accuracy: 0.9586\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0842 - accuracy: 0.9655\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0648 - accuracy: 0.9786\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0892 - accuracy: 0.9689\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1074 - accuracy: 0.9543Epoch 50/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1094 - accuracy: 0.9545\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1435 - accuracy: 0.9427\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.1060 - accuracy: 0.9583Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0685 - accuracy: 0.9752\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1084 - accuracy: 0.9490Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1109 - accuracy: 0.9579\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0858 - accuracy: 0.9655\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.1127 - accuracy: 0.9565Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0690 - accuracy: 0.9758\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.0745 - accuracy: 0.9777Epoch 35/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0969 - accuracy: 0.9634\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.0609 - accuracy: 0.9801Epoch 35/50\n",
      "12/12 [==============================] - 0s 5ms/steposs: 0.0647 - accuracy: 0.\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0652 - accuracy: 0.9752\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.0740 - accuracy: 0.9717Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0652 - accuracy: 0.9765\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0511 - accuracy: 0.9688Epoch 36/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1159 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:24:37,119] Trial 16 finished with value: 0.9476584022038568 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 13 with value: 0.9669421487603306.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0719 - accuracy: 0.9717\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.0686 - accuracy: 0.9707Epoch 36/50\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.0673 - accuracy: 0.9747"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0782 - accuracy: 0.9696\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.0715 - accuracy: 0.9731Epoch 37/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0706 - accuracy: 0.9717\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0664 - accuracy: 0.9745\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.0749 - accuracy: 0.9792Epoch 37/50\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.0729 - accuracy: 0.9750Epoch 1/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0732 - accuracy: 0.9731\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0760 - accuracy: 0.9669\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.0641 - accuracy: 0.9769Epoch 38/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0626 - accuracy: 0.9772\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.0981 - accuracy: 0.9625Epoch 38/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0701 - accuracy: 0.9752\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.0552 - accuracy: 0.9814Epoch 39/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0538 - accuracy: 0.9814\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "Epoch 39/50\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.0341 - accuracy: 0.9872"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:24:38,931] Trial 15 finished with value: 0.9366391184573003 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 13 with value: 0.9669421487603306.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0739 - accuracy: 0.9703\n",
      "Epoch 40/50\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.0597 - accuracy: 0.9773"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0593 - accuracy: 0.9772\n",
      "10/46 [=====>........................] - ETA: 0s - loss: 0.0688 - accuracy: 0.9750Epoch 40/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0723 - accuracy: 0.9731\n",
      "Epoch 41/50\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.0990 - accuracy: 0.9607Epoch 1/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0932 - accuracy: 0.9634\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0532 - accuracy: 0.9821\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1031 - accuracy: 0.9637Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0957 - accuracy: 0.9669\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0959 - accuracy: 0.9565\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0527 - accuracy: 0.9841\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0611 - accuracy: 0.9772\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0536 - accuracy: 0.9793\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000Epoch 44/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0500 - accuracy: 0.9814\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0394 - accuracy: 0.9896\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0768 - accuracy: 0.9689\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.0342 - accuracy: 0.9917Epoch 46/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0365 - accuracy: 0.9896\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0578 - accuracy: 0.9793\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0531 - accuracy: 0.9793\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0507 - accuracy: 0.9841\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0532 - accuracy: 0.9821\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0858 - accuracy: 0.9662\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.9869\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 6s 11ms/step - loss: 0.6523 - accuracy: 0.6149\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0534 - accuracy: 0.9807\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5995 - accuracy: 0.7500Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0500 - accuracy: 0.9814\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5267 - accuracy: 0.7709\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9779\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0476 - accuracy: 0.9841\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3612 - accuracy: 0.8606\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 4ms/steposs: 0.4218 - accuracy: 0.78\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.7036 - accuracy: 0.4773  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:24:45,037] Trial 17 finished with value: 0.9614325068870524 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'optimizer': 'adam'}. Best is trial 13 with value: 0.9669421487603306.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8778\n",
      "Epoch 5/50\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.6812 - accuracy: 0.5528"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 6s 7ms/step - loss: 0.6798 - accuracy: 0.5590\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.2154 - accuracy: 0.9307Epoch 2/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2176 - accuracy: 0.9220\n",
      "Epoch 6/50\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.1961 - accuracy: 0.9318Epoch 1/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.6138 - accuracy: 0.6729\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1982 - accuracy: 0.9248\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.8116\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1733 - accuracy: 0.9351\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.3803 - accuracy: 0.8259Epoch 8/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.3504 - accuracy: 0.8544\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1522 - accuracy: 0.9489\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2525 - accuracy: 0.9130\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1586 - accuracy: 0.9472Epoch 6/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1522 - accuracy: 0.9462\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.2461 - accuracy: 0.9078Epoch 10/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2280 - accuracy: 0.9130\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1355 - accuracy: 0.9517\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2233 - accuracy: 0.9034\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.1448 - accuracy: 0.9503Epoch 8/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1458 - accuracy: 0.9420\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1733 - accuracy: 0.9420\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1707 - accuracy: 0.9365\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.1625 - accuracy: 0.9432Epoch 13/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1566 - accuracy: 0.9413\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1505 - accuracy: 0.9427\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1570 - accuracy: 0.9406\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1469 - accuracy: 0.9441\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1594 - accuracy: 0.9420\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1180 - accuracy: 0.9551\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1696 - accuracy: 0.9296\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1292 - accuracy: 0.9469\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1543 - accuracy: 0.9372\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 4s 7ms/step - loss: 0.6965 - accuracy: 0.5293\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0987 - accuracy: 0.9614\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1198 - accuracy: 0.9565\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.6523 - accuracy: 0.5983\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1115 - accuracy: 0.9545\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.1063 - accuracy: 0.9652Epoch 19/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.9627\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.5271 - accuracy: 0.7709\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1102 - accuracy: 0.9572\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1177 - accuracy: 0.9572\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3628 - accuracy: 0.8758\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0988 - accuracy: 0.9634\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1176 - accuracy: 0.9551\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2848 - accuracy: 0.8944\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.1094 - accuracy: 0.9602Epoch 6/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1021 - accuracy: 0.9627\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1165 - accuracy: 0.9604Epoch 22/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1178 - accuracy: 0.9586\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2297 - accuracy: 0.9158\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0862 - accuracy: 0.9710\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1200 - accuracy: 0.9545\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9689\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1957 - accuracy: 0.9344\n",
      "Epoch 24/50\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0937 - accuracy: 0.9641\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1860 - accuracy: 0.9317\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1081 - accuracy: 0.9517\n",
      "Epoch 9/50\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1002 - accuracy: 0.9607\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1663 - accuracy: 0.9325Epoch 22/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1726 - accuracy: 0.9310\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.9593\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.0926 - accuracy: 0.9688Epoch 26/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0922 - accuracy: 0.9696\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1483 - accuracy: 0.9489\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.9696\n",
      "Epoch 11/50\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.1968 - accuracy: 0.9253Epoch 27/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2203 - accuracy: 0.9096\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0815 - accuracy: 0.9683\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1543 - accuracy: 0.9441\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.1019 - accuracy: 0.9615Epoch 12/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1036 - accuracy: 0.9614\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0809 - accuracy: 0.9696\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.0934 - accuracy: 0.9663Epoch 29/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.9448\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.9689\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.0823 - accuracy: 0.9720Epoch 26/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.9538\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1296 - accuracy: 0.9511Epoch 30/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1281 - accuracy: 0.9531\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9669\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0888 - accuracy: 0.9662\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1162 - accuracy: 0.9607\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.0830 - accuracy: 0.9680Epoch 15/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9669\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0753 - accuracy: 0.9758\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1138 - accuracy: 0.9586\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0764 - accuracy: 0.9765\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0851 - accuracy: 0.9689\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1339 - accuracy: 0.9489\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.1447 - accuracy: 0.9420Epoch 17/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1436 - accuracy: 0.9406\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0707 - accuracy: 0.9738\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1056 - accuracy: 0.9620\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1009 - accuracy: 0.9565\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1072 - accuracy: 0.9531\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1113 - accuracy: 0.9579\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1941 - accuracy: 0.9228Epoch 19/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0861 - accuracy: 0.9676\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1302 - accuracy: 0.9496\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.1251 - accuracy: 0.9568Epoch 36/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1145 - accuracy: 0.9600\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0716 - accuracy: 0.9772\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2366 - accuracy: 0.9375Epoch 33/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9738\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.9579\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9676\n",
      "Epoch 21/50\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0642 - accuracy: 0.9765\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.0891 - accuracy: 0.9659Epoch 38/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1003 - accuracy: 0.9662\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0875 - accuracy: 0.9662\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1802 - accuracy: 0.9062Epoch 35/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0664 - accuracy: 0.9765\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.0749 - accuracy: 0.9696Epoch 39/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0812 - accuracy: 0.9669\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0985 - accuracy: 0.9655\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0660 - accuracy: 0.9688Epoch 23/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1182 - accuracy: 0.9572\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.1803 - accuracy: 0.9224Epoch 40/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0734 - accuracy: 0.9662\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1679 - accuracy: 0.9310\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0603 - accuracy: 0.9779\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1180 - accuracy: 0.9503\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0852 - accuracy: 0.9717\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.0906 - accuracy: 0.9583Epoch 25/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 0.9827\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0635 - accuracy: 0.9786\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0793 - accuracy: 0.9696\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0712 - accuracy: 0.9724\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.2221 - accuracy: 0.9062Epoch 43/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0738 - accuracy: 0.9710\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.0549 - accuracy: 0.9819Epoch 40/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1988 - accuracy: 0.9165\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.0531 - accuracy: 0.9832Epoch 27/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9821\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0608 - accuracy: 0.9772\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.0930 - accuracy: 0.9671Epoch 41/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1000 - accuracy: 0.9648\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9655\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0902 - accuracy: 0.9627\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1148 - accuracy: 0.9559Epoch 42/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1102 - accuracy: 0.9572\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0760 - accuracy: 0.9738\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9814\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0746 - accuracy: 0.9717\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.0762 - accuracy: 0.9740Epoch 30/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0671 - accuracy: 0.9779\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.0679 - accuracy: 0.9756Epoch 47/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9745\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0969 - accuracy: 0.9620\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0683 - accuracy: 0.9752\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.0627 - accuracy: 0.9753Epoch 48/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0633 - accuracy: 0.9745\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9731\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0478 - accuracy: 0.9821\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.0613 - accuracy: 0.9792Epoch 49/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0596 - accuracy: 0.9807\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1267 - accuracy: 0.9538\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.0955 - accuracy: 0.9688Epoch 33/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0511 - accuracy: 0.9821\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0678 - accuracy: 0.9765\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0685 - accuracy: 0.9772\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9793\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0580 - accuracy: 0.9772\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0602 - accuracy: 0.9793\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0740 - accuracy: 0.9703\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.0538 - accuracy: 0.9795Epoch 49/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0565 - accuracy: 0.9807\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 6ms/steposs: 0.0645 - accuracy: 0.97\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.0628 - accuracy: 0.9772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:25:01,316] Trial 19 finished with value: 0.9641873278236914 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'optimizer': 'adam'}. Best is trial 13 with value: 0.9669421487603306.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9710\n",
      "Epoch 50/50\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.0756 - accuracy: 0.9738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0729 - accuracy: 0.9745\n",
      "Epoch 37/50\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.0918 - accuracy: 0.9634Epoch 1/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0967 - accuracy: 0.9620\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0773 - accuracy: 0.9717\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 9ms/steposs: 0.0751 - accuracy: 0.\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.0772 - accuracy: 0.9732"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:25:02,280] Trial 18 finished with value: 0.9724517906336089 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/46 [=================>............] - ETA: 0s - loss: 0.0542 - accuracy: 0.9806"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 10ms/stepss: 0.0501 - accuracy: 0.\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.0536 - accuracy: 0.9833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:25:02,670] Trial 20 finished with value: 0.9504132231404959 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 13ms/step - loss: 0.0545 - accuracy: 0.9827\n",
      "Epoch 39/50\n",
      "10/46 [=====>........................] - ETA: 0s - loss: 0.0410 - accuracy: 0.9906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/46 [==============>...............] - ETA: 0s - loss: 0.0420 - accuracy: 0.9922Epoch 1/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0549 - accuracy: 0.9834\n",
      "Epoch 40/50\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.0338 - accuracy: 0.9866Epoch 1/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0820 - accuracy: 0.9662\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0765 - accuracy: 0.9676\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9841\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0562 - accuracy: 0.9793\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9855\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0454 - accuracy: 0.9841\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.0604 - accuracy: 0.9814\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1142 - accuracy: 0.9538\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0409 - accuracy: 0.9827\n",
      " 1/46 [..............................] - ETA: 4:27 - loss: 0.6929 - accuracy: 0.5000Epoch 49/50\n",
      "46/46 [==============================] - 6s 11ms/step - loss: 0.6752 - accuracy: 0.5887\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0559 - accuracy: 0.9814\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.6605 - accuracy: 0.6523Epoch 50/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6356 - accuracy: 0.7060\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.6849 - accuracy: 0.5534Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0577 - accuracy: 0.9772\n",
      "46/46 [==============================] - 6s 10ms/step - loss: 0.6785 - accuracy: 0.5673\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5760 - accuracy: 0.7702\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6486 - accuracy: 0.6266\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/stepss: 0.6998 - accuracy: 0.\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5000 - accuracy: 0.8095\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 6s 10ms/step - loss: 0.6965 - accuracy: 0.5086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:25:09,705] Trial 21 finished with value: 0.9669421487603306 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.6097 - accuracy: 0.7570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 13ms/step - loss: 0.6068 - accuracy: 0.7605\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.4163 - accuracy: 0.8634\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.6876 - accuracy: 0.5376\n",
      "Epoch 3/50\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.3539 - accuracy: 0.9062Epoch 1/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.5349 - accuracy: 0.8178\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.3627 - accuracy: 0.8914Epoch 5/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.3409 - accuracy: 0.8986\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.6680 - accuracy: 0.6701\n",
      " 1/46 [..............................] - ETA: 1s - loss: 0.2929 - accuracy: 0.9062Epoch 4/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.4649 - accuracy: 0.8489\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.6211 - accuracy: 0.7198\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.3051 - accuracy: 0.8819Epoch 5/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.3052 - accuracy: 0.8813\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.3775 - accuracy: 0.9041\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.3264 - accuracy: 0.8393Epoch 7/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.5163 - accuracy: 0.8475\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.2652 - accuracy: 0.9020\n",
      " 1/46 [..............................] - ETA: 1s - loss: 0.3888 - accuracy: 0.9375Epoch 9/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.3239 - accuracy: 0.9041\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.4361 - accuracy: 0.8750Epoch 8/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.3937 - accuracy: 0.8861\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.2247 - accuracy: 0.9275\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.2651 - accuracy: 0.9244Epoch 10/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.2659 - accuracy: 0.9234\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.3008 - accuracy: 0.9041\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.2114 - accuracy: 0.9248\n",
      "Epoch 11/50\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.2322 - accuracy: 0.9317\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.2483 - accuracy: 0.9193\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.2020 - accuracy: 0.9289\n",
      "10/46 [=====>........................] - ETA: 0s - loss: 0.2655 - accuracy: 0.9094Epoch 12/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.2172 - accuracy: 0.9310\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.2262 - accuracy: 0.9213\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.1674 - accuracy: 0.9500Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1713 - accuracy: 0.9455\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.2152 - accuracy: 0.9167Epoch 13/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1897 - accuracy: 0.9476\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2047 - accuracy: 0.9337\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1967 - accuracy: 0.9365Epoch 11/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1637 - accuracy: 0.9503\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1938 - accuracy: 0.9303\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1947 - accuracy: 0.9275\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.1540 - accuracy: 0.9540Epoch 12/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1749 - accuracy: 0.9317\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1602 - accuracy: 0.9524\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1708 - accuracy: 0.9413\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1553 - accuracy: 0.9469Epoch 13/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1553 - accuracy: 0.9469\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1910 - accuracy: 0.9271Epoch 16/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1842 - accuracy: 0.9317\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1651 - accuracy: 0.9427Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1822 - accuracy: 0.9282\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.1608 - accuracy: 0.9464Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1640 - accuracy: 0.9400\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1431 - accuracy: 0.9062Epoch 17/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1507 - accuracy: 0.9517\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1616 - accuracy: 0.9469\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.1602 - accuracy: 0.9396Epoch 15/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1584 - accuracy: 0.9406\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1415 - accuracy: 0.9496\n",
      "Epoch 17/50\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 7s 10ms/step - loss: 0.6873 - accuracy: 0.5452\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.1240 - accuracy: 0.9625Epoch 2/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9427\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1364 - accuracy: 0.9528Epoch 16/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1392 - accuracy: 0.9538\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.6416 - accuracy: 0.6506Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 0.9524\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.1637 - accuracy: 0.9427Epoch 18/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.6376 - accuracy: 0.6646\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.1432 - accuracy: 0.9438Epoch 3/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1480 - accuracy: 0.9496\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1354 - accuracy: 0.9579\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1044 - accuracy: 1.0000Epoch 20/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1361 - accuracy: 0.9551\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5590 - accuracy: 0.8088\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1382 - accuracy: 0.9551\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1927 - accuracy: 0.9208Epoch 18/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1931 - accuracy: 0.9206\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1428 - accuracy: 0.9517\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.4767 - accuracy: 0.8296Epoch 20/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.4766 - accuracy: 0.8240\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1510 - accuracy: 0.9462\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1454 - accuracy: 0.9441\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1485 - accuracy: 0.9509Epoch 22/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1394 - accuracy: 0.9503\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.3909 - accuracy: 0.8728Epoch 21/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.3879 - accuracy: 0.8765\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.1479 - accuracy: 0.9375Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1409 - accuracy: 0.9531\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.3251 - accuracy: 0.9016Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1332 - accuracy: 0.9531\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1251 - accuracy: 0.9558\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.3231 - accuracy: 0.8958\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.0987 - accuracy: 0.9784Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1346 - accuracy: 0.9600\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1286 - accuracy: 0.9566Epoch 21/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1277 - accuracy: 0.9572\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1357 - accuracy: 0.9451Epoch 23/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1255 - accuracy: 0.9517\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2941 - accuracy: 0.8896\n",
      "Epoch 24/50\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1163 - accuracy: 0.9588Epoch 8/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1355 - accuracy: 0.9517\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1230 - accuracy: 0.9565\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1200 - accuracy: 0.9572\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2519 - accuracy: 0.9075\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.1656 - accuracy: 0.9340Epoch 25/50\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1085 - accuracy: 0.9621Epoch 9/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1506 - accuracy: 0.9448\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1172 - accuracy: 0.9542Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1168 - accuracy: 0.9545\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2247 - accuracy: 0.9289\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1377 - accuracy: 0.9503\n",
      "Epoch 10/50\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1188 - accuracy: 0.9620\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1078 - accuracy: 0.9648\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1395 - accuracy: 0.9489\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2008 - accuracy: 0.9324\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1030 - accuracy: 0.9576Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1214 - accuracy: 0.9634\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1119 - accuracy: 0.9586\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1183 - accuracy: 0.9575Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1209 - accuracy: 0.9565\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1980 - accuracy: 0.9344\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1236 - accuracy: 0.9572\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.2247 - accuracy: 0.9094Epoch 26/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1070 - accuracy: 0.9655\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1981 - accuracy: 0.9281Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1194 - accuracy: 0.9565\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1223 - accuracy: 0.9539Epoch 29/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1956 - accuracy: 0.9317\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 0.9489\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1195 - accuracy: 0.9586\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.1723 - accuracy: 0.9363Epoch 29/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1098 - accuracy: 0.9662\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.1267 - accuracy: 0.9551Epoch 30/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1658 - accuracy: 0.9434\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.1403 - accuracy: 0.9401Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1302 - accuracy: 0.9462\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1249 - accuracy: 0.9579\n",
      "Epoch 30/50\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.1156 - accuracy: 0.9554Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1144 - accuracy: 0.9593\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.1054 - accuracy: 0.9639Epoch 31/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1620 - accuracy: 0.9413\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.1302 - accuracy: 0.9432Epoch 15/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1291 - accuracy: 0.9517\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1249 - accuracy: 0.9469\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1041 - accuracy: 0.9676\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.1635 - accuracy: 0.9451Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1591 - accuracy: 0.9476\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1069 - accuracy: 0.9607\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.2075 - accuracy: 0.9253Epoch 30/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1034 - accuracy: 0.9634\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1016 - accuracy: 0.9655\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.0941 - accuracy: 0.9660Epoch 33/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1770 - accuracy: 0.9393\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1044 - accuracy: 0.9615Epoch 17/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1048 - accuracy: 0.9620\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1393 - accuracy: 0.9406\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1041 - accuracy: 0.9614\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.1734 - accuracy: 0.9403Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1458 - accuracy: 0.9476\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.0984 - accuracy: 0.9653Epoch 18/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1052 - accuracy: 0.9634\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.1471 - accuracy: 0.9432Epoch 32/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1233 - accuracy: 0.9600\n",
      " 4/46 [=>............................] - ETA: 0s - loss: 0.0938 - accuracy: 0.9766Epoch 34/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1026 - accuracy: 0.9648\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.0944 - accuracy: 0.9688Epoch 35/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1532 - accuracy: 0.9413\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.1112 - accuracy: 0.9563Epoch 19/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1039 - accuracy: 0.9669\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0935 - accuracy: 0.9710\n",
      "Epoch 33/50\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1044 - accuracy: 0.9655\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.0877 - accuracy: 0.9659Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1517 - accuracy: 0.9448\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.0872 - accuracy: 0.9688Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0966 - accuracy: 0.9669\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1087 - accuracy: 0.9558\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1237 - accuracy: 0.9565\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.1411 - accuracy: 0.9375Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1410 - accuracy: 0.9482\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.0857 - accuracy: 0.9688Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1000 - accuracy: 0.9648\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.1054 - accuracy: 0.9613Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1119 - accuracy: 0.9593\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1075 - accuracy: 0.9627\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1028 - accuracy: 0.9625Epoch 38/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1222 - accuracy: 0.9614\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.0967 - accuracy: 0.9672Epoch 22/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0878 - accuracy: 0.9696\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1033 - accuracy: 0.9627\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.1161 - accuracy: 0.9563Epoch 36/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1112 - accuracy: 0.9593\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.1260 - accuracy: 0.9489Epoch 39/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1301 - accuracy: 0.9579\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1096 - accuracy: 0.9578Epoch 23/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1298 - accuracy: 0.9551\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1009 - accuracy: 0.9607\n",
      "Epoch 37/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0558 - accuracy: 0.9688Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1010 - accuracy: 0.9620\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1394 - accuracy: 0.9489\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1140 - accuracy: 0.9614\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1171 - accuracy: 0.9572\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1030 - accuracy: 0.9614\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1569 - accuracy: 0.9330Epoch 41/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1268 - accuracy: 0.9586\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1477 - accuracy: 0.9412Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1001 - accuracy: 0.9662\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1329 - accuracy: 0.9448\n",
      "Epoch 39/50\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1090 - accuracy: 0.9614\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1252 - accuracy: 0.9614\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.0941 - accuracy: 0.9680Epoch 26/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0960 - accuracy: 0.9662\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1417 - accuracy: 0.9455\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.1158 - accuracy: 0.9492Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0958 - accuracy: 0.9676\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1216 - accuracy: 0.9655Epoch 43/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1272 - accuracy: 0.9565\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.0865 - accuracy: 0.9698Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1093 - accuracy: 0.9593\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.0886 - accuracy: 0.9688Epoch 41/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0845 - accuracy: 0.9724\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.0767 - accuracy: 0.9760Epoch 43/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1078 - accuracy: 0.9586\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.1109 - accuracy: 0.9661Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1134 - accuracy: 0.9634\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.0908 - accuracy: 0.9721Epoch 28/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0891 - accuracy: 0.9717\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.0848 - accuracy: 0.9688Epoch 42/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0842 - accuracy: 0.9745\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1000 - accuracy: 0.9600\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.0809 - accuracy: 0.9740Epoch 45/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1084 - accuracy: 0.9669\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.0985 - accuracy: 0.9663Epoch 29/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1005 - accuracy: 0.9627\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0836 - accuracy: 0.9724\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0957 - accuracy: 0.9669\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1229 - accuracy: 0.9572\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0977 - accuracy: 0.9627\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.0948 - accuracy: 0.9638Epoch 44/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0782 - accuracy: 0.9745\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1043 - accuracy: 0.9593\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.0970 - accuracy: 0.9663Epoch 47/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1200 - accuracy: 0.9517\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0906 - accuracy: 0.9662\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.0946 - accuracy: 0.9638Epoch 45/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0919 - accuracy: 0.9627\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0994 - accuracy: 0.9648\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.1046 - accuracy: 0.9688Epoch 48/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1094 - accuracy: 0.9669\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0922 - accuracy: 0.9641\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0883 - accuracy: 0.9683\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0894 - accuracy: 0.9710\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.0849 - accuracy: 0.9780Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1018 - accuracy: 0.9683\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0965 - accuracy: 0.9634\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.0852 - accuracy: 0.9732Epoch 47/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0775 - accuracy: 0.9717\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1459 - accuracy: 0.9598Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0928 - accuracy: 0.9683\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1117 - accuracy: 0.9607\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0929 - accuracy: 0.9662\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.0887 - accuracy: 0.9665Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0898 - accuracy: 0.9689\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0940 - accuracy: 0.9669\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0985 - accuracy: 0.9676\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0879 - accuracy: 0.9669\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.1414 - accuracy: 0.9423Epoch 49/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1004 - accuracy: 0.9627\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1151 - accuracy: 0.9510\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.0786 - accuracy: 0.9792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:25:34,989] Trial 22 finished with value: 0.9504132231404959 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0877 - accuracy: 0.9689\n",
      "Epoch 50/50\n",
      " 4/46 [=>............................] - ETA: 0s - loss: 0.1198 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 7ms/steposs: 0.0825 - accuracy: 0.\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1056 - accuracy: 0.9662\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1034 - accuracy: 0.9614\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.0945 - accuracy: 0.9659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:25:35,579] Trial 23 finished with value: 0.9449035812672176 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1000 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0974 - accuracy: 0.9696\n",
      "Epoch 38/50\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1202 - accuracy: 0.9583Epoch 1/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1294 - accuracy: 0.9524\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0993 - accuracy: 0.9641\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0898 - accuracy: 0.9710\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1295 - accuracy: 0.9545\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9669\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0915 - accuracy: 0.9717\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0888 - accuracy: 0.9703\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0943 - accuracy: 0.9724\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0912 - accuracy: 0.9710\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0815 - accuracy: 0.9752\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0905 - accuracy: 0.9669\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1348 - accuracy: 0.9448\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9565\n",
      "46/46 [==============================] - 4s 5ms/step - loss: 0.6918 - accuracy: 0.5197\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 4s 4ms/step - loss: 0.6929 - accuracy: 0.5128\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.5659\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5411\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.6308\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7695\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.6830 - accuracy: 0.5569\n",
      "Epoch 5/50\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.7026\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8468\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.9124\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7840\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2690 - accuracy: 0.9172\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.8585\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2425 - accuracy: 0.9375Epoch 7/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3600 - accuracy: 0.8875\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9158\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2195 - accuracy: 0.9262\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.9006\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2252 - accuracy: 0.9375Epoch 9/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9420\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.8986\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1784 - accuracy: 0.9393\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.9151\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9379\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.2138 - accuracy: 0.9296\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1672 - accuracy: 0.9351\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2064 - accuracy: 0.9262\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.9372\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.9372\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1535 - accuracy: 0.9462\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1924 - accuracy: 0.9262\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9489\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9420\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1334 - accuracy: 0.9551\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1719 - accuracy: 0.9379\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1412 - accuracy: 0.9489\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1580 - accuracy: 0.9455\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9545\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1626 - accuracy: 0.9420\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9565\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9572\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9579\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9393\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1375 - accuracy: 0.9489\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9282\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1341 - accuracy: 0.9545\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9372\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1838 - accuracy: 0.9688Epoch 23/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1689 - accuracy: 0.9365\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1220 - accuracy: 0.9531\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1119 - accuracy: 0.9375Epoch 25/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9614\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9620\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9558\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.9641\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.9586\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1037 - accuracy: 0.9662\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1251 - accuracy: 0.9524\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9627\n",
      "Epoch 28/50\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.9662\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1551 - accuracy: 0.9455\n",
      "Epoch 30/50\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9496\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9648\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9455\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9620\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9614\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1059 - accuracy: 0.9655\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0581 - accuracy: 0.9688Epoch 33/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9586\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1318 - accuracy: 0.9517\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1104 - accuracy: 0.9634\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0622 - accuracy: 0.9688Epoch 34/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0949 - accuracy: 0.9662\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9620\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0276 - accuracy: 1.0000Epoch 35/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9710\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9620\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1099 - accuracy: 0.9648\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9620\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0304 - accuracy: 1.0000Epoch 38/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.9614\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.9600\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1633 - accuracy: 0.9375Epoch 39/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9593\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9703\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1130 - accuracy: 0.9586\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9731\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1056 - accuracy: 0.9614\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0954 - accuracy: 0.9641\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9648\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1064 - accuracy: 0.9641\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1072 - accuracy: 0.9627\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0981 - accuracy: 0.9627\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9614\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0875 - accuracy: 0.9717\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1135 - accuracy: 0.9586\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.1410 - accuracy: 0.9455\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1069 - accuracy: 0.9600\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9620\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9689\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9593\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9689\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9683\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9627\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0915 - accuracy: 0.9689\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9593\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9593\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0913 - accuracy: 0.9710\n",
      "12/12 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:25:50,366] Trial 26 finished with value: 0.9586776859504132 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:25:50,698] Trial 27 finished with value: 0.9504132231404959 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n",
      "[I 2023-07-08 15:25:50,709] Trial 24 finished with value: 0.9393939393939394 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 4s 5ms/step - loss: 0.6955 - accuracy: 0.5031\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.6895 - accuracy: 0.5422Epoch 2/50\n",
      "46/46 [==============================] - 4s 7ms/step - loss: 0.6909 - accuracy: 0.5072\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.6925 - accuracy: 0.5096Epoch 2/50\n",
      "46/46 [==============================] - 4s 7ms/step - loss: 0.6756 - accuracy: 0.5873\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.6922 - accuracy: 0.5114\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.6798 - accuracy: 0.5327Epoch 3/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.6762 - accuracy: 0.5659\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.6832 - accuracy: 0.5755Epoch 3/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6209 - accuracy: 0.6439\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.6795 - accuracy: 0.5845\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7916\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.6399 - accuracy: 0.6611\n",
      "Epoch 4/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4525 - accuracy: 0.7500Epoch 4/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.6185 - accuracy: 0.7205\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.3252 - accuracy: 0.8910\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.5600 - accuracy: 0.8054\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3341 - accuracy: 0.8438Epoch 5/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.5188 - accuracy: 0.8427\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2797 - accuracy: 0.8834\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8758\n",
      "Epoch 6/50\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8868\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.3757 - accuracy: 0.8576Epoch 7/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2342 - accuracy: 0.9103\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3316 - accuracy: 0.8896\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3363 - accuracy: 0.8937\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.2772 - accuracy: 0.8980Epoch 8/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1820 - accuracy: 0.9365\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.2745 - accuracy: 0.8972Epoch 8/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2733 - accuracy: 0.8979\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2810 - accuracy: 0.9144\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1590 - accuracy: 0.9524\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2670 - accuracy: 0.8889\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.2488 - accuracy: 0.9278Epoch 9/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2363 - accuracy: 0.9296\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.2321 - accuracy: 0.9219Epoch 10/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1985 - accuracy: 0.9344\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1619 - accuracy: 0.9441\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1597 - accuracy: 0.9688Epoch 10/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2258 - accuracy: 0.9227\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1935 - accuracy: 0.9282\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1339 - accuracy: 0.9476\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2385 - accuracy: 0.9062Epoch 11/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1936 - accuracy: 0.9351\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1761 - accuracy: 0.9330Epoch 12/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1764 - accuracy: 0.9393\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.1781 - accuracy: 0.9449Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1622 - accuracy: 0.9393\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1824 - accuracy: 0.9441\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1649 - accuracy: 0.9413\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.1692 - accuracy: 0.9323Epoch 13/50\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1676 - accuracy: 0.9331\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1746 - accuracy: 0.9441\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.0873 - accuracy: 0.9688Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:25:59,216] Trial 25 finished with value: 0.953168044077135 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1462 - accuracy: 0.9479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1786 - accuracy: 0.9351\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1295 - accuracy: 0.9503Epoch 14/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1372 - accuracy: 0.9476\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1681 - accuracy: 0.9441\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0632 - accuracy: 1.0000Epoch 15/50\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.2479 - accuracy: 0.8880Epoch 1/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1607 - accuracy: 0.9441\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1367 - accuracy: 0.9455\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1815 - accuracy: 0.9331\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.0703 - accuracy: 0.9750Epoch 16/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1500 - accuracy: 0.9496\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.1530 - accuracy: 0.9375Epoch 16/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1246 - accuracy: 0.9531\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1484 - accuracy: 0.9413\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1219 - accuracy: 0.9688Epoch 17/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1380 - accuracy: 0.9545\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1011 - accuracy: 0.9625Epoch 17/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1496 - accuracy: 0.9455\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1049 - accuracy: 0.9600\n",
      "Epoch 18/50\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1489 - accuracy: 0.9503\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1459 - accuracy: 0.9469\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1227 - accuracy: 0.9520Epoch 19/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1201 - accuracy: 0.9524\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1642 - accuracy: 0.9241Epoch 18/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1402 - accuracy: 0.9531\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1209 - accuracy: 0.9563Epoch 19/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1099 - accuracy: 0.9586\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1281 - accuracy: 0.9558Epoch 19/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1372 - accuracy: 0.9551\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1335 - accuracy: 0.9062Epoch 20/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.1285 - accuracy: 0.9538\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1002 - accuracy: 0.9648\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.1242 - accuracy: 0.9586\n",
      "Epoch 20/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1002 - accuracy: 1.0000Epoch 21/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1263 - accuracy: 0.9579\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1105 - accuracy: 0.9623Epoch 21/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1029 - accuracy: 0.9627\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1303 - accuracy: 0.9535Epoch 21/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.1273 - accuracy: 0.9551\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1226 - accuracy: 0.9572\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1019 - accuracy: 0.9586\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.1194 - accuracy: 0.9620\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1376 - accuracy: 0.9545\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1296 - accuracy: 0.9549Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1323 - accuracy: 0.9531\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.1058 - accuracy: 0.9558\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1138 - accuracy: 0.9614\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1239 - accuracy: 0.9551\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1364 - accuracy: 0.9504Epoch 25/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1065 - accuracy: 0.9600\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.1352 - accuracy: 0.9503\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1149 - accuracy: 0.9579\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1106 - accuracy: 0.9613Epoch 26/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0780 - accuracy: 0.9710\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.1162 - accuracy: 0.9609Epoch 25/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1161 - accuracy: 0.9586\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1104 - accuracy: 0.9627\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1355 - accuracy: 0.9456Epoch 27/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0736 - accuracy: 0.9745\n",
      " 4/46 [=>............................] - ETA: 0s - loss: 0.1260 - accuracy: 0.9375Epoch 26/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1306 - accuracy: 0.9469\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.0636 - accuracy: 0.9792Epoch 27/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1077 - accuracy: 0.9593\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0716 - accuracy: 0.9731\n",
      "Epoch 28/50\n",
      " 1/46 [..............................] - ETA: 1s - loss: 0.0594 - accuracy: 1.0000Epoch 27/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.1330 - accuracy: 0.9524\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 8s 14ms/step - loss: 0.6885 - accuracy: 0.5286\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1003 - accuracy: 0.9704Epoch 2/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0787 - accuracy: 0.9717\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1098 - accuracy: 0.9614\n",
      "Epoch 28/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0288 - accuracy: 1.0000Epoch 29/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.6631 - accuracy: 0.6301\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1145 - accuracy: 0.9500Epoch 3/50\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.1296 - accuracy: 0.9482\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.1086 - accuracy: 0.9509Epoch 29/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0658 - accuracy: 0.9793\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.1130 - accuracy: 0.9524\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1045 - accuracy: 0.9677Epoch 30/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.6154 - accuracy: 0.6929\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1045 - accuracy: 0.9676\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1029 - accuracy: 0.9607\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.0933 - accuracy: 0.9677Epoch 30/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1100 - accuracy: 0.9614\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.2320 - accuracy: 0.9000Epoch 31/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.0986 - accuracy: 0.9634\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.5339 - accuracy: 0.8110Epoch 31/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.5289 - accuracy: 0.8164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/46 [==============>...............] - ETA: 0s - loss: 0.1617 - accuracy: 0.9336Epoch 5/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.1333 - accuracy: 0.9441\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.0980 - accuracy: 0.9698Epoch 31/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.1126 - accuracy: 0.9627\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.0662 - accuracy: 0.9688Epoch 32/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.4259 - accuracy: 0.8758\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.0729 - accuracy: 0.9701Epoch 6/50\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.1060 - accuracy: 0.9641\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0630 - accuracy: 0.9738\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1021 - accuracy: 0.9655Epoch 32/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1075 - accuracy: 0.9655\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.0429 - accuracy: 0.9883Epoch 33/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.3333 - accuracy: 0.9034\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.0526 - accuracy: 0.9792Epoch 7/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1322 - accuracy: 0.9524\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.0621 - accuracy: 0.9731\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.2924 - accuracy: 0.9062Epoch 33/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.0963 - accuracy: 0.9710\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.2814 - accuracy: 0.9089Epoch 34/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.2708 - accuracy: 0.9165\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.1015 - accuracy: 0.9689\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1000 - accuracy: 0.9688Epoch 34/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0760 - accuracy: 0.9696\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.1112 - accuracy: 0.9635Epoch 34/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1148 - accuracy: 0.9607\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.2350 - accuracy: 0.9250Epoch 35/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.2362 - accuracy: 0.9255\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.0884 - accuracy: 0.9725Epoch 9/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0912 - accuracy: 0.9717\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.2065 - accuracy: 0.9297Epoch 35/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0703 - accuracy: 0.9745\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1166 - accuracy: 0.9552Epoch 35/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.1171 - accuracy: 0.9579\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1090 - accuracy: 0.9579\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.2029 - accuracy: 0.9434\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.1223 - accuracy: 0.9495Epoch 36/50\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.0620 - accuracy: 0.9754Epoch 10/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1122 - accuracy: 0.9558\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.0933 - accuracy: 0.9688Epoch 37/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.0506 - accuracy: 0.9841\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1860 - accuracy: 0.9448\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.0883 - accuracy: 0.9696\n",
      "Epoch 11/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2655 - accuracy: 0.9375Epoch 37/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0926 - accuracy: 0.9676\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0611 - accuracy: 0.9743Epoch 38/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.0608 - accuracy: 0.9745\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1887 - accuracy: 0.9331\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0893 - accuracy: 0.9689\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0916 - accuracy: 0.9689\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.1050 - accuracy: 0.9575Epoch 39/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0837 - accuracy: 0.9655\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1692 - accuracy: 0.9474Epoch 38/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.1042 - accuracy: 0.9607\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1675 - accuracy: 0.9476\n",
      "Epoch 39/50\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.1072 - accuracy: 0.9688Epoch 13/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.1178 - accuracy: 0.9579\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.1803 - accuracy: 0.9340Epoch 40/50\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.0625 - accuracy: 0.9765\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.1604 - accuracy: 0.9438Epoch 39/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.1078 - accuracy: 0.9586\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.1757 - accuracy: 0.9379\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.0386 - accuracy: 0.9875Epoch 14/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.1138 - accuracy: 0.9579\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0874 - accuracy: 0.9703\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.0467 - accuracy: 0.9841\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1591 - accuracy: 0.9455\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.0910 - accuracy: 0.9683\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.0565 - accuracy: 0.9814\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.0825 - accuracy: 0.9754Epoch 42/50\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0844 - accuracy: 0.9738\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1620 - accuracy: 0.9386\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0975 - accuracy: 0.9648\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0518 - accuracy: 0.9807\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.0933 - accuracy: 0.9634\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000Epoch 43/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1452 - accuracy: 0.9517\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.0997 - accuracy: 0.9676\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.0499 - accuracy: 0.9811Epoch 44/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.1343 - accuracy: 0.9586\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.0654 - accuracy: 0.9758\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0870 - accuracy: 0.9696\n",
      "Epoch 18/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0599 - accuracy: 0.9688Epoch 44/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1010 - accuracy: 0.9655\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1374 - accuracy: 0.9579\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0922 - accuracy: 0.9689\n",
      "Epoch 19/50\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.0680 - accuracy: 0.9732Epoch 45/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.1030 - accuracy: 0.9586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.1533 - accuracy: 0.9312Epoch 44/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0964 - accuracy: 0.9683\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1300 - accuracy: 0.9479Epoch 46/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1297 - accuracy: 0.9482\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0761 - accuracy: 0.9717\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.1542 - accuracy: 0.9625Epoch 46/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.0442 - accuracy: 0.9841\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1198 - accuracy: 0.9598Epoch 45/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1252 - accuracy: 0.9572\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0977 - accuracy: 0.9627\n",
      "Epoch 47/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1188 - accuracy: 0.9375Epoch 21/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0739 - accuracy: 0.9724\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.0441 - accuracy: 0.9836Epoch 47/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0429 - accuracy: 0.9855\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.2496 - accuracy: 0.8945Epoch 46/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.0901 - accuracy: 0.9669\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.0837 - accuracy: 0.9679Epoch 48/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.2125 - accuracy: 0.9068\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.0796 - accuracy: 0.9716Epoch 22/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.0808 - accuracy: 0.9703\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0548 - accuracy: 0.9793\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1336 - accuracy: 0.9596Epoch 47/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1023 - accuracy: 0.9614\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.0758 - accuracy: 0.9748Epoch 49/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.0785 - accuracy: 0.9731\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.0660 - accuracy: 0.9737Epoch 49/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1162 - accuracy: 0.9634\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.0641 - accuracy: 0.9750Epoch 23/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.0650 - accuracy: 0.9765\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.1432 - accuracy: 0.9471Epoch 48/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0782 - accuracy: 0.9717\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.0872 - accuracy: 0.9683\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.0519 - accuracy: 0.9786Epoch 50/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1181 - accuracy: 0.9607\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.0583 - accuracy: 0.9772\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0859 - accuracy: 0.9683\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0842 - accuracy: 0.9662\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1192 - accuracy: 0.9593\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.0503 - accuracy: 0.9855\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1297 - accuracy: 0.9523Epoch 50/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1185 - accuracy: 0.9565\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0454 - accuracy: 0.9821\n",
      "12/12 [==============================] - 1s 7ms/steposs: 0.1325 - accuracy: \n",
      "12/12 [==============================] - 1s 8ms/steposs: 0.1360 - accuracy: 0.94\n",
      "46/46 [==============================] - 1s 10ms/step - loss: 0.1360 - accuracy: 0.9496\n",
      "Epoch 27/50\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.1027 - accuracy: 0.9618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:26:26,205] Trial 30 finished with value: 0.9504132231404959 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n",
      "[I 2023-07-08 15:26:26,208] Trial 28 finished with value: 0.9586776859504132 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/46 [===================>..........] - ETA: 0s - loss: 0.1063 - accuracy: 0.9639"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 24ms/stepss: 0.1065 - accuracy: 0.\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9620"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:26:26,923] Trial 29 finished with value: 0.9669421487603306 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 20ms/step - loss: 0.1143 - accuracy: 0.9620\n",
      "Epoch 28/50\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.0890 - accuracy: 0.9710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9654Epoch 1/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1099 - accuracy: 0.9655\n",
      "Epoch 1/50\n",
      "Epoch 29/50\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.0696 - accuracy: 0.9746Epoch 1/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1057 - accuracy: 0.9676\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1152 - accuracy: 0.9607\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1069 - accuracy: 0.9641\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1040 - accuracy: 0.9662\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1256 - accuracy: 0.9489\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1133 - accuracy: 0.9627\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1023 - accuracy: 0.9655\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.0934 - accuracy: 0.9710\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1697 - accuracy: 0.9351\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0959 - accuracy: 0.9634\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1035 - accuracy: 0.9648\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1136 - accuracy: 0.9531\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 7s 13ms/step - loss: 0.7110 - accuracy: 0.5052\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.6893 - accuracy: 0.5327Epoch 2/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.0949 - accuracy: 0.9717\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.7330 - accuracy: 0.5018Epoch 42/50\n",
      "46/46 [==============================] - 7s 19ms/step - loss: 0.7238 - accuracy: 0.5052\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.6934 - accuracy: 0.5089Epoch 2/50\n",
      "46/46 [==============================] - 7s 20ms/step - loss: 0.6900 - accuracy: 0.5355\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.6932 - accuracy: 0.5104Epoch 2/50\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.6936 - accuracy: 0.5052\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.6941 - accuracy: 0.5028Epoch 3/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0890 - accuracy: 0.9717\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.6924 - accuracy: 0.5156Epoch 43/50\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.6939 - accuracy: 0.4872\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.6811 - accuracy: 0.5762Epoch 3/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.6798 - accuracy: 0.5769\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.6926 - accuracy: 0.5086Epoch 3/50\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6931 - accuracy: 0.4934\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.0877 - accuracy: 0.9752\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.6923 - accuracy: 0.5114Epoch 44/50\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.6931 - accuracy: 0.5024\n",
      " 4/46 [=>............................] - ETA: 0s - loss: 0.1071 - accuracy: 0.9531Epoch 4/50\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.6397 - accuracy: 0.6736\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.6919 - accuracy: 0.5114\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.6258 - accuracy: 0.6172Epoch 5/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0870 - accuracy: 0.9724\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.6914 - accuracy: 0.5000Epoch 45/50\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.6929 - accuracy: 0.5052\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.5784 - accuracy: 0.7241Epoch 5/50\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.5743 - accuracy: 0.7281\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.6911 - accuracy: 0.5305Epoch 5/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6909 - accuracy: 0.5452\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.1052 - accuracy: 0.9600\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.4621 - accuracy: 0.8594Epoch 46/50\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.4568 - accuracy: 0.8620\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 0.6922 - accuracy: 0.5128\n",
      " 3/46 [>.............................] - ETA: 1s - loss: 0.2789 - accuracy: 0.8958Epoch 6/50\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 0.6893 - accuracy: 0.5238\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.1256 - accuracy: 0.9505Epoch 7/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.1176 - accuracy: 0.9565\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.3820 - accuracy: 0.8590Epoch 47/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.6905 - accuracy: 0.5452\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.6862 - accuracy: 0.5817Epoch 7/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.3789 - accuracy: 0.8606\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.0758 - accuracy: 0.9688Epoch 7/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.6858 - accuracy: 0.5783\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6867 - accuracy: 0.5052\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.2871 - accuracy: 0.9089Epoch 8/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0858 - accuracy: 0.9710\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6843 - accuracy: 0.5000Epoch 48/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2817 - accuracy: 0.9124\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.6653\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.6842 - accuracy: 0.6662Epoch 9/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.6822 - accuracy: 0.6812\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.0976 - accuracy: 0.9641\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.2499 - accuracy: 0.9061\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.6780 - accuracy: 0.6660Epoch 9/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.6737 - accuracy: 0.6605\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.1285 - accuracy: 0.9688Epoch 10/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.6753 - accuracy: 0.6653\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0929 - accuracy: 0.9662\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6783 - accuracy: 0.5938Epoch 50/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.2333 - accuracy: 0.9124\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.0717 - accuracy: 0.9688Epoch 10/50\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.6632 - accuracy: 0.6984\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.0861 - accuracy: 0.9712Epoch 11/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.6661 - accuracy: 0.7509\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.1120 - accuracy: 0.9641\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.6464 - accuracy: 0.7923Epoch 11/50\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 0.1962 - accuracy: 0.9303\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.6438 - accuracy: 0.7909\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.6575 - accuracy: 0.7301Epoch 12/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.6519 - accuracy: 0.7591\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 14ms/step - loss: 0.2003 - accuracy: 0.9241\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.6112 - accuracy: 0.8461\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.6311 - accuracy: 0.8130\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.1805 - accuracy: 0.9301Epoch 13/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1813 - accuracy: 0.9296\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.5640 - accuracy: 0.8737\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.6012 - accuracy: 0.8502\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1718 - accuracy: 0.9324\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.5091 - accuracy: 0.8832Epoch 14/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.5056 - accuracy: 0.8854\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.5715 - accuracy: 0.8822Epoch 15/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.5663 - accuracy: 0.8571\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.1562 - accuracy: 0.9424Epoch 15/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1553 - accuracy: 0.9434\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.5344 - accuracy: 0.9187Epoch 15/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.4410 - accuracy: 0.8965\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.5155 - accuracy: 0.8896\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.1579 - accuracy: 0.9408Epoch 16/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1538 - accuracy: 0.9427\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.4846 - accuracy: 0.8705Epoch 16/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.3789 - accuracy: 0.9082\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.4629 - accuracy: 0.8992\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.3247 - accuracy: 0.9273Epoch 17/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1418 - accuracy: 0.9496\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.4233 - accuracy: 0.8813Epoch 17/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.3267 - accuracy: 0.9241\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.4071 - accuracy: 0.9089\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1609 - accuracy: 0.9343Epoch 18/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1542 - accuracy: 0.9379\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.2880 - accuracy: 0.9248\n",
      "Epoch 18/50\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.3663 - accuracy: 0.8972\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1420 - accuracy: 0.9496\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.2556 - accuracy: 0.9262\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.3393 - accuracy: 0.9141Epoch 20/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.3157 - accuracy: 0.9227\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.1396 - accuracy: 0.9469\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.2892 - accuracy: 0.9375Epoch 20/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.2323 - accuracy: 0.9324\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.2847 - accuracy: 0.9268\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1254 - accuracy: 0.9558\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9344Epoch 21/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2175 - accuracy: 0.9344\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 1s 11ms/stepss: 0.2103 - accuracy: 0.\n",
      "46/46 [==============================] - 1s 14ms/step - loss: 0.2572 - accuracy: 0.9296\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1283 - accuracy: 0.9583Epoch 22/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.9393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:26:49,481] Trial 31 finished with value: 0.9504132231404959 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 15ms/step - loss: 0.1247 - accuracy: 0.9593\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.2072 - accuracy: 0.9393\n",
      "Epoch 23/50\n",
      "Epoch 22/50\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.2550 - accuracy: 0.9279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 16ms/step - loss: 0.1294 - accuracy: 0.9503\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.2389 - accuracy: 0.9324Epoch 23/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1882 - accuracy: 0.9420\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.2374 - accuracy: 0.9344\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.1175 - accuracy: 0.9635Epoch 24/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1635 - accuracy: 0.9688Epoch 23/50\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1305 - accuracy: 0.9539Epoch 1/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1285 - accuracy: 0.9489\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.2271 - accuracy: 0.9301Epoch 24/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1772 - accuracy: 0.9482\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2252 - accuracy: 0.9324\n",
      "Epoch 25/50\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1173 - accuracy: 0.9600\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2030 - accuracy: 0.9455\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1696 - accuracy: 0.9503\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1195 - accuracy: 0.9545\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.1881 - accuracy: 0.9424Epoch 26/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1934 - accuracy: 0.9400\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1678 - accuracy: 0.9496\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.1288 - accuracy: 0.9460Epoch 27/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1114 - accuracy: 0.9593\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.1842 - accuracy: 0.9430Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1890 - accuracy: 0.9427\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1594 - accuracy: 0.9503\n",
      "Epoch 27/50\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1325 - accuracy: 0.9517\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1784 - accuracy: 0.9420\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1603 - accuracy: 0.9496\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0926 - accuracy: 0.9688Epoch 28/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2298 - accuracy: 0.9688Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1089 - accuracy: 0.9593\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1526 - accuracy: 0.9551\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1739 - accuracy: 0.9469\n",
      "Epoch 30/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0892 - accuracy: 0.9688Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1026 - accuracy: 0.9696\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1463 - accuracy: 0.9551\n",
      "Epoch 30/50\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1631 - accuracy: 0.9524\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1109 - accuracy: 0.9627\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1474 - accuracy: 0.9545\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1565 - accuracy: 0.9503\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.1467 - accuracy: 0.9648Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1382 - accuracy: 0.9593\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1303 - accuracy: 0.9462\n",
      "Epoch 33/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0577 - accuracy: 1.0000Epoch 32/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1626 - accuracy: 0.9448\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1193 - accuracy: 0.9621Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1346 - accuracy: 0.9565\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1154 - accuracy: 0.9572\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.1594 - accuracy: 0.9465Epoch 33/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1540 - accuracy: 0.9496\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1356 - accuracy: 0.9604Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 0.9558\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1013 - accuracy: 0.9648\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3465 - accuracy: 0.9062Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1471 - accuracy: 0.9551\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0899 - accuracy: 0.9696\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1332 - accuracy: 0.9579\n",
      "Epoch 35/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2019 - accuracy: 0.9375Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1479 - accuracy: 0.9524\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1073 - accuracy: 0.9572\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1248 - accuracy: 0.9611Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1276 - accuracy: 0.9600\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.1067 - accuracy: 0.9531Epoch 37/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1378 - accuracy: 0.9572\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1193 - accuracy: 0.9625Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1027 - accuracy: 0.9634\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1253 - accuracy: 0.9572\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 6s 10ms/step - loss: 0.6945 - accuracy: 0.4955\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.1447 - accuracy: 0.9482Epoch 2/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1366 - accuracy: 0.9531\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0987 - accuracy: 0.9641\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.6903 - accuracy: 0.5530Epoch 38/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1301 - accuracy: 0.9586\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6900 - accuracy: 0.5535\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.1326 - accuracy: 0.9570Epoch 3/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1339 - accuracy: 0.9586\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.6833 - accuracy: 0.6146Epoch 38/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0995 - accuracy: 0.9607\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1267 - accuracy: 0.9607\n",
      "Epoch 40/50\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6782 - accuracy: 0.6294\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1391 - accuracy: 0.9526Epoch 4/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1328 - accuracy: 0.9579\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.1022 - accuracy: 0.9639Epoch 39/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1229 - accuracy: 0.9614\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0971 - accuracy: 0.9662\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6565 - accuracy: 0.6467\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1334 - accuracy: 0.9600\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1195 - accuracy: 0.9620\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0899 - accuracy: 0.9655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1180 - accuracy: 0.9621Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5998 - accuracy: 0.7750\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1233 - accuracy: 0.9588Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1299 - accuracy: 0.9565\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.5568 - accuracy: 0.7643Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1233 - accuracy: 0.9600\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0976 - accuracy: 0.9634\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5468 - accuracy: 0.7667\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1234 - accuracy: 0.9593\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1194 - accuracy: 0.9607\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.4669 - accuracy: 0.8584Epoch 44/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0914 - accuracy: 0.9662\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4538 - accuracy: 0.8668\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1289 - accuracy: 0.9522Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1213 - accuracy: 0.9607\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.3945 - accuracy: 0.8804Epoch 43/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1133 - accuracy: 0.9655\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.3878 - accuracy: 0.8814Epoch 45/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0985 - accuracy: 0.9614\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8840Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3834 - accuracy: 0.8834\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.1264 - accuracy: 0.9601Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1238 - accuracy: 0.9600\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1167 - accuracy: 0.9620\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.3304 - accuracy: 0.8996Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0846 - accuracy: 0.9724\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1550 - accuracy: 0.9375Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3256 - accuracy: 0.9027\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1229 - accuracy: 0.9593\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1245 - accuracy: 0.9544Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1162 - accuracy: 0.9565\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.1256 - accuracy: 0.9635Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0928 - accuracy: 0.9676\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2841 - accuracy: 0.9082\n",
      "Epoch 46/50\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1181 - accuracy: 0.9627\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.0956 - accuracy: 0.9663Epoch 46/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1127 - accuracy: 0.9614\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2468 - accuracy: 0.9124\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1434 - accuracy: 0.9557Epoch 12/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0826 - accuracy: 0.9724\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1166 - accuracy: 0.9641\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1188 - accuracy: 0.9611Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1210 - accuracy: 0.9579\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.2265 - accuracy: 0.9268Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2274 - accuracy: 0.9268\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0805 - accuracy: 0.9689\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1155 - accuracy: 0.9607\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1186 - accuracy: 0.9600Epoch 48/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1193 - accuracy: 0.9593\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.1070 - accuracy: 0.9609Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2295 - accuracy: 0.9096\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0876 - accuracy: 0.9641\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.2316 - accuracy: 0.9258Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1120 - accuracy: 0.9648\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1982 - accuracy: 0.9341Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1212 - accuracy: 0.9572\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1923 - accuracy: 0.9393\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.0817 - accuracy: 0.9680Epoch 15/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0848 - accuracy: 0.9689\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 0.9634\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1826 - accuracy: 0.9400\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9614Epoch 16/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0950 - accuracy: 0.9614\n",
      "12/12 [==============================] - 0s 8ms/steposs: 0.2913 - accuracy: 0.\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1916 - accuracy: 0.9250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:27:03,604] Trial 32 finished with value: 0.9449035812672176 and parameters: {'activation': 'sigmoid', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1111 - accuracy: 0.9614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1801 - accuracy: 0.9393\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 7ms/steposs: 0.1693 - accuracy: 0.\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1743 - accuracy: 0.9433"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:27:04,154] Trial 34 finished with value: 0.953168044077135 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1698 - accuracy: 0.9448\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 9ms/steposs: 0.1602 - accuracy: 0.93\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1752 - accuracy: 0.9453"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:27:04,525] Trial 33 finished with value: 0.9476584022038568 and parameters: {'activation': 'sigmoid', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/46 [====================>.........] - ETA: 0s - loss: 0.1615 - accuracy: 0.9489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1617 - accuracy: 0.9485Epoch 1/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1651 - accuracy: 0.9434\n",
      "Epoch 19/50\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1630 - accuracy: 0.9448Epoch 1/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1618 - accuracy: 0.9434\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1503 - accuracy: 0.9476\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1588 - accuracy: 0.9420\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.9510\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1391 - accuracy: 0.9545\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1331 - accuracy: 0.9579\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1263 - accuracy: 0.9634\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1372 - accuracy: 0.9510\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 3s 11ms/step - loss: 0.6908 - accuracy: 0.5224\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1199 - accuracy: 0.9614\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.6871 - accuracy: 0.5560Epoch 28/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6873 - accuracy: 0.5514\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1246 - accuracy: 0.9558\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6817 - accuracy: 0.5687\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1260 - accuracy: 0.9579\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6763 - accuracy: 0.5832\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.0722 - accuracy: 0.9732Epoch 5/50\n",
      "46/46 [==============================] - 6s 9ms/step - loss: 0.6913 - accuracy: 0.5349\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.6714 - accuracy: 0.5954Epoch 2/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1191 - accuracy: 0.9572\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6702 - accuracy: 0.6025\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6813 - accuracy: 0.6087\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.1274 - accuracy: 0.9509Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1273 - accuracy: 0.9517\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6626 - accuracy: 0.6218\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 6s 10ms/step - loss: 0.6585 - accuracy: 0.6163\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6627 - accuracy: 0.6170\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1200 - accuracy: 0.9593\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.6541 - accuracy: 0.6332Epoch 4/50\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6548 - accuracy: 0.6301\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5218 - accuracy: 0.7757\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6284 - accuracy: 0.6756\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.3761 - accuracy: 0.8608Epoch 5/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1187 - accuracy: 0.9614\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6422 - accuracy: 0.6715\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.3558 - accuracy: 0.8640Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3521 - accuracy: 0.8620\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.6364 - accuracy: 0.6899Epoch 4/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5619 - accuracy: 0.8047\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.6317 - accuracy: 0.6950Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1174 - accuracy: 0.9579\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6296 - accuracy: 0.6867\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1143 - accuracy: 0.9583Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2754 - accuracy: 0.8730\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.4860 - accuracy: 0.8318Epoch 5/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4766 - accuracy: 0.8406\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1048 - accuracy: 0.9710\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.4257 - accuracy: 0.8568Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6140 - accuracy: 0.7308\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2704 - accuracy: 0.8882\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.6110 - accuracy: 0.6899Epoch 6/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3846 - accuracy: 0.8765\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.2238 - accuracy: 0.8906Epoch 8/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1013 - accuracy: 0.9669\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.2098 - accuracy: 0.9013Epoch 37/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5966 - accuracy: 0.7391\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.0787 - accuracy: 0.9732Epoch 12/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2115 - accuracy: 0.9089\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3117 - accuracy: 0.8999\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.5760 - accuracy: 0.7681Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1150 - accuracy: 0.9593\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.5747 - accuracy: 0.7738Epoch 38/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5747 - accuracy: 0.7695\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.2819 - accuracy: 0.9079Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1700 - accuracy: 0.9358\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.2640 - accuracy: 0.9087Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2649 - accuracy: 0.9061\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1194 - accuracy: 0.9579\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5498 - accuracy: 0.7854\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1601 - accuracy: 0.9463Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.9489\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2209 - accuracy: 0.9344\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.0951 - accuracy: 0.9664Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0974 - accuracy: 0.9669\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5278 - accuracy: 0.7971\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1489 - accuracy: 0.9468Epoch 15/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1501 - accuracy: 0.9455\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.5222 - accuracy: 0.7668Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2083 - accuracy: 0.9227\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.0995 - accuracy: 0.9665Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0977 - accuracy: 0.9669\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4986 - accuracy: 0.8033\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1124 - accuracy: 0.9464Epoch 16/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1504 - accuracy: 0.9489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/46 [============>.................] - ETA: 0s - loss: 0.4800 - accuracy: 0.8156Epoch 11/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1861 - accuracy: 0.9344\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.0980 - accuracy: 0.9653Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1080 - accuracy: 0.9634\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4777 - accuracy: 0.8054Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4777 - accuracy: 0.8054\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.2061 - accuracy: 0.9075Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1934 - accuracy: 0.9117\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1708 - accuracy: 0.9443Epoch 12/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1693 - accuracy: 0.9455\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1153 - accuracy: 0.9531Epoch 14/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0963 - accuracy: 0.9703\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4665 - accuracy: 0.8019\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0718 - accuracy: 1.0000Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1768 - accuracy: 0.9268\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1623 - accuracy: 0.9427\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4666 - accuracy: 0.8012\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1518 - accuracy: 0.9554Epoch 19/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1093 - accuracy: 0.9593\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1452 - accuracy: 0.9455\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.3999 - accuracy: 0.8478Epoch 14/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1730 - accuracy: 0.9317\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9674Epoch 16/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0939 - accuracy: 0.9676\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4001 - accuracy: 0.8316\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.1088 - accuracy: 0.9618Epoch 20/50\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1194 - accuracy: 0.9545\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.0869 - accuracy: 0.9697Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1495 - accuracy: 0.9510\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0928 - accuracy: 0.9674Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0922 - accuracy: 0.9676\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1241 - accuracy: 0.9598Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3806 - accuracy: 0.8392\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2888 - accuracy: 0.9375Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1271 - accuracy: 0.9510\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.1420 - accuracy: 0.9555Epoch 16/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1452 - accuracy: 0.9538\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.0949 - accuracy: 0.9703Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0956 - accuracy: 0.9689\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.8019\n",
      "Epoch 22/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4681 - accuracy: 0.7500Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1261 - accuracy: 0.9517\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1424 - accuracy: 0.9469\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.4152 - accuracy: 0.7979Epoch 19/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4151 - accuracy: 0.7978\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0919 - accuracy: 0.9703\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.4290 - accuracy: 0.7969Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1101 - accuracy: 0.9593\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1990 - accuracy: 0.9199\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.3646 - accuracy: 0.8358Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3644 - accuracy: 0.8364\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1120 - accuracy: 0.9593\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1442 - accuracy: 0.9372\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1408 - accuracy: 0.9476\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3805 - accuracy: 0.8171\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1177 - accuracy: 0.9688Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0946 - accuracy: 0.9669\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.0958 - accuracy: 0.9633Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1113 - accuracy: 0.9496\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.0911 - accuracy: 0.9712Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3242 - accuracy: 0.8585\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1303 - accuracy: 0.9586\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.0897 - accuracy: 0.9707Epoch 26/50\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0889 - accuracy: 0.9696\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3661 - accuracy: 0.8420\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0938 - accuracy: 0.9669\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1278 - accuracy: 0.9586\n",
      "Epoch 21/50\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3872 - accuracy: 0.8261\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1026 - accuracy: 0.9618Epoch 28/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1322 - accuracy: 0.9545\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1021 - accuracy: 0.9620\n",
      "Epoch 24/50\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8592\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1301 - accuracy: 0.9593\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0909 - accuracy: 0.9703\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3328 - accuracy: 0.8475\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1203 - accuracy: 0.9620\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1051 - accuracy: 0.9586\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.1044 - accuracy: 0.9766Epoch 24/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2909 - accuracy: 0.8751\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1232 - accuracy: 0.9641\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0992 - accuracy: 0.9607\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2924 - accuracy: 0.8806\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1105 - accuracy: 0.9662\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1209 - accuracy: 0.9524\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3040 - accuracy: 0.8723\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.9634\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0929 - accuracy: 0.9655\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2453 - accuracy: 0.9165\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.0653 - accuracy: 0.9780Epoch 34/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.9586\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0855 - accuracy: 0.9710\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2198 - accuracy: 0.9096\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.1110 - accuracy: 0.9609Epoch 35/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.9600\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1187 - accuracy: 0.9462\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2625 - accuracy: 0.8916\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.9655\n",
      "Epoch 36/50\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1366 - accuracy: 0.9386\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.1017 - accuracy: 0.9654Epoch 30/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2579 - accuracy: 0.8916\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1182 - accuracy: 0.9572\n",
      "Epoch 37/50\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0822 - accuracy: 0.9703\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1210 - accuracy: 0.9604Epoch 31/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1212 - accuracy: 0.9593\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.1560 - accuracy: 0.9375Epoch 34/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2131 - accuracy: 0.9124\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1170 - accuracy: 0.9524\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.2018 - accuracy: 0.9363Epoch 32/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1080 - accuracy: 0.9607\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.2492 - accuracy: 0.9033Epoch 35/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2704 - accuracy: 0.8937\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0741 - accuracy: 0.9738\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1282 - accuracy: 0.9545\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2776 - accuracy: 0.8937\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0881 - accuracy: 0.9655\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.0978 - accuracy: 0.9696Epoch 34/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0997 - accuracy: 0.9676\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2304 - accuracy: 0.9027\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0908 - accuracy: 0.9634\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9620\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.2115 - accuracy: 0.9207Epoch 38/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2102 - accuracy: 0.9179\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0701 - accuracy: 0.9758\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9683\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2222 - accuracy: 0.9144\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0661 - accuracy: 0.9772\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1301 - accuracy: 0.9531\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.2296 - accuracy: 0.9110\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0873 - accuracy: 0.9620\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.1632 - accuracy: 0.9456Epoch 38/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1023 - accuracy: 0.9614\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2092 - accuracy: 0.9262\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.0588 - accuracy: 0.9816Epoch 45/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0861 - accuracy: 0.9703\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.2817 - accuracy: 0.8779Epoch 39/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1004 - accuracy: 0.9689\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2563 - accuracy: 0.8916\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.0777 - accuracy: 0.9688Epoch 46/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0752 - accuracy: 0.9703\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0932 - accuracy: 0.9676\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1684 - accuracy: 0.9462\n",
      "Epoch 43/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2868 - accuracy: 0.9688Epoch 47/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0642 - accuracy: 0.9772\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1846 - accuracy: 0.9296\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.0665 - accuracy: 0.9706Epoch 48/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1028 - accuracy: 0.9634\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2914 - accuracy: 0.8438Epoch 44/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0779 - accuracy: 0.9710\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1974 - accuracy: 0.9158\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0973 - accuracy: 0.9662\n",
      "Epoch 49/50\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.0716 - accuracy: 0.9705Epoch 45/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0844 - accuracy: 0.9662\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1573 - accuracy: 0.9462\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.0918 - accuracy: 0.9681Epoch 50/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0914 - accuracy: 0.9683\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0528 - accuracy: 0.9862\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.0837 - accuracy: 0.9688Epoch 44/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1636 - accuracy: 0.9386\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0950 - accuracy: 0.9641\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9703\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9724\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9827\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0925 - accuracy: 0.9717\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.9800\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9669\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9607\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9641\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9814\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9738\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9448\n",
      "12/12 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:27:28,525] Trial 37 finished with value: 0.9256198347107438 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:27:28,808] Trial 38 finished with value: 0.9476584022038568 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'sgd'}. Best is trial 18 with value: 0.9724517906336089.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 2s 6ms/step - loss: 0.6940 - accuracy: 0.5135\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/steposs: 0.6917 - accuracy: 0.54\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.6922 - accuracy: 0.5238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:27:30,665] Trial 36 finished with value: 0.9476584022038568 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6879 - accuracy: 0.5597\n",
      "Epoch 3/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6722 - accuracy: 0.5625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/46 [=======================>......] - ETA: 0s - loss: 0.6843 - accuracy: 0.5567Epoch 1/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6833 - accuracy: 0.5680\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.6764 - accuracy: 0.5970\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.6682 - accuracy: 0.6370\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.6515\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6513 - accuracy: 0.6722\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 3s 9ms/step - loss: 0.6825 - accuracy: 0.5645\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6441 - accuracy: 0.6805\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6441 - accuracy: 0.6467\n",
      "10/46 [=====>........................] - ETA: 0s - loss: 0.6485 - accuracy: 0.6656Epoch 3/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.6319 - accuracy: 0.6977\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.5446 - accuracy: 0.7923\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 2s 8ms/step - loss: 0.7082 - accuracy: 0.5038\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6180 - accuracy: 0.7053Epoch 2/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6180 - accuracy: 0.7053\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4353 - accuracy: 0.8668\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.5850 - accuracy: 0.7380Epoch 5/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6785 - accuracy: 0.5638\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6022 - accuracy: 0.7288\n",
      "Epoch 3/50\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.3448 - accuracy: 0.8889\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6567 - accuracy: 0.6170\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.2825 - accuracy: 0.9155Epoch 4/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.5837 - accuracy: 0.7757\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2932 - accuracy: 0.9027\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.6763\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.2601 - accuracy: 0.9201Epoch 5/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5687 - accuracy: 0.7736\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.6163 - accuracy: 0.7169Epoch 14/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2565 - accuracy: 0.9186\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6094 - accuracy: 0.7143\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.5466 - accuracy: 0.7937\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.2194 - accuracy: 0.9382Epoch 15/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2181 - accuracy: 0.9393\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5537 - accuracy: 0.5938Epoch 9/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5782 - accuracy: 0.7440\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1973 - accuracy: 0.9386Epoch 7/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.5271 - accuracy: 0.8061\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.5493 - accuracy: 0.7695Epoch 16/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2058 - accuracy: 0.9337\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5224 - accuracy: 0.8438Epoch 10/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.5439 - accuracy: 0.7736\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.5015 - accuracy: 0.8192\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1993 - accuracy: 0.9281Epoch 17/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2028 - accuracy: 0.9289\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.5360 - accuracy: 0.7812Epoch 11/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.5113 - accuracy: 0.8012\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.8213\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1805 - accuracy: 0.9345Epoch 18/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1762 - accuracy: 0.9386\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.5075 - accuracy: 0.7681\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.4757 - accuracy: 0.8117Epoch 10/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.4722 - accuracy: 0.8144\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.1668 - accuracy: 0.9479Epoch 19/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1711 - accuracy: 0.9455\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.8185\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.2307 - accuracy: 0.9135Epoch 11/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4580 - accuracy: 0.8206\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.4603 - accuracy: 0.8125Epoch 20/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2128 - accuracy: 0.9193\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.4476 - accuracy: 0.8068\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.1895 - accuracy: 0.9207Epoch 12/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.8337\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.1749 - accuracy: 0.9292Epoch 21/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1669 - accuracy: 0.9365\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4647 - accuracy: 0.7605\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4299 - accuracy: 0.8357\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1667 - accuracy: 0.9400\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4142 - accuracy: 0.8199\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1521 - accuracy: 0.9525Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4166 - accuracy: 0.8275\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 7ms/steposs: 0.4534 - accuracy: 0.77\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1437 - accuracy: 0.9517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:27:38,286] Trial 35 finished with value: 0.9504132231404959 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/46 [===========>..................] - ETA: 0s - loss: 0.4302 - accuracy: 0.8224Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3831 - accuracy: 0.8433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.4116 - accuracy: 0.8351\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.4879 - accuracy: 0.7500Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1409 - accuracy: 0.9503\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.4000 - accuracy: 0.8151Epoch 18/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4567 - accuracy: 0.7619\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.3889 - accuracy: 0.8384Epoch 16/50\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.1455 - accuracy: 0.9531Epoch 1/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3980 - accuracy: 0.8302\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.1377 - accuracy: 0.9551Epoch 25/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1410 - accuracy: 0.9538\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4244 - accuracy: 0.7923\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3613 - accuracy: 0.8654\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1294 - accuracy: 0.9614\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3813 - accuracy: 0.8392\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3714 - accuracy: 0.8585\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1313 - accuracy: 0.9572\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3390 - accuracy: 0.8606\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1158 - accuracy: 0.9646Epoch 19/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.3539 - accuracy: 0.8613\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1173 - accuracy: 0.9641Epoch 28/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1219 - accuracy: 0.9627\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3472 - accuracy: 0.8433\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.3534 - accuracy: 0.8498Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3616 - accuracy: 0.8440\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1315 - accuracy: 0.9510Epoch 29/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1410 - accuracy: 0.9496\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3360 - accuracy: 0.8654\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.3333 - accuracy: 0.8634\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1250 - accuracy: 0.9586\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.3837 - accuracy: 0.8391Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3515 - accuracy: 0.8447\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.3631 - accuracy: 0.8446Epoch 22/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.3694 - accuracy: 0.8406\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1485 - accuracy: 0.9441\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.3678 - accuracy: 0.8377Epoch 25/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3439 - accuracy: 0.8516\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3230 - accuracy: 0.8765\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.2427 - accuracy: 0.9330Epoch 32/50\n",
      "46/46 [==============================] - 3s 9ms/step - loss: 0.6978 - accuracy: 0.5776\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1774 - accuracy: 0.9303\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.2879 - accuracy: 0.8870Epoch 26/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2915 - accuracy: 0.8841\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2873 - accuracy: 0.8965\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1383 - accuracy: 0.9539Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6466 - accuracy: 0.6211\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1354 - accuracy: 0.9496\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6416 - accuracy: 0.5938Epoch 27/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2714 - accuracy: 0.8868\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2952 - accuracy: 0.8896\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6099 - accuracy: 0.6749\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1137 - accuracy: 0.9614\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.2451 - accuracy: 0.9012Epoch 4/50\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2691 - accuracy: 0.8910\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3274 - accuracy: 0.8606\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2506 - accuracy: 0.9375Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1058 - accuracy: 0.9641\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5877 - accuracy: 0.7129\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.2976 - accuracy: 0.8700Epoch 5/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2961 - accuracy: 0.8903\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.1120 - accuracy: 0.9641Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2835 - accuracy: 0.8799\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1879 - accuracy: 0.9688Epoch 27/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1025 - accuracy: 0.9641\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.3251 - accuracy: 0.8587Epoch 30/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5497 - accuracy: 0.7191\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.3105 - accuracy: 0.8672Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2783 - accuracy: 0.8834\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.3331 - accuracy: 0.8580Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3299 - accuracy: 0.8606\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1036 - accuracy: 0.9662\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.2990 - accuracy: 0.8824Epoch 31/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5143 - accuracy: 0.7654\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.2587 - accuracy: 0.9053Epoch 7/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2543 - accuracy: 0.9034\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2713 - accuracy: 0.8951\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0986 - accuracy: 0.9683\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.2136 - accuracy: 0.9174Epoch 32/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.5009 - accuracy: 0.7674\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2618 - accuracy: 0.8958\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.0990 - accuracy: 0.9688Epoch 30/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2617 - accuracy: 0.9013\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.4544 - accuracy: 0.8058Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0997 - accuracy: 0.9717\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.3191 - accuracy: 0.8552Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4868 - accuracy: 0.7598\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.1384 - accuracy: 0.9375Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2770 - accuracy: 0.8834\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2563 - accuracy: 0.9027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1095 - accuracy: 0.9634\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.3026 - accuracy: 0.8705Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4733 - accuracy: 0.7888\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2741 - accuracy: 0.8841\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.4264 - accuracy: 0.8164Epoch 32/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2617 - accuracy: 0.9006\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1161 - accuracy: 0.9572\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4317 - accuracy: 0.8081\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.2124 - accuracy: 0.9095Epoch 11/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2187 - accuracy: 0.9068\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9172Epoch 33/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2342 - accuracy: 0.9172\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0965 - accuracy: 0.9683\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.2310 - accuracy: 0.9164Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4726 - accuracy: 0.7743\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2602 - accuracy: 0.8958\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.0995 - accuracy: 0.9598Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2725 - accuracy: 0.8951\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0941 - accuracy: 0.9634\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.2569 - accuracy: 0.8964Epoch 37/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4389 - accuracy: 0.7902\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0825 - accuracy: 0.9688Epoch 13/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2354 - accuracy: 0.9061\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.0938 - accuracy: 0.9688Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2589 - accuracy: 0.8992\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.4002 - accuracy: 0.8326Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0919 - accuracy: 0.9724\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3895 - accuracy: 0.8268\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1885 - accuracy: 0.9375Epoch 38/50\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1846 - accuracy: 0.9386\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2737 - accuracy: 0.8813\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.4792 - accuracy: 0.7692Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0974 - accuracy: 0.9676\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3973 - accuracy: 0.8199\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2453 - accuracy: 0.8958\n",
      "Epoch 15/50\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2340 - accuracy: 0.9082\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.3142 - accuracy: 0.8750Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2418 - accuracy: 0.9110\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0878 - accuracy: 0.9724\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3571 - accuracy: 0.8357\n",
      "Epoch 40/50\n",
      "Epoch 38/50\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2494 - accuracy: 0.9013\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.3554 - accuracy: 0.8578\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1109 - accuracy: 0.9593\n",
      "Epoch 17/50\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1993 - accuracy: 0.9296\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2144 - accuracy: 0.9220\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.3945 - accuracy: 0.8125Epoch 48/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3125 - accuracy: 0.8723\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2099 - accuracy: 0.9165\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0879 - accuracy: 0.9703\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1915 - accuracy: 0.9289\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1865 - accuracy: 0.9400\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3377 - accuracy: 0.8571\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0851 - accuracy: 0.9703\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1986 - accuracy: 0.9310\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.3299 - accuracy: 0.8516Epoch 41/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1952 - accuracy: 0.9282\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3162 - accuracy: 0.8647\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0970 - accuracy: 0.9655\n",
      " 1/46 [..............................] - ETA: 0s - loss: 1.6491 - accuracy: 0.4062Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2446 - accuracy: 0.9027\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2691 - accuracy: 0.9124\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0879 - accuracy: 0.9696\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.5498 - accuracy: 0.6875Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1734 - accuracy: 0.9365\n",
      " 1/12 [=>............................] - ETA: 3sEpoch 43/500704 - accuracy: 1.0000\n",
      "12/12 [==============================] - 0s 9ms/steposs: 0.1369 - accuracy: 0.95\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1526 - accuracy: 0.9408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:27:51,200] Trial 39 finished with value: 0.8484848484848485 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'sgd'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/46 [==========================>...] - ETA: 0s - loss: 0.1253 - accuracy: 0.9501"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3741 - accuracy: 0.8351\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 0.2018 - accuracy: 0.9234Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1209 - accuracy: 0.9510\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.2115 - accuracy: 0.9375Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1894 - accuracy: 0.9310\n",
      "Epoch 44/50\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.2762 - accuracy: 0.8725Epoch 1/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0925 - accuracy: 0.9634\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.2678 - accuracy: 0.8787Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2804 - accuracy: 0.8841\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2584 - accuracy: 0.8841\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.2380 - accuracy: 0.9115Epoch 45/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0927 - accuracy: 0.9662\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3079 - accuracy: 0.8668\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2202 - accuracy: 0.9068\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0940 - accuracy: 0.9641\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1431 - accuracy: 0.9510Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3157 - accuracy: 0.8592\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1654 - accuracy: 0.9062Epoch 25/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1436 - accuracy: 0.9510\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0978 - accuracy: 0.9655\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.1384 - accuracy: 0.9531Epoch 50/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2429 - accuracy: 0.9061\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0809 - accuracy: 0.9688Epoch 26/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1417 - accuracy: 0.9517\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0868 - accuracy: 0.9669\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1688 - accuracy: 0.9337\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2777 - accuracy: 0.8744\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2055 - accuracy: 0.9075\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2628 - accuracy: 0.9013\n",
      " 1/12 [=>............................] - ETA: 3sEpoch 28/50\n",
      "12/12 [==============================] - 0s 8ms/steposs: 0.1700 - accuracy: 0.93\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.1663 - accuracy: 0.9410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:27:54,463] Trial 40 finished with value: 0.9476584022038568 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1768 - accuracy: 0.9281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1798 - accuracy: 0.9262\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2830 - accuracy: 0.8875\n",
      "Epoch 29/50\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.2453 - accuracy: 0.9087Epoch 1/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2513 - accuracy: 0.9068\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.7022 - accuracy: 0.5156Epoch 30/50\n",
      "12/12 [==============================] - 0s 7ms/steposs: 0.1769 - accuracy: 0.\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.1763 - accuracy: 0.9519"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:27:55,377] Trial 41 finished with value: 0.8209366391184573 and parameters: {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'sgd'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 4s 10ms/step - loss: 0.7083 - accuracy: 0.4872\n",
      "Epoch 2/50\n",
      "10/46 [=====>........................] - ETA: 0s - loss: 0.6950 - accuracy: 0.5219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2696 - accuracy: 0.8903\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.6950 - accuracy: 0.5079\n",
      "Epoch 3/50\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.2026 - accuracy: 0.9289Epoch 1/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2115 - accuracy: 0.9220\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6855 - accuracy: 0.5521\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1762 - accuracy: 0.9400\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.6757 - accuracy: 0.5839\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1978 - accuracy: 0.9255\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.6651 - accuracy: 0.6118Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6637 - accuracy: 0.6177\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1893 - accuracy: 0.9227\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.6499 - accuracy: 0.6577Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6469 - accuracy: 0.6639\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2511 - accuracy: 0.9041\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6298 - accuracy: 0.6832\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1861 - accuracy: 0.9296\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6022 - accuracy: 0.7502\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2704 - accuracy: 0.9055\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.5765 - accuracy: 0.7612\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.2026 - accuracy: 0.9174Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2092 - accuracy: 0.9124\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5426 - accuracy: 0.7978\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.1766 - accuracy: 0.9389Epoch 11/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1746 - accuracy: 0.9400\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5166 - accuracy: 0.8012\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1514 - accuracy: 0.9499Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1494 - accuracy: 0.9503\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.8047\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1665 - accuracy: 0.9420\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.5492 - accuracy: 0.7212Epoch 42/50\n",
      "46/46 [==============================] - 6s 9ms/step - loss: 0.6834 - accuracy: 0.5666\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4990 - accuracy: 0.7709\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1780 - accuracy: 0.9351\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.6164 - accuracy: 0.7019\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.2325 - accuracy: 0.9018Epoch 3/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4425 - accuracy: 0.8268\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2363 - accuracy: 0.9013\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5040 - accuracy: 0.7943\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4311 - accuracy: 0.8102\n",
      "Epoch 4/50\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1847 - accuracy: 0.9262\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.4019 - accuracy: 0.8516Epoch 45/50\n",
      "46/46 [==============================] - 6s 9ms/step - loss: 0.6945 - accuracy: 0.4990\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.7950\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3643 - accuracy: 0.8640\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.6960 - accuracy: 0.5161Epoch 5/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1671 - accuracy: 0.9448\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.4017 - accuracy: 0.8125Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6956 - accuracy: 0.5010\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4282 - accuracy: 0.8040\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.2711 - accuracy: 0.9062Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2733 - accuracy: 0.9041\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1730 - accuracy: 0.9358\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.3568 - accuracy: 0.8722Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6917 - accuracy: 0.5141\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.1549 - accuracy: 0.9427Epoch 4/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3709 - accuracy: 0.8468\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2372 - accuracy: 0.9048\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.1393 - accuracy: 0.9524Epoch 7/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1369 - accuracy: 0.9538\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6872 - accuracy: 0.5645\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.1759 - accuracy: 0.9423Epoch 5/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3918 - accuracy: 0.8185\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1750 - accuracy: 0.9306Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1962 - accuracy: 0.9248\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1913 - accuracy: 0.9220\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.4909 - accuracy: 0.7422Epoch 49/50\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.6792 - accuracy: 0.6277Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6779 - accuracy: 0.6591\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1319 - accuracy: 0.9598Epoch 6/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3851 - accuracy: 0.8178\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1792 - accuracy: 0.9413\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1390 - accuracy: 0.9524\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3673 - accuracy: 0.8438Epoch 50/50\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.6654 - accuracy: 0.6979Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6582 - accuracy: 0.6915\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1357 - accuracy: 0.9449Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3641 - accuracy: 0.8447\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9413Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1692 - accuracy: 0.9372\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1547 - accuracy: 0.9413\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6169 - accuracy: 0.7833\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3381 - accuracy: 0.8551\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1851 - accuracy: 0.9206\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.5551 - accuracy: 0.8488Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/steposs: 0.1907 - accuracy: 0.91\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5455 - accuracy: 0.8489\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.3627 - accuracy: 0.8578Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/46 [===============>..............] - ETA: 0s - loss: 0.4715 - accuracy: 0.8900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:28:05,316] Trial 42 finished with value: 0.9449035812672176 and parameters: {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'sgd'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1649 - accuracy: 0.9324\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3279 - accuracy: 0.8627\n",
      "Epoch 12/50\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.4513 - accuracy: 0.8889\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1628 - accuracy: 0.9372\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.3815 - accuracy: 0.9125Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3252 - accuracy: 0.8689\n",
      " 1/46 [..............................] - ETA: 1s - loss: 0.1309 - accuracy: 0.9375Epoch 25/50\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.2182 - accuracy: 0.9354Epoch 1/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.3639 - accuracy: 0.9034\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1320 - accuracy: 0.9524\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.8986Epoch 14/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2768 - accuracy: 0.8986\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3096 - accuracy: 0.9096\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.2096 - accuracy: 0.9424Epoch 12/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2338 - accuracy: 0.9289\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1411 - accuracy: 0.9476\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.2677 - accuracy: 0.9214Epoch 27/50\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.4071 - accuracy: 0.8438Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2671 - accuracy: 0.9220\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2619 - accuracy: 0.8999\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.1536 - accuracy: 0.9411Epoch 28/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1555 - accuracy: 0.9413\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2353 - accuracy: 0.9310\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2699 - accuracy: 0.8834\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1321 - accuracy: 0.9482\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2085 - accuracy: 0.9406\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1270 - accuracy: 0.9538\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3493 - accuracy: 0.8475\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1994 - accuracy: 0.9358Epoch 30/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2027 - accuracy: 0.9337\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1241 - accuracy: 0.9538\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2588 - accuracy: 0.8972\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1900 - accuracy: 0.9406\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1608 - accuracy: 0.9301Epoch 17/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1488 - accuracy: 0.9331\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.2671 - accuracy: 0.8968Epoch 20/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2631 - accuracy: 0.8992\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1717 - accuracy: 0.9476\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.1299 - accuracy: 0.9479Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1154 - accuracy: 0.9586\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.2477 - accuracy: 0.8990Epoch 21/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2425 - accuracy: 0.9034\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.1078 - accuracy: 0.9531Epoch 33/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1610 - accuracy: 0.9455\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1476 - accuracy: 0.9365\n",
      "21/46 [============>.................] - ETA: 0s - loss: 0.1529 - accuracy: 0.9568Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2870 - accuracy: 0.8827\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1612 - accuracy: 0.9476\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.2420 - accuracy: 0.8979Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1057 - accuracy: 0.9655\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2225 - accuracy: 0.9151\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1470 - accuracy: 0.9507Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1539 - accuracy: 0.9476\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0966 - accuracy: 0.9703\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2694 - accuracy: 0.8903\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1474 - accuracy: 0.9579\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1073 - accuracy: 0.9662\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.1433 - accuracy: 0.9648Epoch 25/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1924 - accuracy: 0.9358\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1110 - accuracy: 0.9643Epoch 37/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1450 - accuracy: 0.9476\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0923 - accuracy: 0.9676\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.1158 - accuracy: 0.9659Epoch 26/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2909 - accuracy: 0.8834\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.0921 - accuracy: 0.9570Epoch 38/50\n",
      "46/46 [==============================] - 6s 11ms/step - loss: 0.6900 - accuracy: 0.5362\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.1419 - accuracy: 0.9527Epoch 2/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1380 - accuracy: 0.9565\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0953 - accuracy: 0.9627\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.2640 - accuracy: 0.8906Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2608 - accuracy: 0.8923\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6626 - accuracy: 0.6259\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.2100 - accuracy: 0.9199Epoch 3/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1374 - accuracy: 0.9565\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.1948 - accuracy: 0.9260Epoch 25/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1865 - accuracy: 0.9310\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1150 - accuracy: 0.9593\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6152 - accuracy: 0.6701\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.2496 - accuracy: 0.8969Epoch 4/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1310 - accuracy: 0.9558\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1081 - accuracy: 0.9627\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3121 - accuracy: 0.8737\n",
      "Epoch 41/50\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5536 - accuracy: 0.7874\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1313 - accuracy: 0.9551\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0975 - accuracy: 0.9634\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9413Epoch 30/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1652 - accuracy: 0.9413\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1150 - accuracy: 0.9614Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4825 - accuracy: 0.8150\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.1844 - accuracy: 0.9375Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1245 - accuracy: 0.9614\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.1697 - accuracy: 0.9408Epoch 28/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0982 - accuracy: 0.9600\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1653 - accuracy: 0.9406\n",
      "Epoch 31/50\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3811 - accuracy: 0.9013\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1285 - accuracy: 0.9510\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3184 - accuracy: 0.8750Epoch 29/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2324 - accuracy: 0.9006\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.1304 - accuracy: 0.9594Epoch 44/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0917 - accuracy: 0.9669\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.1372 - accuracy: 0.9544Epoch 32/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1328 - accuracy: 0.9510\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.3054 - accuracy: 0.9153Epoch 30/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3053 - accuracy: 0.9158\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0906 - accuracy: 0.9676\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9424Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1628 - accuracy: 0.9427\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.2575 - accuracy: 0.9391Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1291 - accuracy: 0.9572\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2571 - accuracy: 0.9248\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.1648 - accuracy: 0.9422Epoch 9/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1581 - accuracy: 0.9462\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1151 - accuracy: 0.9630Epoch 46/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1122 - accuracy: 0.9607\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1811 - accuracy: 0.9062Epoch 34/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1219 - accuracy: 0.9620\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2271 - accuracy: 0.9241\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1613 - accuracy: 0.9427\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.2150 - accuracy: 0.9135Epoch 47/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0748 - accuracy: 0.9738\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.3590 - accuracy: 0.8125Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1192 - accuracy: 0.9572\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2032 - accuracy: 0.9262\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.2159 - accuracy: 0.9054Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2111 - accuracy: 0.9103\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.1112 - accuracy: 0.9561Epoch 48/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1125 - accuracy: 0.9545\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.1117 - accuracy: 0.9600Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1185 - accuracy: 0.9565\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1817 - accuracy: 0.9434\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2574 - accuracy: 0.9027\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.1195 - accuracy: 0.9557Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0779 - accuracy: 0.9731\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1172 - accuracy: 0.9565\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1741 - accuracy: 0.9434\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 0.1604 - accuracy: 0.9403Epoch 13/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1587 - accuracy: 0.9406\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.0889 - accuracy: 0.9704Epoch 50/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1003 - accuracy: 0.9641\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1137 - accuracy: 0.9607\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1343 - accuracy: 0.9375Epoch 36/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1673 - accuracy: 0.9455\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1784 - accuracy: 0.9337\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1174 - accuracy: 0.9558\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1089 - accuracy: 0.9676\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.1125 - accuracy: 0.9464Epoch 37/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1708 - accuracy: 0.9427\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.0947 - accuracy: 0.9647Epoch 15/50\n",
      "12/12 [==============================] - 0s 6ms/steposs: 0.1042 - accuracy: 0.\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0853 - accuracy: 0.9696\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1537 - accuracy: 0.9554Epoch 40/50\n",
      "45/46 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9646"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:28:18,462] Trial 43 finished with value: 0.8953168044077136 and parameters: {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'sgd'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1059 - accuracy: 0.9648\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1505 - accuracy: 0.9563Epoch 38/50\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1495 - accuracy: 0.9581"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1461 - accuracy: 0.9579\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.1116 - accuracy: 0.9563Epoch 16/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1187 - accuracy: 0.9531\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1125 - accuracy: 0.9586\n",
      "Epoch 39/50\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.1506 - accuracy: 0.9482Epoch 1/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1521 - accuracy: 0.9496\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0790 - accuracy: 0.9731\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1434 - accuracy: 0.9438Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1125 - accuracy: 0.9579\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1330 - accuracy: 0.9510\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0830 - accuracy: 0.9703\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1068 - accuracy: 0.9655\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.1150 - accuracy: 0.9519Epoch 41/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1446 - accuracy: 0.9531\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0885 - accuracy: 0.9655\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1236 - accuracy: 0.9622Epoch 44/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1028 - accuracy: 0.9648\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1289 - accuracy: 0.9593\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.1247 - accuracy: 0.9622Epoch 20/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0799 - accuracy: 0.9696\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1050 - accuracy: 0.9641\n",
      "29/46 [=================>............] - ETA: 0s - loss: 0.1369 - accuracy: 0.9547Epoch 43/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1303 - accuracy: 0.9579\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.0781 - accuracy: 0.9743Epoch 21/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0742 - accuracy: 0.9745\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1060 - accuracy: 0.9614\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.1215 - accuracy: 0.9579Epoch 44/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1257 - accuracy: 0.9586\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0813 - accuracy: 0.9724\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.0969 - accuracy: 0.9695Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0975 - accuracy: 0.9689\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.1144 - accuracy: 0.9688Epoch 45/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1301 - accuracy: 0.9551\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.0924 - accuracy: 0.9646Epoch 23/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0847 - accuracy: 0.9641\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1044 - accuracy: 0.9645Epoch 48/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0993 - accuracy: 0.9641\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.1159 - accuracy: 0.9595Epoch 46/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.1162 - accuracy: 0.9627\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.0855 - accuracy: 0.9653Epoch 24/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0804 - accuracy: 0.9689\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.1195 - accuracy: 0.9567Epoch 49/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1105 - accuracy: 0.9551\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.0995 - accuracy: 0.9661Epoch 47/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1197 - accuracy: 0.9579\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0886 - accuracy: 0.9669\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1377 - accuracy: 0.9503\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.1181 - accuracy: 0.9577Epoch 48/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1185 - accuracy: 0.9572\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.0649 - accuracy: 0.9783Epoch 26/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0733 - accuracy: 0.9731\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1024 - accuracy: 0.9634\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1139 - accuracy: 0.9627\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0943 - accuracy: 0.9717\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 7ms/steposs: 0.1099 - accuracy: 0.95\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.0988 - accuracy: 0.9604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:28:24,368] Trial 44 finished with value: 0.9366391184573003 and parameters: {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1104 - accuracy: 0.9655\n",
      "Epoch 28/50\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.1009 - accuracy: 0.9621"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0972 - accuracy: 0.9641\n",
      "46/46 [==============================] - 6s 10ms/step - loss: 0.6945 - accuracy: 0.5045\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1086 - accuracy: 0.9648\n",
      "Epoch 2/50\n",
      "Epoch 29/50\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 0.1014 - accuracy: 0.9688Epoch 1/50\n",
      "12/12 [==============================] - 0s 8ms/steposs: 0.6902 - accuracy: 0.53\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.1010 - accuracy: 0.9665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:28:25,313] Trial 45 finished with value: 0.9393939393939394 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5438\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1017 - accuracy: 0.9676\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6725 - accuracy: 0.8125Epoch 30/50\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1064 - accuracy: 0.9557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (10, 10) which is of type tuple.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6717 - accuracy: 0.6542\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0995 - accuracy: 0.9662\n",
      "Epoch 31/50\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.1013 - accuracy: 0.9635Epoch 1/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.6406 - accuracy: 0.6901\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.1145 - accuracy: 0.9607\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5942 - accuracy: 0.7543\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.0999 - accuracy: 0.9676\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.5359 - accuracy: 0.8259Epoch 33/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4984 - accuracy: 0.8468\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1068 - accuracy: 0.9586\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.3930 - accuracy: 0.8867Epoch 34/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3652 - accuracy: 0.8896\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.1064 - accuracy: 0.9669\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2877 - accuracy: 0.9103\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1093 - accuracy: 0.9607\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2402 - accuracy: 0.9227\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.0924 - accuracy: 0.9688Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1006 - accuracy: 0.9655\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.2718 - accuracy: 0.8854Epoch 37/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2387 - accuracy: 0.9048\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.0954 - accuracy: 0.9676\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 11ms/step - loss: 0.2077 - accuracy: 0.9282\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.1004 - accuracy: 0.9665Epoch 12/50\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 0.0882 - accuracy: 0.9703\n",
      "20/46 [============>.................] - ETA: 0s - loss: 0.1763 - accuracy: 0.9453Epoch 39/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1929 - accuracy: 0.9351\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0885 - accuracy: 0.9676\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.1799 - accuracy: 0.9470Epoch 40/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1771 - accuracy: 0.9455\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0940 - accuracy: 0.9655\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1707 - accuracy: 0.9441\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 6s 9ms/step - loss: 0.6934 - accuracy: 0.5086\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0843 - accuracy: 0.9689\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1564 - accuracy: 0.9531\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.6747 - accuracy: 0.6250Epoch 16/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6871 - accuracy: 0.5549\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.0827 - accuracy: 0.9748Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0793 - accuracy: 0.9745\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 6s 10ms/step - loss: 0.6777 - accuracy: 0.5845\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1579 - accuracy: 0.9427\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.6744 - accuracy: 0.6074Epoch 17/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6724 - accuracy: 0.6080\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.1406 - accuracy: 0.9643Epoch 4/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.6501 - accuracy: 0.6301\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0809 - accuracy: 0.9731\n",
      "13/46 [=======>......................] - ETA: 0s - loss: 0.6520 - accuracy: 0.7163Epoch 44/50\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1572 - accuracy: 0.9441\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.6416 - accuracy: 0.7012\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0807 - accuracy: 0.9703\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5695 - accuracy: 0.7681\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.6174 - accuracy: 0.7589Epoch 4/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1428 - accuracy: 0.9476\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.5769 - accuracy: 0.7992\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.4628 - accuracy: 0.8489\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0924 - accuracy: 0.9655\n",
      "Epoch 5/50\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1425 - accuracy: 0.9531\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4719 - accuracy: 0.8516\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1002 - accuracy: 0.9641\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3602 - accuracy: 0.8903\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.4078 - accuracy: 0.8479Epoch 6/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1425 - accuracy: 0.9496\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3578 - accuracy: 0.8868\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.0816 - accuracy: 0.9729Epoch 8/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0787 - accuracy: 0.9710\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3090 - accuracy: 0.8896\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 0.3082 - accuracy: 0.8984Epoch 7/50\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1298 - accuracy: 0.9575Epoch 48/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.1313 - accuracy: 0.9572\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.2845 - accuracy: 0.9020\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.1311 - accuracy: 0.9567Epoch 9/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2600 - accuracy: 0.9096\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 0.1295 - accuracy: 0.9557Epoch 8/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0732 - accuracy: 0.9772\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.1300 - accuracy: 0.9557Epoch 49/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1320 - accuracy: 0.9558\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 0.0468 - accuracy: 0.9821Epoch 23/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2327 - accuracy: 0.9262\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.2183 - accuracy: 0.9303\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.0797 - accuracy: 0.9725Epoch 9/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1259 - accuracy: 0.9572\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.0773 - accuracy: 0.9731\n",
      "Epoch 24/50\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2189 - accuracy: 0.9248\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2079 - accuracy: 0.9262\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.2031 - accuracy: 0.9250Epoch 10/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.0718 - accuracy: 0.9765\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1251 - accuracy: 0.9565\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.2712 - accuracy: 0.8938Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2123 - accuracy: 0.9213\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.2063 - accuracy: 0.9255Epoch 12/50\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2020 - accuracy: 0.9275\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.1289 - accuracy: 0.9517\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 6ms/steposs: 0.1834 - accuracy: 0.\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1836 - accuracy: 0.9398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:28:36,022] Trial 46 finished with value: 0.9559228650137741 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1772 - accuracy: 0.9434\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1927 - accuracy: 0.9275\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 0.1279 - accuracy: 0.9544Epoch 12/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1332 - accuracy: 0.9524\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1665 - accuracy: 0.9488Epoch 27/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1601 - accuracy: 0.9496\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1871 - accuracy: 0.9331\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 0.1620 - accuracy: 0.9412Epoch 13/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1152 - accuracy: 0.9607\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1700 - accuracy: 0.9350Epoch 28/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1670 - accuracy: 0.9420\n",
      "25/46 [===============>..............] - ETA: 0s - loss: 0.1474 - accuracy: 0.9525Epoch 15/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1636 - accuracy: 0.9427\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 0.1186 - accuracy: 0.9583Epoch 14/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1228 - accuracy: 0.9551\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.1468 - accuracy: 0.9489Epoch 29/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1532 - accuracy: 0.9489\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1683 - accuracy: 0.9427\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.9545\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.1732 - accuracy: 0.9297Epoch 30/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.9517\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1473 - accuracy: 0.9427\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 0.1108 - accuracy: 0.9611Epoch 16/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1076 - accuracy: 0.9620\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1357 - accuracy: 0.9531\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.1668 - accuracy: 0.9427Epoch 18/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1450 - accuracy: 0.9482\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1048 - accuracy: 0.9696\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1321 - accuracy: 0.9586\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.1404 - accuracy: 0.9514Epoch 19/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1446 - accuracy: 0.9441\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1061 - accuracy: 0.9676\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 0.1550 - accuracy: 0.9410Epoch 33/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1341 - accuracy: 0.9524\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.1530 - accuracy: 0.9375Epoch 20/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.1447 - accuracy: 0.9455\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.9565\n",
      "Epoch 19/50\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1267 - accuracy: 0.9538\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.1150 - accuracy: 0.9688Epoch 21/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.9489\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.1402 - accuracy: 0.9527Epoch 20/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1158 - accuracy: 0.9565\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1366 - accuracy: 0.9510\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1357 - accuracy: 0.9510\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1216 - accuracy: 0.9586\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 0.1184 - accuracy: 0.9643Epoch 36/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1259 - accuracy: 0.9607\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1215 - accuracy: 0.9648\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9676\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0858 - accuracy: 0.9688Epoch 37/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1155 - accuracy: 0.9586\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 0.9669\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1313 - accuracy: 0.9496\n",
      "Epoch 38/50\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1267 - accuracy: 0.9496\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9648\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1330 - accuracy: 0.9489\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.1203 - accuracy: 0.9375Epoch 24/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9572\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1117 - accuracy: 0.9600\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1186 - accuracy: 0.9579\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1666 - accuracy: 0.9344\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9614\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1252 - accuracy: 0.9558\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1235 - accuracy: 0.9545\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0958 - accuracy: 0.9703\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1186 - accuracy: 0.9579\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.9641\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9710\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1104 - accuracy: 0.9614\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0955 - accuracy: 0.9669\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1105 - accuracy: 0.9579\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.0832 - accuracy: 0.9701Epoch 44/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1248 - accuracy: 0.9545\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.3269 - accuracy: 0.7812Epoch 29/50\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.0947 - accuracy: 0.9655\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1458 - accuracy: 0.9393\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9662\n",
      "Epoch 45/50\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1005 - accuracy: 0.9627\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1201 - accuracy: 0.9558\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9710Epoch 31/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0945 - accuracy: 0.9710\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0742 - accuracy: 0.9688Epoch 46/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0904 - accuracy: 0.9641\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.0979 - accuracy: 0.9651Epoch 33/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.9683\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.9614\n",
      "Epoch 32/50\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0937 - accuracy: 0.9689\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0885 - accuracy: 0.9703\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9648\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0336 - accuracy: 1.0000Epoch 33/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9710\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 0.0889 - accuracy: 0.9766Epoch 35/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0875 - accuracy: 0.9745\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0992 - accuracy: 0.9641\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.0933 - accuracy: 1.0000Epoch 34/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.1116 - accuracy: 0.9531\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9724\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.0968 - accuracy: 0.9618Epoch 50/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0974 - accuracy: 0.9669\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0849 - accuracy: 0.9710\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.0917 - accuracy: 0.9707Epoch 37/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.9572\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9662\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9641\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9538\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.0823 - accuracy: 0.9699Epoch 37/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9634\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9572\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9586\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.9303\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 0.9607\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9496\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9689\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9689\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9724\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.0962 - accuracy: 0.9662\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 5ms/steposs: 0.0745 - accuracy: 0.\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:28:45,412] Trial 47 finished with value: 0.9614325068870524 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9676\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0804 - accuracy: 0.9689\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9717\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0838 - accuracy: 0.9717\n",
      "27/46 [================>.............] - ETA: 0s - loss: 0.0910 - accuracy: 0.9722Epoch 46/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.9689\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9731\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 0.0810 - accuracy: 0.9677Epoch 47/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0820 - accuracy: 0.9689\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9745\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9627\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9655\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9662\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.9696\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9607\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 0.0999 - accuracy: 0.9665Epoch 49/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9662\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0830 - accuracy: 0.9717\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0838 - accuracy: 0.9717\n",
      "12/12 [==============================] - 1s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:28:47,459] Trial 48 finished with value: 0.9559228650137741 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:28:47,833] Trial 49 finished with value: 0.9559228650137741 and parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'optimizer': 'adam'}. Best is trial 18 with value: 0.9724517906336089.\n"
     ]
    }
   ],
   "source": [
    "# objective function to be minimized\n",
    "import random\n",
    "import optuna\n",
    "def objective_fun(trial):\n",
    "    \n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid'])\n",
    "    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes',[(100, 100, 100), (50, 50, 50), (10, 10, 10), \n",
    "                                  (100, 50, 10), (10, 10, 10), (10, 10)])\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0.001, 1)\n",
    "    optimizer = trial.suggest_categorical('optimizer', ['adam', 'sgd'])\n",
    "#     epochs = trial.suggest_int('epochs', 10, 200,10)\n",
    "    par = {'n_features_in_': X.shape[1], 'n_classes_': len(np.unique(y))}                                      \n",
    "                                          \n",
    "    net = KerasClassifier(model=build_model(par, hidden_layer_sizes, activation, optimizer ))\n",
    "    \n",
    "    net.fit(X_train, y_train, epochs=50)\n",
    "    y_pred = net.predict(X_val).astype(int)\n",
    "\n",
    "    error = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective_fun, n_trials = 50, n_jobs = -1, catch=(ValueError,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 2s 9ms/step - loss: 0.6805 - accuracy: 0.5749 - val_loss: 0.6438 - val_accuracy: 0.7493\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.7315 - val_loss: 0.5242 - val_accuracy: 0.8815\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8592 - val_loss: 0.3669 - val_accuracy: 0.8127\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.8979 - val_loss: 0.2135 - val_accuracy: 0.9229\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.2389 - accuracy: 0.9103 - val_loss: 0.1676 - val_accuracy: 0.9366\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1823 - accuracy: 0.9344 - val_loss: 0.1544 - val_accuracy: 0.9477\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9337 - val_loss: 0.1455 - val_accuracy: 0.9504\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.9420 - val_loss: 0.1431 - val_accuracy: 0.9504\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1561 - accuracy: 0.9455 - val_loss: 0.1717 - val_accuracy: 0.9256\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.9462 - val_loss: 0.1270 - val_accuracy: 0.9504\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9572 - val_loss: 0.1537 - val_accuracy: 0.9421\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9406 - val_loss: 0.3221 - val_accuracy: 0.8457\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1308 - accuracy: 0.9482 - val_loss: 0.1517 - val_accuracy: 0.9311\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1344 - accuracy: 0.9455 - val_loss: 0.1121 - val_accuracy: 0.9559\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1375 - accuracy: 0.9462 - val_loss: 0.3564 - val_accuracy: 0.8540\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1469 - accuracy: 0.9427 - val_loss: 0.1301 - val_accuracy: 0.9504\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9648 - val_loss: 0.1190 - val_accuracy: 0.9532\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9538 - val_loss: 0.1412 - val_accuracy: 0.9504\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9641 - val_loss: 0.1130 - val_accuracy: 0.9532\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9593 - val_loss: 0.2096 - val_accuracy: 0.9229\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1017 - accuracy: 0.9689 - val_loss: 0.1237 - val_accuracy: 0.9532\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9586 - val_loss: 0.1161 - val_accuracy: 0.9587\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1497 - accuracy: 0.9379 - val_loss: 0.1121 - val_accuracy: 0.9532\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1136 - accuracy: 0.9572 - val_loss: 0.1470 - val_accuracy: 0.9394\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9600 - val_loss: 0.2174 - val_accuracy: 0.9201\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.9593 - val_loss: 0.1157 - val_accuracy: 0.9532\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0927 - accuracy: 0.9648 - val_loss: 0.1262 - val_accuracy: 0.9532\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 0.9731 - val_loss: 0.1331 - val_accuracy: 0.9421\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9724 - val_loss: 0.1085 - val_accuracy: 0.9614\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9696 - val_loss: 0.1291 - val_accuracy: 0.9477\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.9683 - val_loss: 0.1456 - val_accuracy: 0.9421\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9717 - val_loss: 0.1198 - val_accuracy: 0.9532\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9745 - val_loss: 0.2774 - val_accuracy: 0.9063\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9517 - val_loss: 0.3078 - val_accuracy: 0.8760\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9420 - val_loss: 0.1097 - val_accuracy: 0.9532\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9676 - val_loss: 0.1372 - val_accuracy: 0.9477\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9779 - val_loss: 0.1152 - val_accuracy: 0.9642\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 0.9689 - val_loss: 0.1418 - val_accuracy: 0.9559\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0782 - accuracy: 0.9696 - val_loss: 0.1277 - val_accuracy: 0.9532\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9683 - val_loss: 0.2478 - val_accuracy: 0.9063\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1037 - accuracy: 0.9614 - val_loss: 0.1043 - val_accuracy: 0.9614\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0879 - accuracy: 0.9696 - val_loss: 0.1205 - val_accuracy: 0.9587\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9827 - val_loss: 0.1208 - val_accuracy: 0.9504\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9752 - val_loss: 0.1198 - val_accuracy: 0.9587\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9614 - val_loss: 0.1695 - val_accuracy: 0.9339\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1814 - accuracy: 0.9255 - val_loss: 0.1207 - val_accuracy: 0.9532\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9683 - val_loss: 0.0941 - val_accuracy: 0.9614\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9814 - val_loss: 0.1020 - val_accuracy: 0.9614\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9855 - val_loss: 0.1041 - val_accuracy: 0.9642\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9779 - val_loss: 0.1410 - val_accuracy: 0.9559\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "{'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'optimizer': 'adam'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       309\n",
      "           1       0.89      0.95      0.92       308\n",
      "\n",
      "    accuracy                           0.92       617\n",
      "   macro avg       0.92      0.92      0.92       617\n",
      "weighted avg       0.92      0.92      0.92       617\n",
      "\n",
      "Accuracy 0.9173419773095624\n",
      "F1-score [0.9148581  0.91968504]\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "par = {'n_features_in_': X.shape[1], 'n_classes_': len(np.unique(y))}   \n",
    "\n",
    "net = KerasClassifier(model=build_model(par, **best_params), epochs=50)\n",
    "net.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)), \n",
    "        validation_split = 0.2)\n",
    "\n",
    "y_pred_test = net.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(best_params)\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred_test))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred_test, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAADrCAYAAAAhW/5oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8wklEQVR4nO3dd1yV5f/48dc5TBFx7zIVFa3cigrm3ouhSebem9Ryz0yLjxbOzEzSrMxPDlJz416AGh/UEjUpEEVxy17n+v3Bj/sriQpo53a8n4+Hj4fnHtf9vjmHN9e51m1QSimEEEKYjVHvAIQQ4lUjiVcIIcxMEq8QQpiZJF4hhDAzSbxCCGFmkniFEMLMJPEKIYSZSeIVQggzk8QrhBBmJolXCCHMTJfEm56eTocOHfS4tBBC6E6XxGthYUGRIkVITEzU4/JCCKErS70uXK5cOXr06EG7du2ws7PTtvfp00evkIQQwix0S7xKKapVq0ZERIReIQghhC4MsiykEEKYl2413rS0NFavXs2xY8cAaNy4MX369MHSUreQhBDCLHTLcj4+PkRGRvL+++8DsGHDBq5evcq0adP0CkkIIcxCt8QbFBTE5s2bMRozBlY0a9YMDw8PvcIRQgiz0XUChclk0v4vTc1CiFeFbjXexo0bM2DAADw9PQH45ZdfeOedd/QKRwghzEa3UQ0mk4l169YRGBgIQKNGjfDy8tKaHoQQ4mWl+3CyzMsbDAY9wxBCCLPRrXp5/fp1Bg8eTM2aNalZsyZDhw4lJiZGr3CEEMJsdEu8M2fOpG7duhw5coQjR45Qt25dZsyYoVc4QghhNrol3ujoaIYNG4aDgwMODg4MGTKE6OhovcIRQgiz0S3xKqW4ceOG9vrGjRsypEwI8UrQbTjZgAED8PDw0IaQHT58mAkTJugVjhBCmI2uoxouXLhAcHAwAA0aNKBy5cp6hSKEEGaj+3AyIYR41Zi9qaFFixaPHbO7d+9eM0YjhBDmZ/bE+/XXXwOwbds2rly5gpeXFwDr16+nTJky5g5HCCHMTremhq5du7Jx40bttVKKbt26ZdkmhBAvI92Gk8XFxZGQkKC9TkhIIC4uTq9whBDCbHQbTtapUye8vLxo164dADt37qRz5856hSOEEGaj66iGgwcPcvz4cSBjdbKmTZvqFYoQQpiNDCcTQggzk8VvhRDCzCTxCiGEmUniFUIIM9Mt8aalpfHtt98yc+ZMACIjI7WONiGEeJnplnhnz55NeHi4tkhOoUKFmD9/vl7hCCGE2eiWeENDQ5kzZw42NjYAODg4kJaWplc4ZuHk5ISTkxPjx4/XtvXu3RsnJycOHTqkS0xLlizBycmJJUuWPPOyo6KiWLJkCZs2bXrmZT9KixYtcHJyIioqymzXzM5nn32Gs7MzTk5OjB079qnKyvzcPO8CAgJYsmQJ586de+xxUVFRODk50aJFCzNF9vzRbQJFZsLNlJ6e/soshP7rr78yZMiQf30ZzLS0NCwtdXuLuXLlCkuXLsXZ2RlPT89/9VpKqefm83Pr1i1Wr16NnZ0dPj4+lC9f/qnK8/X1fTaB/csCAgLw9/enbNmyVKtWLdtj0tLSKFKkCL6+vuTLl8/MET4/dKvxOjk5sXnzZkwmExEREcycORNnZ2e9wjGr/Pnzs3Dhwmz3XblyhQ8++AAXFxfq1avHoEGDuHTpEgCbNm3KUoMKCgrCycmJ3r17A/9Xex0zZgzvvfcetWrVAmDy5Mm4uLjw9ttv4+rqyqRJk3I8PTuzBunr60vLli2pX78+S5cu1fafP3+eQYMG4ezsTIMGDfjggw+4fv06QUFB9OnTB4Dg4GCcnJyYNGkS06dPx8nJicOHD6OUolGjRtSrVw+TyaTdT+aC+GFhYQwcOJD69evTsGFDRo4cSWRkZJafxcCBAxkwYAC1atXi6tWrWWI/ffo09evXp3HjxoSFhT10b8nJySxcuJDWrVtTvXp1mjZtytGjR3N17cGDB1OnTh08PT2JiIggKioKFxcXIGMa/KRJkzhy5Ij23nz++edZypg0aRKQMZmoc+fO1KhRg9q1a+Pu7s7FixcBGDduHOPGjdPi3rVrFx4eHtSqVYtmzZoxd+5c4uPjAZg0aRJOTk5Mnz4dT09PateuzciRI0lOTn7s++vj40PTpk1p3LgxO3fu5NNPP6V27dq0bduW0NBQIKMfxt3dndq1a1OjRg3atWvH+vXrtev6+/sDGZ83JycngoKCtHimTp2Km5sb7du35/bt24wbN445c+YAMGPGDJycnFi9ejUmk4nevXtTtWpV3b4FmoNuiXfSpEmcOnWKmzdv0qNHD4xGIx9++KFe4ZjVgAEDCAgI4PTp01m2p6enM2zYMA4ePIiHhwf9+vXjzJkzDB48mJSUlByXv3fvXpo1a6YlsCpVquDt7c3kyZNp2LAh/v7+fPPNN7mK+eTJk/Tv35+UlBSWLl3K5cuXiY2NZeDAgfz+++/06tULLy8v9u3bxwcffEClSpUYMWIEAI6Ojvj6+tKjRw8tKZ08eZKLFy9y+/ZtYmNj+eOPPwgKCgLAxcWF+/fvM3DgQI4fP86AAQPo3r07AQEBDBkyhNTUVC2uo0eP8uabbzJp0iQKFCigbQ8NDaV///44ODiwdu1aqlat+tA9zZs3j6+++oqCBQsyY8YM3nvvPUwmU46vHRgYSL169XB2dub333/nq6++okiRIkybNg2AwoUL4+vrS9u2bZ/48/X19eXy5ctMnjyZCRMmULNmzWyb3k6dOsWYMWO4ceMGEydO5O2332bNmjVaEst04MAB3n33XUqVKkVAQADbtm177PXPnTvHu+++y40bNxg7diwxMTF4enry999/a38sLCwsaNOmDVOmTOGDDz7AaDQyY8YMwsPD6dGjB/Xr1wfgvffew9fXl0qVKmnl79mzB09PT4YMGfLQtadOnUrVqlXx9fVl5syZBAcHM3ToUJo0afLEn9uLSrfvofnz52f27NnMnj1brxB006tXL3766ScWLFiQZfvff//NhQsXAFi5cqW2/e7du/z55585Lr9z584MGzYMAJPJRGRkJL/88kuWRYl+//33XMU8adIkatSowa+//kpISAiXL18mPDxce27el19+qR0bEhKCpaUlDRs2ZNmyZRQtWpSOHTsC8MYbb2A0GgkODqZ48eKUK1cOGxsbTpw4oXW0NmrUiJCQEG7evImrqyvDhw8HYP/+/Vy4cEGrCULGk0s++uijh+KdOHEiRYsW5aeffqJEiRLZ3tOOHTsAWLBgAa+//rq2/eDBgzm6tqurK0OHDuXo0aPs37+fiIgI7OzsaN68OXPmzMHOzk677127dj325+vo6EhYWBgHDx7EycmJli1bZvvHYu/evZhMJnr16kWPHj1o164de/bsYc+ePXz22WfacX379qVHjx5cu3aN5cuXExER8djrjxkzhrfffpslS5ZgMpmYMmUKSUlJ/PDDD9q5ycnJHDx4kNOnT2MymbRzw8LC6NChA6+99honTpygZs2a2n0/GE/fvn0BHmp/t7GxYeHChXh6evLzzz9Tr149vL29Hxvvi06/BkAyaiWRkZGkp6dr29zd3fULyExsbGwYMWIEs2bNylJLy1SmTBnmzp2rvTaZTJQtW1b7pc/8ed27dy/b8kuXLq39/9ixY6xdu5Zy5coxceJErl27xieffPLIr56PUqRIEQCsrKwAstTGqlevnuWrsMlkwtbWNtsF7wsVKkS1atU4c+YMBQoUoH79+tja2nLo0CFCQ0NxdHSkZMmS2TYNPOleH1S8eHGio6M5cOAA3bt3z/F95kbmzySzHf3Bz/E/WVhYZDnmn+/dvHnz6NChA2fPnuX48eMsX76cqVOnas01j/KohwrkJjbI6NzOfG8BChYsqH3Lyjz3yy+/5H//+x+enp507NiRH374gf3795OUlPTYWODR71OmO3fuaNe7ffs2ycnJ2NnZPfacF5luTQ0zZ85k3Lhx7Nq1i3379rFv3z7279+vVzhm161bN8qVK0dsbKy2rXz58lSpUoWrV6+ye/durl27xsmTJ5k1axYFCxakXLlyAPz222/s2rWLFStW5Ph6ycnJ3Lp1i507dz6ze6hTpw7Fixfn999/JygoiOjoaI4ePcqSJUuwsbGhYMGCQEZNfvPmzVpbtaurK6mpqRw6dAhnZ2ecnZ05duwYKSkpWlNE7dq1KVasGEFBQXz99dcsWLCACxcuUKFChRx1Si5atIgKFSowY8YMNmzYkO0xmSvjjR07lvXr17N8+XIOHTr01NfOTuZ7d/jwYXbt2sWPP/6YZb+Pjw9///035cuXp2LFigBER0c/VE6rVq0wGo38+OOPrFu3jhkzZgDQunXrPMWVF7GxsYSHh3Pq1Kks2zPf74MHD7Jt27Yc/3G/e/cu48aNw87OjtGjRxMeHs6sWbOeddjPFd0S7/Hjx9m+fTtLly5l8eLFLF68mEWLFukVjtlZWVkxevToLNssLCxYvnw5HTt2ZM+ePcyaNYtff/01SzLq2bMnCQkJ+Pr6Urt27Sdex9XVFS8vL2JjY1m+fDmNGzd+ZvdQoEAB/Pz8aNKkCevWreOTTz7hwIEDWrxVqlShU6dOxMbGMmHCBO2xTpn7lVLUr18fZ2dnrbbUqFEjIKMG5ufnR4MGDVi5ciXr1q2jZcuWrFixIkvN7FGKFCnC6tWrKVu2LNOnT9c6fh40YcIEhg4dyt27d/n4449Zu3YtFhYWT33t7LRt25a2bdty5coVli1bRoMGDR465ocffmDatGkEBATQvHlz+vfv/9AxderUYeHChRQtWhQfHx9CQ0Pp3bu31q78bxo1ahRvvfUWBw8e1PoRHtStWzcqVarEnj17GDduHPfv339imUopJk2aRHR0NB9//DGjRo2iffv2bN68Weu4exnptjpZz549+eGHHx779UQIIV5GZk+8mbWekydPEhUVRfv27bOM6W3ZsqU5wxFCCLMze+LNHHOaHYPBwJo1a8wYjRBCmJ8shC6EEGamW+dat27dcrRNCCFeNrol3n+OK0xNTdWmPQohxMvM7BMoVqxYwTfffENCQkKWtRmSkpJeickTQghh9jbe2NhY7t27x6xZs/j444+17fb29toA7KdheP/fXfFLvHxurTqmdwjiBVPEpvhTnf/Sda5J4hW5JYlX5NbTJl555poQQpiZJF4hhDAzSbxCCGFmuiXe7t27s3Xr1iwLSwshxKtAt8Tr7e3Njh07aNGiBQsXLuT69et6hSKEEGalW+Jt3Lgxy5Yt47///S8mk4muXbvi7e390BqfQgjxstG9jff+/fvcvHkTo9FIiRIl+OSTT17JxwEJIV4duj36Z9u2bXz//ffEx8fTu3dvZsyYga2tLenp6bRu3VpbWV8IIV42uiXerVu34u3trT2NIJOFhYVZVtMXQgi96D5z7dq1axgMBkqWLPlMypOZayK3ZOaayK2nnbmmW403LCyMsWPHcvPmTQwGA8WKFcPX1zfbR1oLIcTLRLfOtalTp+Lt7c2JEycIDg7G29ubqVOn6hWOEEKYjS6JNz09nVu3btG+fXttW7t27UhJSdEjHCGEMCtdEq+FhQUJCQkEBQVp24KDg3n77bf1CEcIIczK7G287u7uGAwGlFL06dOH119/HYCoqCgqV5aOMSHEy8/sNd4pU6YwefJkChQogNFoJDU1FaPRSLly5UhOTjZ3OEIIYXZmr/FmPu7Hx8fH3JcWQojngm7DyTITcObiOM9qHK8QQjzvdEu8ly5dwtvbm5iYGABKlSrFwoULcXR01CskIYQwC93G8c6aNYthw4Zx4sQJTpw4wbBhw5g1a5Ze4QghhNnoVuO9du0apUqV4sSJEwCUKFGCGzdukJycjI2NjV5hCSHEv063xHv9+nV69+5NuXLlMBgMREREYGVlRatWrZg/fz4NGzbUKzQhhPhX6dbUUK9ePfLnz0+pUqUoUaIE9vb21K9fn2XLljFv3jy9whJCiH+dbjXemzdvsmfPHkJDQwGoWbMm/fr1o3r16qSlpekVlhBC/Ot0S7xGo5Hg4GDtYZcnTpzAaMyogBsMBr3CeiHZWFmzbvRC3ixbicSUJGLu32b4tzO4dD2SwNkbsLG0BsDSwoK3X69CjYmdOHP5vHZ+1TKOnJrrz4p9/2Xs93P1ug2how+GjuXWzdsYjQbs7OwYO2kMTtWq4NGuG9ZWVtjYZvS79BnYm1btWuoc7YtPt8TboUMHxowZg62tLQDJycmMGzeO+Ph4+vXrp1dYL6wV+/7Ljv8dBGBkm16sHPwpzef0ouGMbtoxXZ3bMdNzVJaka2lhyYpBn+B/co/ZYxbPjznzZ1PAoQAAB/YeZM70uXy/4TsAPpk/mypVZTr/s6Rb4t2xYwfbtm3TmhUsLCwYP348gwcPxsPDQ6+wXkjJqSla0gUIvPg/Puo48KHjBjbrht+BDVm2zfAcxfqgnRSxL0ghO4d/PVbxfMpMugDxcfHyrfNfplviTU9Pp0KFCty4cYP09HQAWavhGfmgXV82n9qbZdtrRUrRtJozvb8ar21zdqxJo8q1aP1pP2Z2HW3uMMVz5uMpn/DbiRAAvvhyvrZ99tQ5KKV4s3o1RnwwjMJFCusV4ktD18Rbs2ZN8uXLh8FgICUlRdbjfQYmuw2jUqk3aDm3T5bt/Zp25deQ/dyKvQNAPmtblg2YRbeFknBFhpmfTgdg2+YdLFv4Fb7LPuerVUspVboUaalpfL10BZ9Mm4vvss91jvTFl+PE+8svv+ToOHd39xwdFx8fT4UKFQgPDwfgrbfeYv78+U84SzzOhx0H4lm/Da0+7UtiSlKWff2bdmX4t//35GbHkuUoV7QM+6d9D0AhOweMBiOF8zvQb/lEs8Ytni8d3dozb8587t29R6nSpQCwtLLEq1d3vDr30Dm6l0OOE++kSZNy1O6T08RbvHhx1q9fT3x8PAD58+fPaSgiG2M79KeHSydafdqXewmxWfa1eKsRlkYL9pw5qm07e/kCJYY10F7P7DqaQnYOMqrhFRR7P5akpGSKlygGwMF9hyhYsCDW1tbE3o/V2n/37AigStUqeob60shx4i1TpkyW19euXcNoNFKoUCHu3r1Lenr6Q8dkJ3OKcNWqVZk9ezYuLi5YW1tr+5s0aZLTkMT/V7ZIKXx7TeHS9Uj2T/0BgOS0FG1Ew8Bm77Lq4EZ0fqC0eE7FxcUz9aPpJCclYzQaKFS4EJ8vncft27eZPG4apnQTSinKvlaGGXOn6R3uSyFPj3dfvXo1GzZsYM2aNRQpUoTbt2/Tu3dvPDw8GDRo0GPP7dq1KwBnz57Ndv/58+ez3Z5T8nh3kVvyeHeRW7o83n3lypW88847FClSJCOIIkWoUaMGq1evfmLi3bhxIwCTJ0+mU6dOuLq6AnDs2DG2bduWl3CEEOKFkqfEazKZ2LFjB5UrV6ZChQpcunSJ7du356qd9uzZs3z22WfaaxcXF3kqhRDilZCnxOvm5saqVauyjEJQSvH+++8/8dxevXrxww8/8Oeff1KnTh0sLTNCSE1NJSkp6QlnCyHEiy9Pq5N99NFHjBs3jnLlymFtbU25cuUYO3YsH3744RPP9fX1BWDhwoXkz58fOzs77OzssLe3Z/HixXkJRwghXih5qvFaWFgwZMgQhgwZkutzS5QoAWQ8+mffvn3aON6KFSvyzTff0Lp167yEJIQQL4w8r8d78OBBhgwZQtu2bbl+/TpLly7l9OnTOT5/z549WFlZ4eTkhJOTE1ZWVuzZIwu1CCFefnmq8e7Zswdvb2+UUhgMBooWLcratWu5ePEiixYteuy5hw8f5vDhw1y/fj1L51psbOxjzhJCiJdHnhLv8uXLcXBwwNHRkZCQECwtLalTp06Oarw2NjY4ODhgNBopUOD/VkQqXbo0I0aMyEs4QgjxQslT4g0PD6dz587Y2toSEpKxmlHRokW5ffv2E891dnbG2dmZVq1aUbVqVVJSUrSZa2FhYXkJRwghXih5auMtXLgwf/31l/Y6NTWVkJAQihUrluMyxo4dS6dOnWjVqhWQMa53wIABeQlHCCFeKHlKvA0aNODkyZPaimVt27bl4sWLNGjQ4PEnArdu3SIsLIyrV68ycOBA7OzsCAsLIzExkfv37+clHCGEeKHkaa2GGzdu4OXlxdWrV7VtJUuW5Oeff6ZkyZKPPfe7777ju+++4+rVq5QpU4aYmBhKlChBgQIFuHfvHgcOHMj1TTxI1moQuSVrNYjcetq1GvKUeAESExPZvXs30dHRlCpVitatW+dqynCTJk3Yu3cv3bt3x9/fn+joaEaOHMmmTZvyEo5GEq/ILUm8Ird0WSSnT58+tGvXLssU4YCAAE6cOMHkyZMfe25CQgJ2dnaMGjWKoUOHcuvWLebNm8f27dvx9vbOSzhCCPFCyVMbb3BwMBEREVm2BQYGsmbNmiee27NnTwBmzJjBsWPHuH79On5+fkRHRzN16tS8hCOEEC+UXNV4ly5dqv0/NDRUe62UYt++fdjY2DyxDH9/f0CGjgkhXl25TrwGgwGDwUBoaCihoaHaPqUU9evXz3FZv/32G/7+/ly5coU7d+6QkJBAsWLF+PHHH3MTkhBCvHBylXjd3d0xGAz4+/vj6OhIjRo1ADAajZQuXRovL68cl9W/f3969uxJx44dmTdvHpUqVcJkMuUueiGEeAHlKvFmLlQeFRVFu3bttPbavFBKMWHCBP773//St29fRowYQZcuXfJcnhBCvCjy1Lk2YcIESpUqRXp6OgDp6ens27fvkc9Ry46VlRUREREcPXo0RxMvhBDiZZGn4WSTJk3C3t6eli1bAhnr8/r5+XH//n22bt362HNHjhyJwWCgcOHCtGnThgIFCmAymVi+fDnXrl3LSzhCCPFCyVPivXz5Mu7u7lm2OTo6snnz5ieem7k2Q8uWLUlMTMTW1haDwUBycrL24EshhHiZ5SnxFixYMEuzglKKs2fP4uDg8MRzPTw8ADh06BBNmjTJsu/QoUN5CUcIIV4oeWrjfeuttzh37hzdu3dn7ty5eHl5ce7cOd5+++0cl7FgwYIcbRNCiJdNnmq83t7eHDt2jNOnT3PmzBmUUlhZWfHBBx888dy//vqL8PBwYmNj2bt3r7Y9NjaWxMTEvIQjhBAvlDwl3jfffJOffvqJH3/8kWvXrlG6dGl69uxJ1apVn3ju//73PzZt2sStW7dYtWoVKSkp2NjYYG9vz6RJk/ISjhBCvFDyvDrZ05o3bx5btmzB0tKSAwcOcPr0adasWcPnn3/+VOUmpSc8owjFqyJfuyp6hyBeMGpP1FOdn+Ma74MrkvXp0yfbYwwGA999912Oyjt58iRr167VViSrUaMG586dy2k4Qgjxwspx4g0ODqZatWra/7NjMBhyfOH09HTKlSuXZZuVlVWOzxdCiBdVjhPvZ599hqOjo/b/p2VjY0N8fLyWrM+fP4+tre1TlyuEEM873dp4169fz8aNG4mMjMTFxYXjx4/z+eef06hRo6cqV9p4RW5JG6/Iradt481x4n3SkyUgo6nh008/feJxSimaNWtGmTJlqFy5MlWqVKFJkyYPNT3khSRekVuSeEVuma1zzd/fH4PBQGaezmwiUEpp23OaeAHs7e0ZMGAAa9eu5ejRoyQmJvLuu+9SqFCh3N+FEEK8QHKceDPX4gVISUlhx44dVKlSBUdHRy5dusT58+dp165djsoyGAyUKlWKunXr0rp1a86ePcuoUaNYunQpnTt3ZvTo0U98WrEQQryocpx4M9fiBZg2bRoNGzbk22+/1bb1798/V51j+fPnp1OnThQpUoQrV67w+uuvU69ePSpUqMCgQYOeuMqZEEK8qPK0VsP27dvJly9flm358uVj165dOS7j3LlzpKamUqJECXr16kWbNm0oX748AwcORKf+PiGEMIs8jWpo1aoVV65coUmTJlSsWJFLly5x+PBhXnvtNfbs2ZOjMnbt2kXr1q0xGvOU+x9JOtdEbknnmsgts41qeNAvv/yiravwYIebj4/PQ+v0Ps6GDRvYu3cv6enpVKhQgbJlyz5yVlxOSeIVuSWJV+SWLokXICQkhE2bNmmL5Hh4eFC7du0cnz9o0CACAwMxGo2ULFmSy5cvU6lSJX799de8hKORxCtySxKvyC2zDSf7p9q1a1O7dm2uX7+epxEIgYGB7N27lyFDhrB582ZCQ0Pp169fXsMRQogXRp4aWNPS0pg/fz61a9emefPmREVF0adPn1zVVi0sLChZsiQmkwmlFDVr1pTHuwshXgl5qvH6+fnh5+cHZLTxvvbaa8TExLB+/Xo6der02HPDwsKAjMcHTZgwgRIlSjB27FiuXLny0EgJIYR4GeUp8fr7+1OxYkWqVq3Kjh07gIzHAR0/fvyJ544YMQLImPF24sQJlFLcu3cPpVSOntkmhBAvujwl3uvXr9O5c+csEyby5ctHQsKTO7b27duXl0sKIcRLI09tvKVLl+bkyZNaog0PD+fAgQOULVv2mQYnhBAvozwl3o4dOxIeHs7GjRu117du3aJDhw7PNDghhHgZ5SnxDh48mDZt2qCU0v41a9aMQYMGPev4hBDipZPrCRTp6elcvHiRfPnyYWNjw9WrVylVqhRlypTJ1YVPnz5N5cqVyZcvH9u3b+fMmTP069fvqVclkwkUIrdkAoXILV1mrr311lt06dLlqR4BVL9+fVq2bEl8fDxHjx6lbNmyxMXFMWHCBNq3b5/nciXxitySxCty62kTb56aGipXrkx8fPxTXdjCwoLff/+d5ORk6tati9FoJD4+nu+//x5fX9+nKlsIIZ5nee5c27t3LwsWLODo0aOcOHFC+5dTiYmJfPnll6SmpjJmzBjWrl1LSkoKfn5+BAQE5CUsIYR4IeRpHO8XX3yBwWBgxYoVrFixQttuMBj4448/clRGgQIF8PT0xMXFhbfeeovIyEiUUuTLlw9ra+u8hCUAn7n/4eD+g1y9Gs1/N66jajUnIOOpIZ/P8+X4kWNY29hQxakKn82bq3O0Qi82Vjasm/olb75RhcTkJGLu3mT44ilcuvo39arUZOGIWdjb5kehGLf8Y/b/7xgAcwdMxNO1PcmpKaSmpzJ11Tx2nzyo8928ePKUeHPbkZad+vXrY2trS9euXTl58iSbNm2iadOmpKSkPPM1el8lrdu2ov/AfvTr1T/L9kW+izEAW3ZsxmAwcPPGTX0CFM+NFdvXsiM4Y0LTSLd+rBw3n+YfvYv/rJX0mz+WvSFHqFy2AgHz1uHUvylJKUkcPhPMJz8sIikliRoVq3HIdyNl3qtLQlKiznfzYsl14g0MDKR169YULVoULy8vChYsmKcLN2zYkL179zJhwgQAHB0dcXd358aNG6xcuTJPZQqoW6/uQ9sSEhLx3/gLu/fv1J6bV6x4MXOHJp4jyanJWtIFCDz3Gx91G0pRh8IUL1iEvSFHALh45S/uxt2nvXNz/I/sYOeJ/do5Z/4Kw4CB4gWLEpH0dJ1Nr5pcVS13797NgAEDWLNmDQsWLMDLy4u0tLQ8XXj37t0EBgbyxhtvUL58eYKDg1m3bh1eXl4EBgbmqUyRvajLlylY0IGVK/zo8e779Os1gKDjQXqHJZ4jH3gMZPPx3dy6f4fo2zG82yRjsat6VWri9FpFypd87aFz+rf1IvxaJBHXJenmVq4S78qVKzGZTFSqVAkHBwciIiLYvXt3ni5sa2vLmDFjaNCgAXXq1KFbt27cvHmTdevW8dVXX+WpTJG99PR0rl6NxtGxIj+tX8vEKROY8OEkbt28pXdo4jkwuccoKpUpz2S/jOGhbjMHMKDde/z21U4+8BjIkd9PkJaenuWcFrVdmdl7LF5zhusR8gsvV00N4eHhuLq64ufnx8WLF+ncuTPh4eF5unBgYCC3b9+mRo0aGI1GrK2tuXPnDq+99pq08T5jpUqXwmg00qFTxpTuam9WpexrZbh44SJFixXVOTqhpw+7DcWzcXtaTehBYnISAKfDz9F+Si/tmD/89vN7xHntdZMaDVn1kS+dp/fjQlTefv9fdblKvHFxcVSqVAnIGMsLEBsbm6cLp6am0r17d+0ZbZs3b6Z8+fJ5Kks8XuHChXFu6MyxI8d4p+k7REVd4UrUVSo4VtQ7NKGjsV0H06O5G60m9uBe/H1te6kiJbh2OwaAQe3fJz4pgX0hRwF4p3oDvp+4CLcZAzgdfk6XuF8GuZq5VrVqVRo1akS7du0AmDlzZpbXAF5eXjkqy8vLi9TUVC5cuKCV/Z///IfSpUsTEhKCq6trbu5D86rPXJs9cw6HDx3m1s1bFCxUkPx2+fl11xaiLkcxc/rH3L1zF6PRwNDhQ2jVppXe4T4XXsWZa2WLlSbqpxNcuvo3sYkZk6GSU1Jo6N2ZGb3G0rOlBwaDgXORFxm5ZCpRN6IBuLD6MA529kT//8QM0NvnA87+HabLfejFrFOGq1atqvWKP8q5czn7KzhjxgzOnz9PkyZNsLa2xsbGBkCeMizM7lVMvOLpmPVhl89i/G6m1NRUrK2t2bJlCwAlS5aU9XyFEK+EXCXeZ/n0iLJlyxIWFkaPHj0wGAxs3ryZ119//ZmVL4QQzyuzDx8IDg4GYOPGjQwZMoTXX3+d1157jUGDBrF+/XpzhyOEEGaXpynDT2PLli04Oztz584d1q5dm2XfnTt3zB2OEEKYndkT75w5cwDo0KGDNqQMYMOGDbz22sOzY4QQ4mVj9sSbqWTJkqSkpGiLqTdq1IgrV67oFY4QQpiNblPETp8+jZOTE5s2bWLTpk3cu3ePfPny6RWOEEKYjS413tOnT2Nra8u0adNYuHAhVlZWlClTBj8/Pz3CEUIIszJ7jTckJISBAwdSsWJFpk+fTlJSEkopzp49y5kzZ8wdjhBCmF2eHnb5NOrWrUuhQoVwcHAA4MaNGzg4OJCSksLdu3c5efLkU5UvM9dEbsnMNZFbZp259izY29s/8unE48ePN3M0QghhfmZPvIUKFcLZ2TnbfYULFzZzNEIIYX5mT7yRkZH07ds3230RERFmjkYIIczP7InX2tqasLDsl5DLXKFMCCFeZmZPvEFB8qwvIcSrTbeZawDbt28nLCyM5ORkbdvkyZN1jEgIIf59us1cmzNnDlu2bGHTpk0YDAZ27dqV58cICSHEi0S3xBsUFMSyZcsoUqQIkyZNYv369Vy/fl2vcIQQwmx0S7zW1tYYjUYMBgOpqakUL16cmJiYJ58ohBAvON3aePPnz09iYiJ169Zl/PjxFCtWDFtbW73CEUIIszH7lOFMN2/exMHBAZPJxKpVq7h//z59+/alVKlST1WuTBkWuSVThkVuPe2UYd2aGg4cOIC1tTW2trYMHz6ciRMncuTIEb3CEUIIs9Et8f74448Pbfvno4CEEOJlZPY23tOnTxMSEsLt27dZs2aNtj02NpaUlBRzhyOEEGZn9sQbExNDWFgYSUlJnDt3TtueP3/+R65aJoQQLxPdOtcOHjxI06ZNn3m50rkmcks610RuPW3nmm6JVwghXlW6da4JIcSrShKvEEKYma6JNyYmRlsmMi0tTUY1CCFeCbol3p07d+Ll5aUtA/nnn38ycuRIvcIRQgiz0S3xrlixgk2bNmlPG65atSpXr17VKxwhhDAb3RKv0Wh86OGWVlZWOkUjhBDmo1vizZ8/Pzdv3sRgMABw/PhxChYsqFc4QghhNrqN4z1z5gwzZszg8uXLVK5cmaioKFasWEG1atX0CEcIIcxGl8RrMpk4c+YMFStW5LfffgOgdu3aWnuvEEK8zHSr8Xbp0oUtW7bocWkhhNCVbm285cuXJyIiQq/LCyGEbnR79M/du3dxd3endu3a2NnZaduXLl2qV0hCCGEWuiVeDw8PPDw89Lq8EELoR72Amjdvrtq0aaM6d+6sWrVqpYYNG6ZOnTqld1j/ii5duqjY2FillFKrVq1SMTEx2r7AwEB18OBB7fW1a9dUjx49nun1AwMDVZcuXZ6qjHv37qmvv/46y7ZevXqpPXv2PFW5/3T+/HnVvHnzR+5v3ry5+uOPP5RSSiUlJalhw4ap0aNHq+TkZDVlyhR1/PjxbM/z8fFRixcvfqax5sWePXtUSEhIjo7duHGjGj58uFLq8e/h4+47rx78OefVxo0b1Z9//pnldeb9PEseHh4qMDDwmZf7JLrVeAG2b99OWFgYycnJ2rbMKcRPsnDhQm3o2e7duxkyZAh+fn7UrFnzX4k1t0wmE5AxUeRpbN68Wfv/mjVraNCgAcWLFwcgODiY+/fv06RJEwBKliz5XD4+6f79+6xYsYIhQ4boHQoAcXFxDB8+nPLly/Pxxx9jNBqZO3fuQ8elpaVhafnv/oqkp6djYWGRo2MDAgKoWrUqtWrVembXz+6+nwf+/v44ODjg6Oiodyi5ktPPjG6Jd86cOURFRXH27Fk6derEzp07cXFxyVNZbdq04fTp0/j5+bF48WLi4+OZM2cOZ86cAaBdu3aMGjUKgEuXLjFlyhTi4uKoUKECCQkJdOrUCU9PT9avX8+qVauwsrLCZDIxZ86chxL5+fPnmTVrFklJSSQnJ9OpUydGjBgBwJIlS7hw4QIJCQlER0ezatUqLly4wLJly0hOTsZoNPLRRx/RsGHDh+5h2bJlbN26FWtra+112bJlcXJy4sSJE6xZs4aYmBjGjBmDra0tPj4+rFu3jvT0dIKDg2ndujXu7u64u7tz8uRJAJycnBg7diwBAQHcvn2bkSNH0rVrVwB+++03Pv74Y0wmE2+//Ta///47U6dOpUGDBg/Flp6ezoQJE/jjjz+wtrZm7ty5VKtWjaFDh9KpUyc6d+4MwJEjR1i0aBHr16/Pcv7MmTOJj4/Hzc0NCwsLNm3aBMCpU6f49ttviYmJwcXFhdmzZwMZidHHx0f7o1yrVi2mT5+u/WwetGTJErZu3Yq9vT3vvPNOln2//PILfn5+AJQuXZr09HTu3r3LtGnTMBgMhISE0KVLFxo0aEBYWBj9+/cnICCApKQkjh49SmJiIvXq1aNw4cJUrFgRgH379rFgwQKMRiPp6emMGTOGVq1aZbnujRs3GDduHPHx8SQnJ9OgQQOmTZuG0Whk06ZN+Pv7U6hQIf7++29mz56NhYUFn3/+OXFxcZhMJoYOHUr79u2zlHnw4EH27dvH0aNH8ff3p1evXjRr1uyR13mUuLg4vL29qVOnDqNGjaJ379707duXVq1aMWnSJKytrYmIiODatWtUrlwZX19frK2tiYuLY9q0aYSFhVGkSBEqVapESkoKPj4+2V5ny5YtTJ06ldjYWLy8vBg0aBA7d+7k559/5ttvv9U+V61ateKbb76hUqVK2rnr16/n7NmzfPrppyxZsoRx48YBkJCQwLhx47h48SJWVlYsWrSI119/XXuvf/zxR9LS0rCzs2P69OlUrVr1obgyP/fp6elUr16d9PR0bV9ERAQzZ87k1q1bGI1GRo8erb23hw8fxtfXl7S0NAoWLMisWbOoVKkSQUFBzJ49m5o1a/L7778zbNiwh967bJm9jv3/derUSaWnp6vOnTsrpZSKiYlRAwYMyNG52X2V2b17t2rfvr1SSql58+apcePGqfT0dBUfH6/c3NzUtm3blFJKeXp6qg0bNiillPrzzz/V22+/rTZu3KiUUqpOnTrq+vXrSimlUlJSVFxc3EPXjo2NVcnJyUoppRITE5Wbm5v29W/x4sXK1dVV3bhxQymlVGRkpOrevbvWVPD3338rV1dX7fxMd+/eVXXr1lWJiYlKKaUSEhJUUlKSUkqpKlWqqHv37mV734sXL1Zz5szRXl++fFnVrVtXe12lShXl5+en3WutWrVUamqqSk5OVk2aNNG+Yh4/flxVqVIl269cgYGBqkqVKurYsWNKKaW2bdum2rZtq0wmkzpy5Ijy8vLSjh02bJjy9/d/qIx/xqVURlPDiBEjVGpqqkpMTFTNmzdXv/32m1JKqWnTpmnlmEwmNWXKFPXNN988VO7+/ftVhw4dVGxsrDKZTOrDDz/UmhrOnz+vXFxc1LVr15RSSi1btkxVr15dOTs7q/79+6tevXqp5ORklZqaqgYNGqRatGih9uzZoyZOnKjq1Kmj/vOf/yilMppvGjRooDU1dO7cWYszPT1de28elJSUpH120tLS1JAhQ9Svv/6qlMr4ylyjRg116dIlpVRGM4ybm5v2ubt165Zq2rSpFveDJk6cqFatWpXj6/yzqeHq1avKw8Mjy3v0YJPPxIkTVbdu3VRCQoJKS0tTXl5eauvWrUqpjOaWiRMnKpPJpGJjY1WnTp3UxIkTH4pRqYzP6fjx45XJZNLu59SpUyotLU01b95cu/fdu3erPn36ZFvGP5uiNm7cqOrUqaMiIyOVUkrNnz9fTZ8+XSml1MmTJ9WgQYO036sTJ06oDh06PFRm5uf+6NGjSimlDh8+nOVz361bN/XTTz8ppZT666+/lLOzs4qKilI3b95Uzs7OKiwsTCml1ObNm1X79u2VyWRSgYGBysnJSQUFBWV7H4+i23Aya2trjEYjBoOB1NRUihcvTkxMTJ7LUw8MRz5+/Djdu3fHaDRiZ2eHu7s7R48eJS4ujrCwMNzd3QFwdHSkbt262nmNGjViwoQJfPfdd0RFRZE/f/6HrpOcnMzUqVPp3Lkz3bt35+rVq1meHde0aVOKFSsGwKFDh4iIiKBnz564ubnh7e2NwWB4aDEge3t73njjDcaPH8+6deu4d+8eNjY2ef5ZPCizNuro6IilpSU3b94kPDwcCwsLrebdsGFDypUr98gyypYtS6NGjQDo0KEDN2/eJDo6GldXV2JjY/njjz+4cuUKZ86coUOHDjmOrUOHDlhaWmJra0u1atWIjIwEMr5S+/n54ebmptXgM/c96Pjx47Rv3x57e3sMBgPvvfeeti8oKIh33nmHkiVLAvD++++TnJxM06ZNCQkJoXnz5lhbW2NpaUn37t25f/++dm5qaio9e/YEMppvWrRooe1r1KgRc+fO5ZtvvuH8+fPZTvoxmUx8/vnndOnSBXd3d86ePZvlM1K7dm2tBh0SEsLly5cZPHgwbm5u9O/fH4Dw8PAn/vyedJ0H3bp1i549ezJ+/Hjt85+d1q1bky9fPiwsLKhRo4b2cw8MDMTT0xODwYC9vf0Ta3XdunXDYDBQpEgRWrduzbFjx7CwsKBHjx5ac9iPP/5Ir169nnifmWrVqqXVcGvVqqXFtnfvXsLCwnj33Xdxc3Pjk08+4d69eyQlJWU5P/Nzn/nNunHjxlp5cXFx/PHHH3Tr1g3IGO5ap04dTp48SWhoKFWqVMHJyQnImIMQExPD9evXAXj99ddxdnbO8X2Ajk0N+fPnJzExkbp16zJ+/HiKFSuGra1tnss7c+YMlStXzvV5mWtFQMbX1rNnzxIcHMyQIUMYM2YMHTt2zHK8r68vhQsXxt/fH0tLS0aNGpWljfrBoXEArq6ufPHFF4+NwcLCgp9//pmQkBCCgoLo3r07vr6+1KtXL9f3808PJnCj0UhaWlq2xz34c3gSg8GgHd+7d2++//57ihUrRteuXbNtDshJbBYWFtrXPqUUixcvpkKFCjkuKycxA/Tp04dz587xzTff0K5dO8qUKfPQvT/u9eTJk7l48SJBQUFMnDiRzp07M3jw4CzHr1q1ilu3brF+/XpsbGz47LPPHvkZUUpRuXJl1q1bl+t7etJ1HlSgQAHeeOMN9u/fT8OGDR/5fj/4/j34nvxTbj4vDx7fvXt3OnbsiJubG5GRkVn+qD3J4z4vHh4eWpNEXuLK7b4H/fN3Pid0q/H6+vpiYWHBhAkTcHJywsrKisWLF+eprICAAH766ScGDBgAZNRKNmzYgFKKhIQEtmzZgqurK/b29jg5OWkz5sLDwzl16hSQ0SgeGRlJ9erVGThwIG3btuX06dMPXev+/fuUKlUKS0tLwsPDOXr06CPjaty4MceOHSMsLEzbll2ZcXFx3Lx5k3r16jFy5Ejq1q3LH3/88dBx+fPnJzY2Vnttb29PXFxcDn9K/6dixYqkpaURHBwMZHTSPW4yy5UrVwgMDAQy1lEuWrQopUqVAsDNzY0jR46wadOmLDXOB9nb25OUlJTjhe4z2/0y/0jcu3cv2/hcXFzYuXMncXFxKKX4+eeftX0NGjTg8OHDWq1k3bp12NjYaLUue3t7evXqRWRkJOvXr89Scy1fvjwbN24EMhbr37dvn7bv0qVLVK5cmV69etGjRw9CQ0Mfiuv+/fsUL14cGxsbbty4wc6dOx95r7Vr1yYqKopjx45p286dO5ftz+qf73durmNtbc2SJUuIiYlh2rRpWudvTjVs2BB/f3+UUsTHx7Njx47HHu/v7w9kjNcPCAjQvjEVLFiQFi1aMGrUKLy8vB7ZsfjPz/rjtGzZki1btmjfJDOXJPinihUrkp6ern2Wjx07ptWa7e3tefPNN7X+h4iICE6dOkX9+vWpVasWFy5c4MKFCwBs27aNkiVLat+m8kK3Gm/m13GA4cOH5/r8MWPGYGNjQ2JiIo6OjqxYsULrCBsxYgRz5szRvma3a9dO+wo8b948pkyZgp+fH+XKlaN69eo4ODhgMpmYMmUK9+7dw8LCgiJFimT7uPnhw4czYcIE/P39KVeuXLYdZZneeOMNvvjiC2bOnEliYiKpqam8+eabD9WAMzs8EhMTgYxf/OzGOPfp04fp06drnWutWrVi8+bNuLm5aZ1rOWFtbY2vry+zZ89GKcVbb71FhQoVHrlWRuXKlfH392fu3LlYWVnh6+ur1Qby5ctHmzZtiImJoXTp0tmeX6hQIdzd3enSpQt2dnbah/tRJk+ezBdffIG7uzsGgwFLS0vGjx/PG2+8keW4pk2bcvr0aTw9PR/qXKtSpQrjx49n0KBBQEbnWuYypF5eXly+fJmtW7fSvn17OnbsqP0hgYyv2yEhIXTo0IGSJUtmeY8XLFjAX3/9hZWVFba2tsyaNeuh+Pv06YO3tzcdO3akRIkSj+00LliwIF9//TX/+c9/8PHxIS0tjdKlS7Ns2bKHju3SpQuTJ08mICCAnj175uo6kLHs6hdffMG0adP46KOPmDdv3mOPf9DIkSOZMmUK7du3p3DhwlStWpUCBQo88vjChQvj6elJbGwsPXv2pE6dOtq+7t274+/vz7vvvvvI8728vPDx8WH16tVPrMnWq1eP8ePHM2rUKNLS0khNTaVZs2ZUr149y3HW1tYsWLAgS6fygx1wn3/+OTNnzuSHH37AYDAwd+5cypQpA8D8+fOZOHGi1rm2aNGiXNf6s8hVi/BLIC4uTplMJqVURueXi4uLunr1qs5RmV9mh59SSoWGhipXV1eVkJCQ63LS0tJUly5d1IkTJ55leOI5k5KSonX4xsfHq/fee0/rsM6tlStXqsmTJz/L8F44uo7j1UNISIj2l95kMjF58uRH1tReZrt372b16tUopbC0tGTevHnky5cvV2Xs3buXuXPn8s477zyT9mjx/Lp//z6DBw8mPT2d5ORkWrZsmbNhU//QsWNHDAYDK1eu/BeifHHotjqZEEK8qnTrXNu3b5/WUeDn54e3t7fWeC2EEC8z3RLvggULsLe3JywsjC1btuDi4pJtR4UQQrxsdEu8mfOZjxw5Qvfu3Xnvvfe0Xn0hhHiZ6ZZ409PTCQ0NZffu3dpwnUcN7hdCiJeJbol3zJgxzJgxgzp16uDo6Eh4eDjly5fXKxwhhDAbGdUgXgotWrTgypUrj9w/atQoRo8ebcaIhHg0s4/jfdKjfTKXbxQiNzw9Pbl37x4AO3bs4MaNG9SsWVObzfjP5T1TU1OxsrIye5xCgA6JNz4+HoDr169z/PhxWrRogcFgYN++fdp8biFy68E/2KGhody4cYN33nmH0aNH07t3b9asWcPQoUM5deoUoaGhLFy4kICAAPz9/fHw8NDWlc2sOWcuOp+cnMzKlSv59ddfiY6OpmTJknh4eDBw4EBJ3CLPzJ54J06cCMCAAQP45ZdftIUmYmJicvz0CSHyYsWKFbi4uODm5kahQoVydM748ePZtWsXFSpUoFOnTpw6dYoFCxZw79497bMsRG7p1rkWExOTZXWfEiVKaCtJCfFv6NChA99++y1z587N0RTn6Ohodu3aBUDdunXJly+ftqjKTz/9lOsVvoTIpNtaDSVLlmTx4sXaCkUbNmx4qmXWhHiSnCxW/eCQxgcXrN+wYUOW4xITE4mJicmyqpkQOaVb4vXx8WHOnDnaUoYuLi6PfH6TEM/CPxdpz1zAOrNT7vbt29y6dUvb/2BS3b59e5YHL16+fFmSrsgz3RJv8eLFWbRokV6XF4K33noLyJg96ePjQ3BwcJYab9myZWnevDn79++nT58+NGvWjKSkJM6ePUuJEiX4/vvv9QpdvODMnniDg4NxdnZm79692e5v2bKlmSMSr6ouXbpw8uRJ9uzZw+7du+natSt37tzJ0sSwYMEC/Pz82LZtG1u3bsXOzo7KlSs/dhFvIZ7E7BMopk2bxpw5c+jdu/fDwRgMrFmzxpzhCCGE2Zk98T5u4PqVK1coW7asOcMRQgizM/twsvHjx2e7PTo6mj59+pg5GiGEMD+zJ96UlBRmzpyZZVt0dDS9e/emX79+5g5HCCHMzuyJd+HChfz1118sWLAAgGvXrtGnTx969+6dbbuvEEK8bHRZnSwuLo5+/frh6urKzp076dGjh9R2hRCvDLMn3rCwMADu3LnD2LFjad68OX379tX2P/iceyGEeBmZPfG2aNHikfsMBsMjx/cKIcTLQhZCF0IIM9NtdTIhhHhVSeIVQggzk8QrhBBmJolXCCHMTBKvEEKYmSReIYQwM0m8QghhZpJ4hRDCzCTxCiGEmf0/WQMczxPFxBQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cfm(y_test, y_pred_test, title=\"Neural network confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                11600     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,802\n",
      "Trainable params: 16,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = net.history_\n",
    "plt.plot(history['loss'], label='Train')\n",
    "plt.plot(history['val_loss'], label='Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boundaries_on_embedding(reducer, net, embedding=embedding, \n",
    "                        n_pts=30,\n",
    "                       cmap=\"inferno\",\n",
    "                       titile=\"Neural network on PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:30:00,669] A new study created in memory with name: no-name-7752a621-87bb-4ff1-82cd-364b23ebc0ce\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:30:15,948] Trial 1 finished with value: 0.9586776859504132 and parameters: {'n_estimators': 230, 'max_depth': 60, 'max_features': 'auto', 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:30:26,582] Trial 3 finished with value: 0.9559228650137741 and parameters: {'n_estimators': 650, 'max_depth': 90, 'max_features': 'sqrt', 'min_samples_split': 17, 'min_samples_leaf': 5, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:30:47,701] Trial 4 finished with value: 0.9504132231404959 and parameters: {'n_estimators': 950, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 10, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:31:05,954] Trial 0 finished with value: 0.9586776859504132 and parameters: {'n_estimators': 1910, 'max_depth': 90, 'max_features': 'auto', 'min_samples_split': 2, 'min_samples_leaf': 9, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:31:08,599] Trial 2 finished with value: 0.9586776859504132 and parameters: {'n_estimators': 1710, 'max_depth': 60, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:31:17,394] Trial 6 finished with value: 0.953168044077135 and parameters: {'n_estimators': 540, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 17, 'min_samples_leaf': 2, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[W 2023-07-08 15:31:17,414] Trial 9 failed with parameters: {'n_estimators': 420, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 10, 'min_samples_leaf': 1, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:31:17,423] Trial 9 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:31:47,548] Trial 7 finished with value: 0.9559228650137741 and parameters: {'n_estimators': 1010, 'max_depth': 80, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 1, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:31:51,069] Trial 5 finished with value: 0.9586776859504132 and parameters: {'n_estimators': 1540, 'max_depth': 100, 'max_features': 'auto', 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:32:04,960] Trial 11 finished with value: 0.9559228650137741 and parameters: {'n_estimators': 390, 'max_depth': 20, 'max_features': 'auto', 'min_samples_split': 18, 'min_samples_leaf': 1, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[W 2023-07-08 15:32:04,971] Trial 13 failed with parameters: {'n_estimators': 1310, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 20, 'min_samples_leaf': 10, 'bootstrap': True, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:32:04,987] Trial 13 failed with value None.\n",
      "[I 2023-07-08 15:32:13,587] Trial 10 finished with value: 0.9586776859504132 and parameters: {'n_estimators': 1450, 'max_depth': 50, 'max_features': 'auto', 'min_samples_split': 14, 'min_samples_leaf': 2, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:32:20,898] Trial 8 finished with value: 0.9559228650137741 and parameters: {'n_estimators': 1860, 'max_depth': 40, 'max_features': 'sqrt', 'min_samples_split': 18, 'min_samples_leaf': 1, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:32:24,360] Trial 12 finished with value: 0.9586776859504132 and parameters: {'n_estimators': 790, 'max_depth': 40, 'max_features': 'sqrt', 'min_samples_split': 19, 'min_samples_leaf': 1, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:32:31,863] Trial 17 finished with value: 0.9504132231404959 and parameters: {'n_estimators': 230, 'max_depth': 70, 'max_features': 'auto', 'min_samples_split': 7, 'min_samples_leaf': 9, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:32:36,829] Trial 14 finished with value: 0.9504132231404959 and parameters: {'n_estimators': 770, 'max_depth': 70, 'max_features': 'sqrt', 'min_samples_split': 9, 'min_samples_leaf': 5, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[W 2023-07-08 15:32:36,904] Trial 19 failed with parameters: {'n_estimators': 1280, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 6, 'min_samples_leaf': 7, 'bootstrap': True, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:32:36,909] Trial 19 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:33:02,606] Trial 15 finished with value: 0.9476584022038568 and parameters: {'n_estimators': 2000, 'max_depth': 80, 'max_features': 'auto', 'min_samples_split': 8, 'min_samples_leaf': 9, 'bootstrap': True, 'criterion': 'gini'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[W 2023-07-08 15:33:02,665] Trial 21 failed with parameters: {'n_estimators': 1290, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 5, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:02,667] Trial 21 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:33:06,428] Trial 16 finished with value: 0.9586776859504132 and parameters: {'n_estimators': 1310, 'max_depth': 70, 'max_features': 'auto', 'min_samples_split': 7, 'min_samples_leaf': 8, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[W 2023-07-08 15:33:06,491] Trial 23 failed with parameters: {'n_estimators': 1290, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 4, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:06,493] Trial 23 failed with value None.\n",
      "[W 2023-07-08 15:33:06,567] Trial 24 failed with parameters: {'n_estimators': 1220, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 4, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:33:06,569] Trial 24 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:33:37,557] Trial 18 finished with value: 0.953168044077135 and parameters: {'n_estimators': 1260, 'max_depth': 100, 'max_features': 'auto', 'min_samples_split': 7, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[W 2023-07-08 15:33:37,619] Trial 26 failed with parameters: {'n_estimators': 220, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 4, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:37,631] Trial 26 failed with value None.\n",
      "[W 2023-07-08 15:33:37,695] Trial 27 failed with parameters: {'n_estimators': 1160, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 4, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:37,709] Trial 27 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[I 2023-07-08 15:33:42,709] Trial 20 finished with value: 0.9559228650137741 and parameters: {'n_estimators': 1280, 'max_depth': 100, 'max_features': 'auto', 'min_samples_split': 5, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[W 2023-07-08 15:33:42,784] Trial 29 failed with parameters: {'n_estimators': 210, 'max_depth': 50, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "[W 2023-07-08 15:33:42,794] Trial 29 failed with value None.\n",
      "[W 2023-07-08 15:33:42,864] Trial 30 failed with parameters: {'n_estimators': 200, 'max_depth': 50, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 7, 'bootstrap': True, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "[W 2023-07-08 15:33:42,866] Trial 30 failed with value None.\n",
      "[W 2023-07-08 15:33:42,940] Trial 31 failed with parameters: {'n_estimators': 200, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': True, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:33:42,942] Trial 31 failed with value None.\n",
      "[W 2023-07-08 15:33:43,011] Trial 32 failed with parameters: {'n_estimators': 1680, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': True, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:43,013] Trial 32 failed with value None.\n",
      "[W 2023-07-08 15:33:43,078] Trial 33 failed with parameters: {'n_estimators': 1710, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:43,080] Trial 33 failed with value None.\n",
      "[W 2023-07-08 15:33:43,149] Trial 34 failed with parameters: {'n_estimators': 1660, 'max_depth': 50, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "[W 2023-07-08 15:33:43,151] Trial 34 failed with value None.\n",
      "[W 2023-07-08 15:33:43,220] Trial 35 failed with parameters: {'n_estimators': 1660, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': True, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:43,224] Trial 35 failed with value None.\n",
      "[W 2023-07-08 15:33:43,291] Trial 36 failed with parameters: {'n_estimators': 220, 'max_depth': 50, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "[W 2023-07-08 15:33:43,293] Trial 36 failed with value None.\n",
      "[W 2023-07-08 15:33:43,364] Trial 37 failed with parameters: {'n_estimators': 200, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:33:43,369] Trial 37 failed with value None.\n",
      "[W 2023-07-08 15:33:43,439] Trial 38 failed with parameters: {'n_estimators': 200, 'max_depth': 50, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': True, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "[W 2023-07-08 15:33:43,440] Trial 38 failed with value None.\n",
      "[W 2023-07-08 15:33:43,509] Trial 39 failed with parameters: {'n_estimators': 1640, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:43,511] Trial 39 failed with value None.\n",
      "[W 2023-07-08 15:33:43,585] Trial 40 failed with parameters: {'n_estimators': 1680, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': True, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:43,586] Trial 40 failed with value None.\n",
      "[W 2023-07-08 15:33:43,655] Trial 41 failed with parameters: {'n_estimators': 1730, 'max_depth': 50, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "[W 2023-07-08 15:33:43,656] Trial 41 failed with value None.\n",
      "[W 2023-07-08 15:33:43,728] Trial 42 failed with parameters: {'n_estimators': 1690, 'max_depth': 50, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "[W 2023-07-08 15:33:43,731] Trial 42 failed with value None.\n",
      "[W 2023-07-08 15:33:43,797] Trial 43 failed with parameters: {'n_estimators': 220, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:33:43,802] Trial 43 failed with value None.\n",
      "[W 2023-07-08 15:33:43,868] Trial 44 failed with parameters: {'n_estimators': 1700, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:43,870] Trial 44 failed with value None.\n",
      "[W 2023-07-08 15:33:43,940] Trial 45 failed with parameters: {'n_estimators': 1640, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 11, 'min_samples_leaf': 6, 'bootstrap': True, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:43,941] Trial 45 failed with value None.\n",
      "[W 2023-07-08 15:33:44,009] Trial 46 failed with parameters: {'n_estimators': 200, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:44,011] Trial 46 failed with value None.\n",
      "[W 2023-07-08 15:33:44,076] Trial 47 failed with parameters: {'n_estimators': 200, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': False, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:44,077] Trial 47 failed with value None.\n",
      "[W 2023-07-08 15:33:44,145] Trial 48 failed with parameters: {'n_estimators': 200, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 6, 'bootstrap': True, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:33:44,150] Trial 48 failed with value None.\n",
      "[W 2023-07-08 15:33:44,213] Trial 49 failed with parameters: {'n_estimators': 210, 'max_depth': 0, 'max_features': 'auto', 'min_samples_split': 1, 'min_samples_leaf': 7, 'bootstrap': True, 'criterion': 'entropy'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/3682342589.py\", line 16, in objective_fun\n",
      "    rf.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:33:44,215] Trial 49 failed with value None.\n",
      "[I 2023-07-08 15:34:03,779] Trial 25 finished with value: 0.9559228650137741 and parameters: {'n_estimators': 1220, 'max_depth': 100, 'max_features': 'auto', 'min_samples_split': 4, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:34:06,073] Trial 22 finished with value: 0.9559228650137741 and parameters: {'n_estimators': 1290, 'max_depth': 100, 'max_features': 'auto', 'min_samples_split': 5, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n",
      "[I 2023-07-08 15:34:22,820] Trial 28 finished with value: 0.9559228650137741 and parameters: {'n_estimators': 1170, 'max_depth': 50, 'max_features': 'auto', 'min_samples_split': 4, 'min_samples_leaf': 7, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9586776859504132.\n"
     ]
    }
   ],
   "source": [
    "def objective_fun(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 200, 2000, 10)\n",
    "    max_depth = trial.suggest_int('max_depth', 0, 100, 10)\n",
    "    max_features = trial.suggest_categorical('max_features',['auto', 'sqrt'])\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 1, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "#     epochs = trial.suggest_int('epochs', 10, 200,10)\n",
    "    par = {'n_features_in_': 231, 'n_classes_': 2}                                      \n",
    "                                          \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth , max_features=max_features, \\\n",
    "                               min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \\\n",
    "                               bootstrap=bootstrap, criterion=criterion)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "    error = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective_fun, n_trials = 50, n_jobs = -1, catch=(ValueError,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 230, 'max_depth': 60, 'max_features': 'auto', 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False, 'criterion': 'entropy'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       309\n",
      "           1       0.90      0.92      0.91       308\n",
      "\n",
      "    accuracy                           0.91       617\n",
      "   macro avg       0.91      0.91      0.91       617\n",
      "weighted avg       0.91      0.91      0.91       617\n",
      "\n",
      "Accuracy 0.9092382495948136\n",
      "F1-score [0.90879479 0.90967742]\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "rf = RandomForestClassifier(**best_params)\n",
    "rf.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(best_params)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred_test))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred_test, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cfm(y_test, y_pred_test, title=\"Random forest confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nbr_features = X_train.shape[1]\n",
    "\n",
    "tree_feature_importances = rf.feature_importances_\n",
    "sorted_idx = tree_feature_importances.argsort()[::-1][:10]\n",
    "df2 = df.iloc[:, sorted_idx]\n",
    "\n",
    "y_ticks = np.arange(0, len(sorted_idx))\n",
    "fig, ax = plt.subplots()\n",
    "plt.barh(y_ticks, tree_feature_importances[sorted_idx][::-1])\n",
    "plt.yticks(y_ticks, list(df2.columns)[::-1])\n",
    "plt.title(\"Random Forest Feature Importances (MDI)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boundaries_on_embedding(reducer, rf, embedding=embedding,\n",
    "                       cmap=\"inferno\",\n",
    "                       n_pts=30,\n",
    "                        title=\"Random forest on PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAADoCAYAAACnz4zGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGFElEQVR4nO3deXhMZ//H8fdMJgkSsS+1qyX22CKboIk9KoTH1lraaIVaailBtEGpLaEJqlVb0GpJ1Fo0tTzIgtJSJSEidtWgssg65/dHfjmP7NvMZCbu13W5IjNn+c6Z+Dq555zPrZAkSUIQBEHQGWVpFyAIgvC6EY1XEARBx0TjFQRB0DHReAVBEHRMNF5BEAQdE41XEARBx0TjFQRB0DHReAVBEHRMNF5BEAQdE43XQFlaWsp/2rRpQ+/evdmyZUtplyW7du0a/v7+BAcHF3qd4OBg/P39uXbtmvyYp6cnlpaWBAUFabzGoKAgLC0tmT59usa3XVxBQUH4+/tz79690i6lSM6dO4elpSXff/89ULz3Pz/+/v74+/trZFvZ5XbMfXx8aN26NdHR0VrZp2i8Bm758uV4eXmRkJDAsmXLOHz4cJG3kZaWpvG6rl27xtq1a4vceNeuXZul8Y4cORJfX1+sra01XqM+yXwP9u7dy9q1a7l//34pV1Q0vr6+WFhY4ObmBhTv/c/P2rVrWbt2rUa2lV1ux3z06NGo1Wqt7VM0XgPXr18/RowYwcCBAwH47bffAIiIiGD8+PF06dIFGxsbpk2bxuPHj4GMswdLS0s+/vhjRowYQfv27YH/nUX7+vpiZ2eHs7MzISEhzJw5EysrK9zc3IiJicmyjVWrVgH/O3v09PQkKCiIuXPnAhk/1JaWlvj7+3Pnzh0GDRpEhw4daNeuHX379mX37t1Axpnt3r17AZg7dy6WlpaEh4fz/fffM2PGDM6fPw/A3bt3mTp1KnZ2dnTu3Jlx48bx119/ARAeHo6lpSVubm7MnDkTa2tr+vTpwx9//FGoY5n5mqZMmcLw4cNp3749c+fO5dSpUzg5OWFtbZ3lrCvzeK1btw5HR0e6desmv57MekaMGEHHjh3p2rUrnp6exMbG5vkejB49mnPnzgEwZswYLC0tuXfvHjt37uStt96ibdu2WFtb89577xEVFVXo1/zTTz8xaNAg2rdvj42NDd988w0Az549w8vLi27dutGhQwdGjRrFpUuX5Oc8PDywtramTZs2ODk5sXnz5lyPW2RkJJcuXcLZ2RlTU9M833+A3bt3M2DAAKysrOjZsycbN26Ut7Nx40Z69OhBmzZtsLGx4Z133pGP86vH3MnJKUcNycnJzJkzBxsbG9q0aYOjoyPLly8HQK1W880339C7d2+srKzo37+//BtUXse8Zs2adOrUiaNHj/L8+fN8fmqKRzReA/f8+XNiYmIIDw8HoG7dusTFxeHu7s7Vq1d59913GT58OMePH2fatGlZ1v3111/p0aMHs2fPzvL4nTt3cHFx4d69e7i7u1OpUiWcnJy4evUqX331VYE1WVtbM2LECPnvvr6+9OnTByMjI3r37s28efOYNm0aSqWSTz/9lFu3bjFy5Ej5rHbEiBH4+vrStGnTLNtNT0/Hw8ODo0ePMmjQID788EMuXLiAu7s7z549k5e7evUqtWvXplevXty+fVv+z6GwwsLCGDhwIJUrVyYoKIhFixYxfvx40tPTWbduHXfv3s2yfEREBB4eHrx8+ZJPP/2U69evc/fuXT788EMiIiKYNm0ab731Fnv37s0xrPHqezBp0iSaNGkCwKRJk/D19aVq1apUr16d999/nwULFjBq1CjCw8OZP39+lu3k9ZqPHj3KnDlz+Oeff5g+fTpTpkyhXLlyAMyePZvAwEB69+7Nhx9+yKNHj/jwww+JjY1l3759nDhxgj59+rB48WIGDRqEQqHI9XiFhIQA0KFDByDv9//w4cN4eXlRpUoVPvroI5o2bcqqVav44YcfePHiBatWrcLMzIzFixczceJEatSoAWScTWfy9fXFy8srRw2nT5/mp59+onPnznz++ee88847mJiYALBp0yZ8fHxo2rQpH330EVWqVGHu3LmcPn06z2MO0LFjR1JTU+X/9DVJpfEtCjrVrVs3+e9du3aV/2E+efIEgHXr1snPX7p0iX///Vf+/u2338bDwyPHNufNm0diYiLbt2/HxMSE+fPnc+7cOQ4fPiyf8eanfv36WFlZsWvXLurVq4eLiwsAt27d4tSpU1y+fBm1Wi0vf/36dfr370+9evU4f/48VlZW8jqvio6O5ubNmzRs2JA5c+YAcPHiRU6cOMGFCxewsLAAoGnTpnzyySfcvn2bwMDAQtX8qn79+vHOO+9w8eJFDh48yLBhwxg1ahQHDx7kt99+4+7du9SvX19eftGiRVSuXJno6Gi2b9/O2bNnKVeuHElJSQwbNoyxY8eiVqv5+eefCQ8Pz/c9qFatGlFRUdja2mJjYwNk/Of69ddfy+8pIJ/lZ8rrNf/8888AfPzxxwwdOlRePjExkdOnTyNJEtu3b8+yrYsXL8rN6OLFi6hUKlq2bEm/fv1yPV6Z+6pduzaQ9/u/fv16IGM8OPMsE+DkyZMMGTKEN954g4cPH3LmzBmaNWvGhAkTAHBxcWHGjBny33PToEEDVCoV165do0qVKjRv3lwe9jh27BiQ8Z/cr7/+Kq9z6tQpvLy8cj3mALVq1QIyTkQ0TTReA/fNN99QoUIF6tSpQ926dbM817ZtW/kHFjJ+5co82wF44403ct1mpUqVSElJAcDc3BwjIyOUyoxfjtLT0wEwMjLK8v2rzQTI9exo3bp1/P7777i5ueHi4sKOHTs4ceIESUlJea6Tm4KWyzxjUalUWWosrMwGbmxsnOX7zNesyTHxvN6DTC9fvmThwoUolUqWLl1K7dq18fDwIDk5OctyxX3N5cqVY926dfL7C9CkSRNq1arFvn37CAkJ4caNG3z22Wfs2rVLHg7KzavvS37v0cSJE+nSpYv8vbm5OSqVin379hEcHMyNGzf44Ycf+PLLLwkMDKRVq1YFvo7mzZtz+PBhTp06RVRUFD4+PmzYsIFTp07JyyxYsIA333xT/r5atWr5bjPzmGgjOVcMNRg4W1tbrK2tszTdjh07UqNGDa5evUp4eDgPHz7k7Nmz+Pv7Y2pqqpH9NmjQAMj4Fe/o0aPs3Lkzy/OVKlUCMn4FPnjwIA8ePJCfi4uL49atW/J4dPZ1Tp06xaFDh3I0l8aNG9OsWTNu377NihUr2LhxI2fOnKFq1ap07txZI6+rOD799FN27tzJvn37UCqVODg40K1bN8qXL8+hQ4cICAjA29ubuLg4bGxs5NeZm8qVKwNw5MgR+WxVoVCQlpbGv//+y88//yz/p1gYffv2BWDNmjVs27aNnTt3EhAQQIUKFXB0dCQpKYk9e/bw6NEjLl++zLJly0hNTeXIkSMcOHCAihUr0qZNG0xNTbO8h6/KPPt/9OiR/Fhu73/v3r0BOHToEDExMURHR/Pjjz9y9uxZ4uPjWbRoEUlJSbRo0YJatWqhVqvlzyUyj8vOnTuznC1nOn/+PNu3b6dcuXK0adMGc3Nznj59SnJysrzfoKAg7t+/T2RkJFu2bJE/xM3tmL/6el797UZTxBlvGVSxYkU2bdqEr68vu3btIjk5mbp168o/gJrQp08fjh07xunTp1m/fj02NjZZxj4dHBywt7fnwoULzJw5E19fXyZPnkx0dDSnTp0iLi6OHj16sH//fnmdoUOHcvr0aX755ReOHDnCmTNnsuzTyMiIr776ihUrVhAUFERaWhqdO3fmk08+oUqVKhp7bUXVunVrNmzYQPny5Zk9ezYtWrQA4Ouvv2b16tWsXr2aChUqMGjQoBzj6dmNHj2aq1ev8v3337Nnzx6uXLnCp59+ypo1a/jqq68YM2YMlStXLvQHPn379mXp0qVs27YNX19fTE1NcXd3B2DFihWsXr2aU6dO8euvv1KjRg06depEpUqVKF++PKdPn+a7774jPT2dhg0b5viMIJODgwOQMZQ1bNgw+bHs77+LiwsJCQkEBASwbNkyypUrh6WlJe3bt0elUhEbG4u/vz9xcXFUqVKF0aNH4+joCGSMv65fv55FixbRtWvXLGfMAOXLl+fSpUvs3btX/nmfNm0a5ubmuLu7I0kSgYGBLF68mIoVK9KqVSv5Q7vsxzxzSOXixYsYGxvn2JcmKMQMFIJQPJn/cCMiIkq5ktI3YsQIoqOjOX36tPyhliF78uQJ3bt3p0+fPqxevVrj2xdDDYIglNj06dN5/vx5vmPAhiQgIACFQsGUKVO0sn1xxisIgqBj4oxXEARBx0TjFQRB0DHReAVBEHRMNF5BEAQdE41XEARBx8QNFHpEkiTUav28yESpVOhtbbkR9WqPIdUKuqtXqVQU+rZ30Xj1iFot8fRpQmmXkYNKpaRKFTNevEgkLU1d8AqlTNSrPYZUK+i23qpVzTAyKlzjFUMNgiAIOiYar1Ao1//4reCFBEEoFNF4hQKFHNuP0f4lhP6yv+CFBUEokGi8QoGe3I/BSKng73tFCxQXBCF3WvtwbdeuXWzduhVTU1O2bt2q9di+iIiILJF7cXFxxMfHy9mdTk5OGBsby0HgEyZMoH///iXe56JFi4iNjUWlUtG2bVs+++yzLGHjgiAI2Wmt8W7bto0vvvhCnodJ2ywtLdm3b5/8/aJFi3Jc2rFmzRpatmypsX2ampqyYMECWrRoQXp6OjNnzmTjxo1aSzQqLXfuxECN//8qCEKJFanxZs6Kevz4cWJjY5k3bx5RUVEcPXqU+Ph4Fi9ejI2NDVOnTuXu3bt4enpiaWmJn58fJ0+exN/fn9TUVBQKBYsWLcLKyopLly6xYsUKEhISkCSJadOm0bNnzzxr8Pf358CBA5ibm+Po6MiBAwc4fvx4lmWSk5M5cOAAAQEBxTsqZOSLzp49m44dO7JixQoOHDjA6dOnAXB2dmb79u00atRIXt7IyIi2bdty48aNYu8TMi5/0TcJifHyV32sLzsjI2WWr/rOkOo1pFpBf+st8hlvhQoV2L17N6GhoUyaNIkFCxYQFBTEzz//zIoVKwgMDMTPzw8nJyf5DDM6Opq5c+eyY8cOmjRpQmpqKklJSTx//pyPPvoIPz8/OnfujFqt5sWLF3nu++TJkxw5coSgoCDMzMz45JNPcl3u2LFj1K9fP8fZbeZQRNu2bZk1a5Y8T1Vu7OzsCAkJoWPHjoSFhVG7dm1u3ryJiYkJKpWKOnXqZFk+MTGR3bt3M3PmzMIeyhyUSgVVqpgVe31tUamM5K/6WF9eLCzKl3YJRWJI9RpSraB/9Ra58WaOi7Zp04bExER51s927drlOZtrSEgIjo6O8sylxsbGGBsbc/LkSRo3bizPl6VUKuX5j3ITGhpKv379MDc3BzLOSi9evJhjuT179jBkyJAsj+3YsYM6deqQmprKmjVrmDNnDhs3bsxzX/b29qxZs4ZRo0ahUqno27cvISEhmJiYYGtrm2XZlJQUpk+fTteuXenVq1ee2yyIWi3x4kVisdfXlrS0dPnrs2f6d4NHdkZGSiwsyvPixUvS0/X/In9DqteQagXd1mthUb7QZ9ZFbryZkyVmzsCZ+b2RkVGRZ3PVhrt37/LHH3/g7++f5fHMM1RjY2PGjh1Lnz598t1O+/btuXHjBr/++iu2trZyIzYxMcnyoVxqairTp0+nRo0azJ8/v8T16+PdQGYVzIFEzCqY62V9eUlPV4t6tcSQagX9q1cnAx9du3blzJkzREVFARnNKi4ujg4dOhATE8OFCxeAjOnH85vEz97eniNHjhAfH48kSfz44485lgkMDKRnz57ylNyQMQzw6hDGoUOHCpwy2tjYGCsrK7766ivs7OywtLQkKiqKc+fOyWe8aWlpzJgxg0qVKrF48eJC36dtaBo0aJjlqyAIJaOTrIaGDRvyxRdf8Mknn5CWloaRkRELFy6kXbt2rF27lmXLlpGQkIBSqWTatGk4OTnlup3u3btz+fJl3Nzc5A/XXqVWq9m7dy/Lly/P8nhsbCxTpkyRz8jr1auXY5nc2Nvbc+7cOTp16oRCoaBdu3ZER0fLwyGHDx/m2LFjWFpaMmjQICBjavXPPvusiEdIv9Ws15D0iHPUrCcaryBogkHPuRYZGYmHh0eOqxoMVXq6Wm9Dch7fuU6tBi306te1vGQGozx7liDq1TBDqhV0W29GSE7hBhH06xoLQW+1sOpU2iUIQpmhl7GQbm5uOT6oa9q0KT4+Plkea968eYnOdmNjY3n//fdzPG5vb8+cOXOKvV1BEIT86GXjDQoK0sl+qlWrluVuN0EQBF0QQw2CIAg6JhqvIAiCjonGKwiCoGOi8QqFImagEATNEY1XKJCYgUIQNEsvr2owFKGhofj4+JCYmIhCoaB79+7MmjVLzrEoK57cj6GlmIFCEDSmbHUIHatUqRKrV6/m8OHDBAUFcenSJX766afSLkvjMgPQRRC6IGiGVs94k5KS8PT0JDIyEpVKRfXq1dm8eTOBgYEEBAQgSRIqlQo/Pz/q1auX6zb8/f25efMmycnJREdH06hRI2bOnMny5cu5d+8erVu3ZtWqVSiVSjn8PDU1FbVazccff4yTkxNJSUkMGzaMSZMm0bdvXy5dusTMmTPZs2dPnpm8jo6O7Nmzh1q1ajFt2jQeP37Mrl27SElJwdHRkdOnT2cJ2jE1NaVly5bcv3+/RMdMH4PGRRC6dhlSvYZUK+hvvVptvKdPnyYuLo7Dhw8D8Pz5c8LDw1m3bh27du2iZs2avHz5ssDt/PnnnwQFBWFhYcHo0aPx8vJi8+bNlCtXjiFDhvDf//6XHj160LVrVwYMGIBCoeDevXsMHz6crl27Uq5cOb788kvGjRtHnTp1mDVrFitWrCgwCD00NJSBAwdy/fp1VCoV8fHxXLlyhdatW2NiYpJl+SdPnnD06FE2bNhQ7OMlgtA1S9/CrwtiSPUaUq2gf/VqtfG2aNGCqKgovL296dKlC926dePkyZO4urpSs2ZNAMqXL/iAODg4UKlSJQBatWqFiYmJHIbeqlUrbt++DcC9e/eYNWsWjx8/xsjIiH///Ze7d+/SpEkTGjduzKxZsxgxYgRTp06Vw9fzYm9vT0hICE2bNqVFixZUr16d8PBwfv/99xxB6PHx8Xh4eDB+/Hjatm1b1MMkE0HomiHCurXHkGqFMhSEXhT169fn0KFDhIWFERoaysqVK3FwcCjyLLyZYeuQEbj+6vdKpVLOdZgxYwYzZ86kb9++AHTp0oWUlBR52b/++ouqVavy8OHDAvdpZ2eHj48PTZs2xd7enmrVqhEaGsqlS5fw9vaWl4uPj2f8+PE4Ozvz3nvvFel15UYfE59EELpuGFK9hlQr6F+9Wh34ePToEQqFAmdnZ2bPno0kSbi6urJ//37+/vtvAF6+fFmo4YbCePHihTxWvG/fPv7991/5uRMnTnDmzBkOHjzI5cuX5eGPvNSqVYuKFSuya9cu7O3tsbW15cSJE9y/f5/WrVsDkJCQwPjx4+natSuTJk3SyGvQRyIIXRA0S6tnvBEREfj6+iJJEunp6bi6umJtbc3kyZNxd3dHoVBgbGyMn58fdevWLfH+5s2bx9SpU7GwsMDW1lae7ufBgwd4e3uzadMmKleuzJdffsno0aNp1apVlpmCs7O3t+fEiRPUr18fgBo1atCqVSv5crGAgACuXLnCy5cv+eWXXwDo27cvEydOLPFr0SciCF0QNMugg9DLGhGErhkirFt7DKlWEEHogoETQeiCoDl6cefatWvX8PT0zPH44MGDGTduXJnbryAIrzcx1KBH9HmoQfx6qT2GVK8h1QpiqEEQBEH4f6LxCoIg6JhovIIgCDomGq9QKCIIXRA0RzReoUAiCF0QNKtYjdfS0pIXL15ouhaCgoJKfOttQkIC7u7u2NjYFBiEUxzz588nLCxM49vVZ0/ux2AkgtAFQWP04jpeTTI2Nmb8+PFUrlyZ0aNHa3z7S5Ys0fg29d2dOzFQQwShC4KmlLjxXrlyhSVLlpCQkICpqSlz586lU6eMu5x27drFli1bqFChAj179sTPz4+IiIhCbffJkyfMmDGDhIQEkpOTsbGxwcvLC6VSSWpqKkuWLCE0NJRKlSrRsWNHrl69yvbt2zExMcHOzo579+4V+jV4enpibGzM3bt3uXPnDjY2NowcOZKVK1fy4MEDevbsydy5cwEYPXo0Y8eOpWfPnnh6emJiYkJMTAyPHj2iWbNm+Pr65sjqLQp9DBoXQejaZUj1GlKtoL/1lqjxpqSkMGXKFBYvXoyjoyMXLlxg6tSpHDt2jPv377N27Vr27t1LjRo18PPzK9K2LSws2LBhA2ZmZqSnpzNp0iR+/vlnXFxc+PHHH4mJieHgwYMAfPjhhyV5GQBERkYSEBCAQqHAxcWFFy9esHnzZlJTU+nZsydDhw6lWbNmOda7du0aAQEBmJiY8M4773Ds2DEGDBhQrBpEELpm6Vv4dUEMqV5DqhX0r94SNd7o6GiUSiWOjo4AdO7cmWrVqnHt2jX++usvHB0dqVGjBgDDhg1j3bp1hd62Wq1m1apV/Pbbb0iSxNOnT2nWrBkuLi7yzBDGxsYADBo0iD179pTkpeDs7Czn/DZv3pyuXbtibGyMsbExTZo0ISYmJtfG26tXLznMvV27dty5c6fYNYggdM0QYd3aY0i1wmsUhK5QKIr0eF62bNlCbGwsu3fvxtTUlC+++ILk5GSNbDs3rw4PZA9bNzIyIi0trVDrZYayF5c+3oYpgtB1w5DqNaRaQf/qLdHAR+PGjVGr1Zw9exaAixcv8s8//9CyZUtsbGw4ffo0sbGxAOzevbtI237x4gU1atTA1NSUJ0+ecOTIEfk5W1tbDh48SGpqKqmpqezbt68kL0MogAhCFwTNKtEZr4mJCf7+/ixZsoRly5ZhamrKl19+iZmZGZaWlkycOJGRI0diZmaGo6MjFStWLPS2x4wZw9SpU3FxcaFmzZrY29vLzw0fPpzIyEhcXFywsLCgTZs28owWAG+//TbPnj0jPj6ebt26YWNjw8qVK0vyUgVBEDRGq+lk8fHx8qSU27Zt4/Tp03z77bca3XZqaiqzZs2idevWGvmQrTTpazrZ+RMHaRaxmxuW/8H6reJ9cKhLIkFLewypVtDfdDKtXsfr4+PDxYsXSUtLo2bNmixatEhj237vvfdISUkhOTmZTp06MWbMGI1tW8jKrtdAHls2x85AZqAQBH2n8zze2NhY3n///RyP29vbM2fOHK3t99SpU/j6+uZ4fMKECfTv319r+y0KfT3jFWc52mVI9RpSraC/Z7wiCF2PiMarGaJe7TGkWkF/G69+3c4hCILwGhCNVxAEQcdE4xUEQdAx0XiFQhFB6IKgOWUuFlIouvT0dMLCQnj8+BG1atXG1tYeIyMj+fmQY/tpHrmb0GzX8aakpLBly0Zu346mUaPGvPfeByVKZhOE14VovK+5gwf34+09P0vWboMGDfH2XsKAAQOBjCD0ltmC0BcuXMCGDWuzZFN4e3vh4TGZzz5brLsXIAgGSAw1FFNycjKTJk2iT58+DBw4kPfee4+YGMMKCj94cD/u7qNp2bIVhw8Hc+vWAw4fDqZly1a4u4/m4MGMqX4ym3Lm14ULF7Bu3ZdUrVoNX18/rly5ga+vH1WrVmPdui9ZuHBBqb0mQTAE4jreYkpOTiYsLIxu3bqhUCjYsWMHR48eZfv27cXepi6v401PT8fGpj0tW7Zi27bvUSr/93+wWq1m7NiRXLt2jfDwS/h6TcGjcSIboiswbeEaGjasRdWq1fjjj+uoVP/7pSktLQ0rqxY8ffqUmJhHpTbsIK411R5DqhX09zreEg01JCUl4enpSWRkJCqViurVq7N582YCAwMJCAhAkiRUKhV+fn7Uq1cv1234+/tz8+ZNkpOTiY6OplGjRsycOZPly5dz7949WrduzapVq1AqlcTHx7Ns2TKuX79OcnIy7du3Z8GCBZiYmLBlyxYOHjxIWloaKpUKLy8vOnToAICTkxOurq6EhITw5MkThg4dmu/cbr6+vlSoUAEPDw9OnTrFhx9+yJEjR2jcuDFz587FxsaGQYMG0b17d3kdKysrNm/eXJLDCehuBoqwsDPcuRPDxo1bMDHJ/mOgZPr0WfTt68z586Eo/r8khRK2bfuW9PR05s//lHLlsjZWlcqEuXO9mDFjKtu2fcvEiZN18lqy09dZB/JiSPUaUq2gx/VKJXDs2DHp/fffl79/9uyZFBYWJr311lvS48ePJUmSpMTERCkxMTHPbfj5+UlOTk7S8+fPJbVaLb3zzjvSf/7zHykuLk5KTU2VBg4cKJ04cUKSJEny8vKS9u7dK0mSJKnVamnevHnSxo0bJUmSpNjYWHmbly5dkvr06SN//9Zbb0mLFy+Wl+vYsaP06NGjPGsKCQmRRo8eLUmSJC1ZskQaPny4tGPHDkmSJKl79+65rjtr1ix5H8WlVqtLtH5RfPfddxIgxcXF5fr8ixcvJED67rvvpHkTx0pRn7tJ8yaOlSZPniwB0sOHD3Nd7/79+xIgTZ48WZvlC4JBK9EZb4sWLYiKisLb25suXbrQrVs3Tp48iaurKzVr1gSQZ2fIj4ODA5UqVQKgVatWmJiYyKlmrVq14vbt2wAEBwfz+++/s2XLFiDjjDvz0/e//vqLDRs28Pz5c4yMjIiOjiYpKYly5coByNPxVK1alfr163P37l1q1aqVaz2dOnXi+vXrJCUlcf78eWbPns3OnTuxs7OjfPnyOdbbsGEDd+7cYevWrUU4ejnpcgYKc/PKAISEnMfaukuO58+dOy8v9+oMFG/8/28uP/wQyJgx43Ks98MPgQC88Ua9UputQsySoD2GVCuU0Rko6tevz6FDhwgLCyM0NJSVK1fi4OAgN7vCyj7bw6vfK5VK+ZNzSZLw8/OjcePGWdbPnPtt27ZttGvXjvj4eDp16kRKSopcS17bzI2JiQlt2rThyJEjmJqaYmNjw6effsqZM2ews7PLsuymTZs4duwYW7duLdR/MgXR1biZtbUdDRo0xNd3Za5jvKtXr6JBg0ZYW9tx6df9ZM5AMXbseD79dD5Llixi2LBROcZ4v/jic4yMVIwdO77UxwD1bdaBghhSvYZUK+hfvSUa+Hj06BEKhQJnZ2dmz56NJEm4urqyf/9+OZj85cuXvHz5UiPF9uzZk40bN8rT8Pz777/ExMSQkpJCamoqderUASjRB1yZ7Ozs8PPzw87ODqVSScuWLdm6dWuWQPYtW7Zw6NAhtmzZgoWFRYn3qUtGRkZ4ey/h2LEjjB07kvPnw4mPj+P8+XDGjh3JsWNH8Pb+HCMjoywzUJiYmODhMZknT/7GyqoFAQFbePToIQEBW7CyasGTJ3/j4fGRuJ5XEPJRojPeiIgIfH19kSSJ9PR0XF1dsba2ZvLkybi7u6NQKDA2NsbPz4+6deuWuNi5c+fi4+PDoEGDUCgUqFQqPvnkExo2bMi0adP4z3/+Q5UqVTQS82hvb8+qVavkRuvg4MAvv/xCly4Zv5Y/evSIZcuWUb9+fTkL2MTEpMhTHJWmAQMGsmnTdry95+Pi0kt+vEGDRmzatF2+jrdmvYakR5yjZr2MBpx5ne6GDWuZNWuavJ6RkYqPPpomruMVhAKIy8n0SGnFQhZ055pKpeTxnevUyhaErq93rolLnrTHkGoF/b2cTDRePSLyeDVD1Ks9hlQr6G/j1cktw9euXcPT0zPH44MHD2bcuHG6KCFXHh4ePHz4MMtjFhYWGhkjFgRByIs449Uj4oxXM0S92mNItYL+nvHq2e0cgiAIZZ9ovIIgCDomGq8gCIKOiTxeIYdbt24SHx8vf5/bbZfK1JeojfO/U8/c3Jw332yq1VoFwRCJxitkcevWTWxtO+a7TP0qFfh1eh+cVx/l7rP8syXCwi6K5isI2ZRK47W0tOT8+fNau802KCgIKysrmjRpIn8fHBzM+vXrNbqfQ4cO8c0338i5D25ubrz//vsa3YemxcbGUq1atTyfzzzTXb9+I82bWwI5z3hNEv7G6Mp37NwaQIpZzVy3ExkZwaRJH2Q5c9Z0rYJgqMrkGe/evXuxsLCQG6+21K5dm2+//ZYaNWoQFxeHm5sbrVu3xsbGRqv7La7bt6Oxte1AWNglGjVqnO+yzZtb0q5deyDnJTnp/9wm8Qo0a9Yco+qNSr1WQTA0pd54b9++zdKlS4mNjSUlJYXhw4fz7rvvAhlnxtOnTyc4OJinT5/y0UcfMWTIEAAuXrzIwoULUavVtGnThqtXrzJ//nzu3LnDn3/+ydKlS/H392fGjBkAJCYmMmPGDG7cuIGxsTFffvkl9evXz7WmxMREevTowdmzZzE2Nmbo0KE0bNgQHx8fHjx4wJgxYwgODqZTp07yOhUrVuTNN9/k/v37JToe2gxCT0iIQ61Wc+nSBRIS4nJdJirqBpBxlptZS44w6Ve+z6vezGWjom4UK4Q6MjICtVpNQkJckY+J3oZf58GQ6jWkWkGP6y2NEODmzZtL//77r5SWliYNHjxYunnzpiRJGaHpAwYMkP744w95uU2bNkmSJEk3b96U2rdvL6WmpkrJyclSt27dpNDQUEmSJCk0NFRq3ry5FBYWJkmSJL377rvSL7/8Iu8vMDBQ6tixo3Tnzh1JkiRp5cqV0oIFC/KtcdSoUdK5c+ek58+fSwMHDpR69eolqdVq6ccff5S8vLxyLH/jxg2pS5cueQaEF4a2g9CDg4MloFB/goOD89xO0oMoKepzNynpQZRG9lXcOgTBUJXqGW90dDQ3b96Uz0oBEhISiIqKol27dgC8/fbbADRp0gSVSsU///wjh53b2toCYGtrS4MGDfLdV/v27eUz3Pbt27Njx458l7ezsyMkJISnT5/i4ODArVu3iIiIIDQ0lJ49e2ZZ9tGjR0yaNAlvb29q165dtIPwCm0HoRsZZWQTf/31Jnn8NrvIyAgmTHDHyKicHGSefYw3LS4j5vNF3EtU5XK/064w+8pPbnUUlgjr1h5DqhXKaBB6SUmSRKVKldi3b1+ey2QPMM/M4s1OoVDku6/sYev5BaFDRizkihUrePr0Kb169aJWrVqEhIQQHh6Ol5eXvNzjx48ZN24cEydOpF+/fvluszC0eVujmVlFlEolHTp0znPcNPOHM7fg6MzHXl2GPOrNXKZJk2a0bt2u2LWamVUs9jHRt/DrghhSvYZUK+hfvaXaeBs3boy5uTmBgYHy2G1MTAyVKlWicuXKea735ptvkpaWxrlz5+jSpQvnzp3LMrW6mZkZcXG5j2EWVrt27YiOjiY2Npa5c+dSq1YtJkyYQPXq1alatSoAf//9N+PGjeODDz5g8ODBJdqfLjRq1JirV6MKdaXA5ct/yH/P7aqGusCNG5GkPHie6/qRkRE6q1UQDE2pNl6VSsXXX3/N0qVL2bp1K2q1mipVquDj45PveiYmJvj6+rJo0SIkSaJ169Y0btxYvjxt+PDhLFu2jK1bt2YZxihqbR06dCAxMZFy5crRrFkzUlNTs0z94+fnx8OHDwkICCAgIACAMWPGyP+J6KOCGlnmbxQzZkzJc5nM63jfGTemwOt4M+fOKw7RdIWyymDTyeLj4+V/1JcvX2bSpEn88ssvGpn3rLToSzrZxYsXssylZmh3rokELe0xpFpBf9PJSv1ysuLKnGBSkiRUKhUrVqww6KarTzp27Jzle0P7xyYI+s5gG6+bmxtubm4l2sapU6fw9fXN8fiECRM0Mm+bIAhCbgy28WpC9+7d6d69e2mXIQjCa0bPbucQBEEo+0TjFQRB0DHReAVBEHTstR7jFYove1h6YRXmMrRMIkhdKKtE4xWKrDBh6bkpSoB6JhGkLpRFxW68mggz37BhA3v37iUmJoa1a9fmCJ8pqp9++onNmzejVqupVq0aX3zxBXXq1AHAyckJY2NjypXLCG/RxCVjCQkJTJ06lT///JP09HQuXLhQou3pgibCxXMLSy+MwgSoZyooSF2EpAuGrFTPeO3t7XFxcWHevHkl3lZUVBQrV65k79691KxZk3379uHt7c0333wjL7NmzRpatmxZ4n1lMjY2Zvz48VSuXJnRo0drbLvaoulw8VfD0gtDUwHqIiRdMHQaabzLly/n3LlzpKWlYW5uzuLFi3nzzTcBCA4OxsfHB2NjYxwdHdmzZw+BgYHUq1dPjn4sCn9/fw4cOIC5uTmOjo4cOHCA48ePc+PGDSwtLalZM+NMqnv37syZM4dnz55RpUqVIu9nxIgRzJ49m44dO7JixQoOHDjA6dOnAXB2dmb79u3UqVMHOzs77t27V+Tt56W0g9Bzo1QqMDcvR3x8Emq1lGtYeqEUIkBdXjSfIPWCQtL1Nvw6D4ZUryHVCvpbr0Ya7wcffMCcOXOAjHnIlixZwqZNm4iNjWX+/Pl89913NGnShMDAQJ4/f17s/Zw8eZIjR44QFBSEmZkZn3zyifxcixYtuHr1KtHR0TRu3Jj9+/cjSRIPHjyQG+/s2bMBaNu2LbNmzZJTxnKTmcfbsWNHwsLCqF27Njdv3sTExASVSiUPYWiSUqmgShUzjW83U3p6EgATJrhrbHtFqTc5qTxxgEXF8pgWsF5hai1o/xYWhnULuSHVa0i1gv7Vq5HGe/bsWXbs2EFCQgJqtZp///0XgN9//53mzZvLc58NHjyYzz77rNj7CQ0NpV+/fnI4zogRI7h48SIAjRo1YuHChcyZM4e0tDR69OiBhYUFRkZGAOzYsYM6deqQmprKmjVrmDNnDhs3bsxzX/b29qxZs4ZRo0ahUqno27cvISEhmJiYyAHsmqYPQei5yX7GW9yQ8sIEqBem1oL2L8K6tceQaoUyHIT+4MEDFi9ezJ49e2jQoAHXr1+X50zTtb59+9K3b18Anjx5wsaNG2nYsCGAfIZqbGzM2LFj6dOnT77bat++PTdu3ODXX3/F1tZWbsQmJiZazXEo7SD03OSY7DKfsPT8FCZAPfuyuQWpFzYkXd/CrwtiSPUaUq2gf/WWuPHGxcWhUqmoUaMGkiSxc+dO+bn27dsTGRnJrVu3ePPNN9m/fz+pqanF3pe9vT0rV65k3LhxmJmZ8eOPP2Z5/u+//6ZmzZqkp6ezatUq3nnnHcqXL09iYiJpaWnyFRiHDh2iVatW+e7L2NgYKysrvvrqK5YsWYKlpSVRUVHExcWxaNGiYr+G0qTpcPFXw9ILozAB6pnyC1IXIemCoStx47W0tKR///64uLhQuXLlLJeEVatWjc8//5yPPvoIExMT7O3tqVChgtwA169fz65du3j69CmRkZEsWrSIn376Kc+x1+7du3P58mXc3NzkD9deNW/ePB48eEBKSgo9evSQQ9BjY2OZMmWKPN1PvXr1WL58eYGvzd7ennPnztGpUycUCoU8K8Wrs2O8/fbbPHv2jPj4eLp164aNjQ0rV64s0jHUJU00q8KEpeemKAHqmfIKUhdNVzBkWg9CfzWwPPMKh59//lkj246MjMTDw4Pjx49rZHulTV+C0LPLLY83e1h6YenizjVDyw82pHoNqVZ4jYPQd+zYweHDh1Gr1Zibm7Nq1Spt71LQgexh6YIgFJ5eTv3j5uaWYxbgpk2bFjgXW1HFxsby/vvv53jc3t5evjxOlwzpjFefiXq1x5Bqhdf4jLc4goKCdLKfatWq5Tu1vCAIgjbo1+0cgiAIrwHReAVBEHRMNF5BEAQd08sxXsGwZA9FN7Sw8/T0dMLCQnj8+BG1atXG1tZevtVcELRBNF6hRLKHohta2PnBg/vx9p7PnTsx8mMNGjTE23sJAwYMLJWahLKvzDTe0NBQfHx8SExMRKFQ0L17d2bNmoVSqeTevXv06tWL5s2by8v7+/vToEGDEu3z0KFDfPPNN/Klb25ubrlenlaWZQ9FN6Sw84MH9+PuPprevfuyYcMmWrRoxfXrf/Hllz64u49m06btovkKWlFmGm+lSpVYvXo19evXJzk5mXHjxvHTTz/h5uYGgJmZmcYvHatduzbffvstNWrUIC4uDjc3N1q3bo2NjY1G96PPHjx4AIC5eUXatWtvMGHn6enpeHvPp3fvvmzb9j1KZcbHHZ07d2Hbtu8ZO3Yk3t5e9OvnIoYdBI3TWeNNSkrC09OTyMhIVCoV1atXZ/PmzQQGBhIQEIAkSahUKvz8/KhXr16u24iPj8fLy4tr165RtWpVmjVrRkpKCsuWLcsSemNqakrLli25f/9+sWpNTEykR48enD17FmNjY4YOHUrDhg3x8fHhwYMHjBkzhuDgYDp16iSvU7FiRd58881i7zOTNoPQiyu/MOmXLxPkryqVUmdh58WtN1NY2Bnu3Ilh48YtmJhk/2egZPr0WfTt68z586F07dqtSPsvKn0N686NIdUK+luvzhrv6dOniYuL4/DhwwA8f/6c8PBw1q1bx65du6hZsyYvX77Mdxvr1q3DxMSEI0eOEB8fz7Bhw7Cyssqx3JMnTzh69CgbNmyQH3v58iVDhgxBrVbj7OzMxIkT8zyTqVChAs2aNZPzhFNTU7ly5QqSJHH27Fns7OxyrHPz5k1+//13Fi5cWJTDkoW2g9BLKrcwaTMzU/lrlSpmOg87L2q9meLjnwNgb2+NuXnO7dvbW8vL6eo90bew7vwYUq2gf/XqrPG2aNGCqKgovL296dKlC926dePkyZO4urrK0/WUL5//wQkLC2Pu3LkoFAoqVqzIgAEDuHv3bpZl4uPj8fDwYPz48bRt2xaAmjVr8t///pdq1arx/Plzpk+fzubNm/nggw/y3FfmDBRPnz7FwcGBW7duERERQWhoaI5JOR89esSkSZPw9vamdu3axTk8gPaD0IsrvzDphIRk+euzZwk6Czsvbr2ZzM0rAxASch5r6y45nj937ry8XFH3X1SGFC5uSLVCGQ5CL6z69etz6NAhwsLCCA0NZeXKlTg4OMiz/haHQqHI8n18fDzjx4/H2dmZ9957T37cxMRE/pCmcuXKDBkyhIMHD+bbeO3t7VmxYgVPnz6lV69e1KpVi5CQEMLDw/Hy8pKXe/z4MePGjWPixIn069ev2K8lkz7f/55bmLRarZa/Zg9JL0nYeXHD1guqN5O1tR0NGjTE13dlljHezNeyevUqGjRohLW1nc7eE30L686PIdUK+levzgY+Hj16hEKhwNnZmdmzZyNJEq6uruzfv5+///4byBgOyG+4wc7OjqCgICRJIj4+nkOHDsnPJSQkMH78eLp27cqkSZOyrBcbGysHsKekpHDs2LECZxvOzN4NCQmhc+fO2Nvbs2PHDqpXry7nBf/999+MGzeODz74gMGDBxfruBg6M7OKWb5qioVFJZRKJRYWlTS63UxGRkZ4ey/h2LEjjB07kvPnw4mPj+P8+XDGjh3JsWNH8Pb+XHywJmiFzs54IyIi8PX1RZIk0tPTcXV1xdramsmTJ+Pu7o5CocDY2Bg/Pz/q1q2b6zYmTZqEl5cXffv2pWrVqnTq1ImUlBQAAgICuHLlCi9fvuSXX34BMqYCmjhxIr/99ht+fn4olUrS09OxtbVl4sSJ+darUqno0KEDiYmJlCtXjmbNmpGampplfNfPz4+HDx8SEBBAQEAAAGPGjGHIkCGaOGQGIXNKpX/+ecLly78b1CwTAwYMZNOm7Xh7z8fFpZf8eIMGjcSlZIJW6WUsZGHt2LGDP//8k2XLlpV2KRphiLGQFy9eoG9fJ/l7fbiBoqhRgKV955ohRS0aUq0gYiGFMqpjx84cOXI8y2wU91JfsmX39EKtrw+3DBsZGeHg4FjwgoKgIXrXeK9du4anp2eOxwcPHsy4ceOyPFbS2YxPnTqFr69vjscnTJig1ZmEyxoxG4UgFI1BDzWUNYY41KCPRL3aY0i1gv4ONejX7RyCIAivAdF4BUEQdEw0XkEQBB3Tuw/XhNdD9vD0ksgevK6J20T14WoLoewSjVfQuezh6SVRnOuGC6s0A9qFsk00XgOl7ZBwbcoenl4SuQWvl/SMt6CAdkNmyD83ZYnBNd5du3axdetWTE1N2bp1K1WqVNHq/h4/fsy8efO4d+8eJiYmNGrUiIULF8p5DU5OThgbG8thP7q4BljbIeG60ry5Je3atS/RNnILXje0S550paz83JQFBtd4t23bxhdffEGHDh10sj8jIyMmTpxI584ZNwksX76cFStWZLlNec2aNQWG7mjSixf/olarefHiX53tUzB84udGf+hF47W0tOTjjz/m+PHjxMbGMm/ePKKiojh69Cjx8fEsXrwYGxsbpk6dyt27d/H09MTS0hI/Pz9OnjyJv78/qampKBQKFi1ahJWVFZcuXWLFihUkJCQgSRLTpk3LkaP7Kn9/fw4cOIC5uTmOjo4cOHCA48ePU716dapXry4vZ2Vlxc6dO7V2LAoz20J+Mzdog1KpwNy8HPHxSajVJb/fJirqBlC4WSoKlMuMFyWddcDQj29eNHHc9XVGh7zobb2SHmjevLm0detWSZIkKSQkRGrfvr0UGBgoSZIkHT58WHJzc5OXfeutt6S//vpLkiRJunXrlmRrayvdvHlTkiRJSklJkV68eCE9e/ZMsrOzk86fPy9JkiSlp6dLz549y3P/J06ckPr37y/FxcVJarVamjlzpvTWW2/lWC4tLU169913pS1btmSpZ8CAAdKAAQOkuXPnSrGxscU+Dmq1ulDLBQcHS4DB/wkODi72scqU9CBKivrcTUp6EFXibWUqK8dXm8ddKBm9OOMF5HHRNm3akJiYiIuLC5CRixsTE5PrOiEhITg6OtKkSRMAjI2NMTY25uTJkzRu3FgeHlAqlVSuXDnPfYeGhtKvXz/Mzc0BGDFiBBcvXsyyjCRJLFy4EAsLC8aMGSM/vmPHDurUqUNqaipr1qxhzpw5bNy4sVjHoLAzUOQ3c4M2aPqMrCSzS2SX24wXJf1wzdCPb140cdzFDBR508sZKApiapoxd1fmTACZ3xsZGcnTp5emzz//nIcPH7Ju3bossxVk5tEaGxszduxY+vTpU6L9FObDIDOziiiVSjp06KyTD0k0/WGVJmaXyG1b2We8KO7285sZQxt09WFg5s+NmVlFjRx3Q/rgUt/q1ZvGWxxdu3Zl3bp1REVF0aRJE1JTU0lKSqJDhw7ExMRw4cIFOnfu/P8fKLzI86zX3t6elStXMm7cOMzMzPjxxx+zPP/5558TExPD+vXrMTExkR9PTEwkLS0NCwsLAA4dOpRltmNt0UVIuC5cvvxHibeRW/C6Ji4nK4vKys9NWWDQjbdhw4Z88cUXfPLJJ6SlpWFkZMTChQtp164da9euZdmyZSQkJKBUKpk2bRpOTk65bqd79+5cvnwZNzc3+cO1TL/99hvbt2/nzTff5D//+Q8A9erVY926dcTGxjJlyhT5jLxevXosX75c+y8cDPofT1paGgAzZkwp8bYyb6B4Z9wYjd9AkTn0VJYY8s9NWSJiIXMRGRmJh4cHx48f1+l+X6dYyIsXL2QJTy8JQ79l2JCuOzakWkF/YyEN+oxXMFzaDE83tOYgvH5eq8br5uaW44O6pk2b4uPjk+Wx5s2b6/xsVxCE18dr1XiDgoJKuwRBEASRxysIgqBrovEKgiDomGi8giAIOvZajfEKpU+TM0/kRROXk2W/RE3MSCFokmi8gs5ocuYJbcprVgsxI4WgKWWy8QYFBWFlZSWH52R34sQJNm/ezPbt20u0n8uXL7N06VKuXbuGg4MD69evL9H2dKE0ZyDQ5MwT+SnpGW/2WS1KY0YKMVNE2VYmG+/evXuxsLDIs/FqSs2aNZk3bx5//fUX//3vf7W6L03QlxkINDHzRH5KegNFbrNa6JK+vE+C9pRa401KSsLT05PIyEhUKhXVq1dn8+bNBAYGEhAQgCRJqFQq/Pz8qFevXq7bOH78OKtXr0apVJKens7HH3/Ms2fP+PPPP1m6dCn+/v7MmDEDe3t7lixZQkhICBYWFnJcZF4SExPp0aMHZ8+exdjYmKFDh9KwYUN8fHx48OABY8aMITg4mNq1a1O7dm1u3rypseNS4mDwfCQkxKFWq7l06QIJCXGFXk9TsYUaDUDPR4nDr7OFq2s7GD378Y2MjECtVpOQEKfV41Qcehssngd9rbfUGu/p06eJi4vj8OHDADx//pzw8HDWrVvHrl27qFmzJi9fvsx3G2vWrGHRokV06NABtVpNfHw8FhYW7N+/n7Fjx8ozTuzcuZPo6GgOHjwIgLu7e77brVChAs2aNeP333+nefPmpKamcuXKFSRJ4uzZs9jZ2WngCOSkVCqoUsVMK9sGSE9PAmDChPxfv7alpydp9XVmsrAoX/BCuUhOKk8cYFGxPKZVzErtuOnqOBVHcY9tadG3ekut8bZo0YKoqCi8vb3p0qUL3bp14+TJk7i6ulKzZsZsseXL53+w7OzsWLJkCX369KFr1655znsWGhrKoEGD5EjHIUOGEBgYWOC2Q0JCePr0KQ4ODty6dYuIiAhCQ0PznUKoJAobhF5cxQ341tQZryYD0PNT0jHe7OHq2g5Gz+2MVxfHqThEEHreDCIIvX79+hw6dIiwsDBCQ0NZuXIlDg4O8my9hTF37lxu3LhBeHg4c+bM4e233+aDDz4ocD2FQlHgMvb29qxYsYKnT5/Sq1cvatWqRUhICOHh4Xh5eRW6xqLSRRB2UQPUNRU6o8kA9MLuryRB6Jnh6toORs9+fDUZWK4t+hYsXhB9q7fUGu+jR4+wsLDA2dkZR0dHgoODcXV1xdPTk5EjR2YZasjrzDcqKopmzZrRrFkzjIyMOHv2LABmZmbExf1vDNPOzo79+/czYMAAJEkqVGZDu3btiI6OJjY2lrlz51KrVi0mTJhA9erV5andDY2+BGFrIgA9P5q4quHVcHVdB6Pry/skaE+pNd6IiAh8fX2RJIn09HRcXV2xtrZm8uTJuLu7o1AoMDY2xs/Pj7p16+a6jdWrVxMdHY2xsTHlypXD29sbgOHDh7Ns2TK2bt3KjBkzGDZsGDdu3MDFxUX+cO3q1av51qdSqejQoQOJiYmUK1eOZs2akZqammV899atW4wbN46kpCSSkpLo1q0bEyZM4J133tHYcdK00vzHrMkAdG3KK1xdl8HooumWbSIIXY+8DkHomgxAz4uh3blmSPnBhlQriCB0QQC0G4CeydCag/D60fvGe+3aNTw9PXM8PnjwYMaNG1eibZ86dQpfX98cj0+YMEGebl4QBEHTxFCDHnkdhhp0QdSrPYZUK+jvUIN+3c4hCILwGhCNVxAEQcdE4xUEQdAxvf9wTRDKmuxh8CW9/C37pW/5EYHuhZeenk5YWAiPHz+iVq3a2NraY2RkpJFti8YrCDqk6TD4vELb8yMC3Qt28OB+vL3nc+dOjPxYgwYN8fZewoABA0u8fdF4S8AQg9Bfd6UdMJ5bGHxJznizh7bnpySB7qV93HTp4MH9uLuPpnfvvmzYsIkWLVpx/fpffPmlD+7uo9m0aXuJm69ovCVgaEHorzt9Chh/NQy+JJc86SK0/dXj1rSpdicXKG3p6el4e8+nd+++bNv2PUplxsdgnTt3Ydu27xk7diTe3l706+dSomEHg2i8uYWmT5gwgaVLl7Jv3z4AIiMj8fDw4Pjx49y7d49Bgwbx7rvvcurUKRISEvjiiy84evQo4eHhpKen4+vrS/PmzXPdX1kNQi8ufQ2Tzkte9RY3CF6TcguDL9HxzRbanu+ixQx0fzWYvaz8LOQlLOwMd+7EsHHjFkxMsrdHJdOnz6JvX2fOnw+la9duxa7LIBpvbqHpERH5J0bFxcXRpk0bPv74Y3bv3s348eP56quvmDdvHt9++y1r167Fz88v13XLahB6SelbmHRBsterL0HwkHvIeXGOb/bQ9oL2CcV//enpSXKNhv6zkJf4+OcA2NtbY26e83ja21vLy5Xk36pBNN7cQtMLYmpqKgeWt23blgoVKmBrawtkRD4eOHAg3/XLYhB6cZWV8GttB5oXRm4h5yU5vtlD2/NT3Nf/as0vXrwsEz8LeTE3rwxASMh5rK275Hj+3Lnz8nLZQ+oNIgi9KHILTV+5ciVq9f8OZHJycpZ1MmebAFAqlZiammb5Pj09Pd99lsUg9JLStzDpgmSvt7hB8JquKbfa8nqsKNujgHWLG+j+ajC7rsPsNaWw9Vpb29GgQUN8fVdmGeMFUKvVrF69igYNGmFtbVei128QjTe30HRJkrh//z5Pnz6latWq8livppTFIPTXnT4FjL8aBl/SqxpeDW3PT3ED3fXpuGmbkZER3t5LcHcfzdixI5k6dQYtW7bi2rW/8PPz5dixI2zatL3E1/MaROPNKzR9/PjxDB06lOrVqxdq+KEoymoQ+uuutJuHpsPg8wptz09xAt1L+7jp0oABA9m0aTve3vNxceklP96gQSONXEoGIp1Mr4h0Ms3Q93qzh8Eb0p1r+n5ssyvRpXpFvHNNBKELgh7LHgZvaM3sdWFkZISDg6NWtv1aN14RhC4IQmkQQw16RJIk1Gr9fDuMjJQGcflQJlGv9hhSraC7epVKBQqFolDLisYrCIKgY4Zx358gCEIZIhqvIAiCjonGKwiCoGOi8QqCIOiYaLyCIAg6JhqvIAiCjonGKwiCoGOi8QqCIOiYaLyCIAg6JhqvIAiCjonGKwiCoGOi8QqCIOiYaLyvudu3bzNixAj69OnDkCFDuHHjRq7L7d69m969e9OzZ0+8vLxITU0t1HP6VOu9e/cYPXo0nTp1wtXVVSs1arLe0NBQhg4dSv/+/XFxcWHFihVZ5hnUt3ovXbqEq6srrq6uuLi48Omnn5KSkqKXtWaSJIkxY8bQuXPnXNfXGkl4rY0ePVoKDAyUJEmSfv75Z8nNzS3HMnfu3JEcHBykv//+W1Kr1dKECROkHTt2FPicvtX67Nkz6fz589KJEyekgQMHaqVGTdZ79epV6c6dO5IkSVJSUpI0YsQIeXv6WG9iYqKUkpIiSZIkpaenS5MmTZK2bNmil7Vm2rx5szR//nypU6dOWqkzL+KM9zUWGxvLn3/+ycCBGXNI9enTh0ePHhETE5NluaNHj+Lk5ESNGjVQKBSMHDmSgwcPFvicvtVauXJlOnfuTPnyhZsmp7TrbdWqFfXr1wfA1NSUli1bcv/+fb2tt3z58hgbGwOQmppKUlKS3tYKcOPGDYKDg/nwww+1Umd+RON9jT18+JAaNWrI838pFAreeOMNHjx4kGO5unXryt/XrVuXhw8fFvicvtWqS5qu98mTJxw9epQePXrodb337t1j4MCB2NraUrFiRUaNGqWXtaamprJgwQIWLVqUZQp3XRGNVxD0XHx8PB4eHowfP562bduWdjn5qlevHvv37+fMmTOkpKTwyy+/lHZJuVq7di29evWiSZMmpbJ/0XhfY2+88QZPnjyRpxyXJImHDx9Sp06dHMu9+ivu/fv3eeONNwp8Tt9q1SVN1RsfH8/48eNxdnbmvffe0/t6M5mZmeHi4sKBAwf0stbz58+zY8cOnJycGDVqFPHx8Tg5OfH06VON15sb0XhfY9WqVaN169bs378fyBgTq1WrFg0bNsyyXJ8+fTh+/DhPnjxBkiS+//57XFxcCnxO32rVJU3Um5CQwPjx4+natSuTJk3S+3pjYmLkqwYyz3YtLS31stbvvvuOEydOcPz4cb777jvMzc05fvw4VatW1Xi9udLpR3mC3omKipKGDRsm9e7dWxo8eLB0/fp1SZIkad68eVJwcLC83A8//CA5OztLzs7O0ty5c+VPrwt6Tp9qTUxMlBwdHSUbGxupdevWkqOjo7Rq1Sqt1KqJetevXy+1atVKGjhwoPxn/fr1elvvrl27JBcXF+ntt9+W+vfvLy1evFhKSkrSy1pfdffuXZ1f1SAmuxQEQdAxMdQgCIKgY6LxCoIg6JhovIIgCDomGq8gCIKOicYrCIKgY6LxCoIg6JhovIIgCDomGq8gCIKOicYrCIKgY6LxCoIg6JhovIIgCDr2f5gSmgZQiiIbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_idx = result.importances_mean.argsort()[::-1][:10]\n",
    "df2 = df.iloc[:, sorted_idx]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.boxplot(result.importances[sorted_idx].T, vert=False, labels=list(df2.columns)[::-1])\n",
    "plt.title(\"Permutation Importances (test set)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=60, max_features=&#x27;sqrt&#x27;,\n",
       "                       min_samples_leaf=2, min_samples_split=7,\n",
       "                       random_state=582153120)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=60, max_features=&#x27;sqrt&#x27;,\n",
       "                       min_samples_leaf=2, min_samples_split=7,\n",
       "                       random_state=582153120)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=60, max_features='sqrt',\n",
       "                       min_samples_leaf=2, min_samples_split=7,\n",
       "                       random_state=582153120)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plot_tree(rf.estimators_[0], \n",
    "          feature_names=df.columns, \n",
    "          class_names=['speech', 'song'], \n",
    "          filled=True, \n",
    "          rounded=True,\n",
    "          fontsize=12,\n",
    "          max_depth=2)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "plot_tree(rf.estimators_[1], \n",
    "          feature_names=df.columns, \n",
    "          class_names=['speech', 'song'], \n",
    "          filled=True, \n",
    "          rounded=True,\n",
    "          fontsize=12,\n",
    "          max_depth=2)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-08 15:37:06,461] A new study created in memory with name: no-name-f8313081-7fbb-4389-b389-6d467c582714\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[W 2023-07-08 15:37:06,494] Trial 2 failed with parameters: {'n_estimators': 1, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 9, 'learning_rate': 0.04759393411373759, 'criterion': 'mae', 'subsample': 0.9905901712216874, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:06,506] Trial 2 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:37:07,380] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 11, 'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 9, 'min_samples_leaf': 10, 'learning_rate': 0.11134307248679587, 'criterion': 'friedman_mse', 'subsample': 0.9447631859254138, 'loss': 'deviance'}. Best is trial 3 with value: 1.0.\n",
      "[I 2023-07-08 15:37:07,385] Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 9, 'max_depth': 90, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 8, 'learning_rate': 0.26349390807939693, 'criterion': 'friedman_mse', 'subsample': 0.8066432639526417, 'loss': 'deviance'}. Best is trial 3 with value: 1.0.\n",
      "[W 2023-07-08 15:37:07,398] Trial 5 failed with parameters: {'n_estimators': 6, 'max_depth': 90, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 4, 'learning_rate': 0.23691784792014906, 'criterion': 'mae', 'subsample': 0.5481429147035359, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:07,415] Trial 5 failed with value None.\n",
      "[W 2023-07-08 15:37:07,427] Trial 7 failed with parameters: {'n_estimators': 1, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 10, 'min_samples_leaf': 10, 'learning_rate': 0.055291729039840934, 'criterion': 'friedman_mse', 'subsample': 0.9618308847643597, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:37:07,442] Trial 7 failed with value None.\n",
      "[W 2023-07-08 15:37:07,455] Trial 8 failed with parameters: {'n_estimators': 2, 'max_depth': 80, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 10, 'learning_rate': 0.15644926314058064, 'criterion': 'mae', 'subsample': 0.6928788586025709, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:07,467] Trial 8 failed with value None.\n",
      "[I 2023-07-08 15:37:07,682] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 11, 'max_depth': 30, 'max_features': 'log2', 'min_samples_split': 15, 'min_samples_leaf': 1, 'learning_rate': 0.21851345750437506, 'criterion': 'friedman_mse', 'subsample': 0.794711774550472, 'loss': 'log_loss'}. Best is trial 3 with value: 1.0.\n",
      "[I 2023-07-08 15:37:07,855] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 1, 'max_depth': 30, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 1, 'learning_rate': 0.16428067071262342, 'criterion': 'friedman_mse', 'subsample': 0.8010880863975152, 'loss': 'log_loss'}. Best is trial 3 with value: 1.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:07,869] Trial 11 failed with parameters: {'n_estimators': 18, 'max_depth': 30, 'max_features': 'log2', 'min_samples_split': 1, 'min_samples_leaf': 10, 'learning_rate': 0.12856520569627752, 'criterion': 'friedman_mse', 'subsample': 0.8980586238352251, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'min_samples_split' parameter of GradientBoostingClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of GradientBoostingClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "[W 2023-07-08 15:37:07,871] Trial 11 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:37:08,064] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 15, 'max_depth': 60, 'max_features': 'sqrt', 'min_samples_split': 11, 'min_samples_leaf': 4, 'learning_rate': 0.09956315298050765, 'criterion': 'friedman_mse', 'subsample': 0.693708946704637, 'loss': 'log_loss'}. Best is trial 3 with value: 1.0.\n",
      "[W 2023-07-08 15:37:08,078] Trial 13 failed with parameters: {'n_estimators': 5, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 6, 'learning_rate': 0.10539717397275303, 'criterion': 'mae', 'subsample': 0.8024644848423035, 'loss': 'deviance'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:08,082] Trial 13 failed with value None.\n",
      "[W 2023-07-08 15:37:08,095] Trial 14 failed with parameters: {'n_estimators': 16, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 20, 'min_samples_leaf': 4, 'learning_rate': 0.0672202834594629, 'criterion': 'mae', 'subsample': 0.9279901767409361, 'loss': 'exponential'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:08,099] Trial 14 failed with value None.\n",
      "[W 2023-07-08 15:37:08,110] Trial 15 failed with parameters: {'n_estimators': 8, 'max_depth': 90, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 6, 'learning_rate': 0.14111689732531116, 'criterion': 'mae', 'subsample': 0.7137884559206822, 'loss': 'exponential'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:08,118] Trial 15 failed with value None.\n",
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "[I 2023-07-08 15:37:08,361] Trial 12 finished with value: 1.0 and parameters: {'n_estimators': 2, 'max_depth': 60, 'max_features': 'log2', 'min_samples_split': 4, 'min_samples_leaf': 2, 'learning_rate': 0.25503610357638323, 'criterion': 'friedman_mse', 'subsample': 0.6598114806713284, 'loss': 'deviance'}. Best is trial 3 with value: 1.0.\n",
      "[W 2023-07-08 15:37:08,373] Trial 17 failed with parameters: {'n_estimators': 2, 'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 3, 'min_samples_leaf': 4, 'learning_rate': 0.2691715070923717, 'criterion': 'mae', 'subsample': 0.8162453674302875, 'loss': 'exponential'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:08,376] Trial 17 failed with value None.\n",
      "[I 2023-07-08 15:37:08,751] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 18, 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 5, 'min_samples_leaf': 8, 'learning_rate': 0.10569359267079786, 'criterion': 'friedman_mse', 'subsample': 0.6936192365224629, 'loss': 'exponential'}. Best is trial 3 with value: 1.0.\n",
      "[W 2023-07-08 15:37:08,763] Trial 19 failed with parameters: {'n_estimators': 8, 'max_depth': 10, 'max_features': 'log2', 'min_samples_split': 11, 'min_samples_leaf': 9, 'learning_rate': 0.1235806503515604, 'criterion': 'mae', 'subsample': 0.9546104968797688, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:08,764] Trial 19 failed with value None.\n",
      "[I 2023-07-08 15:37:09,141] Trial 18 finished with value: 1.0 and parameters: {'n_estimators': 9, 'max_depth': 40, 'max_features': 'log2', 'min_samples_split': 18, 'min_samples_leaf': 5, 'learning_rate': 0.21569682687592184, 'criterion': 'friedman_mse', 'subsample': 0.6318973101758611, 'loss': 'exponential'}. Best is trial 3 with value: 1.0.\n",
      "[W 2023-07-08 15:37:09,151] Trial 21 failed with parameters: {'n_estimators': 9, 'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 6, 'min_samples_leaf': 7, 'learning_rate': 0.15048356846846467, 'criterion': 'mae', 'subsample': 0.7655928461313127, 'loss': 'exponential'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:09,158] Trial 21 failed with value None.\n",
      "[W 2023-07-08 15:37:09,171] Trial 22 failed with parameters: {'n_estimators': 16, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 8, 'learning_rate': 0.2964413487382829, 'criterion': 'friedman_mse', 'subsample': 0.953751423347378, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got 0 instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "[W 2023-07-08 15:37:09,173] Trial 22 failed with value None.\n",
      "[W 2023-07-08 15:37:09,190] Trial 23 failed with parameters: {'n_estimators': 4, 'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 11, 'min_samples_leaf': 1, 'learning_rate': 0.030996532521069015, 'criterion': 'mae', 'subsample': 0.9489951087755328, 'loss': 'exponential'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:09,194] Trial 23 failed with value None.\n",
      "[I 2023-07-08 15:37:09,303] Trial 10 finished with value: 1.0 and parameters: {'n_estimators': 19, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 8, 'learning_rate': 0.09825261112715178, 'criterion': 'friedman_mse', 'subsample': 0.7071246704201315, 'loss': 'exponential'}. Best is trial 3 with value: 1.0.\n",
      "[I 2023-07-08 15:37:09,436] Trial 16 finished with value: 1.0 and parameters: {'n_estimators': 16, 'max_depth': 80, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 10, 'learning_rate': 0.20070389716398387, 'criterion': 'friedman_mse', 'subsample': 0.8411802046581802, 'loss': 'deviance'}. Best is trial 3 with value: 1.0.\n",
      "[W 2023-07-08 15:37:09,508] Trial 26 failed with parameters: {'n_estimators': 6, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.019867600538758162, 'criterion': 'mae', 'subsample': 0.5840177990132029, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:09,510] Trial 26 failed with value None.\n",
      "[W 2023-07-08 15:37:09,585] Trial 27 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.017252518992074695, 'criterion': 'mae', 'subsample': 0.5107637329203266, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:09,589] Trial 27 failed with value None.\n",
      "[W 2023-07-08 15:37:09,666] Trial 28 failed with parameters: {'n_estimators': 6, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.29529828492125254, 'criterion': 'mae', 'subsample': 0.528142807995498, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:09,669] Trial 28 failed with value None.\n",
      "[W 2023-07-08 15:37:09,746] Trial 29 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.04700414441467872, 'criterion': 'mae', 'subsample': 0.5544333139023473, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:09,751] Trial 29 failed with value None.\n",
      "[W 2023-07-08 15:37:09,825] Trial 30 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.038923532675220085, 'criterion': 'mae', 'subsample': 0.5874501149842417, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:09,830] Trial 30 failed with value None.\n",
      "[W 2023-07-08 15:37:09,898] Trial 31 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.03567298752383659, 'criterion': 'mae', 'subsample': 0.5192384081242613, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:09,903] Trial 31 failed with value None.\n",
      "[W 2023-07-08 15:37:09,980] Trial 32 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.023523703457226153, 'criterion': 'mae', 'subsample': 0.5220401118162405, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:09,983] Trial 32 failed with value None.\n",
      "[W 2023-07-08 15:37:10,059] Trial 33 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 3, 'learning_rate': 0.29976934257417814, 'criterion': 'mae', 'subsample': 0.5268724716510589, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:10,061] Trial 33 failed with value None.\n",
      "[W 2023-07-08 15:37:10,134] Trial 34 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.294251867464858, 'criterion': 'mae', 'subsample': 0.599546872950166, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:10,137] Trial 34 failed with value None.\n",
      "[W 2023-07-08 15:37:10,213] Trial 35 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.017304178860571506, 'criterion': 'mae', 'subsample': 0.5209012492910923, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:10,217] Trial 35 failed with value None.\n",
      "[W 2023-07-08 15:37:10,291] Trial 36 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.011748899658327122, 'criterion': 'mae', 'subsample': 0.5320212100729204, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:10,295] Trial 36 failed with value None.\n",
      "[W 2023-07-08 15:37:10,371] Trial 37 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.018835105863095808, 'criterion': 'mae', 'subsample': 0.5286103747087547, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:10,374] Trial 37 failed with value None.\n",
      "[W 2023-07-08 15:37:10,452] Trial 38 failed with parameters: {'n_estimators': 13, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.013824149495242188, 'criterion': 'mae', 'subsample': 0.5021447690648471, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:10,457] Trial 38 failed with value None.\n",
      "[W 2023-07-08 15:37:10,530] Trial 39 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.017007269070556524, 'criterion': 'mae', 'subsample': 0.5220332277326085, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:10,533] Trial 39 failed with value None.\n",
      "[W 2023-07-08 15:37:10,607] Trial 40 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.017676857330439194, 'criterion': 'mae', 'subsample': 0.51423775372329, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:10,609] Trial 40 failed with value None.\n",
      "[W 2023-07-08 15:37:10,686] Trial 41 failed with parameters: {'n_estimators': 6, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.29919471723824875, 'criterion': 'mae', 'subsample': 0.5101974035487227, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:10,688] Trial 41 failed with value None.\n",
      "[W 2023-07-08 15:37:10,763] Trial 42 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.04590769409765365, 'criterion': 'mae', 'subsample': 0.5414085496884833, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:10,770] Trial 42 failed with value None.\n",
      "[W 2023-07-08 15:37:10,847] Trial 43 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.041387508773750775, 'criterion': 'mae', 'subsample': 0.513125959528134, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:10,850] Trial 43 failed with value None.\n",
      "[W 2023-07-08 15:37:10,925] Trial 44 failed with parameters: {'n_estimators': 6, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.2985167070470033, 'criterion': 'mae', 'subsample': 0.589258734701771, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:10,928] Trial 44 failed with value None.\n",
      "[W 2023-07-08 15:37:11,006] Trial 45 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.014502967608426176, 'criterion': 'mae', 'subsample': 0.5057385059914583, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:11,009] Trial 45 failed with value None.\n",
      "[W 2023-07-08 15:37:11,086] Trial 46 failed with parameters: {'n_estimators': 6, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 3, 'learning_rate': 0.015998974327328164, 'criterion': 'mae', 'subsample': 0.502789137138103, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:11,089] Trial 46 failed with value None.\n",
      "[W 2023-07-08 15:37:11,159] Trial 47 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.044473569123999704, 'criterion': 'mae', 'subsample': 0.5045488749693945, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:11,165] Trial 47 failed with value None.\n",
      "[W 2023-07-08 15:37:11,240] Trial 48 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.017810139824715188, 'criterion': 'mae', 'subsample': 0.5849044669156842, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:11,243] Trial 48 failed with value None.\n",
      "[W 2023-07-08 15:37:11,319] Trial 49 failed with parameters: {'n_estimators': 6, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.010503045533406696, 'criterion': 'mae', 'subsample': 0.6023498922803496, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:11,320] Trial 49 failed with value None.\n",
      "[W 2023-07-08 15:37:11,399] Trial 50 failed with parameters: {'n_estimators': 6, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 3, 'learning_rate': 0.29925808635275464, 'criterion': 'mae', 'subsample': 0.5768443213665897, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:11,403] Trial 50 failed with value None.\n",
      "[W 2023-07-08 15:37:11,485] Trial 51 failed with parameters: {'n_estimators': 12, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.02361212663696141, 'criterion': 'mae', 'subsample': 0.5067016939566411, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:11,488] Trial 51 failed with value None.\n",
      "[W 2023-07-08 15:37:11,564] Trial 52 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 3, 'learning_rate': 0.027592800404521917, 'criterion': 'mae', 'subsample': 0.5175186032746477, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:11,568] Trial 52 failed with value None.\n",
      "[W 2023-07-08 15:37:11,648] Trial 53 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.024082236492791065, 'criterion': 'mae', 'subsample': 0.5254591178072844, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:11,651] Trial 53 failed with value None.\n",
      "[W 2023-07-08 15:37:11,725] Trial 54 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 3, 'learning_rate': 0.019046175464106585, 'criterion': 'mae', 'subsample': 0.5086908741560375, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:11,730] Trial 54 failed with value None.\n",
      "[W 2023-07-08 15:37:11,803] Trial 55 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.15764603233122818, 'criterion': 'mae', 'subsample': 0.5019047962100537, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:11,804] Trial 55 failed with value None.\n",
      "[W 2023-07-08 15:37:11,879] Trial 56 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.2910162584577663, 'criterion': 'mae', 'subsample': 0.527169064109767, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:11,883] Trial 56 failed with value None.\n",
      "[W 2023-07-08 15:37:11,959] Trial 57 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.024996918958308828, 'criterion': 'mae', 'subsample': 0.5313061309312848, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:11,962] Trial 57 failed with value None.\n",
      "[W 2023-07-08 15:37:12,035] Trial 58 failed with parameters: {'n_estimators': 6, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.03446711867819563, 'criterion': 'mae', 'subsample': 0.5082872775734864, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:12,038] Trial 58 failed with value None.\n",
      "[W 2023-07-08 15:37:12,111] Trial 59 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.29283701342347035, 'criterion': 'mae', 'subsample': 0.5419653723497203, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:12,115] Trial 59 failed with value None.\n",
      "[W 2023-07-08 15:37:12,191] Trial 60 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.012527648026254862, 'criterion': 'mae', 'subsample': 0.5242042790913151, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:12,195] Trial 60 failed with value None.\n",
      "[W 2023-07-08 15:37:12,268] Trial 61 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.013771825487044087, 'criterion': 'mae', 'subsample': 0.507038369377955, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:12,272] Trial 61 failed with value None.\n",
      "[W 2023-07-08 15:37:12,371] Trial 62 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.020980468540947705, 'criterion': 'mae', 'subsample': 0.5214736318883287, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:12,375] Trial 62 failed with value None.\n",
      "[W 2023-07-08 15:37:12,452] Trial 63 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.015541994331890518, 'criterion': 'mae', 'subsample': 0.5094790847561312, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:12,456] Trial 63 failed with value None.\n",
      "[W 2023-07-08 15:37:12,527] Trial 64 failed with parameters: {'n_estimators': 12, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.01898058794285834, 'criterion': 'mae', 'subsample': 0.5027577858168488, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:12,535] Trial 64 failed with value None.\n",
      "[W 2023-07-08 15:37:12,609] Trial 65 failed with parameters: {'n_estimators': 6, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.027279822497257078, 'criterion': 'mae', 'subsample': 0.5076799117110805, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:12,613] Trial 65 failed with value None.\n",
      "[W 2023-07-08 15:37:12,688] Trial 66 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.04810641008842036, 'criterion': 'mae', 'subsample': 0.5182770367886609, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:12,691] Trial 66 failed with value None.\n",
      "[W 2023-07-08 15:37:12,764] Trial 67 failed with parameters: {'n_estimators': 6, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.014434857311214022, 'criterion': 'mae', 'subsample': 0.5294858739993, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:12,767] Trial 67 failed with value None.\n",
      "[W 2023-07-08 15:37:12,841] Trial 68 failed with parameters: {'n_estimators': 12, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.022929432568662728, 'criterion': 'mae', 'subsample': 0.5056809572468738, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:12,845] Trial 68 failed with value None.\n",
      "[W 2023-07-08 15:37:12,925] Trial 69 failed with parameters: {'n_estimators': 5, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.020095696196004653, 'criterion': 'mae', 'subsample': 0.5361949620250565, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:12,929] Trial 69 failed with value None.\n",
      "[W 2023-07-08 15:37:13,001] Trial 70 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 3, 'learning_rate': 0.2967713742178172, 'criterion': 'mae', 'subsample': 0.520546876850946, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,004] Trial 70 failed with value None.\n",
      "[W 2023-07-08 15:37:13,075] Trial 71 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 3, 'learning_rate': 0.025406929044370863, 'criterion': 'mae', 'subsample': 0.5332861213404206, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,078] Trial 71 failed with value None.\n",
      "[W 2023-07-08 15:37:13,150] Trial 72 failed with parameters: {'n_estimators': 5, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.2902440004941355, 'criterion': 'mae', 'subsample': 0.5148142402365793, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,155] Trial 72 failed with value None.\n",
      "[W 2023-07-08 15:37:13,231] Trial 73 failed with parameters: {'n_estimators': 6, 'max_depth': 0, 'max_features': 'sqrt', 'min_samples_split': 16, 'min_samples_leaf': 3, 'learning_rate': 0.03462085282814514, 'criterion': 'mae', 'subsample': 0.5006164425126518, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,234] Trial 73 failed with value None.\n",
      "[I 2023-07-08 15:37:13,241] Trial 20 finished with value: 1.0 and parameters: {'n_estimators': 12, 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 7, 'min_samples_leaf': 7, 'learning_rate': 0.19162456950634538, 'criterion': 'friedman_mse', 'subsample': 0.6470649957833937, 'loss': 'exponential'}. Best is trial 3 with value: 1.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:13,379] Trial 74 failed with parameters: {'n_estimators': 6, 'max_depth': 90, 'max_features': 'sqrt', 'min_samples_split': 13, 'min_samples_leaf': 3, 'learning_rate': 0.2970686440706328, 'criterion': 'mae', 'subsample': 0.5320732167999738, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,381] Trial 75 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 13, 'min_samples_leaf': 3, 'learning_rate': 0.27741812331554333, 'criterion': 'mae', 'subsample': 0.5012395829263149, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,384] Trial 74 failed with value None.\n",
      "[W 2023-07-08 15:37:13,390] Trial 75 failed with value None.\n",
      "[W 2023-07-08 15:37:13,537] Trial 76 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 13, 'min_samples_leaf': 3, 'learning_rate': 0.2786049765189332, 'criterion': 'mae', 'subsample': 0.555554700160334, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,538] Trial 77 failed with parameters: {'n_estimators': 6, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.2862894292978839, 'criterion': 'mae', 'subsample': 0.5058120523948524, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,541] Trial 76 failed with value None.\n",
      "[W 2023-07-08 15:37:13,546] Trial 77 failed with value None.\n",
      "[W 2023-07-08 15:37:13,691] Trial 78 failed with parameters: {'n_estimators': 7, 'max_depth': 90, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 4, 'learning_rate': 0.2969869050184937, 'criterion': 'mae', 'subsample': 0.5301396268539311, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,693] Trial 79 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.29821330259028067, 'criterion': 'mae', 'subsample': 0.5438365342569973, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:13,695] Trial 78 failed with value None.\n",
      "[W 2023-07-08 15:37:13,705] Trial 79 failed with value None.\n",
      "[W 2023-07-08 15:37:13,808] Trial 80 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 3, 'learning_rate': 0.29173923147319547, 'criterion': 'mae', 'subsample': 0.8046432731910517, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,825] Trial 80 failed with value None.\n",
      "[W 2023-07-08 15:37:13,863] Trial 81 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 3, 'learning_rate': 0.29990016784137397, 'criterion': 'mae', 'subsample': 0.5444095764401385, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,922] Trial 81 failed with value None.\n",
      "[W 2023-07-08 15:37:13,959] Trial 82 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.2988166206826005, 'criterion': 'mae', 'subsample': 0.8050683649910593, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:13,995] Trial 82 failed with value None.\n",
      "[W 2023-07-08 15:37:14,023] Trial 83 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 3, 'learning_rate': 0.29974773810553795, 'criterion': 'mae', 'subsample': 0.5101285522456024, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:14,054] Trial 83 failed with value None.\n",
      "[W 2023-07-08 15:37:14,127] Trial 84 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.28757930625624967, 'criterion': 'mae', 'subsample': 0.510305796213159, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:14,167] Trial 84 failed with value None.\n",
      "[W 2023-07-08 15:37:14,173] Trial 85 failed with parameters: {'n_estimators': 8, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 4, 'learning_rate': 0.2907918733441027, 'criterion': 'mae', 'subsample': 0.5003086785490884, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:14,196] Trial 85 failed with value None.\n",
      "[W 2023-07-08 15:37:14,304] Trial 86 failed with parameters: {'n_estimators': 6, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.2837614763910953, 'criterion': 'mae', 'subsample': 0.5114098975007828, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:14,326] Trial 86 failed with value None.\n",
      "[W 2023-07-08 15:37:14,327] Trial 87 failed with parameters: {'n_estimators': 6, 'max_depth': 90, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.29867527314979053, 'criterion': 'mae', 'subsample': 0.5046408539317161, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:14,341] Trial 87 failed with value None.\n",
      "[W 2023-07-08 15:37:14,418] Trial 88 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.299917633245572, 'criterion': 'mae', 'subsample': 0.521369409704364, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:14,440] Trial 88 failed with value None.\n",
      "[W 2023-07-08 15:37:14,494] Trial 89 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.28535497393710396, 'criterion': 'mae', 'subsample': 0.8178956605115433, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:14,552] Trial 89 failed with value None.\n",
      "[W 2023-07-08 15:37:14,629] Trial 90 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.278760680651779, 'criterion': 'mae', 'subsample': 0.556920809853814, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:14,641] Trial 91 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 4, 'learning_rate': 0.29066450510548636, 'criterion': 'mae', 'subsample': 0.8135613850924117, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:14,644] Trial 90 failed with value None.\n",
      "[W 2023-07-08 15:37:14,656] Trial 91 failed with value None.\n",
      "[W 2023-07-08 15:37:14,767] Trial 92 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.28119422347926326, 'criterion': 'mae', 'subsample': 0.537789822959642, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:14,798] Trial 93 failed with parameters: {'n_estimators': 6, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.297593750529378, 'criterion': 'mae', 'subsample': 0.5123006128124434, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:14,799] Trial 92 failed with value None.\n",
      "[W 2023-07-08 15:37:14,803] Trial 93 failed with value None.\n",
      "[W 2023-07-08 15:37:14,927] Trial 95 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 4, 'learning_rate': 0.2854183740290314, 'criterion': 'mae', 'subsample': 0.5503627307880463, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:14,949] Trial 94 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.299304020580579, 'criterion': 'mae', 'subsample': 0.5184213856102935, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:14,950] Trial 95 failed with value None.\n",
      "[W 2023-07-08 15:37:14,952] Trial 94 failed with value None.\n",
      "[W 2023-07-08 15:37:15,101] Trial 97 failed with parameters: {'n_estimators': 6, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 13, 'min_samples_leaf': 3, 'learning_rate': 0.28951735255576216, 'criterion': 'mae', 'subsample': 0.5119603589352242, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:15,105] Trial 96 failed with parameters: {'n_estimators': 6, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.29490622757353685, 'criterion': 'mae', 'subsample': 0.5334911085610707, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-08 15:37:15,106] Trial 97 failed with value None.\n",
      "[W 2023-07-08 15:37:15,115] Trial 96 failed with value None.\n",
      "[W 2023-07-08 15:37:15,262] Trial 99 failed with parameters: {'n_estimators': 7, 'max_depth': 100, 'max_features': 'sqrt', 'min_samples_split': 14, 'min_samples_leaf': 3, 'learning_rate': 0.2989334146956993, 'criterion': 'mae', 'subsample': 0.8061028195786323, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:15,265] Trial 99 failed with value None.\n",
      "[W 2023-07-08 15:37:15,270] Trial 98 failed with parameters: {'n_estimators': 7, 'max_depth': 90, 'max_features': 'sqrt', 'min_samples_split': 15, 'min_samples_leaf': 3, 'learning_rate': 0.2890365669457964, 'criterion': 'mae', 'subsample': 0.5135430993919567, 'loss': 'log_loss'} because of the following error: InvalidParameterError(\"The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_122476/2811804968.py\", line 17, in objective_fun\n",
      "    gb.fit(X_train, y_train)\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "[W 2023-07-08 15:37:15,275] Trial 98 failed with value None.\n",
      "[I 2023-07-08 15:37:15,401] Trial 24 finished with value: 1.0 and parameters: {'n_estimators': 10, 'max_depth': 60, 'max_features': 'sqrt', 'min_samples_split': 11, 'min_samples_leaf': 4, 'learning_rate': 0.14886982605014423, 'criterion': 'friedman_mse', 'subsample': 0.9004885160255992, 'loss': 'log_loss'}. Best is trial 3 with value: 1.0.\n",
      "[I 2023-07-08 15:37:15,484] Trial 25 finished with value: 1.0 and parameters: {'n_estimators': 20, 'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 13, 'min_samples_leaf': 5, 'learning_rate': 0.22974370949910772, 'criterion': 'friedman_mse', 'subsample': 0.6132176305877628, 'loss': 'log_loss'}. Best is trial 3 with value: 1.0.\n"
     ]
    }
   ],
   "source": [
    "def objective_fun(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 1, 20)\n",
    "    max_depth = trial.suggest_int('max_depth', 0, 100, 10)\n",
    "    max_features = trial.suggest_categorical('max_features',[\"log2\",\"sqrt\"])\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 1, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "    criterion = trial.suggest_categorical('criterion', [\"friedman_mse\",  \"mae\"])\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1)\n",
    "    loss = trial.suggest_categorical('loss',['log_loss', 'deviance', 'exponential'])\n",
    "                                  \n",
    "                                          \n",
    "    gb = GradientBoostingClassifier(n_estimators=n_estimators, max_depth=max_depth , max_features=max_features, \\\n",
    "                               min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \\\n",
    "                               learning_rate=learning_rate, criterion=criterion, subsample=subsample, loss=loss)\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "    error = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective_fun, n_trials = 100, n_jobs = -1, catch=(ValueError,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djanloo/.local/share/virtualenvs/DM2-PeqFRmfa/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 11, 'max_depth': 100, 'max_features': 'log2', 'min_samples_split': 9, 'min_samples_leaf': 10, 'learning_rate': 0.11134307248679587, 'criterion': 'friedman_mse', 'subsample': 0.9447631859254138, 'loss': 'deviance'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       309\n",
      "           1       0.85      0.90      0.87       308\n",
      "\n",
      "    accuracy                           0.87       617\n",
      "   macro avg       0.87      0.87      0.87       617\n",
      "weighted avg       0.87      0.87      0.87       617\n",
      "\n",
      "Accuracy 0.8719611021069692\n",
      "F1-score [0.86898839 0.8748019 ]\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "gb = GradientBoostingClassifier(**best_params)\n",
    "gb.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "\n",
    "y_pred_test = gb.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(best_params)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred_test))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred_test, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAADoCAYAAACnz4zGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADAmklEQVR4nOydd3wU1dfGv7M12U3vIfTeO1JVQMXeRVEREQUVQbCABVTsDUUEG6AiIip2BEVEuvTeQu8JpNfdbJ/3j8luZmt2UwDfX57PB81OuXOnnTn33Oc8RxBFUaQOdahDHepw3qC40B2oQx3qUIf/NdQZ3jrUoQ51OM+oM7x1qEMd6nCeUWd461CHOtThPKPO8NahDnWow3lGneGtQx3qUIfzjDrDW4c61KEO5xl1hrcOdahDHc4z6gxvHepQhzqcZ9QZ3gsMu93O3LlzueWWW+jUqRNdunThmmuu4eWXX67R4/Tt25dWrVpx5swZzpw5Q6tWrRg4cGCNtP3zzz8zY8YMzpw543ebgQMHuo5/PjF37lxmzJhBcXHxBe9LVdCqVSvXv/bt2zNo0CC+/PJLt21++OEHbrvtNjp16kTXrl258847WbdunWu9KIpcccUVtGrVim7dulFWVna+T6MOHlBd6A78r+OJJ57gr7/+on79+owZM4aoqCgOHDjAsmXLeOmll3zuY7PZUKmqfuvi4uJ4//33CQ8Pr3Ibcvzyyy9s3ryZSy65hPr169dImzWFefPmkZGRwa233kpUVBQAkydPpqysjLi4uAvcu+Dx9ttvYzKZmDFjBm+99RbJyclcd911vPnmm8ydO5fExEQee+wxoqKi2LlzJ3v37qVfv34AbN68mTNnzqBUKiktLWXZsmXcfPPNF/iM/sch1uGCYcuWLWLLli3F7t27i3l5eW7rSkpKXH+3bNlSbNmypTht2jSxb9++4ocffihu3bpVvO6668ROnTqJnTp1Em+66SZx+fLlrn1WrVolXnXVVWKXLl3Et99+W+zdu7fYsmVL8fTp0+Lp06fFli1bigMGDHBtv3DhQvH6668XO3bsKF5xxRXirFmzXOsGDBggtmzZUnzvvffEgQMHit27dxdnzJghiqIoDh061NU/57/Tp097nauzjRkzZoh9+/YVe/XqJc6cOdO1Pj09XRwxYoTYvXt3sWfPnuLo0aPFkydPutYvWLBAvPbaa139mzFjhmi1WkVRFMWff/5ZvOqqq8R27dqJ3bp1EwcPHizm5eW5jin/J++L/Fpceuml4ssvvyz27NlTvOyyy8QVK1a4jv3JJ5+IvXr1Evv27StOnz7d69rJYbPZxI8++ki88sorxY4dO4rXXHONOH/+/KCupS84+20ymURRFMW33npLbNmypfjKK6+IZ86cEVu3bi22bdtWPHLkiNt+drvd9fczzzzjuvYtW7YUhw0b5vd4dTg/qAs1XEDs2rULgG7durm8r/z8fPLz87FYLFitVrftt23bxvjx4+nZsyfh4eHccsstTJo0idGjR1NQUMBTTz1FcXEx+fn5PPHEE2RmZvLoo49SUlJCXl6e33788ccfTJ48mdjYWB577DGaN2/O1KlT+f77792227p1Kw888AAWi4WZM2dy+vRpRo8eTbNmzQAYPXo077//fkBPcvPmzYwdO5awsDA+/PBDVq5cSXFxMQ8++CAbNmxgxIgR3HnnnSxfvpxRo0ZhtVpZvHgxU6ZMQRRFJk+eTEpKCjNmzODTTz8F4PXXX8doNDJlyhTGjx9PkyZNsNlsrnMCyct9//33/fYrKysLk8nE7bffzrlz53j11VcBWLduHdOmTUOtVjNmzBg2bNjgtw2AOXPmMH36dOLj45k8eTIqlYpXXnmFX3/9tdJrGQiFhYWcPHmSTZs2AZCWlsbu3btxOBw0bdrUdQ+cUCikV9tgMPDXX38RGxvLww8/TIsWLdi0aRMZGRkBj1eH2kVdqOEigtlspnfv3q7fs2fP5rLLLnP9fuedd0hNTQVg+/btLFq0iMOHDyPKBOaOHz9OXl4eBoOBfv36MXLkSOx2O7///rvf2N6yZcsAyShu3rzZtXzVqlXcddddrt/PPvssHTt2ZPHixezYsYPTp0/Tp08f4uPjOXr0KL169aJnz54Bz/GZZ56hXbt2GI1G3nrrLdauXYtCoSA3N5e+ffvy6KOPArBy5UoOHTrE4cOH+fvvvwHJsN944420adOG22+/nWXLljFmzBiaNWvGvn37WLNmDS1atGDw4MEkJSUxcOBAdDodBQUFDBgwIGAYJCIigldffRWHw8GcOXPIyMjAarW6YqX33HMPQ4YMoUWLFtxzzz1+23H2deLEiXTt2pWoqCgef/xx/vrrL2655ZaA17JBgwZ+25U/B/369eOee+5h5cqVAa81wF9//YXRaGTgwIFkZWXRr18/Dh8+zC+//MKYMWMq3b8OtYM6w3sB0blzZ0AyogUFBURHR/Pll1/y1ltvcfDgQa/tnUYXJCN86NAhHnroIfr06cO0adPYs2cPJpPJ57HEINQ/H330US655BLX74iICLf1Tk9WrVYDUqz5QkAQBLffc+fO5Z9//uHAgQP89ddfzJw5k48//pgrrrgi6Dajo6NRKpUolUrXMofD4feYVe2rE6Fey1mzZqHT6ahXrx5paWkAdOrUCYVCwbFjxzh27BhNmzZ167tCoeCXX34BYPHixSxevNi1/tdff+Wxxx6r8nnVoXqoM7wXEN26deOaa65h6dKlDBkyhCFDhhAbG4vRaAy6jeLiYvbt28eBAwdcyzp37oxer2fTpk3MmTOHkydP+jXIAIMGDeLPP/9kyZIlJCcn43A42LJlC61ataJjx46V9iEmJgaApUuXkp+fz7XXXut327fffpvrr7+eefPmAXDppZfSpUsXEhIS2LRpE5999hlGo5FDhw7RpEkTWrRowaBBg1i6dCmffPIJJpOJRYsWufoN8OKLL9KuXTuaN2/OkSNHOHz4MGfPnnX1LSMjg19++YWOHTty+eWXV3o+cvTr148vv/ySBQsWEBMT4xUy8MSgQYPYs2cP7777Lrfddhtff/01AFdffXVIx/VEr1690Gq1bsvq1avH/fffz5dffsn999/PsGHDiI6OZufOnTRq1IjrrruOLVu2kJaWxvPPP+/a7+OPP2bfvn1s2bLF7UNbh/OHuhjvBcZ7773HxIkT0Wg0vPfee7z66quEhYVx33330apVK7/7PfPMMzRp0oTffvuNvXv30qtXL9e6uLg4pk2bRmpqKrNnz0aj0QSMu1533XW89tprhIWF8dZbb/Hhhx+Sn5/v8sgrw3333UdaWhrffvstEydODLhtjx49+OyzzzCZTDz++OMMGDCAqKgoPv/8c3r27MmcOXP47rvvuOKKK5g1axZqtZrrr7+eKVOmAPDaa6+RmZnJmDFjeOSRRwApRDNnzhwmT57Mzp07uemmm7j11lsBeOihh0hMTGTmzJm8+eabQZ2PHP369eOJJ57AYrEwa9YsOnXqBEgesi88+OCDjBs3jpycHF577TUsFgsvvPCCW5ihJvHss8/y6quvkpiYyIwZM3jzzTc5cOAAbdu25ddff0UURa688kq3fzfccAOAyxuuw/mHIAYzBq1DHf6H8dVXX9G4cWNAoqetW7eO0aNHM27cuAvbsTr8Z1FneOtQh0rw+OOPs379eiwWC6mpqdx444088sgj1eJS1+F/G3WGtw51qEMdzjPqYrx1qEMd6nCeUWd461CHOtThPKPO8NahDnWow3lGneGtQx3qUIfzjDrDW4c61KEO5xlB82Fsy89vXnf6+qNszB9+Xo/pC73i5tKmT7PKN6wC0tcfBaj0PHvFzQWolX7468Oo6UNJTIzkbPYMAL59zYy1WIfNcvGkmIZyb2r6edpydD1Ltv/oSsW22+2udOO4iATGXTepRo5Tm/c+FIRy/Zx9hgvf7/MN1ZUzg9uulvtRhwBwPZTr5wLexq82H+BgjL7T6ALc9ATo9Xa+GF/3yADE6mNdRtdisWI2W4iM1CMIAgWGPF7+8UmUChU3dx9Ch4Zdq3ycjfnD6RU313W//guGzPlMOfv9X+jz+UZdqOEigPPB7BU312Vs5Z5OTT646euPBmV0Xxr6FgaDGZUwHJUwnOiIh1EJw7FThkrzv039tjvsxOoTXAIzarWKyEg9AO071OPxcVcgimCz2/hl8wKMZkO1jrcxf7jrXjnv3X8B8j7/l/p9PlDnvlwkcBrX9PVHay28EWxoA+D2FstZ9Zb3d/nm58tISlIzb6Lyogo71Da6RH3B3E2Z/HGgALNNRKEQEEURQRDIysolLExLTEwUt93Wlbh4SdVNpVJgszkwWgzotPpq98F138pHSP8FT9LT+w0VtTXSq622O1wZ3LZ1hvciw4U2uPLwRvcukgylPNYbpR9FsWFWjffxYkavuLlMWHSM3ZkGBEEgOiYMRCgsLEMURaKjo1AqpY/UKy9L0osqlQK73UG9uDTiIhJqpB8O0UGpqZh/c++jb8LX/8nwQyio6RCL/D2oyTBIVT4oNWJ47aiwKXSI1JwHJOoT0NrUNdZedfphUvhWojpfEBBRiBZUoimkKyx/IEIxuvKHsXDxQ0Rc38/1Ozz8wt+T8wXn9UjpWJ89n+1CECQvt7BAEpQvKzMTHq4lLEyDVqvi2+9H8dabf7Bzx2k0go7uLfvQt9UAFEL1I3pFxgLmr/uUnKIcYiJiyO/7MIlRyf+v46g1FSv25XjU1OjBs+0OQe5XbcNrUCaSoe+LqNRCDRpeR28rrRwRlW9Yy3AoRnBSe6GNjQiiA53lLCll21GLlev1VsXL9fXw6bVKt99lZVZUwnBmjJ6DVh1Wedf/o5Bfk8FvrEH6/InY7Q4EAaxWG4WFxSiVMWg0ahwOB6++vJi9ezOw2Ry0qN+Mlqlt0ai0AY9TGcL0Du553QFE8k7SKXJySkjsFMnyPYu5u++D/8nwQ6io6jkG43hUdfIylPfLF6pleO2oyND3Ra1PIDKsZoyTxWiR/tCAwRFbI21WB3qFCo1Oc6G7gc0hUmLUcUIVS7PiJShw+NyuOg+EP69CXLUFY4+ONGv8lKsqw9iPH+L14e+TGJ0U8nH+a9h9otDFYCgrK0MUITJST2JiHGq19ArZbCJ792YgKAQEAfaf2UV6xm5u7zmU9g26VLsP2dnF5OSUALBr11GKSify08uiK87uNCAHtpwAoHXPpuDw/YxUFc6P0YWgecpDYMGiTZ9mIYUBQv1oVec6VMvw2hQ6RKWWyDA1GlX1hlOmUrPUIYVAqV2KiSkvgrkblUKo9rnVBDSAUqEj32bCqtCjdZS4rQ81rCCHrwkQ+UN4YMMRGvboyLmcmaiEirYnzX2SWePmh3Ss/wrc4oBJOnacLkEURSIjI1xGOCxMgyiKpMSkkVeaRVyCDoUgoNNrWfLH4wwf9iVbj/xbI4a3XvLjbr8NBjOg8+rziA8qSgid/O4fGia4b1NVeE7+ni/jW11KpdP4+vpoXEi+cbUMrxTTrb51dBpdp8Gtg28I5f8VPViA1R32OBFoBvrHNxTc/3q1mv/PwXk9nhs4h4cXHiSnxExRUSkxMVGoVWqUgpLkuHrc3mMoH//9NmFaNceP5xIZGcZPP23j+PFcYjS+C1iqNCLD3rEDsGCyElOp4FruRCDWSL3kx/lk3GyUhPtcbzCYufHV1VzfMoY3Huvtc5uqoDLueSgoLivCYC4lKSoFpULptb6mkkc8Pxq+1p1vXFBWg9PgQnBGN0KZW+n2CxZ+xR233I1GU7XwQHX3rw7k18MXbA4Rq9nKsR2nEAwV16KmvQ+ntydvWzIIdvbuf524+EgAmjV+qkaPe7Fiv/EhIvUzyS4+iM1mRwDaN+jMbT3vdW3TKL4Zh48f4IWXrmf2Z2t57pmfSYvRMvFaC6lRc13bKXVaWj092K39e16zs/+V+QhqJW2eu7viuK/ML/8/bH59EK3G3U50xMMB+/rayGNMnt3Utd3+/afo3yyGBlGaGjUygTzJypBRcJovV8zALtpQKATsdpFODbtza0+penNteaJyA3yhY+EXxPBW1eCGRWhd+zuXee7/7Q/zuOn626tsOKu7f1URjNdvF22YHTYOFt2Kudhaq/3x9yK1b1szqbD/NVzW5krO5J0gOTketVJNr5aXua3v2eIyDp87QGxsBHcN6cH0D/7h5ykDSIl190iFK317n236NAOFwntZOQw2kdSkseh0Gozl8yDdYhfS9SXJ+Du95tJiGw3T3Ove7Sq+kQZRf9U4/SzU8IPNYWNt+nJW71/mWma3i4iiyK5TW+mQeIqh3VNqtI+B+n0hcd4Nr9PAFFvjcDgcBKqeIvdwnUZX/rfTADuN1UezpgHw7AvjUSgUTH7mVb7/aT7HTxzFarXQqkVbHn5wLGq1mu9/ms+qtf+gVkmTgpOfeZUfflngtv8rL7xNhP8akTWCUD9CFwo2i8CCyd7Dwf8VNE9pzZhrniO7+Cz1YusTFR7jtv7u1hs4dCqKJ8d/T3i4mkdvak1KvD6oCS5x1RbvZavdlwmXduNsdjcAUpPGAtCyVxPX+ntek9K5myW3ollKCzIzs13rhr+mJSlpKPMmKuke8VWNe3zBhh9+3fwt+87sBCRaYkmJlNGnUkmx8q2nS3j98b411q+LGefN8MoNzKJ/tvPejDcxm03cdftQHho+2pV+6YSnl+sLYRFaN+P72KgnWPr3Yt569QMi9BHM/PR92rXpwNhHnkIURWZ8+h6///Ezg664jl8WLeSrWT+g1WoxmU0oBIXX/hJy/R6/uvivxbZtFvjzr6e59uqpADx1+/n3fp0x0GJjMT3fWk1Z2XLXuoyFw0iK9R3zrAnERcQTFxHvtqxiWCzw/ZSB7M8oocMDFaXcxeUb3LYXV2yS/lCrEC6VDKnLODscFdsrFC7vWFy9xS3EEB+vJyv3I6/+Ofsi9HuYvi2vRKPS8NSnCej1Fe9QsMkDVpuDT/84zO7jBfRqncADVzVDoQg8nyMPP3gaX5O1jANnd9OwYRzhOhXLlleEqVo1n4TRaKFv59SA7V9sqM4kY60bXk+PrqzMyNvTXmHAgJY0bprAZ5/Mo1ePvnRo39ltv1J7AhHKXEylZr/Gt7KY6MYt/3Lg0H5+/f1HACwWMwqFgvBwHamp9Xlvxpt06dSNHl17kRCfWL0TrQI8Pxz/BVw1qD02cS7ABRHMGfaOnezsYuolP05R6WduBintznlY/3aPgdbUxKMv+Jr8ad8oxvfG8jCCwwFmi8vIZheUkXbnPAAKF41A75GkIlzeI2A/nMbcafj6xM9Do70fkISNnDiQsYc7m23ldKGFuEoSYT749QAf/X4Qs8XKsu1nEQQYMah5wH0CXeu8khxsNjuvvH4TVw18G5UwnKLSz9DrtVitNgRBYNS1LQO2fzEh0EcmGNTqm+PLoysrK8NisTLgitZ07dqQzz5ZTWFRoc/95cYX3EMM8m38QRRFnnv6JdLqec8sT319BgcO7WPPvl08/fwYJoyfRLs2HUM+x+pCbnzhv+P9ns+wg5wBAJCUFIVNnFtOqfKN6tDrKkOws+2pSWM5PPcu9DotQv8K4ymu2CQZX7UK4fIeJAOJib+4eLq+8N5jl/HUR2sA+PvdGyvaWrvNbbs2fZpxYMsJt+vVvs1LWK02ysqs/LpBSanZTlxMONOSYunfIdlnOOTf/dkYy0wUFBSTmBDLxgO5fg1vZddaSnUuQaNSc9XAt73Wq9UqruyUQEpc7Y1WagPVYXjUiuENNISOjY2jX5/LeHbiTwDUT6tP187d/bblbENugP21DRAersNoNBChj6DXJX356dfveOzhJ1EqlZSWllBcUkxMTCxlZUbatelIuzYdOXX6BEePH6Fdm45u+58vBDNpeDHAZhH45DEnT1T6v3wYez5FcwwGM21aPev6/d5j79E3ZvF5MbgQwOg6HC6us06nIeK6ft7blHu/ck9WLsEprt4CVhviik2UmKzc/tpajp4pol69JBQKgSGvr+FLo5VL2iQhDOxZsV+5B926Z1O3wxUXl/H9jw+ze9cZXn91CZ/OGsp113f02k+Obi3i2Xm0ABDQaNR0buo7mcl5vX843J+1B5Yj8DmXt72aerH1OVuYwbJdv3KuMAODqYxz53Lc9u1/2TuIZi1P9k1lxD3V5zpfKLgzPO4Kap+gy7v7EkI3KaI5GX0t8TGxaFSKoD1Rm83GmnUrcFhyGNivD1GRkZXuEyy+/WEea9YuQ6vV8PpzE/nu10Xs3LsPBDUKpZIHho6iflpD3nrvZUwmE4IAqan1Gffo0+j1EXz7wzxWrV2OVhPGKy+8Tf04e8A4c23A34fLLtooLsnh4LLTtcpq8OQ6yg3YqOlDXX/rdBo3wZyaDj04+2GP0tNh/K0YDGb0ei0njufQvOkE13bnI4kjFE6pM3TgeX1Cgbh8Aza7gw9+SWfG74f4fclYjhzJ5olx39OmTQoRdis/vtDfzfD++dZPfPrnYWKiwvjq9/EAdO4whfx8I6Io0rZdPQ6knyUuTseO3VPcjuUJk8XOuz/tZ8eRfPq1S+Lxm1uhUlaES+RhBYO5lBlLX6dx0zhsNgeZZ0p49MqJTP/zNWx2G6Io4nCIZGVVzJcUlX7GqNuW07/VDfRN+PqiYBrUBM67EHooE0Ux2kJuuqKrm0GrKW9v5JDrGDnkOlfbzzzxqM++TX3D9wW6e/Aw7h48TLak9ibX/OFChh98GpjyodTW0vvPaz+MFjsDp/1LsWEWBoOZ6IiHSUyMDDgkr41+QGgUpKTYcA7Pu5sWw751eb/OuLgnUpPGYTSaKCr9zG25KIqM+nAT/+w8B8CDD8ylXfs0NBoVOp0GW5HFbfvjP6xi9Eeb6dm7KWfzDHRp8wJFBgsms42SklKioiJJ338WpVKB0Vjx0bav2uJTlDtMo+SFu70lX3yNKHKKszBZzLz3wWCMRiuDb/uErcc2uIyuUz7TieTkBCbfd5Ar2tzs7xL+v0e1Da/VbMVitGASK5+c8kcPk/+u6mRTMG1TevEO4z3hK/xQZIupteMFMjDOoVSPWP+eZU3FfOX9MJRZCQ/fDOCK554vo1sdEr+hzEqLYd+6LUtNGusWTgB45oFZqNVaYqK1XHnZOyxfU8G/PXaulH92nuO99+8kMSmSYUM/J2/1Qex2kb27z/DZ2J5uLIgDR/OwO0TefW8w+/ZmMuqheUSEqTCWmTGbLTgcDpRKBQkJETz7/LVufY1UBxci8jd5lhSVgk4bzmOPLMBudxARHoHZagIgMSmS3JxSiotLiYqKICJCh0qhpnFi4Im6/++osuFNX38UUZ8AvSUxm8p0FYKhhznXh2p8a6ttuTG/UPA1oViTCNbAOAn+np5ZTYYXfBn/8HANKYljOHriPbdtdToNf47vx37jPVBLBTH8Xo/ySTGQTZTJ1kVc2Rv4wm2XnJwSsn74h6RYnRuL4cvJgzCaHVzePtHlHYeHq9nw4S0AbN12guhoSW9h5iPdWbc/hwYJevq0dXd0ujSLJUqn5q7bPyUvT+LHlppsqNVqUlISadY8kZWrJ7gYIQCZWR+SdG0fzv24kuSYwEpzgRgLOq2e+y59lHUHVyAgcOOlV5GRfwqAQYPasuCbzdhsdpRK6Ubd0WsokeFRQNXEb/4/oEoxXudN2GEbSatBDYiKTEQp+H4BgzWKnjCVmqvs9fo6VnWz5S40TKVmimwxNRbjrapHd3DnaVo/fafrd23FdUHqV7bBQtotXwKSsV058VIUahVdnq9Ira0tWpvXh0ChAIUCY4+OLg9ct2U3BqMZfbk6X8SNUkbb/n0ZdGzvznPOWHgf+jA1MTdVGGUnpcoZSpHjk6eu4I3v9+IQRYZf2YwlWzMpMlqxWGwM6JTCF+N7uQ3h958qYtafh1i6I4uDRyRhjc4dppCbW8qZsxL3Wi5yBFII5KkhM+ndJpE29aNo648OR2jUPJPVxOwV75FXnOcWaghTh/PMza/RO/4r4OLIIqtJBBvjDcnwel54bZTar+ENNPQPBlUxvL6O+183uE7UpOGtjvhI+vqjbrHe2mIyuJIB1EoaPn4b4M6gkKM2+cTyfsh1FKL0o1ypu3I4Y7m+DGkgHDn2rtuEIYD174cxmm3YHSIrdp7j8U+3sn7Tc6xZfYiJT//oYgnIE0eyCsq49JnlHD72hqudhmkTOZXxDuBteHv1au0K3yiVAv3bJjJzdA+vhCY5gjXAZRYj6Rl7yCw4zemcE8RFxvPaIDt6jXS//r8ZXaiFybVQvnYX0nj5op+FGla42IxuTaGmxEeqa2yDEVaRK6WdfO8HFDqNm6ftRG3ziZ396J38daXb6nRSWATAaLSQlJTAzI/v5s47ZlSyJ15G949xfdm26hA6jXR+lrNS+OCzT1Zz+FAWem3FlJg8cSQiTOXGHgDQaCtec2eoKDriYdq1a8TZzEKOnnzLtb5V80nsOFpA1+b+c+U9BXICYUCK8y/nO6iq1TpqweJCG/2gDe/FbnA9EWp8GC6OftcGalrtKSxC5J7XJIJ+qEUv5X0JxQALBhOtQ+1oDWJLwVDaYA+4jZw69vNrCxn/ydaAUg27Zg+m08gfXL9njZuP2Wpi7McPcd30f13LANDCgHbL+HruMs5kngu6300bP8UxWXxcPmpIjdRwuKTMbfuDR15nwydLKm33QhsuJ6qcmXiBK3bUyBhNryhAVZ7H/V8yXhfTh6K2UFOapnI4jW5N9CPYtMuR7zzEuJmSYtz0MR/zwNsqV1/OR+qyzSIwb6ISs9VMt5jvWTP5Cjo/V0GWv6T7q27bX3dJfRauPsmT478nJSWRJ25tzdABjUm7s8JzLjuRy8ZJA9hSICmMOY2uP1zedhDf/D3Pa/nKCe5KaUajxS2JwxdSUhLZf6qIzMxsL+PcLYC3e7GguqngVS35U1OodmkFraIUkIzXxWDAFiz8CovFO/YmR4Qy18vo5uTl88iTz9V6/ypD70G3UFJaWu12esXNdZWJv5DeibMf4J+q5rmdPxiNFumfpaimuxkUbBYBpRjGzoL73YwuwMrVE12qYQBalZJvJvRl6asDOXcuh2c+WetmdAG2FNzL7tIH0arDfNavmzrSWwjHc/2M0XMY8O4a1Fd9xrpl6ejD1Vj/fhjr3w9TuGgEmT8M87nvrZc2cv2d60HRc5YzuhiRvv5ojQr/O9uoSriiOqjWFe4c/QtK7cO1VpOsKnxef3q6drudaE2B67fnRyIxPo5P338z5D6++u50rh80kK6dgq0vGjqqSiWrrVjavIkVcdVgwwyVUdWCefDlmWA/viFgMQjYrDU3uefkngIhFfKUU7Scnqb174dRKATaNHSvUL1ywmXsNQwL6hhROu/q1q8Pf59Jc58s3196hp1e7fUfbaRoUBvXtk6xHXHFJrcMN4AZC8ewuOEztGnjo0KGLD5iKKuYxNXrta52nGnNFwo1mQ4uL6Z5vpyUi/bTVpWkB0893ri4eGJj4jh7LoPi4jzmzZjGmzM+4tSZDKw2G8mJCTz/5Bji42I5ey6LYY8+wd/lmry9B93Cww/cy5r1myksLGLE0Lu44eorguq7yWTm5nsfYsHsD4mPk3Lc58z7llKDkfGPPsiHs75k5+592Gw29Dodzz7xGI0apHm348XIuDAPenXruQUa0lW17WvHSUZywSSF3/I3/lBsLOLp2Y8BuFVLlg/zA1VR1sdWGKYfX4chk93roWUsdPcyV064jAHvSgI3ew3D/LarVYcxY/ScgH1PjE5yS5E2W01usWUvXrFz+b87EPq66yHk5BRw+rQ0OozSj/JKbzaUWd2ob9Z/HnX9LVzew2eqcW2jJksPXUhcGMMr2IluuAuA4tMdEB3+JepCSZ/11NOdNvNtjh3bz4w3XiEuMQaA8Y8+SGyM5EnM++4n5nz9Hc+Me9Rnexq1mi9mvMuJU2d4cOzTXHNlf1TKymfRw8K0DOjXi6X/rObewbcgiiJ//L2Sd155HoD77ryNx0c9AMDfK9cy7ZM5fPDGS25tXCxavTUxrPNXTDOUtmeMnuOmuCWnaoVaat5pdKuKu16qMGx3TAImV6xbOeEy8tIzyZNtHx+hCVpPwmyt+NgGc07SNu4fZH9eqhypSWMxmSpCcvK4sC9pyosN1Sk9dDHggnu8UQ32UHSya8BtfKXPBkKEMo8IpQm1wkz/Pr1cRhdg2co1LF2+CovFitlqISYqym87Vw+8HIDGDeujVCrJzy8gKTGBjz+fx8Yt2wE4l5PLrn3p6MKkl+TpsY/QsV1rrr/6Ct6c9hH3Dr6FjRu3ExkRQf3EVEylZv5dv5Vf/liKsawMURQpLi11827NBgvmsAsrCl0bKl+eBjiUdvV6LYunim5GL1ioNCJmsYhHp0pUr/BwNWVl3jzoqSM/cjPK/gpSypGdXez2e1vhXVBYYdynjvzIZ8hADqfxMFrs9Jq+0rU82A/KgslK14SnMLAnEVTwjOVeqhP+OMhOCAN7wva94HGN1Fd8QuFi60VjlC9U5WN/SF9/lA5XBrftBTe8oSDYyTutXkNYhBalSkFkdIW84669+/nh18XM+uBt4mJjWLthM7O/WuC3HY2m4gFTKBTY7dLDPfrBYYx+UBpO+ovxdmjbGrvNzo4d+1i8YiMD+19PqT2B7Jwsps+ey/tvfUxqSj2OnzzKcy8+4ebZltrjOX+ilO6oTVnFqrbrqcc7+wnvkIsoihQY8nCojDz/2fMkJERwLkcis3uqmb054gOUovQsyQ1blC7awzOtyC2Ssyd+elPB7c9JHwDPsuue3vTTsx/z6e3Kwx0bJw2gW/+WbFt1yGObYrRqM3ExUQE/AKZSgS/Gq9xKuyckRroxFQDEjbvAaOLovCGk3uHNjpBDuLQb+uUbKFw0wi3cgMMRVDmj84kLHX6oysTchTG8opKiU51qpWmdLpxSg5HICG/TVVxSii48nOioSKxWK78u+atW+uD0Xq8Z2J+Fi1eybedmRg6XXjKj0YBKpSQ2Ng5RFFny52+10oeqoDarNdQmNCoti7Z9x47jW9xqjYGUQeaZnKBVabCVO3NmqymkMIVKI2IoEELmL8thtprcDHTrnk1k/6/weJ2TaJ+Mmw1ITkCw9DlPowsg9OpE2R/rSIgO5693b2LK/F2UWe1MuL09/TskufQj5DCYareoak3iQoQfPN+ZYKfYL5zHK9ZOxtE9t9/MuGenEKbVkBDvzkfs3aMrf61YzV0PPkZ0ZCQ9unYiJzfPT0tVgzw22/fSW/h8wd306XkpERGS5nDjRk25tM8AHnviQaIio+h1yYUv7vdfNbggDeUzC06z4/gWJr1wPY89+mXA7Wc+PhMl4Tz6cYWusL8hvZO764Sn5/3FeBVvDH+f58sNpBNT7n2TKd885+qfHL3i5tLxpeX4gpMK5jmpVWwsBuJ97uOsQQeQ/ua3LhF0X3FdgFtfX8t3z/WjXrwOmyiQXWjhx39PcU33elhXPeYS/zn+61qe/WQTPy3b69r38LwhF02YwR/OV/ihuiPDoLUaZo//3vW384si6hNQ9n/YJYReh9qdFAtFCD2YxInzEVaoKcgNjKeneSr3OF+snMH7H9zFmdN5PP2UFD5KSIhg9743XOGA14e/T2J0EuAu6B5sLNWX4ZW3I0egyTTPfTzrxHkaXoAvJlRwgOXnLw8vHJi6kFZdG7mVFfKHmy59gz/WuYc2Cpc85FWmSK7t8F+YdPNEME5FVZKM/L07Iz8IrgJFyB6vvJMmRTQnQ23g/zkuFu1fOTcR/NO4LnaD60SgYX39+Ea0qteWJ8udg+v6XM/tfe5CEASWTvVtBD0n0kJFTWlE/DHefcSTvv4oRot3ZmAwYQ2nloW4fINUOmj5BlelYq/jehhdv2WK/uMIFH6oTiq9p2ft2XZlCNrj3fNKhXiy86CepX/q4I5QldEqQ1VL//jKCPuvGNxg4RAdnMk7iUJQkBbXMKC6lhOiKHL4XDq5Jdk0S25FcnToTBL5JJkTvpgM8uSMEmOxKzyxcdIAlxCOE6uzhnilDjs/Hs7jBSor5CthQo7SvzYQc427rnJ4uJoS42y3ZalJY8nJKaFB/ST+ev0KWtTzzwD6L0DubNR0Kr2z7Q4v/hnU9iF5vBdaGKOqGVwXKpU5VBpcZbA5RMyKUjpH/4Kgcm8vWKWvyratCuSG/UIZdIWgoGFCk5D2WXdwBf/sWVK+v5IHB44lLa5hSG14MyF8Y+zHD7npJjj32V2eHS6PR4ZHmLxK1ztRmZcurt7ivWzFJrKLTBw8WcDAJ34F4MS399L47m9c2xz5tiL8Ia7ewrFT+S65yG8m9K220ZUPzS+UHZGzH2q6D6G2F7Th9dWwgEityf/LUJ24qa/y8OcbNXVcs82B2qKicZf6aB0VHlWww53zUnX3P5RRtPXIvxiNZRQWlpCaksTuU9sqNbxyIZtgOLpyyD3UeRNFt/CB/HoNf1uFwVARbqhMswGkeLNTm8NZxdgFh4OkSA1p5UYX4KHpG9020SkVbploTVOjvGLPVYFnLPRCCtM4caEdSKgmq0HlMCLYzZSYrESG1XzQ3SIjeRscsVQlZdZZp0yvKKC0WBru1Za2RG3C5hApMZahsBtROwxu66obb6oK/A3V/ksZRZHh0RRo82ncOJwjxyWh8JmPFTL+YynRorJJN0+ObiC5zGCMp3x/vV7rElWX08ecsWmj0UKUfhQzH/s8YJu+PGCAnUcK3Mo45f6+joiwmiM5+Zt88kyiuRiM4IVAta60Ehtphn/JoC95Ji1QM4IlVnNF/NLscPJxc6rVpjO/SKsohRJQa/9Ls7MiiA50lrOklG1HgW8C+/mi0rg8Kz+42DKK/OGGboOZu+ojDh1/2bVszEcRPD9XEzCzyx8CyWVG6aJZMLnCsDrZEXID7bn/gkkKLxEgrVrrFrIwmeyoFBWvcfr6o7Tp10LSbAC/yQ65ufm0aPoMCoUCvT6cVW8Ep0MSDIKZuL0QwjQXE6r9idPbc2hWvBibQodYA4b32I5TKICdRbeWLykItHlI6Bz9CwBNuzQEUyUbX0QQEFGKZpSiudIrfL7YCpUNF88na+JM3kl2n9pGRFgUvVpchkZV+YimwJDPN+s+w2QtC7idJ40tGCEbfzCVSrxgOSUtEPKLStCpKkIZKo3Iobx9biGL2y//jeu73A5UDOXlE2tO0Zxio5Xb+rfm51UHKtorv06jr21OSlxoQkOBIB/1+Lv//6tFLp2okbGFEhtKR3HlGwaA80UVcL6sNZcx4xoWdyo3Eo4Lo+damzifhi7QcPF809SyijL5YuUM7HYHggLO5J3gnn7+xcSdWLF3CQ6FhcjIMKxWO2p1BbPgvVEfY7NIw31P3i74F69xJluYLSZs5ZKJlfGDzRYTj04fCYBFmMkj0yoyLsfM1AM2FkxWYrM4vWT3jM+TuYfdfm/MH05bHyG5937ez7/7KyZkk5MTaJYSwazxvWieGhmwj1VBoJh/bYjz/9dwwbUaapPE72vyx2y1Y7Y6iNL9l0IN/nEhkyA8ucK11Y+SsmLsop0YXawbfat5o6bERSbgcDg4ey4bvV7HYdLdqtr6g8lqol69aI4fz6X3JW9gMJhp36ArN3YbjFJUoVRDqBPHzpCB05CCFJPVqrWoNFKYQKV2b1MeShjzwRgemTaXpo2fwmgwu7Qm7nnN7pZB50S/3m+THOU9GSgXzTmw6Rii1c6xzBKysisMr91u59i5Un7feIYnbm3j1UZNwVd9tv9lg+tEjRreqqq414bBkH9Vz+QaeXvhXv7eeY6jmSU4RBjYKZnPx/dGoQgtPOJ5jjX5ENXm9avO0K6y9mvT4K/a9xer9kuaGl0aX8KS9Ytd646cPEa9eqWIiMTFRaNWq4iLSAiKw3tJs358t/5z7A4HOdmldG3ai6va3eo3UaGqCRPunNuKuG4FvL1TXzoLcrwx7GNW7cuhdbSGLq3v8FrvFM2RcB+94ubSTOe+jcPhQEQkt6gM9VXSJFttZabVGVpv1JjhvVgyoTyHMRsP5DLkzbUu38VkMmM2W1ixC56bu4O3RwSWpJTD5znWQNG88+31h4wLRBErLitk1f6/KC014nA42HFis9c2WVl5xMZGER4uDemH9B1Rabsmq4mTuUdpkdKWhMhkOjbuRlJUitd2NosQcj03lUYkM+tDV5pyeLiahAR3wSZ/xj0z60Ofy+dNVNI94iv2vyL9fm5YF57D+dxI2XqVTWS9/lsFTzcxMQ6VSgkIvPONb9ZDHWoX1Ta8F5vBBXcDM2HOVilwLIJSqUCnC6O01AjAoo1ngjK8gc6xutzE2rp+NTm0u1AUMVu5DKfdbsdul2bn9XodBoN0/xIT4yguLkWhEFCpFMTo4kiMSq603e/+/YITOUdw2B0oVUraN+xco/1OSorCJs4lO7vYraovwPcvu3NsteowZo2bj0oj8ue7Ive/681C6B7xFeCbugeB2SNFxgJW7nVX4RNFB2fP5hMf78FBVqtcKcYXurTP/3dUy/BeDEY3kIH5+d9TnMqRZq1vva0LXbs14sXJv5KQEIvD4SBKV7kwSijUmFC4iefr2tXUME/+kp8v7Du9E1EUiY6WJn9EUcRqtRIVpScqSo+gUKBWx0jr7AI3dh3ity25wM2MjmcpKirBYCijXr0kjmcfISXGu/RSdWAwmN20ep2cXLPBt7drswicLcigVfMZTHnlJhBFpk//h5f7pzFoUKuAx/L3YTRaDMxaPo0ig/tkcm5uIeHhYYRpNTx0UyemPtQNgIhr+ri2uVClff5XUG2P92Iwuv6My4eLDrr+/uXnHfzy8w7XxEu4Vhl0mCHYc6xMmAbO32SY3BOvCeN7IT6y6w+v4I7BXZnxoeSxJSclkJAg1bBTKTUoELBjJi4yjmGXPUaMLjaodnfsfon6qRNcBVGTY+rVWJ+d4QlzFbxFQRAoK7NSXGzCarWTmVGEaK3cgwf3D2MKn7I7s5SdOS0xmEvJzvaWPi0rM9GxWyOmDO3kiuvKi3YWlX6GzmuvOtQULjirIRBMVhM2u5WIMHe6S7DDaJPFjlarxGy2U1xcSlmZmeTkeJ66rTUPXdMCnbZ2Tt9f+OF8G69gPgSV4UKxJg6fS8fmsHL6dAWPOys7lz6d+hCmCefazreiVYdRXFZInD4BlTK0e9kitTUlZcVc0rwvTZNa1HT33WqnOVFZvDg5uh692vTm/anLAOjetDcNE00VKcBBVH4oiY9m7Jw9OBCw2zMDTjQueqm/22+5h+5YuZkDOQYcIrRpEBXUhGUdgscFN7z+ZtuX7M/jo3UZOETokhZBZpEZi11kWI9kiIsPyojcfXlj3v9FohfJy/g0S42sNaPrhK8Cj7XF3giGdSDvR6iozfizHFa7g++2Z7M3s5Q/t58AcCvICPDpbU4/7NeAxwjU5wWTldx3Weg6BKFk4TlLrzsxc4zBLRnCF9RaWLj8VkBKHvp8nJK2z1fwiOUVhE0WO3OXHyW7wMTNvRvQqank7X+76gSaMA2xcToeGzuA5yb+TExMFGq1CkEQsNvtiKKDxilRrqKYvpgML83byfdrTpKVJVHQCn57gIiLNNW+Ks/1hWZaXDDDG8hrLSmz8tGs3RjLzNjtdrafkWJ7druDD9fYuOHq1kEd4/GbW9G6QRSvLNjD6Ryp+m/X5nFc271m43mBUJtpu55/n0+BnFAh1yE4OFVLy871vbZ5/bs9LNydS4tWFcPrrKxcEhPj+erpPvRpkxgU3Uk+2SQXtckvDE3UxolQr7Unpo78qFKj6wuBvMxxn27hr21nAZGvlh9jySsDaN0gmthIDWazlajIMGJjpI+U0ViGIAjEx8egUilRCrB9/xmX2LpTDKdwkcQIOZZVyg0vrXIZXYBtR/K5vKM38+NCo8pOTQ2wkXz146IudhkoNutwiPy24TR2h0hYmOQ1iKJIaWkZNpuN8PAwTucaaVm/cpk6QRC4uls9BnVN5VSOAZVSQb0aTI28EPD3wbrYhWnkOgStnh7sc+Jm86F8rr2+I88+fw2NG1SU08nJyaNn6+CMLrhnTclFxf0VnvSH6lxrJ1uhqnDyhg9O/YFWTw92WyeKIn/vOEdRcSmlpUbS6iWxak8WrRtEM/amVqzdm8OBA+d4ZNR8RFEkPj4GQYBW9aN4f2RXYiLUNJFJQjrhvL6+RoNXPvXbRVWBorqjyJpSSvMMxV2UNdcCGVxRFNl7opBXv93LpoO5CIJAbm4BWq2GyEg9cXHRCEB8lJbuLeK89g8EQRBolBTBgpXHeXnBbkQRJg3pwP1XNq2Bszp/CHT9LiZhGqeXGUis2xc6NY/l1Y/v8bmuKpmGbfo086rcGywuxLX2xRu2G81eHynpedZhs9lRqZSIQLMUaR4kNkLL329cwdsL9/LxksPk5RUSEaEnQqfl58mXERGudoUYADIWDvPqR9OUCO4d0Jiv/xE5d6564lQ1jZqcc6iuUlp1jH+1DW8wXlagsEJOkYkX5u3kr21ncZRzbRUKKZSlUilRKhUIwPhbWyOKcNdljYjWhx5rysgz8vzcnRiMJkDkpa93MaBjMg2T9EGd44X2IkPNPLuQfT6QIRVIjI7RuWp2FZV+hm7TzoD7jbu5IoQklyx0KW2FCrWKNs8Ngdelyr3BSDOGgmDEYGoLs8f1ZsKcbZwrMHHvwCZc2cU9DNA4RUraUKmUKATpwxVR7q3qw9Wusu1pd84jY+EwkmIrRoKCIPD6/Z0ZflUzcotMXD5OEpcSNOoKnq8s3nwhUJPXO9RJ6JqYs6mW4Q3my18Z5WvsJ1vYkJ6LIEBYmAqTycYfS8fxzIQf2bNH8oTvuqwR42+pXj55frEZEYlGI4oiOl04OcWmSg3vxSLwHczX+WLgVeeX5vLzJqnY5NnMQtdyg8HMyXWHAz7UYeVCNQaD2VV9ITPrQxKrOLwVLu+BHolDG2o59sroeBf6WjevF8kvL/b3u/6W3g34Y3MGq/ZAmEbB1JHd/G6bduc8L9FzQRBomRZFywYxLg7yxYDafB8rCz/UpLddI6EGXwTuYBWIthzMdXFrk5KjOHUynw+n/0NSciTskR6ASXcHGznxj9YNomnfKBpnsepW9aPo0Dg43ifUTvZWVaoZ+Po6X2gjIEdeaQ6iD3GZR+5ewtOX2NwfaoXCJWEort6CHqlQo2iuiMvWS34c698Ps+d4AWv3ZdOqfjRXdA48yeM8Rls/hR6DRaBr7bb+IoRWrWTuU33IL7GgD1MRJqvrZiizYjDVnPrfhUBtZVP6cnBq454HXezStnxMUA2GUlspI9dIn6ckcrzD4QAEtFoFoiiiVCopKjKiC9ey99Mb0deAOr7BZOO3DacRgZt71XcNvUJFTdCyVBqR218yutXVCrWUTKi1zmpz8k3OWmjZ7HkMBgtarYJTp7IBSE5OpFlKC4b3Hy1pxqqVtHnubrc29r8iTUYZLXZ6lYcHAOY/3IvnlhxHrVZiMtsY2TuV2zsmBuzPxvzhAUvCQ2jX40Jd68pE56sCpygOQMbC+9CHqf1Pmsk+jnKULl2P3mnML2DIAWp39BHqM1IrxS6DQSgPyYzyzDLJ9gtegfwmTVK5okNy0Eb3wOkijmeV0r1FPInRFenAJoud7CIT9eLCuWdAaAURfaGqiQiV3USn3GHI3m8lkI8+asNLEEXRjbXQomUye3ZnEBmpIzU1kbNnczAajWTkn3IdV6URaYO7ILi8PzNG3+v6+7tdi0irX8SqtU8z/vHv+H1tNmn1K++7v9CC15xDEMPWUK+15++L1TsOaHQ9YPh7E6m3fM6R41Opd600abp77+u0OXuqNrtYKWo7/FAZqqL8d0FrspdZ7ISHqxEEgbAwb9k9s9nKH1sz+Xv7Wa91VpuDVxfs5qrnlzPx8+18/tcRrp68gkdmbGbAM39z7JxUIXXfyUJ6jv+DS59exmUTlnE2P3DFgdpCmz7NXA+I80bp9VqfilRPz36MYmP1xdp7xc31Cvn46kdVoNKIjPjAxogPbBwr2uW2LjOjkFtu7YLVZud05rvYxLmcOfs+J0+fYdT0oT7PzVNvVqsOc/2LCo/m3LkiPv1kNVu3nCJSGzon1gn59ZBfE+e6ql4Tz2st/xeo7bCIiuso99BrE76YDH7hcEjhn+UbEE1mRFF0y3Dr2H6S6+9tR/JYujWTYuOFCWPUxH0MFb6ep2BQ46GGULD9SD63v74ahwPSD73qVc46PFxNXGwMY25qzdO3t3Vb9+FvB/jkzyMYy0yEh4dRZrSAIGA0lqHThTHymuZEhqvLM9ekfRQKgdb1o/hp0mWgUGAwWdGHqcHhqHF+oiiKLFx7ks0H8+jcNJZ7BzRx0/5NX38UQa3knzM3uoorOuGsqfXeqI9RipUL+fhCsDH2qg7T5KIzgIu98MST1/Hzjzuw2uw0b9CUFRsfAdwnzACXIpfZItVgslkFv9UaLDYzv2z5hsNnD5Ack8Ltl9xPXER8SP2tzetRnbZHfFCh6eBrArA2Qg2BIIoic5cf47cNp2maEsHkuzsQF6nFUGZ1JVzIa74ZjRYyFg4j7c55AKSkJBKmUfLDpEvp3DQ02mdNorbnPfwxtVRXzgxq//PK45XfvMysD+l2ZRSP7clixq8H3KqqAjRMm4jVakVEoFdr77LuR7MNbNv1outlTk5OQBAktgLAmdwy/tx6lLIyc7kYioggKNl3ssjVBzmcsS7wnUJZGQpKzew7WUSz1EhS48L5esVxXpi3C4fdzo/rTlFqsvHo9S2BiodCtNq9jC4ELgNek6gNpbFp7/8BSB+N2OhIl4SjweCtXWAwmBn7cUW1Bn8JBxqVlrt6V66zWxmCMWCekykXQ9vnE39szWTK/N2YTGZ2HtWQW2xm3tN9Xes9udkqYbjL6IKU7JKUFM+IaRvZMv1alCEWGqgpXOzX+rxnrjm/ls2bPE2xYRZXda3HJ4sP8eADc/n8y+EAXHXp29x/ZVOyCk3c1Ks+/dolebXTt6375EpWVi7JyZIXFBehZsfRfBwOBwUFxURG6tHrJYMsjyMXlX6GXq8lUjeStDu/di33pNZUhsOZxdz26hqKjVZUSoEvnujN6t1ZWMwWcvMKiYuLZuWuczx6fUsObDmBoFaypWAoNotAYuImzmbPACA54THy8gyVHC04VMZNrEmPIDVprNcyjUqDzSJ4jWJAimGrNCJ3vW7nlR8iXec/+wlTlT38/yrkIZba+sAGDbWKG567gxueu4Mo/SisVhs7j4ZWbFatlkKH+SVmRn24kdmP9wq5yst/Ab60WEIZmdSq4ZVnyDi9SM9MptTyFN4d209xSbfXuW9YL05kFDGofQKv3Ode2E+Owf0a4R2tFRAEKDBYsdlMKJVKmdq+cxKv5vH50qMUG8xk5xQQGxPFez/tp1/7JP7ZqSEmJhKtVkO84GDHv8fo+pI0adQGO1+MV7mMDkjUuaLSzzAYzF4C2sHAM0Zoswh+BXKCNbhma0U5ZnkoQJ5l9eLgaQCUGIt5fu6TBELFxKHUV/n5/39HdkEZHV9aDixnxug5aNVh2CyCWx055/IahUI2leOHgWAosyL07grlz17r1vXZvO1FQEqWcKUTy8IMzg/u4XlDWLjuNB/+dhClUkF4uJp27dP4d28Ge04UugR8/j/C0wDXuFZDVdx26SGTsHHSAHQaJW1vdN8m/0Am17eOZcmBAgZd3Y7RYwbw84/bSD+QTfp6d+MjyCrBtu7ZFN2G7fz17k2MmLYRu0MkKiqMfpc2Z+mf+8jPL0KjURMdHekyuIIgkJyc4Cb+AbDqmcvoOeUfAH4e3cuNbuPsdyCU5JQgiqBQKECA9FNFTOibwsm2cezKLOVYThGf/vOc136ehvLoifdcBnf3tJ/p+uQiAN4e+R6xusp1WT3Lhju9KfnDIf8dDJw8Y/BvFJzLtNHe+gRTR37kMiogTRx+92hvyswCev0ot22fmjWaV+6dViUhm/8C5ENyOeTXp8bhQQfzJ24uhd+kEFxR6WcuoytHxk/DSb6tv+v376O60+v1lbQY9h0Ak+7vxXfrTnPwyOuubfZ/sbQGTuLCwHOCrjLWSygTekEb3lBe1oy8M7w8/1m3ZVsK7kWrDmPn5Arq0YLJSkyl99GlDRSLy/hjyVLatnoRk8lKn0sfZmN+S7c25BMRAFk/rODqCYtcv2NiGvDX0n2olAKxsZJXJYoiarWSSJ2ark1jefja5lzSKgFBqYRNO0nfdIxwQXAZjNumD3U7hu7uK2nUOIGfXtb5HQo2a5SHsP91EhJiCQtTYzHbWLCvLZe0G0WHliaGvWP38mJTk8Zy5PhUovRj2Zf+Bg0aJqDXa13bFecWu7Z9ZvZTVRJccRpip2da3bBCmF5EdFdp9OsRVyzTehnfiUuOY7M5+GH/2yxa/QwGg5nUpLEYjZaQhWzqUPMQ12yDa/t4LU+KcReYmr2jJVDBt/7y72MM7OYuKt+6QeViVhcjPCdMg0kNv+AiOZ5GVw73CqgVuLztIFJi0sgqOkvTpBbUj29U6XE8PYgDB04za+KVdGsex1Ozt3HwTDFKpYIOHdJITIrk72X7GXdza+b9c5zMozkMbBHDfuNDflqX4KTLJCREkJtb6tPri9HHEa4Jo3P3NG67vSsTnvrBJcw99uOHGPuxtJ0zpuxkAIA0K9yk0dOu34V/PYKoEmjRtfLz94S8rHdN4YPRM10TgHe+5OD7Se7rK/OI5etTUxLpd2lzzp4t4tixXA6cqaCVGY0eFj0ADOZSLDYzMbq4/5RAd+GiERzYdNzlhDjxybjZrr+V1F6MW1ztv7ClvEAnDoe7PkZ5eOLApmO0KfeeX3lsL+8v7MrnERX7JyVF0fuSN9yO91+6P+CfoVLTHPgaM7zOTCyAUdO91wcTt2pVrx2t6rXzu15uWPyV237gKumCWQUF117XgZUr0nlwZF+aNUtm2V/7GfPxZk7lGAGR73eZub7rATQqLfXjG2GxWdweQLeHUQZ5lhZIQ/rrugzmt00L2LD+KE2Sm9OhoXdufEriGNeDGB/vRyPCbAGF2sWwAPjruf6khs0FAt9w50dN3r+qliV3IkofXWO5+iIwbHgfHh75NWVlJsxmBe1aTebf965m05QrEK3SC7671H8bW4+uZ8n2nxARaZHShiF9R6BUBHeONVUGqarQh6vRaZRcnvyd6z6G6R3c83rFvf5ifA0ftJyHWxmcBTrBWwBHHmb8YrwKURR58aP2AF7PxobNz/P4mG/ZuO4Qm6YOqn7/zyMqowXWpCpd0Dze2eO/D7jeThmPTh/ptfyloW+REJVQ4xMGKo3INU8XuAyjZ+qjU0VJ7l02b5KK0WwnL68Qh8NBYmIFzzBWH0+BIY+oyHAub3MtXy+T4l1Go2SMmzd5GqPRwozRc3j0I/fvlZN/WWYxUmYxEquPdxlY+cSJJwoXjcBgsrl57oE0T8+3JoMzjKBSi2g10v3zDLdUNjHUQjOLAe+uAaBzu4aUmu0YjVays/NQKpXEx8ew4q0raZYqyRoGOkeb3cYbvzxLqcGIxWIhJiaKO3sPp239jkGdT2UvVlVz8kPl2srPUTK8FUbOczRYk9WiA0KlQujfAwDDXxuIvuYzt9XybEpRFHlweuUjqwtdLDN9/dEq8bGh8mfEX7sjP7grqGNV2+M12op4/ssnAGnG0zlkrO043ancEyQlNXB9cWeOm8t1PdJoEoCDW1pmQ6kU0OvDsdvtOBwixcWlOEdDDz7Uj8zMIv78axHTHvmUB9+TZoO/nmTl7eFSvEAyLL4LGYZrdIRr3EsERumimTVuPmariR6x30jZeholrXs2QR+uduMvi6u3YCgu88kGgfOvlBbMxJrz/PwhPkLjouedLbUSfZU0VO3S4SXMZgct60fRSKYQF+gcHaIDh+jAbrdjs0kvvs0ROEvKU4hoUP1ffNJ/PF+o2mQayM9RodMAd/rdtrqasUFD5uHqr+4NuBtez2vx8E1r2HZ6FVt3eE/C/VcRiCJW00I51TK8cfXtjHhaz5iZ7oTqmeOCy96oKg6fTeeX7V8xmddcy2YuOcwnfxxmyZT+CILA3T1eY/2WyW7hgiZN4iktMJDnEMk8m0NRUcWY1mAoo3v3Rpw+U8Cff+zBVGbji/FOI6pCK7Pn8pCHwWDGbFH4zbySv/grJ1xGv0Hu8pbZBUbSZJq1MR68V+s/j3pRgGpLc6G24PyQRF/V043Xe8fA1vy44gDh1xzx8vRb9GzCu3O2cKrgNXo0jESIGodGpaFvq4H8e3AFkZF6kqJSaVWvvWufyib65BN3nhQ7z2tY00yD7IIy18imcPFD6MPVtOnTjANbTri2CRQWqonCpTUBlUYaAfVtPYCC4hJaNZeC/uHacIYPGMX4mRLnPlA8+WKHLwMsX14TCNrwyt1wo8XOjbO2+uRg2sS5pL/5LaLVXisGwWgx8MfOnxEEgU8/Wcn0af8wZuxAtux4gS4dXmbZDknXISOz2C3MALBhwwEAoqMjfLb98Kj5KBQCXRr38PJc5ZBPEI6aXnGMXh0vISkqlSs73kCYWpoB7hFbUWJlwLtrsHoY3rQ7vgKk9GhfEAb29Dlk84w31QZWTrjMFSaoKowWuyxT0D1j8McVB/zu9/bCfcxanwmig5UnSjh4RBplhE2+nrb1O1JmMdIosSlqpYawCJGbnzN6pSQHguezabKaUCvVQceLQ4U8nCT074Gg1yIu30DrHo0Rl28gff1ROmtgI8P9tgFSvztGfO6iPMpFzP2NlELFZ08ZeH34+67fk2Tc7JHTVOAUN5p4E40SmjLtp7eldZtlNMAqlLe/2FC1MEUNhxrkX9jsAiNns+/32iY1aSxns2fQumdTUCpoe7l08UMVoQ6ExdsWYhMMXH55S9547U/UaiW//76b4hITFqudBsmROBwOlCr/x5N7unL0aduXVmntaJbckkpGsD7RuK2abVu3Y7aV8e61kpfasEsT5JQbfygrs3plefkS0PFEbXs+1kFtyr/631XpQyqXdwwPV7P7iyG0uPtrr+08pxqWbsvEYCijqKiEZk0qKEr3vGbni/ENAcnDNTtMjHhNhSGIhD9fFSisdgvf/fslR7MOEqYO5+6+D9IosSkzRs9xbVPVMIM8Rb4yhBJG2lJwL85nKu3Oeex++Ura9Gnmdqxg6qM5DfWBTcfRaZRsXNS3fITm7u1PHfmRV9VkJ5xG938ZwWp1yBF6qEGhoMXw7ykefAWAi4MJ0kSU0zuTk7adfNKaMMDnijO4485uTHn5Jnr1eIPifBsFGXnM+3wdD9/QimsnSKWxb37294DtJCXFk52dB4BeH05SUiwL/7mlfK0YcHZZnvjwwWMfMf4j6UH9bM4w3n7zT/76ZRvQynUjnNVbfcG5Tv7SOGlnULNDNvlw17PcSyBUNbThmSByLmemFNMecgUN0yZSWFiM0SiFBzxpR60bRHM6p9yaeqScOvncqUlPkJNTwqMfzXVbLzewlRWd3H5sE0ezDlJYWIxeb+OHjfO4qfudNE1qiUqpwmKTDPORcwdIik7lrj73E6YOR6Vxth98hmHh4ocQ+vdAr9f6va/BXOuwCGlkeeJ4Ds2bTqDjS8v5+bEAVBA/kD9zUuzW93byEM2CyWKllMWDU3/wWUX6/xuqYnCdqFKMVxRFovSj0Ok0iKIYNAezR+x8NmTdV5VDutA4vjnfzNvEti2nOHu2iHb1O9Ms5jTXtI7j+pvbV95AOZxGFyBCH0H3pt6EcX9wzxDTc+zs0/y4cR73D/2C3btOc0OPem43w83zUKsQLpdmj+WpmBk/P0DabV+6NquNGWH5cNdXuZdA8DXJUBmGvWPnmqd9U/Ju6V2fXzecoWG9OD4Z09PLO3vrgS6ApLF8dbd62P7ZiFIQ3D7oZ7NnoBKGE1WeAffFhK9D/rCXWY0ggslkRq/XUWoqZsG6OaTFNuSBgWP49+AKDmTuobi4FKvNypLtP7Fq2yoZjcpO+pvBhSf0WiVs2O6jPoc7KqMtaVUawEHzphNcy277aKPbNjmFZQE9Xs/7aLaag/LsnWE2s9XEKz+MdV2H2U/Y+H6StH+XJLuLVfT3zCVcNeZ6oNyJOM8hiNqqh1cdowtV1OPds+8NjEYLubmlLlGXwkUj3Dw7ccWmqhcpDIBru9xO7xYDseXHEatPYN+Znfy2O4/xvxxh9fKDru3Wb3jBa19/Q/es7Bx++OdHl4LWwpcVqDRi0Pqo7Rt05qbud1F0RseNrWN5bZh/jQmn0QUkI3xlb4Qre5MUq8MmzsUmzq2SToMLCoWrTdQqt+XO9hMTI0NuNn390ZDpOVDBD5Wfl7h6C9Mf6cHB2Tex66Mb6NI0FkOZlRNni1Ff9Rnqqz5j+5E8GiXpGXdLayYNaY9SFP3qDBiNFl65d1qVRlMdG3ZHqw4jJSURtVpFUVEJeXmFZBSc4kT2UYqMhdjtDkpLjZjMJgpK8ypvtBzOopKe70ZlcF5rqPqEToth37rFfD3b3pg/nDdkcVznZKJWHeYVkvFXJFQ+xyP3/Ls8P8T1t9Pogsezfx5Qm/q8zvsiv1ehoEp6vAaznZgbKmJgAYetMoGO9HWHa+zrU2Yp4+3fJmE2W3A4HISHh3FLj7u5PG0zzy45TpnZ7qZEdsslTdiVY+L4cWnyLSUlAdEBWdkVug1OqkxlGqmeCQqmUmm9XKPW6+su83R9QVy1BSePsnTpemLKFf5DCQkA/nPzPZaX/r4mqAmY6szqyq/TvIlKukdIE4meXoJcG0MuOzho4HscOJjFE7e0Zvyt5ZOS8hFD+TWuSh/zS3M5mXOMpOgUIsOjST+zmyXbf8ZoNGK3O4iOjmTEgLFY7Ra+XjMLRBGHWFHuPD5eT1auZJDS3/yW1j0ah3RtfCGU8wjTOzBbzGQXZzNp1iSf22ycNIBu/d2lSOVtyxk3EBoF1Gw1ufHZne+J53JPXChub23WypN7v7Wqx6vXKt2+4AFf4Fqqx6RQKFCplKSkJhIepubkyTxKTMW8tqIQQdBwaTMNt9/ajMZx4bz7byIbDq1CqVQw/IH+DLq6LfcMkXi5Tw+exNQfJFGPHrHfsLv0wUqP7S/t2QmDwUxOw8auoWDGwvtILo+JOyGu2ORey6o8wyh9/VGMlopQRqghAU8YzTZW7DyHTq/hioEVy50TKsEg2PInXkyBUsFFvRv2jp15E++ne8RXQcvoLVvxFOMf/44/txytMLxWm9fL64vhEajPmQWnmbv6IyxWKUR2c48h9GxxKZ//UfEBuKzjABrEN0YQBEYMGMOx7EPE6ROY+aukxJaXZ0AlDGfWuPn0iqt+mnYoHq7rHA3DOZ5xmrR6SXz3wygWfr+VGR+6i9IEa3D8ebX+oFWHMfuJCvqeUqxIkfeMuTtxISlmNZl15gk51a/G1ck8UdMVG0JFkaGA6OgwNm+Vvva9e77Bl0svBy5nyouL+OLzdTRveC9Z1Gfj4ck8/OjlzJ+3gcjIcJfRBWiU2ITdL1dcrV5xc1kw+f5qaR7I2QkajYK0O7+mqLSfWwjBYrGxctoirnniJmmBQkH6usM+23MOGYO65rI8e5PVzi2vrObgGUlw59Jf9/P7luOANDyviSQX+RDOl9HzvI6+OJLyCgaHv3YvgLl29UG6NgpOrSzYl2vbsQ0kJulZ+vckxj/+HVu2r6FL40vctrmuy22uCb+GCU1omNDEjSdcU6iKwZX/3qZoBYJAQUEZBoOFpo0aMP66FxEEgd2lYRw+l87Wo/8SptYxsH0B0boKiUatOowvJsgZJqGJ7vvTTo7UjaSs/Jl1ThT/+9Fi+rQKrWpIbaC267MFK5JTtdI/Qeh7+kIoMUKb3cbBs/sQgJap7VyiM05YbGYemVm5x5aSOIbIyCjuf6APebkGfvpxG5mZ2a718uGYvJ/g/6YUGPL4Z88Syixl9GpxGS1SK7i5rfRfcPkbK3zu5yTOi6LIfe+sZe3eHE5lvONaP/sJGwaD2RVv8+TRBkMRkmPlrnMMf38DubkFqFRKoqIi3cIv1TW8viYYPD2sYErbADTq1ojRMzez+Ug+6YelEcgV/d6iXoSadx/qSnJM6JQuf/fx792L2Xn6X6a8ehOffLQa0RDF/ZeNDipbTV4vTqvWolWHVak8T6hDX3/X2mR1MHnpCfZmlqJUKLm5+xA6NpJ0QrKKzjJr+Xu0a5/G2bOFKG16Hr5ighuDxFPxz3MkV1lSiic8U+Sd4jme+g/gkVQS4rNdE6iN8EPtpQwrFBh7dnb91G3YHnITlcFoNjL+U2mmOjk5gSbJzRnefzQKQUGZpYxlu38jt+Qcj1B5HbhzORUxl84dpqBRaUlJSSRSKzBuQCMMSXH8tDmDgiIzZRY713RJDkjpcYgOvlr1CQWledhsdo5lHeLRQRNIik4BQBGuIjxc7friu8HhAIeDU1mlrN2bQ0GBe9HHp2aNdmOI7DUMA0JPYDCUWTmw6TiZWdLEp1arQalUIFDxwlU2tPSMz8oNZqAZXU+vc97ECr63L2/KqWP67PR/Wb47F7vdToN6E0AUidCpmffGlVUyus6++LqPfVsP4FTeUSY89QMxETHc3ecWQEp//nD0HH7b8i3T/3idlvVbsGjtPUBFLL8mtIKr4uUGutbvqAQyisxEaVWkl1WIM2Xkn8LucPD9j6NYsng3Tz/5A2abyZXc4wsjPrC5xWs9Y8CVfZz8XR9fiUD+9InPF2oz/FAZqhRqkA+lg/pSlU/stL2yNzsni67JKH84V5jh+jsrKxelUsGBjL20SevAHzt+5Hh+Ov0HtKRV80lc0/lWujWVYqWlJgOjP/T/ku7cM4UGqRMoLTUgijoe+dI7LbRNs+dZ8vIAv/Qpk6WMQmM+hUUlmExmUlMTySw47TK8zUbdgPDmKo4ce9eN7iNHpE6NIIBWq3UlnfiDp5atP/gj6992+WA2Hl6NQlBwbZfb6NEsONpcdeUlnUave8RXfh9o52SkwTCYT16qeKZ0ujDKyqRru3pPFnf3b1Ltfsih0+gZ0f9xTFYTWrUWhVAxglu590/SM/ZQWmpEVFR8BKXEDf+vSzA6CrUlctSub3MUznOUlWVJi2uAQqHg7jtnk5lRSFJMMlqV+/vhS0pUiscrMfvwHUJNpa4WQ+c8QR5+OF/Gt9oiOcLAnlL6Y5AcvXtes/PJYxXbOb+YeaU5LFz/FXmlOSREuNdYE0WRhRvmEqOLxY6VG2/tyNvv3EH/S6dyKusUner3kvpiV7kZMl8ldKw2G6WlRrRaDb5gsTn4Z+c5HrqmuXTcndn8ffQDYvUJXN3pFsI1OuIiJEaELcKGIChIi2vo2l+v12I0WlxGt3DxQxJ/sxzOl+/GbneyZPtPWK02V2rz1JEfEROrZfjb0m1xpl47M5OqgikDCzD0a8e2wvvQqHyfc6iQlxPy1a/qGhidLhyNRvqYbzuSX2XDG2goKQgC4Rpvzy+vJAez2UJxcSnR0f7TxuXwLK/kr76dr37UVNu+2k2OrseQPiPYcvRfUsITGXjJdV6JKs6JYs+QA0iaDE6EMvm2cdIAWvdsAgpFwEQgeWz/fw1VivFmF5lcGgNuWVb+qCIeVCa5hsIn42aj1YQxa+lMTuQcw2AwEhmhx+5wIAgCDocDlUqJ1WpDXc5LVSoVtGuXxu7dp7mj1320b9DF65AqjYhW5+CuKRWn16Xjy+TmShk+CQkR7Nj9kts+ox+ez+LFu+nUNJZwrYq2DSL5Ytkxrr+hI/+uPUJyRGPu7vMQRcYCVuz9kzJLGT1bXEqz5IoYcUSsg3umDHP93jhpAN0Gtnad/8GpP/DvGWkCye6wIyKiUlR8/+QvwIGpC2nVuYHva+oBXx6vk4pWFUMo5zAHmnCRD4UDGRhf7VV4vGa3atEKhUBEZBjx8XpaxGr44oneQfcbqmfoth3bwO/bfkB0gKCA2/rcRdcml7j1OxB8VS6oSj8qa7vG1bJkVEiQwkuev6EieWjuMzYcZt+jy/Ndkr6mUBWeuidqPMabvv4oDbs0pN6Q+RQbZmETBwTfm/KZ9u1rD7G9YIjbqnted6DX2xn2zqO0av4c584Z0OvCpaKVBYVERUVit9tdRhdAdAiUnAujZWo7HA4Hoih6fcm7R3xVXqOtYpY8N6eEgsISoqO9jW6zxs+i1yqJjtBQaBfQRur5ctkxUpIj+fjTe3n15cX8+O1uAKJ1sdx6yT0+T7W0wDsnRa7c3+rpwfw7XlpemSBL66fv9Dkp4QtOsr78txOeM7mhoLIH0dMj82VwVWrRp+aszSKUv9A6vpjwNa3VX/DNwSJ+3XiG9u3qsXnzce7rHXw2IlTP0NnsNnaf3AZIRrdjo250TOuJzeLOKKis/AtQa7PmobZ9IGMvf+78BVF0cGXHG+joQ6Af5Pei4rccb//2Aq3rtWcYdwAw/G1VzYu2g0+edmWoSpXf2oD0jNTC5NqBTce9lomryocQlRgHg8FcXlDyH7/bHDzyJg3rTQQBomPCOXN2KgCtmj9PWZkNq9WG1WpFpwvnePYREEUOnd1HXmkOA9pd42rH+ZK07tEYccUmTmaX8vGSQwgKBZGROlRKb4Nnt4m8Maozoz/awqtvXc1ll7ekc4eXOZdVwrVXT+fIoWzapnUOfIHKIRdY2V0ahsoi0obAMVNnn9PfVNLmubu9N/CRgOFplCuLtVfpwQziJQ+0zrMApyfkL3hEhJKpI7vRsn4UO48WMGlIex4c1DyoboZqcEVRxGAuRaPSoFFJI7aDZ/dxMvcY+flFaLVq9pzczo3dBnNp4gLAfbIumA9SbSHYtg3mUhZu+IoyUxmiKPLLpgXERSRishhJjEohWhfjtr2nsZXHfwuLithr3wHlhtcXTuUe53TecfSNSmnjd6vAEC7vQXZ2sSvNPJjCAFB+TS6QZGZVsuKCNrxbS+/HbDWj07nHapzZVipheEiUkFnj5hMWIaLXu7+YA9pfg1YdzqwlFcPLuLgINmx+HoBG9ScgoMBmlzLToqMj2XVyKwPaXeNzBvjImSJufmU1Jqt0nFYNYrmhZxp/T/+dq8ZJJY9Tk8aSk1PCwx9uol6Cjpdf/I24+Ai0GiUP9khmzalkerdoT7/WFRkIzlJHziGyXKHfc6bX05vwhGe/xdVb3IysZ+nt84ma1v6trBSRSqlg9A2tgm6vKkNuu8POj5vmkX5mD2qViq6Ne5OesRuLXZpME0URUQQRkR4x8wGF696cbzH66qC4rAiHaMdR/nEWEfly5UzsDhtKhZL7LnuYxon+P2ymUoG2zV4jKy+LoqISFAo1bVu8iF20kxpbnzsvecjFkNh/ZjcLN8wF4O/dEFY/npt6hSaUs2jjGW6+EndtD4Wigr7qoxyR/PpXFg+vDVRVsyForYZh79gZOU2qt6QShvPPxC8r38kPnIF6U6m3Qbqi81V0a9rLbZnT6AKEhWlok9YRhUIgMlKPLjyMpjEWvxdgwcrjoFSwe98UHniwL4VGK0/d1pYr2sYzfeyXtGn2HDk5JYDEoEiKCeOaTkm0idPwzYS+3NQ+gTt63ceAdtegVlZMTmn17qFx+Wzv2YIz/LRpPr9u+Za8Uok3a7MIrn9OOHPI2/Rp5t7v8uwscfkGDAYzMTd9QXTEw16ykcHibH4Zh84U43AEpz3hCXn/Qsl7N1tNfDnR6tLAmDdRWSmjJRTIX75QDOD+M7tJP7OHd6bewYArW7Hv3CYSUtWk1NMBIvHxMURE6CSpyvrxAalctaEDEAiiKOIQg+POx+rjEBDQajVoNGpEESwWC9nZeZjMZtakL/faR6URGfGBjREf2FBoTWjVYej14aSmJgIiBUWlZGbmcizzOJsOr3X16e/dv2OxWMnMzMZitvD96hNSg760Q5zGVOFufmYvPUy71pPdlgn9e0gT+OWhOrnWhK97Ll9eFQ2FYCG/7+dFnUwQBK8Cd05ZSH9wXgA5Yd9sNaFSi9z1kgNw9+LUSjWT79vP8r2LsDvsbNn1jGvdwSMSuf76y80cPnmCxKhkxl8e5jr5c/llzPj9IAaTjTv6NeT7NScxmG3M+2oDG9YfRatWuM7j8Ztbk1ds4o1jZ13t14vT8cbwism69NxCn+d010sOnxqwpaYSvlg5E7PFhCAIHD57gPHXT3Iz2tWpo+UW2gki9jt76WFe+3YvAJd1SOKL8b1Rq6qkjUR8m3quWeiVEywctozyu62cAzry3eCSNYIdLlZ3wspiMxEermbI3Zcw5G5p4mz7tpMA3HLTR3Tt1pDt204BMH/Fcbo0i/Pb1vlERv5pvvv3c0pMxbSt34nbet7rNjHriSJjASIiBQVF2O0OkpLiERQCCoWCnJx8cnLWcVfv4X4TI4a/reLNnwowmUyEacNQKdWYTCVYLDYQK5Irjpw7QIEhD7VahV4fjkqtIswmaWi06dfC1Z5weQ+vVHnH3+td8zMxeg3FR/MJC9MSGxPJiGtb+hzhBXPfQ6nYUdXswep41NWmk30wyuDyGHesPUKXS5u7ZtdXTriM+AjJ4MhPSv5SPjrdvVKpMybYtd1P5BYWoFZqeG3EaX7Y+CWNmsSwaIk0DFmy+gGevmM/bet3JClS2t/uEBny1lpOZJVitzv4feMZbA4Rs9nCW2/8iVKpwG53MPfvowwvr0b85G1t2X60gF1HC1CqBNbtzWLmogM8dmOrSktT6/Vaiko/49d3BW6ZIKLX23h9VBZWu4XcvAIpaUEhkF+aR3J0KlA9ObmMhcPAFrysnsli562F+7j73kvo3bsZj4/5luU7z3Jt97TQDlzumbQY/p1r0YB317BxklIS0C6/t/KZ8S8nunvXZqspqMynQMPFmprJb1O/I+m57jKK48d9h+gQUSgEl9EFMOWVetHmalNwJRB+3jSfgtICjMYy9p/ZRZOkFn552WariTC1DqWgIjoqCofoQEBArVRhsQSv8n/wyOuohOHExSmIi44gLMxCeLh0H4uNRRSXFVFiklLSO3dpyO5dp3E4RNo2exSrfRHvfL6ZZ2SGdsGqY9x/xSeAlNX2y9IjjLpWMs4v3tuBoRnFCAoFrRtEMebm1q79qqrzUJPPU3WlIOWotuGVy8ENeHcNG2XCKwPeXVPltNTSslIKCoqJiorgp3+/o6C0lJHX9HXb5s8dv7hVmM0tMnE8y0B+fjEWi5WUlAQAHA4Ri8VCREQ4Dgd8u+qEy/BG6zXkllhISIogL9dAYamZd39KR6tRMvKaFviDM0Ritii453WHazg9floqny4WSUiIRXSAVhVGjD6uyjdNH64OTSRHNgnnWPovDhH0Oi3R0VIszm4PPdzg9FCKDT2J0o9yZdcltE+j9GiO69y2llZkqd35koOR74Z8KMB3gceapGXpNHqGXvqI27ITxyvkHg0GIw6HSGSkHm3UdcBur2HrhYjtlpqkpB2DoYyoyAhKyw2eHGarCbPV7Bb6uqR9DwqNBZSairHaAhtdX5S51NQkBAFEhRmwY7M5UKk0nCxMZ/66TIb2e5hIXST79mYiitCxUVfiIhJ4cbmeHSf28kXT5xEUAt8804/Ve7Jc7dZLfpwOrRtw7GwpT9zWhhb1otjw/jWUlFmJ0qkRBKFG1Myq+zzVRqXnkA2vPKV17jPe3pe81EvQnZAVe6wYWojExkYhKATySnNQKGDqO8v4fPY6jEYLcQl6SkxFHM06SK/ykWBcpBa9VoktSu+KZ0aUT/ap1UoGXtGapX/uo35CBTHe4RApNFpp1ToFs8nCmTOFhIWFs3zHuYCG1/mAPjp9JI9Od18XEaFDpwsnXKtj6k31aZH4LXB+gv3ySTmdRsXjN7Xig9lrmTN7Ld1axHNll9QaO5Zu4CU0HhLFie/+wXjoLD1i5+Ok7+n1WpY+fTnXTF0NQHv9PNfoR45gqVk1behUYhjO2mFdOr5McXEJUVGRiKKIXl/xfNSLbcDG/K6AbxGgmkCwVLVLmvdj7YHlREToUCvVPvnr8hRfgMTESNbvkYxww7SnOZeVS0JCLLm5BX6PI2czTHnwIH1aXU5yXBJvzuvoxrce/mBfZkz/h24xP8DAJziSs5dwjY629Tsi2mD/mV2UlBjIzDSQlprI97/tQ2etmEzX6TTsSH8VgLuun8a343uiUAhE6/0n+ih1Wka8WLWSYqE+T7VhcJ0IOoHiy4nSMLPYUMT4j6VkCmeutjPW4/mllc/0e8JTTAMkwwvSS9sw7Rl0OjWdOtcnO6uEY8dyUKmU7N43hc9nr+ODaX+jUAj0azmIiX0zXBfmje/3MOvPIzRtlohOpyE3o4A37+/EmE+2Umax0yAhnEUv9Sdar5FUv5QKIq7r59YP54egcNEITu04FfAmjZo+1OfyqKgIUuMj+GF4e6lvPoSF5EkPQenuBiFO5FT+hwq62aEzxRQZLbSoF0nirXODP54TMi8669fVpN3qPbFauGgEer3WXeqyHE4v2em5r9qdxcI1J1GWmRjaLZn9xoe89jkfUGlEbHY7X63+mCKzJJzkcIikp58iMlJPdGQkL9xRRbc9CHi+2JUNfUVR5ODZfRQa8mmZ2pa4iASvbTyfR3kYr3Xz58nJLUGvD2dg++u4rE2QGoaAVmfnlkkmtwnefn3bYCwyMue25qi0Kto+X0GDvGfQYtbvX4ugECgtLSM8XMutl9zD8A67+XhzFrsySzE7BHbtneLap2jRGqJ0gVlR8ud7xphSwpVRbinfNYWqjlBrXI/X+WXRqWO8wgf+YndxMVHY/FQFMlvNPpfr9VpmPJWNLlzNgcMV5dtbNZ9EWZmVae/9zerVh1CrlZSVWakX24Ctpw5gSMyjW/M4xtzYmn/357L3SA4alYIPHunOgE4p7Pv0BpehS7jluCtdURLe7uezL8HAl5ZCakoCgkLBPVdUsAHcxMl9JEUEo7tbWRuu5U6Ur29ZPwpwr0Ibks6vTANXrwzgYZRrCoP7CyLHnuMFDH9/PTarDZVKSaZZ5LWBc4HzO3yXiwCNYDSAK1zUrPEEQElkePUFcXzBnydVmWiLIAi0rhc4oUSuaOdZ9WJQ13ps2HWWHg0j6dyqf0h99jXfobJYiIvUMudAMR9+7/4ObDu2gTGPD2T1qkPs25dJ7xYD6NiwGzuKuzN7qe95ishwd3NUmWMyc+mbxOlSGNrv4YBVwUNBTcZxA6HaMV45tOowl9cKoNdXCIt4ystZPAzv7r2vu8IMY99LYux7r7mtV5S/8F/M+RcREYvFilKpZNHWhcwvK4Q/j9OtRRwPDmrOry9cxrFzBhKjtcRF+ua9+ssR98XQCESY16q1bsb384cu4Ui+mfbtUhg8sDlOnnN1YbSDPpgNa0l4vjLkFBoBHQaTFX2YGuGvDeivrjC+GQulNOrNh/IQRcjKzkevD2fbYYGWz1/GoY3HzqtClKcwjDxtGSAtLYUbuvlPFqgqgnmxq8oVltrWuH1Q5R/i6aOkrDXJs54f0rXuEvENcJvbsgOni7nyqjZsPZTltb1SqeChUZeiVivZszuDAe2u8TtZ/fhdM3n6trbE6SrMkWc+gPN9Xf38YSYvLyUuVeDd9wYz4ckf2Xh4jVsCVVVxvowuVNPw+tLq9Efwl8eeXhr6Fi9/85zb+o7tJ/HJuNmM/KDigr/5+h88N+k6ABx2EYUgYLPbKSkxUFJiICUlgeKyQnJzC9Bo1Gw7DNsOb+aha5rzwt2VSxI7vV6VMJzWzVM5cESilQ2+og2zx/VGH66uNFvJM6b24JzN0h8/7+LeV/9y6ZEG0xcXfIQU5EbMEza7g0MZJSREaUnyJaFYrpURART+qapWwUF9uJqMhcPcGA5Go4WOD//kJYVp/Vv6f9FvD7iWdWgcA0B8fAxajZrWDaI4tPFYlftTWxBFB79sXsCIAWOJj0yssXYrExiC6rEmvNr08SH2pdhWGUSrHd2mnW7L1GoFn385nC8+X+daNvuzNbz1xh8oFQLdu7yKxWInMiyKxdt+5MqO16PT6N1iyAen/sD0kd3ILjC6aY34G41d+8E6Lu3WlJiYZG675QMAWqdUTDIGqzHiD+cr6y3oGO/s8d97LZPHk5zxXH/1yPzFQuWYMXoO0bFa1/5tWr6AkjCKDUXcP7wPVqudb+ZLNCC73Y5SqUQQBAoLS9BoVERE6Bg+oi8/fruJPR/f4N54ufExGMyIa7eB1eb2VT2XX8bvm88QrdNwa58GXlxXfy9DMOfljLMFO0MrH6ZH6UdxeO4QkgcPdFvmNGYlZVbufvtf9hwvQKUUmPpQN27t4yGs468OW6jwUzdOJQynqPQzUhLHuBlf6z+PgsPhFuLQh6v5+d9TfLPyOOE2G6P61CMxQnPeWQJavYN7y/UjWjWfxPZdL7o83vBwNTabSEJ8LF2b9eLm7sHl34eKQELyVbkeoYjThCoI42xbXh8vJSWRNm1SOXUqD5PJStPUSDJyjQzolMxTt7bhsz8P88PaU5jNFrQaDc1TWjP0slE+z1veLsjCJAoFxh4dXdls8pi1nGEzY/QcVGrRzXELJOMZ6Byrg1qtueYLT89+jFnj5vutRxasrqxzf6vdQlx4CqdzJWJ7/wGtMJttLPhGGjo5jW7fDslsPyJVdejTtznr/z2C0Wzn/Z/TefI274xxvV4L1/TxMj4pceEBWQy+6nptLb2fD0bPdE02BoL4745Kt/GHFsO/IzMqjOZDF2A0Wjg8t0Jo6NdNGZzINfL1Nw8yf95GXvtur7fhrQn4MLrynHpPZGZ9CHvTvVTTrH8/zG19G9JGkIzxxvzhHM2v+e5Whp/X/MIzqZKnZrWa0Ou1rpc6Sj8Kq9WKQxQJ0i+pEjw5pvLlFyucBtFid3DdCys5ePAcAGlx4SyZ0p9wrcrtnjtHfC2aPkNm/iE6RnyO0YIkG4l7FQo5nPsXLnmIpKQotxCmL7iSdT6Y61rmSzzrYkGNxnjlkwaCukLsRcrPj2bG6DmuC1RU+hnREQ+7VZWVPGRp/wMZ+zide5I5X9zP88/+zAP3SzPpDRvFcepkPlarjehoHd8ufcp1zEb1JxIdreOGGzsy/ZedXN01lc4jJU8948f7SQ7Q92DLkMgNsJQsEMED73zmN53X+cAIfbuw/5X5QX1RPbUanNfnXE6fikm1ckM47MreDCsPh/++aCf2StKCq0pE9+Xpehpdz6zG9E3HMBjcZ1e3rTrk+juYwqKhwDN1158BM1nK+G3dL4B7VWNwlyzNyspF3aJmNIz9Qc4xPd8G12wzk1ucRaw+Hp02qBkE13uhB5a+NpBvV5/A4RC567LGhGu9zUm95MexiXM5fOxtbr3kZRnddCUlSx6qXI+3POzmK4SpVquIjw8nL6/Ia12Xji/TLrUHl7cd5KrsImdZmW1mbHYrem1EUOddGZwfz1ovdgnuXuyq5/vT9kXfw26ner9WHeZiROj1Nq+vmFzl3/mlslrtXD6gFT98vxW9Tk1OdgkqtUBmZgEx0e6znKIIb759G6Io8tfSfeQWV8SgOz/6M2dvl6QsxbXbXMt96dgaTJUXl2zTr4VrFtwX5NQ4OYKpVOBkERjKrG68aXmfI3ywBhb/vpvJd7bzbk/GNqgpROm904XfeGAaCyZVhGhMhvvK5wGkl23qyI/o9XrFqGfaI0MoNRUTFR5drVlpXyyBQMI+oXhBv637mQEdrkanCc4wVRXn2+hmFpn5eNlbFBmKCNNoubvPSBolNvXazjmP46x8LQ8bRes1PHJdhRb1NyuOMfzNv73a8DcyGjRltdvvjIX3kXZnRfFNJ6/fUx7yXH4Zt722Gr0+ArUS8spzX569sS31UyewbPl4ho/oy7jxkhUcOW0WKmG4a1S+/fhGFm/7kdi4cJc8bGXiTYEgDw8FW+yyWoY3ShftqtAb3y7NTyKEBF9fdH8TcWariSaJLWifqufRhyVD/cTt7Xjiw4rMqPqpTyN37mxrtnJV9zSuv0HKZLvhxk6c+3UVIJHInVUpsrOLqXeZ9PeSN6/l+uf+9Dq+/Ob7orFkF5loMexbN6O46vn+dJHxGD3P7ac3BIpCyB+HCsNfWXkgJ5a+OpBGCTVDq3GKmDhZGeL6HQh9Kgj7xYZZNG74JPvS35T6qtcSFx3uoburcPvYeuLLVTPILc5GrVJzZ6/hbkVDg4W/mWhf1Cxf3PGwsAqP9tI+77g5A85RjNVmhdp1fGsPfrjfP+7KQasT+XH+o7zw/K8s2/Ubd/UZ4SrgCXjVXLP2b+nmpMhHhn9syXAzuk8O6caL93QChYIYH0ZXq9WwdvMktxGGPkzN7IlXMuCRq0lMinK9Q8LlPdwch5S4cFa8dRVHz5aQFq8jpjwxxxkn7th+EvcPv9zn5XAoLCze9iOlBiMnzrzlWn7Pa3b2v+LnGvpBdeLxVTa8nl6GZ3AcygVdZDdbbnznTVS6Soso1SJmo/SAeN7sevWkMkBz/z7CE7K2FQqBrKwC6qc8Rc82ify08lk+v6y72/EjwqUbIi8FJP/y+jK6nvDiuyoUpN3xFTqd+5vYuVdTzsxZTKtxtwPw05sKDAWCS7vg9udF5k2UymcHM7PthDOmVvr7GjcPXO5xFhtmYTCYaX639MGQfyxCTtIoh3wyzmAwE91XSs+TszTy80r57U1dSPXZ5KOkgtIcunZrSF5uKX/v+S1kwxssNctpfDtOr1DjSklJxGg0YjbbaZg2EYCRg8a4fTBTUhJRKRWcyj1GXEQC9WIbXLQxQ59QKMhp38btmXcaS1EEQSGg1aj4559dAGzZJ40E/VVYDsSEWLXbnVK2alcWbz/oPWJ89r6efP3PMc5l5Xmt23OikLd+SueBtyufsA7TKGnXKMbv+qOHK/rjpIhmZn3ITVd/gDZMyYkzH1Z6jECobgp7lVI+5A+8r4e+aaMnpVikzeZS0XJu65RTs1kETAYFJoMCQ6GU+tc94it6xH7j1lZZmYmzZ3NQyFgG7038FkQRk8mM1WbHYPL94uu17lUZAoUGAA7P8yFA7gdGo4Vwj1BEyw4V+qO3P+fwSWdpoZnFqOlD6fjScuLbpLoN3XxBH652/ZMvy/xuKJkLh/n0hP3FzWqivpX8Jf5zfD/XZOgX41XYrNL5GgxmvpxodaMbOhGli2bWuPn07NATm93Bxg1HOXkyH4PZh9RbJQhG/s/fC9IqtS0REXqioyOxWm0oBCWLt/zEDddO59OPV9Gi6fOcO5fDmYwsftjwNbP/+YBlu38PuY8XGv4mP2/rlICh2M6N11c+koIKKdeVEy7zub5NA/dkk+3pZ1x/y6mSd13WiIZpMZhtkjPwzavXUbj4IQoXjWDfqSLsdqkUlMFgpnfPN2jXajJFS9YRDOTHWbXuWVTCcFTCcHJySigq/YykpCiato5wKRx6omH3xkEdB6ovCxqSxxvIwzg8725aDJM0CTZOu8kvkd+fsHavuLkIaiWtuzcmPHwdZWVW+ndrwoEzxcTFRYKsNPlT79zNrB93S/W5BBhzUyuvCSkAHA7p675qC0L/Hn5DG4fnDSExRucV081YeB/6MO+vdlHpZxItbf0OsNpIivU9vO8VN5eDU7W0enowAD1i59Ph+Ypy7c6QRkgiOABqlc8YrxzG3l19TvhlF5QF5fX6vJ7OdeWk/Fitgl7auYB0H20WyQiPmj7cta0/78lmt2IyWSgoKCI+PoZ6sVVjYvhTn/JlcOXe9i097+HrNZ9xrvAMarWKAe2uYd2hZVzd/RKGDe/DmMfmuvaz220YDBY2HFrF5W0HERaEytrFjgYxYTw26Dmyi88iOgTe+PYF17p/D6ykXlwDUmMqHAmtWuu6lrtflkZ78vdl2JVNGeWRXb33ZCFNUyJIig2XqIXlWLt5knuVicUPoddr6dgklhMnzrmeW6emRPwNc4IqspCXnukKfYLk4TqP0bnDFL6cN4IF3/qXMhUu7wGbdgadhFSd8vBB83j3vHKt28FqAge2nHAxHw5N/5m0h673MhbtW6ax86D3F+rswhVsP5pP83qRtEyrPEHBGesylFmJuaGiNI/zhjpf1IZdZBWDg6ym4YRT+8GJmOul4zjlMf2FZEI1vG56DM5wTjnfUQ5/TIuQDT14cXHl8DRycm6zP8P7165FbDi0irIyM+HhWq5ofx2XhqAd4AvBshoALDYzX657H0FtRVAIFOSYMJql2ugKBZw5k+3aNjY2ClEUidCH8/MD7QlTBz9QPJ+TZl48VIUCQ5mVnMIyWgyVRpLy593ZN6/wXmoSCJCZWXENPO+jLy8v/Vwpd30i8eybNEjCaHGQlZXrxRwBd/aIaxJtxSbU5ZKRngipBBDuiRQGg5l3f59MXLyerTte8NzdtQ0gJYlUMfszff1ROrxYefgSQvB4fRpcDwX5UDvcuqc0i2owmOn+/FKO3O394q15d5Drb89aTNf1CEFX1tk3jz7mFJa5YqAbJw3g1I5TFedaiSiNwWx3GfGMXx6gxb0VYZLDcytI9wPeXeMydoWLRmAwWV3erlvGWhAwlFlxI8A4BdFlpbSh8rCKC/7OUV50cMWmwAwPjxTXyjjbZquJvq0GYrPbOFtwmqbJLenTKoTiqX4QipErNGWzaecE129nnLeszIRnGDcsTIsgCDzSpx5dLvfP9fZEVTyhGoMsWzECsCYHpk1NHfkRf+z4hRVbl5N5NpuoqMAsDs9z2nl6PR/+dAm2jx+hV/e3iY7RuGLHnjg49Qe33znZxUQ3neBz28rgL5RUajCjVChQKzVo1WG0TOnA3tM7XXMjYWEq8vONru3Dw9Wcywku+cEfQnFKq8Vq8FSicuWF16BegEIQXMNeebzKSfmC0DxTfbjaLSzi/D9Am+eG8NPLOlgvla6X0+Mqq/abduuXbhzWrJ99y2M647XWvx/2yijLXrweneBwhUg84ZwoS0z8oVKWQ7PGTxEXp3N7uMAjjh0go81fmCEQ2vRpxrpl6S6jO3XkRy4vSS6Snpr0hEs8Py0tGbtooVPj7sRH1FxqbmWI1se6/VYoBJo0TeDokRx0OjUmkwlRFCkrs3L2rFS+afjgq1mzJ4un5myjzGznwUHNeOK2tn6P8V+pz+aZ9g5QXGygddOWPHaN9EEKJGLvEB0s37MEkKp5bNz6DDdcWzF5JYoihvJ6gQsmK+msMbNx0gAadKoPahVpMqN75Ni7NC//nfHj/ejL9b39jbLA/bqKosifO39l85G1KAQF13e9nce6H+SS60X+OlCfn9P15BksHDmS6dbeuZyZktcd6ELVIKpseLMKTaR4LHO+xMGWJHeWfRfL+apyw7pr9mDaNi4X2pWpYzkhp3y5hs4BPFT5ULnseI4rFtTxJWmm28lS0Ooc7LTc7z1Tr1aBw1HhBa7dBg4rOp3GJ9dWH6b2UofyBYOsgGW9GyuGY/KhlbPvRhG37Cq5BoL8fLMXrSU3t9Tn8VoM+5Zds++g08gfAThyrCmNmyRKzIXyMMjheXfTRL6TQhHwfvrLPpJ7vZ+Mn4PzcTubPcM11Hxu0rXMm7uRP3f+xNB+j3i1UVUczTrI/jO7iYtIoGeLS71K5Oi1epx6vN27vIrd7uDI4WwEQeDAYSm0JR8OAzz+2TY27JeMsMMhMu3XAzRPi+TGnoHj0zVdMDRUVCVpJjExkr1HK2odLpgsBqyXFxfn7iHv33+OpKQEsrNzKSuzEh3xsItWuJHhAPS605u9kHDwsOsZP/7N36TdITlBniFB8H0dT+UdZ/ORtZSUGFAqlSzZ/gP3d2hHjwEtadtH5MtHF1Nq8D2hPfOpr3ns2uCqWlcXVTa8S3fnMPjaCqMRLNfUCw4Heq3SzUj582Cd23gmPDjhTzbRUGal3pAKLunGZ6SZ2Y35w5kxegjD3rG7zuOuKSL4KMUuXNrN63cEUGzo5RrWG2SKXPowdVAfn8qGWXI6mNyjPvz1Pe4bypIkEnUqrH8/7DOeDLiMrhMqYTg6ncb18Wkx7FsSnvzdNfQS+vcImIBRVbZEt64tGPFgP3bvOsPWf3Oq1IYvHM8+wvy1s6hfP44dezeRV5LNTR56CzaLwMv3neHzFR+Sm1uAIAjEx8cQHu7/lfjyt3F07fQKBQVSdZTU1ETGfLyVkjIb9/Rv4nc/8J70qy24KIp+kmYMZVYObDoOgMlq4vdt39G8SWOOHD8BQFJSAiZTmde7LE9u8oRCULBu40S3ZeOun8DZvBymLnwjqH47J7L1qoqqE864NEgjXLldCJSVCGA2W1CpVDh0YZht0ntos4uUlNkoLi5xbS+nR46+roWUhXUeUGUF4eGv3Angomxs2PRitTriizblbxs5KqWAaTXkd2xDsWGW65+cCnJ58nf89kaQguD++qXXotdrMZitZP+2BoPBjLFnZ+8YuCccDtewCqRhVrBIiglBND0AOrR7noSECLfrA/j04oPBvzNvY8W0W8j+Zbjb8i76b0h/81vmTVQyb6KSSfe+QnZ2Ka1bvMDi33fTuaG3gHpVceRcOvFxEaxdP4GHRvbjSNZ+VBoRo7WQUdOHMmr6UIqNRei1kQDodOHodGGEhak4eKTCUGRmuXM9oyMepmOnNMLCtERHS/tGRmqZPG83WYXe1LnKIJXpkf4VG4vc+ga4LZNT8/wtl9Pr0tcfda/mq1CQvv4oMTd9Qa/XV9Lr9ZX8sf1njuWkc98D3WnRoiEdWrZDpVIQFVX9NNpxH8fSLLXiY/TG8Pfd+torbq4bNU0fFvjdd6IyGleTpBYkRiWTkBBLTEwkbet3Il4vecpqlYLb+jYgKirStX3zJk/TtuVksn9djXCejC5UM8brFBYxGMwMGvAeX4zu5hLdrk045RwBEmUGSE6Bysgz8uPqE4yf+QANZfvKh9QZC4eRl55ZrjVaYcAPTF1Iq66NpB/yYbZSETD2mXTTZeXDU28PNZjwS/jW3QEZB1k/r6owuJW0JQzsSWZWBXne+WWXKzpBRWzLE3KPurKhqnMkMmvpYQa/IXEuuzSL4+j8e2g2dAEgiaKc2nGK7hHS0NGWMJyHrhjP8azDJEWn0Dylte/Gq4DEqBT+PVjCxKd/ZNWKQ9RPSmPYO3ZUQoWYkTN99Pqud/DH9p9wiA5sdvdrmpQUhU2c6xZy2LVT4qeGh2t59LH+JCZG8sqU3zl4uohkX5KcTpR/CFXROka8aPPS/5Xj6dmPMWP0HL8TlIEmLjfmD8dsNdEj9huMPTu739t1h922XbrxDwAmvXAD+/ad5cwBBx0bdSevJMc1CaXTaXjnAW+mgTwLcMboOcx9RqpKLIdceCg1aSw5OSWuEF+9Tg1YsvQIk+7vzd39G/s0uvK5GDmtM1BauEalYeQV4zl0Nh21Uk2L1DZsyBM4W5hBp9zfub91FBFhTXjza2mEdeT4VC7t8zZLNpx21WE8Hwja8HpmWYkrNiGKIruOF5KVZ+DXZ/uQEOWbJ1vTSIoN922gymPBucVmbn5pJWU2B+M9NpHP9suz0va/IoUi2vRpRqvODfyyIDwhj9GGss4J+UfEF2fYq9hlCBOXTsMRKjIWDiMpShu0voM+XI3F5mDm74cYdn9vBl3djqH3zGHb0UK3vnu9MHFAU4ATwEbvhquInrEi+aVXseqvXcTo0ri+y2C/2/Zo1ocDGXsosp9xWz5/ksCy7UvZeMhdT8BotCKKDpRKJatWHOTUqTxUKkXALCr5JGbLgf43kyNMH7r35VXo8vWVbvd/Y/5wpo681ctwd+/8Gtk5xWRmZrOeDW70r9SksT4TgeRtOJOeVMJKt/T8rrHfAdLIWB7Xb927Kbe8uobDZ0uJiNDy07+nWPb6FaTGuY/iGqdGBXRE/PFoNSot7Rt0BqTJtp83z2fPqR2Eh6vRa5SUmNxjvKIoelW/qG2EdDQ3krrDgQB0bhwNjWunREpVsTE9h5wiE+s3Pcfzz/7MG2/dFtDDgKrzk50Ka/7W+dKtkCMpNtxlfGNu+iIoongw8JcA4RlCEDfvgQHuqdZuCRZBUgYFJAaKxWJzHUPhZy6mtsWm09cf5fnLsoAUNuYPL+d02ikq/YyFLyswGSo6tv/sNjKLJSF2k8lKo/rPcHvP+2iT1oE1e1ZiLCsjNTXRFfoTBFAolIiiSHr6WQQBnhnclvhqOB0S+0Prxi648yUHd74kjcwWTFKgpMKbnjG6gofuZBvYBRPPzB3tV8bSKQITpYv2ovu1TOxC/+ZN+OCnd7z2O5s9g08ek2QznawUTzpY6/L7qdP9S05OCSphOJZlozhgUSAfxzhT1nOKTOw8ms/0GUPo07c5Pbq+xpZDedzUqz5VgSd7ZF3uUFbvX8aZ3BPERSay59QOXnntZoY/IFUpl9uCesmP07lDIwZ1q1elY1cVQRteXyWSL1aklQvFvD91GYt/38Wsz1ZiNrvH4Ar/HOW7EoPMO/FURfIHp6GRD43kqJSKVgOpvF5wMkE8KGNeHoRYMZHoFIiXw4sy6McLVqsUPH9Xe15esIXvvt1CrzaJXF3Jw7z9SD5LtmRQP17H0IFNvMTn/cFfMoentOepHadcnpA0MSQ97lrZd23q952YSidAEkTv3KAvDeOb8OgMSZApKkqP0WgiLS0BrSqM0rJScnIKiYmJQgB+e6k/zVMiXH2q7KN5aPrPbM2+g3tel4bhCyYrKSowu4zuG8PfJ1IXhV5f8WpqNUq32oXyD7nNIlH1RryjYuS0WW5GZerIj3xOiHkWoJ3965X8+q4C249zAWja+Cm39WM/fsiNldLq6cHYnh5M9qI16FQVxWKLDf0o/V3KzPzy76O8/M0ePl5+kpOn8hk6oAljb2gBahVJtw/g1O0DuGvwpyxZvBtBgKapIcaVPXjmTlmC9PVHOXz0Xdal56CPULN65yjgVubNXe+3qWSNQInRSmQNODzBosoVKM5nfaKqYM7SI3z652EMJitGk43S0jKKiysoVn6HMMFWayj3BLMLjF6Ul+wik2tZUelnnPlhFYfPltC9eRzJPtJ15eyDmvJ4ffUVCJlj7Vm0MtD1cF63AwtW0DwhDKU/lxdYtj2TkdM3QTlzskW9SBY8c6nv0kUe8He9/C0PJGgy4oOKD02r5pPo3+oGPv/DnQ1Sr14SpzLecUvgSUqK54b2CYzqXU+mMVt5VqCvyg+emWOzxs33W8JGzocGqcqC57Ls7GKSkqK8jK4vdTbwrSboKfu5ZtJAOj8/BE+IKzb5fF/ufnsdYSnxDLiiNS9M+hWHQ6ReQjgrN05yO9aVPV9j1DXNGXxpI0RR5FyBCa1Kwb/pOWQXmhjUNZUGiR7JHJ7vqIdjM/j1NazelUlO/nS33bp0fNklA9m8ybOYTHaUSgFRBI1KwZSrG3HvnZ29zjEU1HoFCmeO/MUAXwpcD13TnIeuaU5BqZnnv9zJvlOFXNquLRMHt0UV5Ix/QJTf6KToMK+XLSlW54qt/fr2z4ydvgFBENBplfzywuW09hAUkcd5awWVGVtnOrXJCuUTTE6jJQ9ZBMsHbX3PwIDxYbtDZMLnO0hKiiQhMZL0/Wc5lFHCpROW8f2z/ejcLC6o4wSDyuhbE4du5535XQGIi0ikY6NuXtuMHiRRpeQ889SUeJo1GsWWgmicesOVYduqQ+VGermbKLcv+KsX5lT0CwR/Nf48jW5CQgRHT7znM+OxXeNObNkv3e9A8wTRN35OsUE2QkQaefy4fB8Aa9YcdKUenzsnhd/k7f39+hWA9EyM/2wrizaeQaeT1NPUKgXTFx1kyZT+NKgXHXRST8/WCWw55K1+NqT7GN55MJ+M/FP0b30DG47+zb5DLwMw7N45fLczk3vvDOoQ1cb5jSjXAEwWO9lFJurFhaNSl3dfZkg9ZRxjI7R8MjYEqlJ5UkelCORFOhyU/r7GjW8cGRlGeFgc3/17milD3F84v5OFtQEnvai8n1ARToigImnA5TH6SF6pLnKLzRSWWpj5zh307tOMbp1fRaEQ0Iar+ezPw3wyJvD98veh8uSCByPd1yS6I2/cn0WJuYS7ez1CuEbnFkMFZxzVPQSzZv1T6PVavpxYEfZYOeEyn2E4Zz+2FNyL00g7WRWecKqABYsRH9hYMFmi6Mm93mCQm1tKz+6vsTf9VbKzi+nUfpJrYizXeIbISD0GQ5nbPtnZxTRv8jSAS51PJQwn77cRjPt0CxsP5HLk+FnX9qdOeVcgduLO66bx/ZO9AFizJ4tFG88w5ZWbGPFgP9c2Hdq8yNJtmYzyIScA3tKzAONubo1KIfDQzdPp0SqevtFKVFolN7Wws6VgKCnxiSze/BsKZcVHbN43DzH0mqmVXrOawn/K8O47Wci976yjoNRK9471+PnP8QAIBjMwx+c+8rhf0Hq0QQzHAw11fKGg+NOQtq8yKgkreMVsV1WtFJAXgvhgGc02Xl2wh53HCwnTKHllyu8kJUehKA9JKBSKoOK8/j5UwYQWPOGZLjtr3Hyv9FiVRvSrffHAO2pEi2RA9xpMjH33IWC513bSBJrvPgQSi/eEwWBGJYx0Yx740kNeMEmBSiO6ec7ySbWi0s94+aFDfLfma06dyqdpoyfdPNHjJyqMpzw5KikpyqfgzQe/pLNydxbFxYHlPeXcaJUsQddkLS9w2ybVbXuL1U5StPv9ENduq0ho8vGMq1UKxt/qru3sDJm1KU+O2n/nMRauclc+7906AaPZhs5HCaOaxgU1vKFm8Tz/+1HyikwUFpXw858VM7B6vdZVOcDTkMg9Iy9R81rE+vSKTKy2bRudl2NWt5pw9qK1rr8PbDqOrjxPPug4fiUfk7d/2McvGzO47oaOHP5tJ3m5pWRnlyAIUgquYLMx7uaq83lDLYvuK1TWQjOLAe9KE0QbJw1Ar9fQ5rm7MXjYk8pogp5werie3rRnPyrrt1PzuDI4K4HI47xRumg349o0qSUxETFc3tebzSBHTk6Jm/Ft1+Y5V+URkByaCZ/vwGK2UlJiIDY2ip5tklm6/rBXW0lJUW6x8lmPdkcfrqZ/h2Q6NIll8O2fUr9+NIuWPO7yrO948Q8y2iW5cdirOwp7a6G7TnF2djHjpq9i3PRVZP44jMToIBw0D6SvP3p+aq5VB1VRcM81TcdmL8RaPvNuMJhJTRpLsWGWlDlmMEteT215kzIE0qsFOHqulMaNUzlw+DXmzF5L986vsHVn9bL7agJe/fZINZbrmfrTuq0qDpwupt9lLXhv2mB2bD/JsWO5GAxGiosNpKYm8vB1LWiWGll5Qz5Q2fMUFiG6PMP0N79FtNpp06cZGT+muSZCPUMY8a1SaJwWA3irvcmNhz/pS1/wJ60Yqp5DZZmFzv6arTa3Y86bWFFbTKfV8cjVT5CesRtTB7trQu2NB6bx0tC3eHn+s65tc3JKOP71XzROjWLvR7e4lourt2B1iGw+mItaoyYlJQGFQsHtfRv4NLx7PviFLk/85vpdUGpiyZYMTFYHX47vSb3B8zhzVsrgdHrWKmE4abfPdbs/oU5Ce85VeL678vj9gInLGHpFM568rS2aIEZgVUkDP++GtzolMy5tcyUZBadJTk6gfasprFj7pNc2hjIrJ88WuvQI/ImZVxsBYp/p64+SYjFjtTq4dtB0Tp/KJy2mCV+MV/kszFgbEFdv8V052U+//XmLNUkjvLR9ElN/2k+3zq+Sl2fA4XCg04UTHi4ZhjB16AUHg32ePIfjzvNIvn0ANrG8CKpHqKTFsG+x/vOoV8kokDw3T4EkrTqMGaPnYLaaZct8e8a+WEG+EgLsDju5JdlEhEWi10a4jqHyQR1PjBtDWloC/258zo2zLg9jOEMPFUyIcKAnX4xXMaDrpdz8nLHcm9fz7s/u59di2LfSiNHD41yyOYMyi538/EL0eh26cA0dNO6TgE6ue4fxt4LM8PZ+chmCICAIAq98s9vntXKiWhPQHs+9uGITM38/yOfLj7FzzxS3TYuMdj5ZcpjFmzP4580r0fp5Ln29M+el2GWoqG6dolb12jHmmmfIKcqiXlx9fvbQ33B6v508VKVqnJ4VAM5zLFCN5t5+B9l1cgudG7TmsrZXAZUYMh/cxJDg8UIE+6AGc19CqRPnD6Ovb0lkuJo3vtuDyWQmLEyL2WxBo1EjiiKvLNhNu0bR9GiZUGP99oXWPZv61lc2Wb0q3RoMZmJ8JN6ohOGuyaUesd+4StVr1WEBvd9g68QBGFZ9zoRFRzmWZ0IhKLit51DaN+iMVh1Wzm6o+JhE6UcRExODYNHz6Tjf8Wg5RU36OLi//tLHKXAIJbfYTFyEBoVC4FS2gfTTRTgcDkRAqVSiUAhEaVXo9Rq/bAidTsOR41Pp2+sNzOaK+2C1i7RtkeYW1jAYzK4wYqAEqJDhcDDm+hbc2VdSlnMeIye7mN4936S4uAxEke/XnGTYFU0xW+1oVApXzb3q2rIqGd7q0MiqK4kXH5Ho0m3tGPE5RqOFKP0o1q2fXK12axLOc2ye0ormKa0CbiOvOFwVDdxgUW/IfNfQzTMxRD7M9Xd/aoI6qFAI3H9lU/7YfIaNB+zY7Q7y8gqJitKj1+uw2R18s+J40IZX3rfK+i2uaOGqmiwM7Om6Bp6qekmxOhc7wmCy+lXCA1g2qT/qMpvL6FbWRyeC/XDttig4lldGXl4Ren04f2z/yZUKK08pbt/2OYxGC0ZjNk8+OhmtUFGKSs6SkLMeUhLHM3KaxDn9/mUFYXqHzxT3Zf88w8czVnH2cCalFjvdxv5By7RIxt/SmrGfbMXuEBFFkWi9GogkWq/m47E9odT/JJvzOTx87C0a1JuAIAh8OPNuEhIiuGfIbH564SrJgVCr0MvCA8EoGIaKpJgwjv24mqZ3SFWJ+970ERaLhbIyEzHREeQUmXhw2gaW7zxHYrSWz8f3plNTScu5OrasSjXX4MInTkh9UWL951GEgT0xGMwcOS7RQeS1li52yD3JtpXUUQsVntUunHDj5ZYbYKfx7Z0sbbulYKhrWBpKsozP8IYHpo7sxr3vrONktpG4uGg0GmkbQVDw59ZMRmcUB1XOydmfA1tOuBIhFkxWYioVvJ9VDw/XWTJ850e3ulHoQBn0S60VBHZWYnRDfmdkE6SqtacREHA4HNLkI+WSh1YTI16qeHX37n/TdQ5Pf/I4s8bNZ9a4+bK4ts0ttgtSjFglDMcmzuWul8rlUw3uDIamjRry6Kj5ruKQnTtMAYONg2eKmTJ/N2UmC/n5hcTFxWC2q3lqcDvG3NgKhSiCItnn6TVt/BTHTrzntXztmsNERUkjhRh9eRzFIzxQWyPXJjEarH/9y5q92aREqMjX69DrdUSEqRBFkeU7z1FUVILdZuPJ2Vv5582rsDtEcoqz0Gsj0GkDV+vwhaAN78WSqebVj/LhdWmxmeTb+gMV4jC1StuqQTi/nMKbktHzNxQOFZU9qE7j40Sbfi1cL30b7G7CQcEimPBGg0Q9q98ZxCXj/iRLFCWjIkBJiQFbuJYR729g3XtXB31MZwkpkIbLofQ7VA51ZtaHLq/wp5d9FzkFKhTCLNCtf8ug25fj/pfvZNav+xGRtDAm3dORrtq5lIkicJ/f/Zw0Ms+49oLJSp/UMzmcWgsA0x75lBxjhXjQzj1TiAgfRXR0JMVlNhcbxWg0cC5nmms753snrtrC6XwjDW+TvMns7GJycyq0cDt3mILJZCY8PIyff9yGCIy/pTVtGp5/7ReVUsHATikM7JTCun3ZnMk1cnmHZOavOI6AiNFoQqVSkV9sobTMyn0L0ik270MU4bLWg7i87aDKDyI/XigbX0ijW5nnEIqa1sWKDVnSyySumwtU83qXx4sjgMKlKgwGM1H6Ua5yNiAZkcqK7dTWPRcEgT9eHch7P6Xzw7qTmC02SkoMqFRKTuUY2H+qiLZVfAH99jnY5JhyOJXh5KnIf7yn85I/9JRIvDz5O1dlE4DCnk2q7K0te+MKdhwtIDUujKYpEuPjz7/S3TzH1KSxru0l+U/nx6eiwsMlSd+yOftu5k1UYrMIfDBSCqEsmFzB9tDrtSQmRmK1CtRLSEOvjSA6shXyWLLVasPhEGmVFkm2MZycnAL/nbfZaBClIefnVSzblsm6zad4a1Rfin9fQ1aBiUiVgC48jMvaJzH9ke6Ea1WEaUKbYPVkFNTE89qvXZLr71v61Ofzv46Qmiq9KQ8Masbkr3aSb7DxwIN9+WvpPtYc+IudJ7fw8JVP+WvSC0FrNdiWj6l8o0rgK089GFws3nYwCHSO5wozWZ2+DNFhp1/rK6kfL+Wnm20mtKowV+AeQhyi+lAQ89RYALy0eKG8tLZW6WonVIEgTwSqRuwPd765ho3pua7zF0WRG3umMXP0JW7XJCCqoUcRCOnrj5JXanFxe31Rx+RVlTdOGoBOo3Q3vKHqbwQ6Fw+udvr+TP6vvTMPb6Jc2/hvsrRN0p02LZR93xcBWWQV9KgorqCiICqI+3Jcj6hH9KhH8SzCUQ+IWBAUgfOpCG4guywiIqgglE2Qli5AlyRtkzb5/khnOpOtSZs0Kea+rl6QzGTyZjLz5Hmf937uu1cPp0WP3E1BFEiSXjOqdv1g8iXrGNJ5lMKmPu/c7yxYP4dqu/M7v7L/BAa0d15DmhgHMZb/8sLXv2EyW9FqBD58cjg9brtEUueTN1UEMtOstjt8anr4gusCV6hKoScKzGz6KZ/WRgMje2Vwy2tb+emUiT17n+PVV75g/rzNVFc7w2heXm4dR3MiogNvUwq4Irx9xkpbBXO/epm0jDhiYjScOF7M5OF388n3H1BYUkBmSnMmXTSdRF2y4nX+nAM3IRsX4RIRngIv1M/uPZgoLKlg2KNfYamswmazERvrnMpPGN6aqwa1ZERPo/8BOEgIpBlDHngloSQ/at0BwyXoAhxf9g0db66t4cvXN6T3dXldlw5P0yVNxzVDZimOddZUxPHCw6QlZNA6TWllNDg1G0PHTPafKKFn22Rapuk9XndAyMt7dTEKQh03Nv+Uz5R/bCMlxcDZs05aZHW1c40p0VC3zyI0wPon1GiKQdcXzpqKMJWbeHX29bwx9yYqrBWs3bcadVwls/8xAZuqjA2/fOX2uh1np7Lj7NSASNriTZaZfj89uj7ptl1uMaTXxygtYsKA9KQ4vn5pDPo4DRqNhtJSE2q1wIotJ5jy+jZmr9wflnGJ577O/WaOZsfM0YoAK9aObWtnhJTOqItRfmd1LSpXlNuY+eyV/Ph7GRckKhkbqfFpXNBusMegC9DaaOCyAS1oWSO76li/U/GH3R72oCtuC/SeCQQjemXwt8vbYS4VHbwFDh97PaBuxogNvHL/qPMBqfFpxOvieeKxlTxw34foYuNAcNCyVQrjruxFZmYi5VZL3QfyAG+qYRaLlRMnzkq+eBaLlcNHZ5MuU68qNc9HuHiQ9BculJZX0dYYj1qtRq+PQ61Ws2ffc0ybPpzsdUfDMiZvvl6u2Ge6E32MmhN7ToR+UDI41u/EmBhH8ao72PuOd5cN7HZ2/OczWmc9wcMPLeO9d7fSJiMerVrw+Rnl2zwmQGKgbYSAK0djuzR7wq039mXF1B7c3C/Nq/i8L0S0SI4nrmtTRaw2jsnD72bT/rU4quzcOuxmyipKWb49m+5dnkOtUjNp2FX+Hcy1Biin3ciaMA4fe90tA+row9E4XFiy/hgzF/0IgN1uR6PRYLVW8cnHP/LjnhOkJDSOpZQcvny9PKGxr1XHJqUqV5/pta4Qgy7swrkzZVTY7BhqJAcGdU3jb1P68P6G46THx/DinYMkf0T5Z9xSeAv7fvue5jFbORuXzEVjg+eFd76hz/BO9BneCdvrG7h45Gvs/P5Zv18b0TVeORpL+7ehN0ygn/F08Slyz52kZWpbjEmZXvcbnJrtHJtLvU6k/ux9dyJ97lwO1LZn/vTLS6SlJ5IUP4Of3p1Ir5rtAA/c0I8XJvdFFRsjWdI7Nu3CVm5l77FzJOq0WI8X0HNYR78/S31x4UNfkHvGTFVVNWfOFNOsWTJZxgSKSipJTYzlrXsHMqRbXfyL0CKQTqWgLfLIvmvzup00v/pdAHKyb1Ko7Mn1qMHJ67107L9Y+sRFihX6urD/28M888Vxfvi9DK1GTXpSLF+8MJokg2drq3AgkPtLumcaAaUWK7fM2sAXu931KTwhojNeORpjehEOW6PM5Cwyk7P8f4FLHVYMsn1kQVW+wiwKn8iDLsCKrb8zblBrxvTNlLLlCms1E1/ezN5jxQDYq+2cnvUN4LQ1ats8NA7ShjgNAqDVakhIMBAbo2Vs30yev6U3sVq1JBsZTrj6evmT/Tb4etLW3p6GsYMkwXGNMNXrgujQoV159JHl6GI1dGoRmOBQs+5Z7J7/E//450T6D2jDqBGz+XZ/IVcMDOD6/IMiUR/DZ6/6zz2P2BpvOCAvykdkbbmGFmQ2V0rqU6Xm+W76qN5QYppHiWke8fGxqFQCZ8uUPf3Zy35k77FizpwpxmSycDq/SNrmyUsuWHjl9n7E62MQBIGkRANDuqfRs00yN/59K5fOXMdrK37BWhUZjTBiEPWn/tvQ60kY3p+CglKpRu9NE1jkG/8wfyLtkrQkO2y898hghc2Uw+Ggwuq7eSJRr0Ufp+HTT/bw7oKtAGT6o18dRcCIBl4PkC/sRUoAFrRq0DgzoKT4GW6CIXKBaTmhXr7dYIjFYIglIyMNY1IsY/rWljYObDuCyNgS1aJcEarzMahLM+4Z15kWzXT0bJNMj9bJPLN4L7sPFZGTa+LN1Yf498cHgv6+9UW3oR0UAbguNOR6cq3Rv3j3Qm66tCdvrznk9mPUq10K2X8eypLHL1KUZk4VmRn08Jd0mb6KUU98TX6x0vgVnB1o3x06w5SL23Fg30k+XvE9j9/QnQs6Bs+GKYpaNJlSQ2Mj0OliKAN0NeW0fvA6BBe6iryvvlf3v0jPFxaWkb+ipkSQfSPGFD2CjMkw69bejOmdQWrNopU4dlXS/bRJmwc4H+t0cRiTM5g09C4McXpgWUg+3/1v7WL1d6dwOBzkniln3/FiKiutUr1Xq9Xw7tdHGD+4pZtfXTgRaPkhkHUKc7kN1mxVPNej87PYcXaPbf65gN8LLbw0ta/XYzgcDv737QmeX7KPErOViopKjuTZeWTe93zw5DDFvk++t4flm38DoEurJD5+dQSGuMgMD75EkeT7RDKazOJauOGLVtNQiThvqLRVUGmr5NklD3Pk+D8wGhMV9t0ixHqfubK65l8bWdcvUm734LXmSgE6sO0IdoeD/zt8Mb8VHSVOq5NkCBvEq5YxLUSInXF2u4Nu96ymvLyC0lITCQmJqFQqHA4HFks5er0OQYC4OC0dM+NZM2t04O/fCPDVcBHwYptWg3aUu/daZmY6guAgL6+IxMR4OrZKZee/L/d6mA83HuOp936kU+cMcg7l43A4lcTUKhVbXr9Ucu89Z6qk732f8/QzVzB4cHvGX/kf3r7/woit7Qb1XAcZIXcZ/qPBkxtDqAKuJsZBtaOCB96YLj3Xu8fTnC78j2RzJNb79LtqxKNVKuLHOdkJ8QAsIj09QcqIHet3Im8bBWdbqbzFV/xMN3TaAJ2UWVpDLmJPcpeiQE9OvplDR2qFlVu1cNLdBAH0eh1VVdWo1Sqqqx0c/L2UNz87yIwrOqFRR1aVzJOIOdSvEcj1fP3l6at58aVr6d71WUxllSQnJxAXF1unlsXGnwoYMLAN//fJfdw1bTFffL6P/PwzNG+ezsZ9+Uwe4xQXitWqidGo+PmnU1Lra0IjalgHCm9Uv6bUdBUNvAHAtfwgf84X/LVzETHltWrMZjvTZaanrq2+Uk++B6sjMSgXFpZx/Fghbdt5p2LJaUglpnl0U6nAbldc1P5maZYBvaVsPDd/Do4tu8m6YRFVDu9ylwk6z5egWq2mosJKYeFZ0tKSUalUVFZaeW3lL5w8WsRtA71T7/wecwjgWn6o7zjkrb8rPtrF4cOFmGoWQ3W6OJISYsn+3CnKUrVxF+oqd12Nri0TeXP1IR7783I2bjiI3e4gMdGZ5YrdZwD6WA0v3daXmYt+ZNWne7lpZBuG9Qgvfc8feArAwf7eg2V75Ypo4K0HAuERQmB+WpoYz5UfUT8VatXyvcG0dof0/47tH6fKkc28L3KYZLWTeFktZ9cTkq56VxHkc/PnwIGDmEtrbb49tcAKIweCbNVdviiUaLiL3BVTnBZMNYFd2i+1NgD06z2Lywe04PphrTl0qpTZKw9gNKaiVqulmm9KSiJbjuvo0mGq188fTJ+4+iLg95XRBB0bd5Fut2P75h7KKmz8bclePtp8GIfDgSA49Xlt1bXXiWbUQN5+ZBF3j1PKT957ZWeKzVZ2bM9haNdmHD5VSrEpltsv7cio3kq93Ikj2nDVoCysVfaI4u36g1B8x65rNsG+nqKBNwTwVGfyNhX1BNEJQAyw7z59hmEZG+l3YU0P/c4fa42xZfVakY9bVGRSHO/O299jw/qDvLXqV5Y+UUzPNsnSNleDR1e0yHiQEtM8hf1NoKI6FosVqr20ltaMu8JazbevXIwuVsOBbUfISFIxG2fmCxAToyUlJZG4uFhaNmsLQGFpPodP/0qCLpEuzXugrTEiC6ZPXGPBtV1bFJxJiFHzytR+fPF9LsUmK8XFpRgMelypza8s/4Ux/TLp1KJ2ETVWq2bWrX0A+O5gEU8u3ENcjJqU+BiPrBVdrAZd4zcJRhTqqh8H63qKBt4go64pjz/Zr8VilcoFv588Q7zQiTg5daiOvnh5+yjAyZPnaN8hneoqO3M++ZX5Dw2WaruGOA22b+4BwLxpl1tJQ2zQKDHNo0PbRxVBXd4xdeoTGxlXj1Bk46Yvt0kOvsnjF3Jq+RRFx5UccTFqxUU/a4MzgAiCgNlsIS4ulri4WHq07MuYXpeTV3yKd9b9i2p7dQ39TcX1g26hZ6t+0jGacsu5JM+5bjsqlcAl/ZqzfPNxyssriY2NQadR0aXjTM6dK8Fud6DXGzhbaoUW7seyVtm581/bOVtWgdVaxfNL99GnfUqUKuaCusqHwbyeImuFoglDJNTLOZ7e4GufKqvAhreSMBoTMRoT+fXjhrfsHjp4mmnTh6NWC9hrSCzJ4xdKf/uPnWXJuiPsPXKW4lV3kLP4ZsAZdPMK5kq8YddMWo5Ok5yuDyJXWP/9PoxJcQqfLH/cKXacncr2M7fx88ndJCY59WJLS82YTBYEQeCqATegVcfw02+7qbbbEQSBkpIyLJZyPvnuQ6rtyiaBvgkLqbYHLmLS2DB9uU3RGOOKOy7tgC5WQ/Pm6eh0cdw/vgs9WiYQF6dHrzfQJSuBvh1SpP0LzpWjvWQe2kvmcfqshdLyKsrKLJSWOr/DE4XePdH+yPBLjS4Ii+nRjLeBCAV9xXROxcKHvf8mOhwOXluxn/fXHyU9KY45dw+gV7sUr/vrYtQ88dhKEvRaZj821G37NS9uotLmzKKfm9SLOy/vLDnEegwENRoC8UB6+goKC8uwWKxuDiDmchvmCpv76/2Aw+GgVetm/LzvdzIymiEIAg6HA43amYHHxyVKDR+VlVYEQaDKXkW1vRq1So3dYWfr3pd4PucciXotb9w9gG71Gkno4aq1UGKah8EQi2PLbum5Hm2S+fqlMWw/UEinVskM6NSMmy9uz5rtJ6my2xk3MEthQy7/kUuNj2Fg51S+PwTgIF6nCbv2xR8d0cDbAISLvvLV7jzeWnMIk8lCsamC6W/sYPFjFwHQKUvZn7/3nRtIMMRyJNdEr3YpNEt0FvHktd04fQzHDjglDed/mUNFNdxfM9V11Rg9tXyK4nFewVyWPL2Uo3kmvjtYxIVdnA7BrsFEnvnWBUEQGNX9cr7et0rRRWdMzESrrrFU73gRRwtyyMnbj9HYDIABHYYSo4lhcGo2Gw8Xsz7nHM8+dyUbNvzKowt+4Ic5lyMIAvnnynli4R6OnDZxSd9MZt7Ukz2Hz/Lfz3OwVtkxl9vITNXx8DXdJAWvUEEumC6HY+MucGEqtM2Ip21GvCRArgOu18rcHrzoKQuCwKJHL+L99Ucps1QxYXhrMpK9W9BHEXo0qcBb326UYPNsw80X/L3IqdtbVuZUv89Tq7lkprNTbcKw1op9+0xfKf1/x8zRFMSo6Ta0A2lJcXz418tY+NUR1u6oVVTasGOmW7AtXj3N+R+73SOj4elFexFw8O7aI3z49EiG3jtOkQ2D/zZAVdVV/FZ0hFZpbZkx9lG+O7yVvJKTpMVnMO6CG6T9tGottw6fjsVq5sjpQ+hi9NzSbRuCkO18v6wUVKqTXDW+D8XFFnZsO4LdAWoBnsr+kf2nLVx+RR+yF2/nTFklq3b8jthKJPYUff1DHlte/xPNU0OjV+At6ALe6/g+xOrlC3TFq23SMcRzf/cV9TPdbGw0pAu0qdTxm0TgbUig85fGFcg46juWYGFM30xm/+8XWjRPw4GA3e7g9OkCAJZt8r7wtuvcLU6/sG3ZLNyZx/IfC0lK8hxU2rd5DK02lh3/uoxkiWtbM5WVmUaOeOIrcnOd752Z0Yyvf8hFLGbkFcxFI0x1y5K9wVplZ+GGueSeOwnAwA5DuXrgjT5fo48x0Kt1v5rvRpC+l2bFFfzns0NcOMBpTX7HpR0kb6+jp01c+qeezHpxPOu/OcC6H0/jcIDZbMFiqSA9PRWHw4Gt2sF3B4u4ekgrv8YfKDwF3VP/u81J9QvQ9NEVBkOsW8bcFNCQpqSmxGKJ6MAbjEAXCI0rlOMIJtplxrN61mhW7zxFWbmNd744LG3Lzy9i0xvX0qddCr/uPEa5tVoyaqy0VRKrjWPH2alsOvoXJk8ZwqwXxzOg34t8u8Op9VCb7apQ2auhuhrXy8RbpmZ3wD8/3MXzC6Z7bG2uCz/8biL33EnOnClGq9Ww68g2RvW4DENsvNfXePtRNibH8fkLo9mw9zRpibEK3uql/TJ5Z8kONq7/ld9PFZOWFEt5ZTUqlUqir4lo3zwwaUV/UXCuXPH41PLJGFO828UrXltQ6u6rBji27EYY3h8AYdRAqTNRLPnk5s8h/ecDjeoW4S+C0QXalFgsERt4gz2dD0TQJJTjCBY6tUjkkWsT2fJzPvM/V4ovJxliOLHnBPoYNfutdwDOwPvqJ09JLcSfjunI+m9+JTlFz48/Pa94/dgRr3LihDOLTb8224236216XFBwBoAE/XQemnCBYn9/uL8xGmdGqtGoawKggErwnPn582OYlhjLhOFt3J5/amJPWqcbOJJnYsykHpw6Y3FyXONi0enipFLDPVd2olfb5DrHHQjMNdKMnaYuQ6+PwWKxBhR0sdu9+6q5uEIXlFRIdD5wcrJF6mCkIBBTUX8hb++PtPtWRMTSyULluRaInmooxyGOpa5x1LW9a6skDHEajMZUMoypdGmfSduM2gxxymu19KrCwjL2/3IKgE+/uY1mhkw+fP97xfEc67bzyePeW3xFpKcnUOXIpsQ0j+LV0zi1fLK0rbzcxt8X76zzGCIO/fg7wtgh3Dr/Hi7o2J+kpAQMBh1/6jMeXYx7KUT+Y1ifG0utEpg8pj3P39qb4T2NXDOkFVq1wMAL2zJhQn8EQeDtBy7kqQk9Az52XYi/YhjxVwxT6Cgb4jzXv83lNokS5pohe4PZXCnp98qDbiRCnuUGex2mIU43/saFhsikRrw6WSin+WGxc/ExDtex+Jtt/3D4LG+tPohareKRa7oqpBOFsUPY/8spevecKT0nUsUA3nvcxu2za2/8/S8swWKtZvBLGwDcmh7EMoP8GN5s40UM79+B9X8f63HbgW1H6P5crT36osdV/JZ3kheWOsc7994Fzro0Ps6HTP1McrsNEB9tPs7MRXuxVdm5dmgr/jm9f3CdL2q0lF2Fikyfbfa68OjKDBFnDb6s47WX1DawiBm1iFMrb8OYFH42Q6jEpVxRX+ufhsSF80adLJTtnw2xc1G8PkjjkC8EBnL8CzqmsuDhIdKKt7ncRvKVCwDIze9BWrr3OuXE5+0sfqJ2Ol9ldU7T9s1yBkrXTjN/miDkaNEinVG93X2/5Bd3d2qnyIIgSEFXhOs5cTgcfJ9zljOllVzUI53EsbUZekFxOVnXO/f31SnnihtHtGXcwCzKrdWkBzk4mSurEYY4Sy8G+fNfbQ/I+l0YO8TpLFxjHe8Len0Mpeb5Eg87738bwh50Q1FWCAUaEhd6ec4v3BDxGa8rQq1CBIH90oVKoKM+IiuSMaLLwtbho7Mld+HDR2fTtl06men3Y7FYySuYy0czDR4PqfiMNUFdFNFp1szAmTPO7iedTku5TF5y/b+uYefBM2w5UMSqjU8CtQpans6zXBioyipw1xu1GfCOmaPR11DgRLy28hfe/OwQAG0z49m8+zlpm2v2HaiuRLDhmrVWObLdOLryc+L6vZvLbdL3ajDE1pnRu+4v4qPnljFxhHu9uzEQroAbDLPLQMc+/d++WTgiIj7jdYUnXdxgoD523qFSwQp2MBcVyhybdsGRw+xe/CVHjv8DgE9f8b6oI37GX3cdp9tfnG3EpeZBaISpUtAFOLzoJgxxWgw6La//bz+3zt4GgEGmcqUZNZD9LyyRjitHlVU5pZ977wIGpiwFoP8oJfe0qtrOvM9zmH7XcK68qg/jr5zLkuc/4tbn/bvgIwkep7QuK/IGndbNecQrtBrix3quzxvCpDjWWGWFUCHQuOAvmlzGK0eos04If/3Xb6hUFPbsRvs2fyYlNZ683GLF5ipHNmZzpcS/Nei0fn9GTYxDsUjn2LgL7ehahwSxzmiprKL7jM+YftcIvt16mFatU5m/oJbDu/gJtVuQdUVd59Jud9D7vjX0H9SeD5ZukZ6XXDjKlS3KgUzlQwGFkNDK2zCm6DmwtZaF4uncu50D1xq2WuWxpi14CboA1rXb0TaiWXMklBVCYe9e1z1z3ma8coSStydXEavrwokIGUIZzcg16B4+Otut/FC86g66De3A7o2H6B3/LgD7THf69VbCqIEKoW4RKkFArRIoLS2neYsktm7J8XwAD/D3x0ulEnhlal8emedZTzjcgdYVogMwOG/aMzXPB2oPL9fBcJWQ9AdatarR+LuRlOWGYl2oIT0BIpp04BURyvJDIHSRSCNwi8wDx8ZdmPd7Vr0S2QsAO2aCPkbtsRQglglEBoLRmEiVI5v8Fd9IwS4uRs0zN/Vi1ge7qKqyk59fhEaYKom+eEOgM5erBrVkUJdmZE1wLvT52xkXTtQnGPljkCnW3HMW30T6mq0Qq6HTpKUSXzscCET4P5SIlLjgCU261OAJwZ7213fM4Sg//Naho9simrzLSQ6xPCCnHxWvuoMTe5xiOa6eYVDzOfRxCEOdmrfNjQ9QWFjmtoCVX1xBywm1HFLxvVyDjz/nyBd1qimgoVNuj9Nll4VOOVJT9Zw9a5Ee5+bPIX3fLwG/b7AQKdlvY8WFP0SpwRMiYtrvYRyBoj7jbtsuXcGvBejY7jFJzHzvf69n6KOraw0wN+1yc6DoNrILwsiBdKeKA698iMPmMhZLBfkrviFr4vtex+FN+co1ExKf84VA6WuhtPypb5YT9KBjdyqoeeJOp6YaFIHXaEwknGrErtSsQBDM8xYpcUHEeRd4RYSSdRDoOAJFfS8Ox6Zdbg61YncUgOnzrYopqDByIMZ12xUZq/z1XQe1d9YFXRZ35J1W3qb5chlIeZYajO9BsWC1fAoHT5Wyfm8+GdU2BrSKRxAEdm885MaIqC/CtVCkiXEgaNVuPnXesPedG0gfP0IxwzF9vQNDBPSn1ut7D7C93x9ESlw4bwMvhLbpIZSod63YVuVchJFxeuXw1ppaF1yDuXzByBuCVRLwFsBFZE1cTIsWRux2OyqVSlJKA9gBbhzgQBHOqbKTSeKk8dXF3xW/D8GY6DQoBQZc8FenfkNsw5TOwoVQ1YojIS6c14FXRKRNM/xFvX+dfdygiYa7pP/nvH8zBq0aQ6JOCq4HP/yGTkaDU3y8jixLTt0yV1SRNXGx1DEFNU7GMuEW+f7+BmZ/9rNarVgsFul9xdrzrnO3MDJjWb1urkipTXqDQaf1KC7vWL8TR2kFnW5Z6ixF2O1Icp5NEMFQF/SGcMaFCJiENB5CKXgTKtRXQERu2ZP/ySZMn22m4IyJ7W9cjcVixWKxknX9IpLHL8QyoLe07/hn1/Pw29/hqJbxdtfvlP7kwVju2+apFivPlMXygPjXEIhBZ8fM0VzUsxVFRcWK7fJySiQETk2MQ/rzF4NTszn4+gqf+xh0WulPgt2OMT6Gkk9vx7Z2RpNbjPQGubhVsFHfuNCQsfwhMl6IXHnHUEEvs4A3qAWSxy+UstGqaeOkrNAVpaUmPtluY9plMknEBvA/RdaEXL3Mb8jdFlzGYNBp6T+qMw+dq+Dbn0+6vfTfd89jhPFDyTaoWbcW0lj8YUcEi68JSoW4QJpIOvdt6eZj90dEKGvs9Y0L9ZWZFXHeB96I6CoLB+oIlqI7hCssFitJSbWcW190LldGhCsy0u6rPa7M9NJf3q28Tu2txnnttb15sKCCOSv3kGi4C70+joSEeKqsVfw3TsPLt/fjqkEtFbQ5f9HQmytQ/GGvVS9ojIALDTvX7kydINPJmlJtVESkZLnhJpJ7g2jfLjY3jB4xm8zMVC7pY6RnG6e0pLfAaq6slrad/GgyCbKALGZpcj0H1CqK10yD6hrfNo0GUSLRtRYcKOas3AMglVCKikqlbdc9k8uB7JsU+yePXxgQJzjQRR55i/UHz6j54Bk1k/5W7XX/xpAcDSW9Ltwt+4EgFOdaXof2FwFlvE2FGRBpATeY09b6QFqIUStL+np9DEnxMyTu74bNzuYL+zc7pCm6G2qoZfGAXr8Yi8VKqxvfp/jLGcT/yakVkP/JJrKufU/xMuPVIzEYYtEIUylePU0h5iKMHOhxSu2JHlcfdJu6jOJVd9SrtiwuCLbu11pqAgnke5z0t2oWPqxh4cOeb7XGUNuTPw5W80Cojx2K+yTUcSGQ4/odeJsCMyBSpmqextHY01ZXGHRaNxGVI8f/QWb6/eT/3wYyrhstLcg5KqqIHzcMgBJTX6eMYY3DsLdAKAyrtfrJuGYker1zVT1n6SQp6IIz2IvH9goZHc6xbQ/C0H4IFw9yLzfU7Jeb34MWGQ+6CX+7fn5fqKq2s2jdUY7klTGmb3PG9M0EcLOol3+PFms1u87dAiCJtfuLcAg8BYM+VdexG3pcT8duKCIlLsgRcI030vQIILJObF03VKT0sQOSaE7W9YtIS/sfRUUmaVuJaSAGQ6wzYNYESlHZTERewVzpGPLMWY4+01dSOulSwEnzcoVjx16wVHgdo9ie7AuibkTXTk9z+HCu2/ZTy6corHNyFt/sFohfWvYz2euO0qZ1Ku9/c4x5D1zIyF4Zin2OnDYxc/Fefiswc9XALF5buhNwal28Pv1NEvXO8kyVVVCIy8sRDicT1+fqEyTrykQbEheaUlkhWGjydLKG+m/5QqTQzoJFoXFs8qzoBSiCLjgda+uCq/CNp8BqsVglDzBPLAphcJ+gqWZNu2uE4vG2N2/AtnYGxhSdolbdacqHoFXmHN8ePMvxk6+y6dsnqa6u4OqZa9xKE82vHsbqLX/htmnDWbLhmM+xVFkF6U9EKK/Vpo5QJCCRtqYiR8AZb6TVTyG8XmyuqKvpoT46v0H7fLYqTJ9t9ljr1Om0CIKAw+GgvNyGuawcPttM/FW1wcxcYcO70brTTNMTUyJg2O212bW8XdY1QNvtHFyyjqtnbWDkqK4cO1rbtfbDgon0apPi9S1c68odmtd+MpHx4eqs0SLjQUpM83jwoTG8n72NXPfk2iMa656pq9mgIfdMXaWySIkLroiUFmFX+B14IyVtD+dUzV/4EsiJNGH1UytvI+P60dJjMXCKIji2b2qz2uRxC2jd5mOO1rhXeD3m8ske25MNOq0i0xRrxx7hLdi6oHOmgZdu7c28Lw8Tb4hh839uoHe7ZAwxyqm+nPomttTK8cLk3orHIuNDrmEsYtjgVygrs/L0zbNonpIFeK7xhuue8SVM09BxeBI6CtaxQ4VIXJ8KKOMN94AjxW/NX7jKH4bby80Tsm5YRIlpqHe9XJfAV+RSLhDruvKGDNEGSIKsEUKxOGe3B6XMcN1FrfnTwCzir6hdtDN/tR2H1ZmtGnRamiXFKWrQ/Xo/z+KHBtGzTTIAFrOV+U8uZc9vJby97F6fera9sy6iba/utEhp6XWfSMgA5bqxobCmipQsUv4j4I/AfKjWp847s8tIsfgJJRrzRpU3RchRYpqH2VypULeybbxPCpb5/7eRPjNWcrrQaWFt3rQbw8j+0r6iWLqgVTuVzWrgzTEhYCt2Odthy26E4c73dmzahdlcqQi8UJu9F6+6A2u1nSGPreXvr93A6NFd6Nn9r7x6R1+uHtyKMyYr457bgNXu4NCRlxXHkLdeGwyxdXaeRULAbWoIVlwIl12XPHHr9dwXfr0mojvXmkJZoaEIx3TUmKLz2HXmaVotz1CNyTryPqpt/ZUHXXCeRzd/NhcmRLC4uWLQlcb4+Vaf+ycbYuiYGc+zMz8mJVnP6dOF3PbyWgDmPDSKcms1P+z7q9vr5k6fjzr+RlJ1zb1zm4mcUtwfAd7OdSCUzWCUHzzFkF5+vjZiA29TKyvUB+HMjowpOmxrZyhaaXMW30R6st6ZWY4a6DEQu8IbbUrErzuP0k3MUms61Dw1S/hULhNLFSrvJJwyk5URvWdJwbNnt2cV2wVBYPGjQ3hz9SFKLTa276jdlpESh63KzttvbeTQwdMszL5d2mY0PuLz80E0y21M+HOuA2lYqm/5oaEz5YgNvBBZbIVQorEL/mKQM1fYOPzRZNJreLrNjQ9QsmY6AKKHgSgjWfLZnWC3k/NLHp0vdm5bPkvlc9r9wTNq+sZU+yX04tqoYNBppUDrWqpwbNxF0rh3pMf7Fkyk4yRnmcNsrsRgiMVms7N17vUM6prm3EmlIjVJx7O39AHg8eu6SRn/pf2ac+elHXjvnS20zkyoc6zeECkLN+cz5CwFb+e6PjRQf/zt5GhoN2pEB95gIZKyXDnCJcgsD3LyBSe9PgZh1EDat/kzR38bSIlpXm2DQ00ttvND10n7V5jdg26VVVC2x6bW/tfhcPD2mkMs23SclmkGXp3en1ZpBs+D9CLmLsJisUpqa3IKm1iT7ZKVQOeWtUHU9VhZwlROLZ+CMUUHwKPXdePR67opsmrHpl0MTj0IBDZthWj2G0r4oog1ZnLVkGao8zrwRmrAdUWk0F3ERbOf9r8C1DRIjLkwaNKEX+3O49UV+7FYKigotdJ64sUcP1YoGXT6DZXKY5ccoFgYNG7+VRFcXZE1cbHk3KDMuO1SuSOQmytSvsc/ArxRNhv7PnflTodEnUz+RpGO+q5w+vsafxHIsUNJd5FfnBseH8Ho2ZsByEy/Xwq4IpobH1B4tclx8PUVdHlsQr3GkJNbhgAUF5eS2dyZjboGXdvaGQqPN6ipDVcrNRrkyM2fQ8d2jymeEzUbsiYu5tTyKfQ1PiBRxDx12PmC+81V9/cYzX4bB/IAHM7kKtDvOCCRnKZwMTWUUhIsHQVfx/an4B+sc+0pGxicms2+WWPp/dd1bqIy7dv8WfGca+twtaXSq9JWXRjR08g//28/LZqn8fP+lzzu89TCPbz6wb21719DOVMsvrlwjvXf73P7oZCXH8RarmtXndw6py5tYQjse4yWHxoXkTyj9YSA7qBInkoFOt3wtjraUI8nX7SicNFdXN+n9vE6SUuhxDQPgyEWi8XK3vdk+rUN0Ml1RZ/2KSx7ajif7jiJ2VzpxpoY3q8NH2w4yqsur5O7Css93cDZKJE8bgFVjjoUzzzAYIiVatciy8MfRMsPUTQU9RLJkXsU+buCWJ+VxkCP7a8/2eDU7DqFSuQeT/6udvorgiI/dl0QP1Og508kpfs6H3PvXcCuVy+Xgi5A3keT6TH1Mp9j9zbuSluF9AeeP9+grmm8PLUfPbr9RfF8iWkeW/b8RklpqdtrfEHsTvNVPji1fDLFq+5Q2A95ahsOBPLv2J9rpCn6/UUROtR7cc3fqVR9C9+B0EZCNc3wt/xQH/K8vJ0zFOg2tEOdmfXIjGVQAfrtP+C/DaMTruej0lbBA29Nk7bvmzW2dhyymq3I5d3w98vpdMvSOt/HbK7ELLMNynl/kmK7mAnLBXqqHNkcPjpbqh+LLcwGnVbRiRfoZ/YEf2dIUa5v5GPH2amNJnfrd8vwOw9/5HO7t/Y9aHhgDPaxxYw3ULgG+oZ2KwXSKtnQMYP7uL0eTx4ofbT1yo+9Kf8mReCVT9tdBdhFlkTBOYuizTcpfoZbKUHkEeeuqPFpq7aDWoUhTkvSVe96FD5PS4uXZC71+hhyV0ypFe0JkgSlJ/g61xANut5Q35bhUKEh35lm7H/q3okAAu9PL1we8IKVv/s3NvOgvkEM3KeKDV34CnXglb+XHMFmTFis1Qx+ySkKfsXwLhw9bWZEj3Ren3YB+nHDFfuLgddcbqPFTUuk50vN8+nScSbFxaU4HFBRUel10cyXlY+c5eD6eldqXCjqrqE816FGOOrQjR146xtz/EFItBoCasHz41iu//eLahVmNKWbSI5Qjls8tm1UZ2bM3cnu30qZOm048/67ibfX5DBDEGgxwckYyHl/EsbEWlaCxWIlLS2eIzVSkwcPv0TnDk9RVFRGQkKiz/ctXnWH1N4M0LHdY5jNlRiNiV7pcCLkwTHYrIOmeI2E8nxEChoj5gRdqyGQFfm64GmqGyl2OFE0DKfOlHPhoPb8+bFL+OrLnzl2upTkcQsASE9PIOO6URQUlOLYtkdiTBQVmUiKnyEt8m3d/jQtMh6ktNQstQADtGvzZ+l9zBU2jCk1uhLiwmDBXLp0eNq5XcaayM2fg9GYiGPTLq9lqj8y68DTWsn5RoOLtJgTMKuhPqv9IuSv8US1CmS1P4rIxPhBWaxZvY++PWdx6FA+lw/IkrblFcyVZCezrn1PElt3hbz7LCl+htQGfMbFnshcblPwewEGdzfSvu2jCjnHFhkPohGmcmBTbfuvN4pdIEydpg7xs3o7H+cDE0OMOZ6YRuGMOfViNQTKdQ2kWB3MzLqusYQT9aXXRXr2Mf2yjrRM03PgZAnDuhvp2cZpAKnXx3jcX84+yEy/X2G144pS83yJNpYxYQzgpJHlvFeraJb90CAsQ+7xqKzmb5ksUq6RUMLf688fdlGkwt/vsaGCN/VBUITQfdG6GkKjCSUzIlwIBiMDwv85AoG53CZ5t7k2Tsg5xN782uT7eILps80KKUnLkAvcAu/LU/9JWpLRr/E2dCGzKSFU926gYwhlwPP1OYJNSZ3+7yBrNfiCp06eYNBogtHGGyl0nmD6uTW1+ps8KBoMsej1MVgsVp8B1ZsITqB44Y5ZZCZE/jkKF0J170YSPN0z4RbQCrr1j/wDhZqm4y/CffHURz8iVHQXCM/5sAy5QAqyiYa7FIF30IC/ce6cBbPZSlZWMsXnzNx8cXuen9S71mVY/q9aJTlQmL/ajl6mxX5g2xEErZpd524F8KkX7A2NnfFGyo9oKO/dut43GIv1oaC7BopGzXjlaAzaUlNBQxTSQkV3CVe2bDDEohGmkps/x63pobi4nIqKKvRxGtJ1Ki7u2orHr+nqZoZZUFpBp1uWSkG7ufEBLBYrtrUzFEFje/5kmgoU10gjdU15Q1O7vxrrngkFzms93nAhWII9oaC7hEu0xbFpl2SmqdfHoNfHSFSxxFg1Qzqn8q+7+pMc76H0UCOKngGUmke61YIj1VnEFzyNuSmWkcKFxrxnQoFGdRn+I6A+WW5dN1goA0vYFuvkmrp1tfG6uFGIamrNjQ+w5r7B5FjvCurQQllq8PdH+Xyrs/pCoB2cInydl3D9GPtbavA78EYRRRRRRBEc1EsWMooooogiivojGnijiCKKKBoZ0cAbRRRRRNHIiAbeKKKIIopGRjTwRhFFFFE0MqKBN4ooooiikRENvFFEEUUUjYxo4I0iiiiiaGREA28UUUQRRSPj/wHvA24V3G4BNAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 354.331x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boundaries_on_embedding(reducer, gb, embedding=embedding,\n",
    "                       cmap=\"inferno\",\n",
    "                       n_pts=30,\n",
    "                       title=\"Gradient boosting on PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2",
   "language": "python",
   "name": "dm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
